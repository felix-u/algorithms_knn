cs.AI:Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem. In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty. The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.
cs.AI:Market price systems constitute a well-understood class of mechanisms that under certain conditions provide effective decentralization of decision making with minimal communication overhead. In a market-oriented programming approach to distributed problem solving, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy. WALRAS provides basic constructs for defining computational market structures, and protocols for deriving their corresponding price equilibria. In a particular realization of this approach for a form of multicommodity flow problem, we see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation, and that the behavior of the system can be meaningfully analyzed in economic terms.
cs.AI:We describe an extensive study of search in GSAT, an approximation procedure for propositional satisfiability. GSAT performs greedy hill-climbing on the number of satisfied clauses in a truth assignment. Our experiments provide a more complete picture of GSAT's search than previous accounts. We describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search. We demonstrate that when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate. Our results allow us to make detailed numerical conjectures about the length of the hill-climbing phase, the average gradient of this phase, and to conjecture that both the average score and average branching rate decay exponentially during plateau search. We end by showing how these results can be used to direct future theoretical analysis. This work provides a case study of how computer experiments can be used to improve understanding of the theoretical properties of algorithms.
cs.AI:As real logic programmers normally use cut (!), an effective learning procedure for logic programs should be able to deal with it. Because the cut predicate has only a procedural meaning, clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems. On the other hand, searching a space of possible programs (instead of a space of independent clauses) is unfeasible. An alternative solution is to generate first a candidate base program which covers the positive examples, and then make it consistent by inserting cut where appropriate. The problem of learning programs with cut has not been investigated before and this seems to be a natural and reasonable approach. We generalize this scheme and investigate the difficulties that arise. Some of the major shortcomings are actually caused, in general, by the need for intensional evaluation. As a conclusion, the analysis of this paper suggests, on precise and technical grounds, that learning cut is difficult, and current induction techniques should probably be restricted to purely declarative logic languages.
cs.AI:To support the goal of allowing users to record and retrieve information, this paper describes an interactive note-taking system for pen-based computers with two distinctive features. First, it actively predicts what the user is going to write. Second, it automatically constructs a custom, button-box user interface on request. The system is an example of a learning-apprentice software- agent. A machine learning component characterizes the syntax and semantics of the user's information. A performance system uses this learned information to generate completion strings and construct a user interface. Description of Online Appendix: People like to record information. Doing this on paper is initially efficient, but lacks flexibility. Recording information on a computer is less efficient but more powerful. In our new note taking softwre, the user records information directly on a computer. Behind the interface, an agent acts for the user. To help, it provides defaults and constructs a custom user interface. The demonstration is a QuickTime movie of the note taking agent in action. The file is a binhexed self-extracting archive. Macintosh utilities for binhex are available from mac.archive.umich.edu. QuickTime is available from ftp.apple.com in the dts/mac/sys.soft/quicktime.
cs.AI:Terminological knowledge representation systems (TKRSs) are tools for designing and using knowledge bases that make use of terminological languages (or concept languages). We analyze from a theoretical point of view a TKRS whose capabilities go beyond the ones of presently available TKRSs. The new features studied, often required in practical applications, can be summarized in three main points. First, we consider a highly expressive terminological language, called ALCNR, including general complements of concepts, number restrictions and role conjunction. Second, we allow to express inclusion statements between general concepts, and terminological cycles as a particular case. Third, we prove the decidability of a number of desirable TKRS-deduction services (like satisfiability, subsumption and instance checking) through a sound, complete and terminating calculus for reasoning in ALCNR-knowledge bases. Our calculus extends the general technique of constraint systems. As a byproduct of the proof, we get also the result that inclusion statements in ALCNR can be simulated by terminological cycles, if descriptive semantics is adopted.
cs.AI:A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments. We introduce the notion of teleo-reactive (T-R) programs whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based. In addition to continuous feedback, T-R programs support parameter binding and recursion. A primary difference between T-R programs and many other circuit-based systems is that the circuitry of T-R programs is more compact; it is constructed at run time and thus does not have to anticipate all the contingencies that might arise over all possible runs. In addition, T-R programs are intuitive and easy to write and are written in a form that is compatible with automatic planning and learning methods. We briefly describe some experimental applications of T-R programs in the control of simulated and actual mobile robots.
cs.AI:Learning the past tense of English verbs - a seemingly minor aspect of language acquisition - has generated heated debates since 1986, and has become a landmark task for testing the adequacy of cognitive modeling. Several artificial neural networks (ANNs) have been implemented, and a challenge for better symbolic models has been posed. In this paper, we present a general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree learning algorithm ID3. We conduct extensive head-to-head comparisons on the generalization ability between ANN models and the SPA under different representations. We conclude that the SPA generalizes the past tense of unseen verbs better than ANN models by a wide margin, and we offer insights as to why this should be the case. We also discuss a new default strategy for decision-tree learning algorithms.
cs.AI:The ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data. We describe a new version of our SUBDUE substructure discovery system based on the minimum description length principle. The SUBDUE system discovers substructures that compress the original data and represent structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of SUBDUE produce a hierarchical description of the structural regularities in the data. SUBDUE uses a computationally-bounded inexact graph match that identifies similar, but not identical, instances of a substructure and finds an approximate measure of closeness of two substructures when under computational constraints. In addition to the minimum description length principle, other background knowledge can be used by SUBDUE to guide the search towards more appropriate substructures. Experiments in a variety of domains demonstrate SUBDUE's ability to find substructures capable of compressing the original data and to discover structural concepts important to the domain. Description of Online Appendix: This is a compressed tar file containing the SUBDUE discovery system, written in C. The program accepts as input databases represented in graph form, and will output discovered substructures with their corresponding value.
cs.AI:The theory revision problem is the problem of how best to go about revising a deficient domain theory using information contained in examples that expose inaccuracies. In this paper we present our approach to the theory revision problem for propositional domain theories. The approach described here, called PTR, uses probabilities associated with domain theory elements to numerically track the ``flow'' of proof through the theory. This allows us to measure the precise role of a clause or literal in allowing or preventing a (desired or undesired) derivation for a given example. This information is used to efficiently locate and repair flawed elements of the theory. PTR is proved to converge to a theory which correctly classifies all examples, and shown experimentally to be fast and accurate even for deep theories.
cs.AI:We report on a series of experiments in which all decision trees consistent with the training data are constructed. These experiments were run to gain an understanding of the properties of the set of consistent decision trees and the factors that affect the accuracy of individual trees. In particular, we investigated the relationship between the size of a decision tree consistent with some training data and the accuracy of the tree on test data. The experiments were performed on a massively parallel Maspar computer. The results of the experiments on several artificial and two real world problems indicate that, for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.
cs.AI:This paper analyzes the correctness of the subsumption algorithm used in CLASSIC, a description logic-based knowledge representation system that is being used in practical applications. In order to deal efficiently with individuals in CLASSIC descriptions, the developers have had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics. We provide a variant semantics for descriptions with respect to which the current implementation is complete, and which can be independently motivated. The soundness and completeness of the polynomial-time subsumption algorithm is established using description graphs, which are an abstracted version of the implementation structures used in CLASSIC, and are of independent interest.
cs.AI:In this paper we describe how to modify GSAT so that it can be applied to non-clausal formulas. The idea is to use a particular ``score'' function which gives the number of clauses of the CNF conversion of a formula which are false under a given truth assignment. Its value is computed in linear time, without constructing the CNF conversion itself. The proposed methodology applies to most of the variants of GSAT proposed so far.
cs.AI:Given a knowledge base KB containing first-order and statistical facts, we consider a principled method, called the random-worlds method, for computing a degree of belief that some formula Phi holds given KB. If we are reasoning about a world or system consisting of N individuals, then we can consider all possible worlds, or first-order models, with domain {1,...,N} that satisfy KB, and compute the fraction of them in which Phi is true. We define the degree of belief to be the asymptotic value of this fraction as N grows large. We show that when the vocabulary underlying Phi and KB uses constants and unary predicates only, we can naturally associate an entropy with each world. As N grows larger, there are many more worlds with higher entropy. Therefore, we can use a maximum-entropy computation to compute the degree of belief. This result is in a similar spirit to previous work in physics and artificial intelligence, but is far more general. Of equal interest to the result itself are the limitations on its scope. Most importantly, the restriction to unary predicates seems necessary. Although the random-worlds method makes sense in general, the connection to maximum entropy seems to disappear in the non-unary case. These observations suggest unexpected limitations to the applicability of maximum-entropy methods.
cs.AI:Information extraction is the task of automatically picking up information of interest from an unconstrained text. Information of interest is usually extracted in two steps. First, sentence level processing locates relevant pieces of information scattered throughout the text; second, discourse processing merges coreferential information to generate the output. In the first step, pieces of information are locally identified without recognizing any relationships among them. A key word search or simple pattern search can achieve this purpose. The second step requires deeper knowledge in order to understand relationships among separately identified pieces of information. Previous information extraction systems focused on the first step, partly because they were not required to link up each piece of information with other pieces. To link the extracted pieces of information and map them onto a structured output format, complex discourse processing is essential. This paper reports on a Japanese information extraction system that merges information using a pattern matcher and discourse processor. Evaluation results show a high level of system performance which approaches human performance.
cs.AI:This article describes a new system for induction of oblique decision trees. This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree. Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes. We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to construct oblique trees that are smaller and more accurate than their axis-parallel counterparts. We also examine the benefits of randomization for the construction of oblique decision trees.
cs.AI:This paper introduces a framework for Planning while Learning where an agent is given a goal to achieve in an environment whose behavior is only partially known to the agent. We discuss the tractability of various plan-design processes. We show that for a large natural class of Planning while Learning systems, a plan can be presented and verified in a reasonable time. However, coming up algorithmically with a plan, even for simple classes of systems is apparently intractable. We emphasize the role of off-line plan-design processes, and show that, in most natural cases, the verification (projection) part can be carried out in an efficient algorithmic manner.
cs.AI:The vast amounts of on-line text now available have led to renewed interest in information extraction (IE) systems that analyze unrestricted text, producing a structured representation of selected information from the text. This paper presents a novel approach that uses machine learning to acquire knowledge for some of the higher level IE processing. Wrap-Up is a trainable IE discourse component that makes intersentential inferences and identifies logical relations among information extracted from the text. Previous corpus-based approaches were limited to lower level processing such as part-of-speech tagging, lexical disambiguation, and dictionary construction. Wrap-Up is fully trainable, and not only automatically decides what classifiers are needed, but even derives the feature set for each classifier automatically. Performance equals that of a partially trainable discourse module requiring manual customization for each domain.
cs.AI:This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, and the manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximization algorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. The main original contributions here are the decomposition techniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms.
cs.AI:For many years, the intuitions underlying partial-order planning were largely taken for granted. Only in the past few years has there been renewed interest in the fundamental principles underlying this paradigm. In this paper, we present a rigorous comparative analysis of partial-order and total-order planning by focusing on two specific planners that can be directly compared. We show that there are some subtle assumptions that underly the wide-spread intuitions regarding the supposed efficiency of partial-order planning. For instance, the superiority of partial-order planning can depend critically upon the search strategy and the structure of the search space. Understanding the underlying assumptions is crucial for constructing efficient planners.
cs.AI:Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k &gt 2 values (i.e., k ``classes''). The definition is acquired by studying collections of training examples of the form [x_i, f (x_i)]. Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that---like the other methods---the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.
cs.AI:The paradigms of transformational planning, case-based planning, and plan debugging all involve a process known as plan adaptation - modifying or repairing an old plan so it solves a new problem. In this paper we provide a domain-independent algorithm for plan adaptation, demonstrate that it is sound, complete, and systematic, and compare it to other adaptation algorithms in the literature. Our approach is based on a view of planning as searching a graph of partial plans. Generative planning starts at the graph's root and moves from node to node using plan-refinement operators. In planning by adaptation, a library plan - an arbitrary node in the plan graph - is the starting point for the search, and the plan-adaptation algorithm can apply both the same refinement operators available to a generative planner and can also retract constraints and steps from the plan. Our algorithm's completeness ensures that the adaptation algorithm will eventually search the entire graph and its systematicity ensures that it will do so without redundantly searching any parts of the graph.
cs.AI:Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor lambda. Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learning. This paper examines the issues of the efficient and general implementation of TD(lambda) for arbitrary lambda, for use with reinforcement learning algorithms optimizing the discounted sum of rewards. The traditional approach, based on eligibility traces, is argued to suffer from both inefficiency and lack of generality. The TTD (Truncated Temporal Differences) procedure is proposed as an alternative, that indeed only approximates TD(lambda), but requires very little computation per action and can be used with arbitrary function representation methods. The idea from which it is derived is fairly simple and not new, but probably unexplored so far. Encouraging experimental results are presented, suggesting that using lambda &gt 0 with the TTD procedure allows one to obtain a significant learning speedup at essentially the same cost as usual TD(0) learning.
cs.AI:This paper introduces ICET, a new algorithm for cost-sensitive classification. ICET uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm. The fitness function of the genetic algorithm is the average cost of classification when using the decision tree, including both the costs of tests (features, measurements) and the costs of classification errors. ICET is compared here with three other algorithms for cost-sensitive classification - EG2, CS-ID3, and IDX - and also with C4.5, which classifies without regard to cost. The five algorithms are evaluated empirically on five real-world medical datasets. Three sets of experiments are performed. The first set examines the baseline performance of the five algorithms on the five datasets and establishes that ICET performs significantly better than its competitors. The second set tests the robustness of ICET under a variety of conditions and shows that ICET maintains its advantage. The third set looks at ICET's search in bias space and discovers a way to improve the search.
cs.AI:Theory revision integrates inductive learning and background knowledge by combining training examples with a coarse domain theory to produce a more accurate theory. There are two challenges that theory revision and other theory-guided systems face. First, a representation language appropriate for the initial theory may be inappropriate for an improved theory. While the original representation may concisely express the initial theory, a more accurate theory forced to use that same representation may be bulky, cumbersome, and difficult to reach. Second, a theory structure suitable for a coarse domain theory may be insufficient for a fine-tuned theory. Systems that produce only small, local changes to a theory have limited value for accomplishing complex structural alterations that may be required. Consequently, advanced theory-guided learning systems require flexible representation and flexible structure. An analysis of various theory revision systems and theory-guided learning systems reveals specific strengths and weaknesses in terms of these two desired properties. Designed to capture the underlying qualities of each system, a new system uses theory-guided constructive induction. Experiments in three domains show improvement over previous theory-guided systems. This leads to a study of the behavior, limitations, and potential of theory-guided constructive induction.
cs.AI:Many studies have been carried out in order to increase the search efficiency of constraint satisfaction problems; among them, some make use of structural properties of the constraint network; others take into account semantic properties of the constraints, generally assuming that all the constraints possess the given property. In this paper, we propose a new decomposition method benefiting from both semantic properties of functional constraints (not bijective constraints) and structural properties of the network; furthermore, not all the constraints need to be functional. We show that under some conditions, the existence of solutions can be guaranteed. We first characterize a particular subset of the variables, which we name a root set. We then introduce pivot consistency, a new local consistency which is a weak form of path consistency and can be achieved in O(n^2d^2) complexity (instead of O(n^3d^3) for path consistency), and we present associated properties; in particular, we show that any consistent instantiation of the root set can be linearly extended to a solution, which leads to the presentation of the aforementioned new method for solving by decomposing functional CSPs.
cs.AI:We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system, without use of either central coordination or explicit communication. We first define a precise framework in which to study adaptive load balancing, important features of which are its stochastic nature and the purely local information available to individual agents. Given this framework, we show illuminating results on the interplay between basic adaptive behavior parameters and their effect on system efficiency. We then investigate the properties of adaptive load balancing in heterogeneous populations, and address the issue of exploration vs. exploitation in that context. Finally, we show that naive use of communication may not improve, and might even harm system efficiency.
cs.AI:Since its inception, artificial intelligence has relied upon a theoretical foundation centered around perfect rationality as the desired property of intelligent systems. We argue, as others have done, that this foundation is inadequate because it imposes fundamentally unsatisfiable requirements. As a result, there has arisen a wide gap between theory and practice in AI, hindering progress in the field. We propose instead a property called bounded optimality. Roughly speaking, an agent is bounded-optimal if its program is a solution to the constrained optimization problem presented by its architecture and the task environment. We show how to construct agents with this property for a simple class of machine architectures in a broad class of real-time environments. We illustrate these results using a simple model of an automated mail sorting facility. We also define a weaker property, asymptotic bounded optimality (ABO), that generalizes the notion of optimality in classical complexity theory. We then construct universal ABO programs, i.e., programs that are ABO no matter what real-time constraints are applied. Universal ABO programs can be used as building blocks for more complex systems. We conclude with a discussion of the prospects for bounded optimality as a theoretical basis for AI, and relate it to similar trends in philosophy, economics, and game theory.
cs.AI:We present algorithms that learn certain classes of function-free recursive logic programs in polynomial time from equivalence queries. In particular, we show that a single k-ary recursive constant-depth determinate clause is learnable. Two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause are also learnable, if an additional ``basecase'' oracle is assumed. These results immediately imply the pac-learnability of these classes. Although these classes of learnable recursive programs are very constrained, it is shown in a companion paper that they are maximally general, in that generalizing either class in any natural way leads to a computationally difficult learning problem. Thus, taken together with its companion paper, this paper establishes a boundary of efficient learnability for recursive logic programs.
cs.AI:In a companion paper it was shown that the class of constant-depth determinate k-ary recursive clauses is efficiently learnable. In this paper we present negative results showing that any natural generalization of this class is hard to learn in Valiant's model of pac-learnability. In particular, we show that the following program classes are cryptographically hard to learn: programs with an unbounded number of constant-depth linear recursive clauses; programs with one constant-depth determinate clause containing an unbounded number of recursive calls; and programs with one linear recursive clause of constant locality. These results immediately imply the non-learnability of any more general class of programs. We also show that learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause is as hard as learning boolean DNF. Together with positive results from the companion paper, these negative results establish a boundary of efficient learnability for recursive function-free clauses.
cs.AI:There has been evidence that least-commitment planners can efficiently handle planning problems that involve difficult goal interactions. This evidence has led to the common belief that delayed-commitment is the "best" possible planning strategy. However, we recently found evidence that eager-commitment planners can handle a variety of planning problems more efficiently, in particular those with difficult operator choices. Resigned to the futility of trying to find a universally successful planning strategy, we devised a planner that can be used to study which domains and problems are best for which planning strategies. In this article we introduce this new planning algorithm, FLECS, which uses a FLExible Commitment Strategy with respect to plan-step orderings. It is able to use any strategy from delayed-commitment to eager-commitment. The combination of delayed and eager operator-ordering commitments allows FLECS to take advantage of the benefits of explicitly using a simulated execution state and reasoning about planning constraints. FLECS can vary its commitment strategy across different problems and domains, and also during the course of a single planning problem. FLECS represents a novel contribution to planning in that it explicitly provides the choice of which commitment strategy to use while planning. FLECS provides a framework to investigate the mapping from planning domains and problems to efficient planning strategies.
cs.AI:This paper presents a method for inducing logic programs from examples that learns a new class of concepts called first-order decision lists, defined as ordered lists of clauses each ending in a cut. The method, called FOIDL, is based on FOIL (Quinlan, 1990) but employs intensional background knowledge and avoids the need for explicit negative examples. It is particularly useful for problems that involve rules with specific exceptions, such as learning the past-tense of English verbs, a task widely studied in the context of the symbolic/connectionist debate. FOIDL is able to learn concise, accurate programs for this problem from significantly fewer examples than previous methods (both connectionist and symbolic).
cs.AI:ion is one of the most promising approaches to improve the performance of problem solvers. In several domains abstraction by dropping sentences of a domain description -- as used in most hierarchical planners -- has proven useful. In this paper we present examples which illustrate significant drawbacks of abstraction by dropping sentences. To overcome these drawbacks, we propose a more general view of abstraction involving the change of representation language. We have developed a new abstraction methodology and a related sound and complete learning algorithm that allows the complete change of representation language of planning cases from concrete to abstract. However, to achieve a powerful change of the representation language, the abstract language itself as well as rules which describe admissible ways of abstracting states must be provided in the domain model. This new abstraction approach is the core of Paris (Plan Abstraction and Refinement in an Integrated System), a system in which abstract planning cases are automatically learned from given concrete cases. An empirical study in the domain of process planning in mechanical engineering shows significant advantages of the proposed reasoning from abstract cases over classical hierarchical planning.
cs.AI:Identifying inaccurate data has long been regarded as a significant and difficult problem in AI. In this paper, we present a new method for identifying inaccurate data on the basis of qualitative correlations among related data. First, we introduce the definitions of related data and qualitative correlations among related data. Then we put forward a new concept called support coefficient function (SCF). SCF can be used to extract, represent, and calculate qualitative correlations among related data within a dataset. We propose an approach to determining dynamic shift intervals of inaccurate data, and an approach to calculating possibility of identifying inaccurate data, respectively. Both of the approaches are based on SCF. Finally we present an algorithm for identifying inaccurate data by using qualitative correlations among related data as confirmatory or disconfirmatory evidence. We have developed a practical system for interpreting infrared spectra by applying the method, and have fully tested the system against several hundred real spectra. The experimental results show that the method is significantly better than the conventional methods used in many similar systems.
cs.AI:Learning and reasoning are both aspects of what is considered to be intelligence. Their studies within AI have been separated historically, learning being the topic of machine learning and neural networks, and reasoning falling under classical (or symbolic) AI. However, learning and reasoning are in many ways interdependent. This paper discusses the nature of some of these interdependencies and proposes a general framework called FLARE, that combines inductive learning using prior knowledge together with reasoning in a propositional setting. Several examples that test the framework are presented, including classical induction, many important reasoning protocols and two simple expert systems.
cs.AI:This paper studies the problem of ergodicity of transition probability matrices in Markovian models, such as hidden Markov models (HMMs), and how it makes very difficult the task of learning to represent long-term context for sequential data. This phenomenon hurts the forward propagation of long-term context information, as well as learning a hidden state representation to represent long-term context, which depends on propagating credit information backwards in time. Using results from Markov chain theory, we show that this problem of diffusion of context and credit is reduced when the transition probabilities approach 0 or 1, i.e., the transition probability matrices are sparse and the model essentially deterministic. The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm.
cs.AI:Symmetric networks designed for energy minimization such as Boltzman machines and Hopfield nets are frequently investigated for use in optimization, constraint satisfaction and approximation of NP-hard problems. Nevertheless, finding a global solution (i.e., a global minimum for the energy function) is not guaranteed and even a local solution may take an exponential number of steps. We propose an improvement to the standard local activation function used for such networks. The improved algorithm guarantees that a global minimum is found in linear time for tree-like subnetworks. The algorithm, called activate, is uniform and does not assume that the network is tree-like. It can identify tree-like subnetworks even in cyclic topologies (arbitrary networks) and avoid local minima along these trees. For acyclic networks, the algorithm is guaranteed to converge to a global minimum from any initial state of the system (self-stabilization) and remains correct under various types of schedulers. On the negative side, we show that in the presence of cycles, no uniform algorithm exists that guarantees optimality even under a sequential asynchronous scheduler. An asynchronous scheduler can activate only one unit at a time while a synchronous scheduler can activate any number of units in a single time step. In addition, no uniform algorithm exists to optimize even acyclic networks when the scheduler is synchronous. Finally, we show how the algorithm can be improved using the cycle-cutset scheme. The general algorithm, called activate-with-cutset, improves over activate and has some performance guarantees that are related to the size of the network's cycle-cutset.
cs.AI:Functionality-based recognition systems recognize objects at the category level by reasoning about how well the objects support the expected function. Such systems naturally associate a ``measure of goodness'' or ``membership value'' with a recognized object. This measure of goodness is the result of combining individual measures, or membership values, from potentially many primitive evaluations of different properties of the object's shape. A membership function is used to compute the membership value when evaluating a primitive of a particular physical property of an object. In previous versions of a recognition system known as Gruff, the membership function for each of the primitive evaluations was hand-crafted by the system designer. In this paper, we provide a learning component for the Gruff system, called Omlet, that automatically learns membership functions given a set of example objects labeled with their desired category measure. The learning algorithm is generally applicable to any problem in which low-level membership values are combined through an and-or tree structure to give a final overall membership value.
cs.AI:This paper presents an approach to learning from situated, interactive tutorial instruction within an ongoing agent. Tutorial instruction is a flexible (and thus powerful) paradigm for teaching tasks because it allows an instructor to communicate whatever types of knowledge an agent might need in whatever situations might arise. To support this flexibility, however, the agent must be able to learn multiple kinds of knowledge from a broad range of instructional interactions. Our approach, called situated explanation, achieves such learning through a combination of analytic and inductive techniques. It combines a form of explanation-based learning that is situated for each instruction with a full suite of contextually guided responses to incomplete explanations. The approach is implemented in an agent called Instructo-Soar that learns hierarchies of new tasks and other domain knowledge from interactive natural language instructions. Instructo-Soar meets three key requirements of flexible instructability that distinguish it from previous systems: (1) it can take known or unknown commands at any instruction point; (2) it can handle instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions); and (3) it can learn, from instructions, each class of knowledge it uses to perform tasks.
cs.AI:OPUS is a branch and bound search algorithm that enables efficient admissible search through spaces for which the order of search operator application is not significant. The algorithm's search efficiency is demonstrated with respect to very large machine learning search spaces. The use of admissible search is of potential value to the machine learning community as it means that the exact learning biases to be employed for complex learning tasks can be precisely specified and manipulated. OPUS also has potential for application in other areas of artificial intelligence, notably, truth maintenance.
cs.AI:The main aim of this work is the development of a vision-based road detection system fast enough to cope with the difficult real-time constraints imposed by moving vehicle applications. The hardware platform, a special-purpose massively parallel system, has been chosen to minimize system production and operational costs. This paper presents a novel approach to expectation-driven low-level image segmentation, which can be mapped naturally onto mesh-connected massively parallel SIMD architectures capable of handling hierarchical data structures. The input image is assumed to contain a distorted version of a given template; a multiresolution stretching process is used to reshape the original template in accordance with the acquired image content, minimizing a potential function. The distorted template is the process output.
cs.AI:In the area of inductive learning, generalization is a main operation, and the usual definition of induction is based on logical implication. Recently there has been a rising interest in clausal representation of knowledge in machine learning. Almost all inductive learning systems that perform generalization of clauses use the relation theta-subsumption instead of implication. The main reason is that there is a well-known and simple technique to compute least general generalizations under theta-subsumption, but not under implication. However generalization under theta-subsumption is inappropriate for learning recursive clauses, which is a crucial problem since recursion is the basic program structure of logic programs. We note that implication between clauses is undecidable, and we therefore introduce a stronger form of implication, called T-implication, which is decidable between clauses. We show that for every finite set of clauses there exists a least general generalization under T-implication. We describe a technique to reduce generalizations under implication of a clause to generalizations under theta-subsumption of what we call an expansion of the original clause. Moreover we show that for every non-tautological clause there exists a T-complete expansion, which means that every generalization under T-implication of the clause is reduced to a generalization under theta-subsumption of the expansion.
cs.AI:We present a definition of cause and effect in terms of decision-theoretic primitives and thereby provide a principled foundation for causal reasoning. Our definition departs from the traditional view of causation in that causal assertions may vary with the set of decisions available. We argue that this approach provides added clarity to the notion of cause. Also in this paper, we examine the encoding of causal relationships in directed acyclic graphs. We describe a special class of influence diagrams, those in canonical form, and show its relationship to Pearl's representation of cause and effect. Finally, we show how canonical form facilitates counterfactual reasoning.
cs.AI:Characteristic models are an alternative, model based, representation for Horn expressions. It has been shown that these two representations are incomparable and each has its advantages over the other. It is therefore natural to ask what is the cost of translating, back and forth, between these representations. Interestingly, the same translation questions arise in database theory, where it has applications to the design of relational databases. This paper studies the computational complexity of these problems. Our main result is that the two translation problems are equivalent under polynomial reductions, and that they are equivalent to the corresponding decision problem. Namely, translating is equivalent to deciding whether a given set of models is the set of characteristic models for a given Horn expression. We also relate these problems to the hypergraph transversal problem, a well known problem which is related to other applications in AI and for which no polynomial time algorithm is known. It is shown that in general our translation problems are at least as hard as the hypergraph transversal problem, and in a special case they are equivalent to it.
cs.AI:This article describes an application of three well-known statistical methods in the field of game-tree search: using a large number of classified Othello positions, feature weights for evaluation functions with a game-phase-independent meaning are estimated by means of logistic regression, Fisher's linear discriminant, and the quadratic discriminant function for normally distributed features. Thereafter, the playing strengths are compared by means of tournaments between the resulting versions of a world-class Othello program. In this application, logistic regression - which is used here for the first time in the context of game playing - leads to better results than the other approaches.
cs.AI:We describe a machine learning method for predicting the value of a real-valued function, given the values of multiple input variables. The method induces solutions from samples in the form of ordered disjunctive normal form (DNF) decision rules. A central objective of the method and representation is the induction of compact, easily interpretable solutions. This rule-based decision model can be extended to search efficiently for similar cases prior to approximating function values. Experimental results on real-world data demonstrate that the new techniques are competitive with existing machine learning and statistical methods and can sometimes yield superior regression performance.
cs.AI:Many applications -- from planning and scheduling to problems in molecular biology -- rely heavily on a temporal reasoning component. In this paper, we discuss the design and empirical analysis of algorithms for a temporal reasoning system based on Allen's influential interval-based framework for representing temporal information. At the core of the system are algorithms for determining whether the temporal information is consistent, and, if so, finding one or more scenarios that are consistent with the temporal information. Two important algorithms for these tasks are a path consistency algorithm and a backtracking algorithm. For the path consistency algorithm, we develop techniques that can result in up to a ten-fold speedup over an already highly optimized implementation. For the backtracking algorithm, we develop variable and value ordering heuristics that are shown empirically to dramatically improve the performance of the algorithm. As well, we show that a previously suggested reformulation of the backtracking search problem can reduce the time and space requirements of the backtracking search. Taken together, the techniques we develop allow a temporal reasoning component to solve problems that are of practical size.
cs.AI:The paper describes an extension of well-founded semantics for logic programs with two types of negation. In this extension information about preferences between rules can be expressed in the logical language and derived dynamically. This is achieved by using a reserved predicate symbol and a naming technique. Conflicts among rules are resolved whenever possible on the basis of derived preference information. The well-founded conclusions of prioritized logic programs can be computed in polynomial time. A legal reasoning example illustrates the usefulness of the approach.
cs.AI:Traditional databases commonly support efficient query and update procedures that operate in time which is sublinear in the size of the database. Our goal in this paper is to take a first step toward dynamic reasoning in probabilistic databases with comparable efficiency. We propose a dynamic data structure that supports efficient algorithms for updating and querying singly connected Bayesian networks. In the conventional algorithm, new evidence is absorbed in O(1) time and queries are processed in time O(N), where N is the size of the network. We propose an algorithm which, after a preprocessing phase, allows us to answer queries in time O(log N) at the expense of O(log N) time per evidence absorption. The usefulness of sub-linear processing time manifests itself in applications requiring (near) real-time response over large probabilistic databases. We briefly discuss a potential application of dynamic probabilistic reasoning in computational biology.
cs.AI:We introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average. This is done by exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices. This quantum algorithm is much more likely to find solutions than the simple direct use of quantum parallelism. Furthermore, empirical evaluation on small problems shows this quantum algorithm displays the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods. Specifically, difficult problem instances are concentrated near the abrupt change from underconstrained to overconstrained problems.
cs.AI:We develop a mean field theory for sigmoid belief networks based on ideas from statistical mechanics. Our mean field theory provides a tractable approximation to the true probability distribution in these networks; it also yields a lower bound on the likelihood of evidence. We demonstrate the utility of this framework on a benchmark problem in statistical pattern recognition---the classification of handwritten digits.
cs.AI:A reported weakness of C4.5 in domains with continuous attributes is addressed by modifying the formation and evaluation of tests on continuous attributes. An MDL-inspired penalty is applied to such tests, eliminating some of them from consideration and altering the relative desirability of all tests. Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies. Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.
cs.AI:For many types of machine learning algorithms, one can compute the statistically `optimal' way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.
cs.AI:Inductive theorem provers often diverge. This paper describes a simple critic, a computer program which monitors the construction of inductive proofs attempting to identify diverging proof attempts. Divergence is recognized by means of a ``difference matching'' procedure. The critic then proposes lemmas and generalizations which ``ripple'' these differences away so that the proof can go through without divergence. The critic enables the theorem prover Spike to prove many theorems completely automatically from the definitions alone.
cs.AI:Termination of logic programs with negated body atoms (here called general logic programs) is an important topic. One reason is that many computational mechanisms used to process negated atoms, like Clark's negation as failure and Chan's constructive negation, are based on termination conditions. This paper introduces a methodology for proving termination of general logic programs w.r.t. the Prolog selection rule. The idea is to distinguish parts of the program depending on whether or not their termination depends on the selection rule. To this end, the notions of low-, weakly up-, and up-acceptable program are introduced. We use these notions to develop a methodology for proving termination of general logic programs, and show how interesting problems in non-monotonic reasoning can be formalized and implemented by means of terminating general logic programs.
cs.AI:Clustering is often used for discovering structure in data. Clustering systems differ in the objective function used to evaluate clustering quality and the control strategy used to search the space of clusterings. Ideally, the search strategy should consistently construct clusterings of high quality, but be computationally inexpensive as well. In general, we cannot have it both ways, but we can partition the search so that a system inexpensively constructs a `tentative' clustering for initial examination, followed by iterative optimization, which continues to search in background for improved clusterings. Given this motivation, we evaluate an inexpensive strategy for creating initial clusterings, coupled with several control strategies for iterative optimization, each of which repeatedly modifies an initial clustering in search of a better one. One of these methods appears novel as an iterative optimization strategy in clustering contexts. Once a clustering has been constructed it is judged by analysts -- often according to task-specific criteria. Several authors have abstracted these criteria and posited a generic performance task akin to pattern completion, where the error rate over completed patterns is used to `externally' judge clustering utility. Given this performance task, we adapt resampling-based pruning strategies used by supervised learning systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis. Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and simplicity dimensions.
cs.AI:This paper presents new experimental evidence against the utility of Occam's razor. A~systematic procedure is presented for post-processing decision trees produced by C4.5. This procedure was derived by rejecting Occam's razor and instead attending to the assumption that similar objects are likely to belong to the same class. It increases a decision tree's complexity without altering the performance of that tree on the training data from which it is inferred. The resulting more complex decision trees are demonstrated to have, on average, for a variety of common learning tasks, higher predictive accuracy than the less complex original decision trees. This result raises considerable doubt about the utility of Occam's razor as it is commonly applied in modern machine learning.
cs.AI:The main operations in Inductive Logic Programming (ILP) are generalization and specialization, which only make sense in a generality order. In ILP, the three most important generality orders are subsumption, implication and implication relative to background knowledge. The two languages used most often are languages of clauses and languages of only Horn clauses. This gives a total of six different ordered languages. In this paper, we give a systematic treatment of the existence or non-existence of least generalizations and greatest specializations of finite sets of clauses in each of these six ordered sets. We survey results already obtained by others and also contribute some answers of our own. Our main new results are, firstly, the existence of a computable least generalization under implication of every finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses). Secondly, we show that such a least generalization need not exist under relative implication, not even if both the set that is to be generalized and the background knowledge are function-free. Thirdly, we give a complete discussion of existence and non-existence of greatest specializations in each of the six ordered languages.
cs.AI:This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.
cs.AI:Although most scheduling problems are NP-hard, domain specific techniques perform well in practice but are quite expensive to construct. In adaptive problem-solving solving, domain specific knowledge is acquired automatically for a general problem solver with a flexible control architecture. In this approach, a learning system explores a space of possible heuristic methods for one well-suited to the eccentricities of the given domain and problem distribution. In this article, we discuss an application of the approach to scheduling satellite communications. Using problem distributions based on actual mission requirements, our approach identifies strategies that not only decrease the amount of CPU time required to produce schedules, but also increase the percentage of problems that are solvable within computational resource limitations.
cs.AI:Speedup learning seeks to improve the computational efficiency of problem solving with experience. In this paper, we develop a formal framework for learning efficient problem solving from random problems and their solutions. We apply this framework to two different representations of learned knowledge, namely control rules and macro-operators, and prove theorems that identify sufficient conditions for learning in each representation. Our proofs are constructive in that they are accompanied with learning algorithms. Our framework captures both empirical and explanation-based speedup learning in a unified fashion. We illustrate our framework with implementations in two domains: symbolic integration and Eight Puzzle. This work integrates many strands of experimental and theoretical work in machine learning, including empirical learning of control rules, macro-operator learning, Explanation-Based Learning (EBL), and Probably Approximately Correct (PAC) Learning.
cs.AI:A fundamental assumption made by classical AI planners is that there is no uncertainty in the world: the planner has full knowledge of the conditions under which the plan will be executed and the outcome of every action is fully predictable. These planners cannot therefore construct contingency plans, i.e., plans in which different actions are performed in different circumstances. In this paper we discuss some issues that arise in the representation and construction of contingency plans and describe Cassandra, a partial-order contingency planner. Cassandra uses explicit decision-steps that enable the agent executing the plan to decide which plan branch to follow. The decision-steps in a plan result in subgoals to acquire knowledge, which are planned for in the same way as any other subgoals. Cassandra thus distinguishes the process of gathering information from the process of making decisions. The explicit representation of decisions in Cassandra allows a coherent approach to the problems of contingent planning, and provides a solid base for extensions such as the use of different decision-making procedures.
cs.AI:An important problem in geometric reasoning is to find the configuration of a collection of geometric bodies so as to satisfy a set of given constraints. Recently, it has been suggested that this problem can be solved efficiently by symbolically reasoning about geometry. This approach, called degrees of freedom analysis, employs a set of specialized routines called plan fragments that specify how to change the configuration of a set of bodies to satisfy a new constraint while preserving existing constraints. A potential drawback, which limits the scalability of this approach, is concerned with the difficulty of writing plan fragments. In this paper we address this limitation by showing how these plan fragments can be automatically synthesized using first principles about geometric bodies, actions, and topology.
cs.AI:Motivated by the control theoretic distinction between controllable and uncontrollable events, we distinguish between two types of agents within a multi-agent system: controllable agents, which are directly controlled by the system's designer, and uncontrollable agents, which are not under the designer's direct control. We refer to such systems as partially controlled multi-agent systems, and we investigate how one might influence the behavior of the uncontrolled agents through appropriate design of the controlled agents. In particular, we wish to understand which problems are naturally described in these terms, what methods can be applied to influence the uncontrollable agents, the effectiveness of such methods, and whether similar methods work across different domains. Using a game-theoretic framework, this paper studies the design of partially controlled multi-agent systems in two contexts: in one context, the uncontrollable agents are expected utility maximizers, while in the other they are reinforcement learners. We suggest different techniques for controlling agents' behavior in each domain, assess their success, and examine their relationship.
cs.AI:Visual thinking plays an important role in scientific reasoning. Based on the research in automating diverse reasoning tasks about dynamical systems, nonlinear controllers, kinematic mechanisms, and fluid motion, we have identified a style of visual thinking, imagistic reasoning. Imagistic reasoning organizes computations around image-like, analogue representations so that perceptual and symbolic operations can be brought to bear to infer structure and behavior. Programs incorporating imagistic reasoning have been shown to perform at an expert level in domains that defy current analytic or numerical methods. We have developed a computational paradigm, spatial aggregation, to unify the description of a class of imagistic problem solvers. A program written in this paradigm has the following properties. It takes a continuous field and optional objective functions as input, and produces high-level descriptions of structure, behavior, or control actions. It computes a multi-layer of intermediate representations, called spatial aggregates, by forming equivalence classes and adjacency relations. It employs a small set of generic operators such as aggregation, classification, and localization to perform bidirectional mapping between the information-rich field and successively more abstract spatial aggregates. It uses a data structure, the neighborhood graph, as a common interface to modularize computations. To illustrate our theory, we describe the computational structure of three implemented problem solvers -- KAM, MAPS, and HIPAIR --- in terms of the spatial aggregation generic operators by mixing and matching a library of commonly used routines.
cs.AI:Finding the stable models of a knowledge base is a significant computational problem in artificial intelligence. This task is at the computational heart of truth maintenance systems, autoepistemic logic, and default logic. Unfortunately, it is NP-hard. In this paper we present a hierarchy of classes of knowledge bases, Omega_1,Omega_2,..., with the following properties: first, Omega_1 is the class of all stratified knowledge bases; second, if a knowledge base Pi is in Omega_k, then Pi has at most k stable models, and all of them may be found in time O(lnk), where l is the length of the knowledge base and n the number of atoms in Pi; third, for an arbitrary knowledge base Pi, we can find the minimum k such that Pi belongs to Omega_k in time polynomial in the size of Pi; and, last, where K is the class of all knowledge bases, it is the case that union{i=1 to infty} Omega_i = K, that is, every knowledge base belongs to some class in the hierarchy.
cs.AI:We propose some domain-independent techniques for bringing well-founded partial-order planners closer to practicality. The first two techniques are aimed at improving search control while keeping overhead costs low. One is based on a simple adjustment to the default A* heuristic used by UCPOP to select plans for refinement. The other is based on preferring ``zero commitment'' (forced) plan refinements whenever possible, and using LIFO prioritization otherwise. A more radical technique is the use of operator parameter domains to prune search. These domains are initially computed from the definitions of the operators and the initial and goal conditions, using a polynomial-time algorithm that propagates sets of constants through the operator graph, starting in the initial conditions. During planning, parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats. In experiments based on modifications of UCPOP, our improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version. Crucially, the hardest problems gave the greatest improvements. The pruning technique based on parameter domains often gave speedups by an order of magnitude or more for difficult problems, both with the default UCPOP search strategy and with our improved strategy. The Lisp code for our techniques and for the test problems is provided in on-line appendices.
cs.AI:Cue phrases may be used in a discourse sense to explicitly signal discourse structure, but also in a sentential sense to convey semantic rather than structural information. Correctly classifying cue phrases as discourse or sentential is critical in natural language processing systems that exploit discourse structure, e.g., for performing tasks such as anaphora resolution and plan recognition. This paper explores the use of machine learning for classifying cue phrases as discourse or sentential. Two machine learning programs (Cgrendel and C4.5) are used to induce classification models from sets of pre-classified cue phrases and their features in text and speech. Machine learning is shown to be an effective technique for not only automating the generation of classification models, but also for improving upon previous results. When compared to manually derived classification models already in the literature, the learned models often perform with higher accuracy and contain new linguistic insights into the data. In addition, the ability to automatically construct classification models makes it easier to comparatively analyze the utility of alternative feature representations of the data. Finally, the ease of retraining makes the learning approach more scalable and flexible than manual methods.
cs.AI:This paper lays part of the groundwork for a domain theory of negotiation, that is, a way of classifying interactions so that it is clear, given a domain, which negotiation mechanisms and strategies are appropriate. We define State Oriented Domains, a general category of interaction. Necessary and sufficient conditions for cooperation are outlined. We use the notion of worth in an altered definition of utility, thus enabling agreements in a wider class of joint-goal reachable situations. An approach is offered for conflict resolution, and it is shown that even in a conflict situation, partial cooperative steps can be taken by interacting agents (that is, agents in fundamental conflict might still agree to cooperate up to a certain point). A Unified Negotiation Protocol (UNP) is developed that can be used in all types of encounters. It is shown that in certain borderline cooperative situations, a partial cooperative agreement (i.e., one that does not achieve all agents' goals) might be preferred by all agents, even though there exists a rational agreement that would achieve all their goals. Finally, we analyze cases where agents have incomplete information on the goals and worth of other agents. First we consider the case where agents' goals are private information, and we analyze what goal declaration strategies the agents might adopt to increase their utility. Then, we consider the situation where the agents' goals (and therefore stand-alone costs) are common knowledge, but the worth they attach to their goals is private information. We introduce two mechanisms, one 'strict', the other 'tolerant', and analyze their affects on the stability and efficiency of negotiation outcomes.
cs.AI:First-order learning involves finding a clause-form definition of a relation from examples of the relation and relevant background information. In this paper, a particular first-order learning system is modified to customize it for finding definitions of functional relations. This restriction leads to faster learning times and, in some cases, to definitions that have higher predictive accuracy. Other first-order learning systems might benefit from similar specialization.
cs.AI:This paper describes an extension to the constraint satisfaction problem (CSP) called MUSE CSP (MUltiply SEgmented Constraint Satisfaction Problem). This extension is especially useful for those problems which segment into multiple sets of partially shared variables. Such problems arise naturally in signal processing applications including computer vision, speech processing, and handwriting recognition. For these applications, it is often difficult to segment the data in only one way given the low-level information utilized by the segmentation algorithms. MUSE CSP can be used to compactly represent several similar instances of the constraint satisfaction problem. If multiple instances of a CSP have some common variables which have the same domains and constraints, then they can be combined into a single instance of a MUSE CSP, reducing the work required to apply the constraints. We introduce the concepts of MUSE node consistency, MUSE arc consistency, and MUSE path consistency. We then demonstrate how MUSE CSP can be used to compactly represent lexically ambiguous sentences and the multiple sentence hypotheses that are often generated by speech recognition algorithms so that grammar constraints can be used to provide parses for all syntactically correct sentences. Algorithms for MUSE arc and path consistency are provided. Finally, we discuss how to create a MUSE CSP from a set of CSPs which are labeled to indicate when the same variable is shared by more than a single CSP.
cs.AI:A new method is proposed for exploiting causal independencies in exact Bayesian network inference. A Bayesian network can be viewed as representing a factorization of a joint probability into the multiplication of a set of conditional probabilities. We present a notion of causal independence that enables one to further factorize the conditional probabilities into a combination of even smaller factors and consequently obtain a finer-grain factorization of the joint probability. The new formulation of causal independence lets us specify the conditional probability of a variable given its parents in terms of an associative and commutative operator, such as ``or'', ``sum'' or ``max'', on the contribution of each parent. We start with a simple algorithm VE for Bayesian network inference that, given evidence and a query variable, uses the factorization to find the posterior distribution of the query. We show how this algorithm can be extended to exploit causal independence. Empirical studies, based on the CPCS networks for medical diagnosis, show that this method is more efficient than previous methods and allows for inference in larger networks than previous algorithms.
cs.AI:Efficiently entering information into a computer is key to enjoying the benefits of computing. This paper describes three intelligent user interfaces: handwriting recognition, adaptive menus, and predictive fillin. In the context of adding a personUs name and address to an electronic organizer, tests show handwriting recognition is slower than typing on an on-screen, soft keyboard, while adaptive menus and predictive fillin can be twice as fast. This paper also presents strategies for applying these three interfaces to other information collection domains.
cs.AI:Decomposable dependency models possess a number of interesting and useful properties. This paper presents new characterizations of decomposable models in terms of independence relationships, which are obtained by adding a single axiom to the well-known set characterizing dependency models that are isomorphic to undirected graphs. We also briefly discuss a potential application of our results to the problem of learning graphical models from data.
cs.AI:Instance-based learning techniques typically handle continuous and linear input values well, but often do not handle nominal input attributes appropriately. The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values. This paper proposes three new heterogeneous distance functions, called the Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric (IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions are designed to handle applications with nominal attributes, continuous attributes, or both. In experiments on 48 applications the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.
cs.AI:Previous approaches of analyzing spontaneously spoken language often have been based on encoding syntactic and semantic knowledge manually and symbolically. While there has been some progress using statistical or connectionist language models, many current spoken- language systems still use a relatively brittle, hand-coded symbolic grammar or symbolic semantic component. In contrast, we describe a so-called screening approach for learning robust processing of spontaneously spoken language. A screening approach is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic, semantic and dialog levels. Rather than using a deeply structured symbolic analysis, we use a flat connectionist analysis. This screening approach aims at supporting speech and language processing by using (1) data-driven learning and (2) robustness of connectionist networks. In order to test this approach, we have developed the SCREEN system which is based on this new robust, learned and flat analysis. In this paper, we focus on a detailed description of SCREEN's architecture, the flat syntactic and semantic analysis, the interaction with a speech recognizer, and a detailed evaluation analysis of the robustness under the influence of noisy or incomplete input. The main result of this paper is that flat representations allow more robust processing of spontaneous spoken language than deeply structured representations. In particular, we show how the fault-tolerance and learning capability of connectionist networks can support a flat analysis for providing more robust spoken-language processing within an overall hybrid symbolic/connectionist framework.
cs.AI:Most modern formalisms used in Databases and Artificial Intelligence for describing an application domain are based on the notions of class (or concept) and relationship among classes. One interesting feature of such formalisms is the possibility of defining a class, i.e., providing a set of properties that precisely characterize the instances of the class. Many recent articles point out that there are several ways of assigning a meaning to a class definition containing some sort of recursion. In this paper, we argue that, instead of choosing a single style of semantics, we achieve better results by adopting a formalism that allows for different semantics to coexist. We demonstrate the feasibility of our argument, by presenting a knowledge representation formalism, the description logic muALCQ, with the above characteristics. In addition to the constructs for conjunction, disjunction, negation, quantifiers, and qualified number restrictions, muALCQ includes special fixpoint constructs to express (suitably interpreted) recursive definitions. These constructs enable the usual frame-based descriptions to be combined with definitions of recursive data structures such as directed acyclic graphs, lists, streams, etc. We establish several properties of muALCQ, including the decidability and the computational complexity of reasoning, by formulating a correspondence with a particular modal logic of programs called the modal mu-calculus.
cs.AI:We argue that the analysis of agent/environment interactions should be extended to include the conventions and invariants maintained by agents throughout their activity. We refer to this thicker notion of environment as a lifeworld and present a partial set of formal tools for describing structures of lifeworlds and the ways in which they computationally simplify activity. As one specific example, we apply the tools to the analysis of the Toast system and show how versions of the system with very different control structures in fact implement a common control structure together with different conventions for encoding task state in the positions or states of objects in the environment.
cs.AI:We describe a new paradigm for implementing inference in belief networks, which consists of two steps: (1) compiling a belief network into an arithmetic expression called a Query DAG (Q-DAG); and (2) answering queries using a simple evaluation algorithm. Each node of a Q-DAG represents a numeric operation, a number, or a symbol for evidence. Each leaf node of a Q-DAG represents the answer to a network query, that is, the probability of some event of interest. It appears that Q-DAGs can be generated using any of the standard algorithms for exact inference in belief networks (we show how they can be generated using clustering and conditioning algorithms). The time and space complexity of a Q-DAG generation algorithm is no worse than the time complexity of the inference algorithm on which it is based. The complexity of a Q-DAG evaluation algorithm is linear in the size of the Q-DAG, and such inference amounts to a standard evaluation of the arithmetic expression it represents. The intended value of Q-DAGs is in reducing the software and hardware resources required to utilize belief networks in on-line, real-world applications. The proposed framework also facilitates the development of on-line inference on different software and hardware platforms due to the simplicity of the Q-DAG evaluation algorithm. Interestingly enough, Q-DAGs were found to serve other purposes: simple techniques for reducing Q-DAGs tend to subsume relatively complex optimization techniques for belief-network inference, such as network-pruning and computation-caching.
cs.AI:An algorithm that learns from a set of examples should ideally be able to exploit the available resources of (a) abundant computing power and (b) domain-specific knowledge to improve its ability to generalize. Connectionist theory-refinement systems, which use background knowledge to select a neural network's topology and initial weights, have proven to be effective at exploiting domain-specific knowledge; however, most do not exploit available computing power. This weakness occurs because they lack the ability to refine the topology of the neural networks they produce, thereby limiting generalization, especially when given impoverished domain theories. We present the REGENT algorithm which uses (a) domain-specific knowledge to help create an initial population of knowledge-based neural networks and (b) genetic operators of crossover and mutation (specifically designed for knowledge-based networks) to continually search for better network topologies. Experiments on three real-world domains indicate that our new algorithm is able to significantly increase generalization compared to a standard connectionist theory-refinement system, as well as our previous algorithm for growing knowledge-based networks.
cs.AI:Several recent studies have compared the relative efficiency of alternative flaw selection strategies for partial-order causal link (POCL) planning. We review this literature, and present new experimental results that generalize the earlier work and explain some of the discrepancies in it. In particular, we describe the Least-Cost Flaw Repair (LCFR) strategy developed and analyzed by Joslin and Pollack (1994), and compare it with other strategies, including Gerevini and Schubert's (1996) ZLIFO strategy. LCFR and ZLIFO make very different, and apparently conflicting claims about the most effective way to reduce search-space size in POCL planning. We resolve this conflict, arguing that much of the benefit that Gerevini and Schubert ascribe to the LIFO component of their ZLIFO strategy is better attributed to other causes. We show that for many problems, a strategy that combines least-cost flaw selection with the delay of separable threats will be effective in reducing search-space size, and will do so without excessive computational overhead. Although such a strategy thus provides a good default, we also show that certain domain characteristics may reduce its effectiveness.
cs.AI:We investigate the computational properties of the spatial algebra RCC-5 which is a restricted version of the RCC framework for spatial reasoning. The satisfiability problem for RCC-5 is known to be NP-complete but not much is known about its approximately four billion subclasses. We provide a complete classification of satisfiability for all these subclasses into polynomial and NP-complete respectively. In the process, we identify all maximal tractable subalgebras which are four in total.
cs.AI:The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning. We test the generality of this explanation by examining one of its predictions: if the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost. Instead, we find the easy-hard-easy pattern in median search cost even when the number of solutions is held constant, for some search methods. This generalizes previous observations of this pattern and shows that the existing theory does not explain the full range of the peak in search cost. In these cases the pattern appears to be due to changes in the size of the minimal unsolvable subproblems, rather than changing numbers of solutions.
cs.AI:This paper combines two important directions of research in temporal resoning: that of finding maximal tractable subclasses of Allen's interval algebra, and that of reasoning with metric temporal information. Eight new maximal tractable subclasses of Allen's interval algebra are presented, some of them subsuming previously reported tractable algebras. The algebras allow for metric temporal constraints on interval starting or ending points, using the recent framework of Horn DLRs. Two of the algebras can express the notion of sequentiality between intervals, being the first such algebras admitting both qualitative and metric time.
cs.AI:Starting with a likelihood or preference order on worlds, we extend it to a likelihood ordering on sets of worlds in a natural way, and examine the resulting logic. Lewis earlier considered such a notion of relative likelihood in the context of studying counterfactuals, but he assumed a total preference order on worlds. Complications arise when examining partial orders that are not present for total orders. There are subtleties involving the exact approach to lifting the order on worlds to an order on sets of worlds. In addition, the axiomatization of the logic of relative likelihood in the case of partial orders gives insight into the connection between relative likelihood and default reasoning.
cs.AI:Many AI researchers are today striving to build agent teams for complex, dynamic multi-agent domains, with intended applications in arenas such as education, training, entertainment, information integration, and collective robotics. Unfortunately, uncertainties in these complex, dynamic domains obstruct coherent teamwork. In particular, team members often encounter differing, incomplete, and possibly inconsistent views of their environment. Furthermore, team members can unexpectedly fail in fulfilling responsibilities or discover unexpected opportunities. Highly flexible coordination and communication is key in addressing such uncertainties. Simply fitting individual agents with precomputed coordination plans will not do, for their inflexibility can cause severe failures in teamwork, and their domain-specificity hinders reusability. Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork. Agents exploit such models to autonomously reason about coordination and communication, providing requisite flexibility. Furthermore, the models enable reuse across domains, both saving implementation effort and enforcing consistency. This article presents one general, implemented model of teamwork, called STEAM. The basic building block of teamwork in STEAM is joint intentions (Cohen & Levesque, 1991b); teamwork in STEAM is based on agents' building up a (partial) hierarchy of joint intentions (this hierarchy is seen to parallel Grosz & Kraus's partial SharedPlans, 1996). Furthermore, in STEAM, team members monitor the team's and individual members' performance, reorganizing the team as necessary. Finally, decision-theoretic communication selectivity in STEAM ensures reduction in communication overheads of teamwork, with appropriate sensitivity to the environmental conditions. This article describes STEAM's application in three different complex domains, and presents detailed empirical results.
cs.AI:SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively. The result is a hierarchical representation of the original sequence, which offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the size of the grammar, and produce structure as a by-product. SEQUITUR breaks new ground by operating incrementally. Moreover, the method's simple structure permits a proof that it operates in space and time that is linear in the size of the input. Our implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences.
cs.AI:Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improvements it provides are dependent on adequate judgements as to problem similarity. In particular, although CBP may substantially reduce planning effort overall, it is subject to a mis-retrieval problem. The success of CBP depends on these retrieval errors being relatively rare. This paper describes the design and implementation of a replay framework for the case-based planner DERSNLP+EBL. DERSNLP+EBL extends current CBP methodology by incorporating explanation-based learning techniques that allow it to explain and learn from the retrieval failures it encounters. These techniques are used to refine judgements about case similarity in response to feedback when a wrong decision has been made. The same failure analysis is used in building the case library, through the addition of repairing cases. Large problems are split and stored as single goal subproblems. Multi-goal problems are stored only when these smaller cases fail to be merged into a full solution. An empirical evaluation of this approach demonstrates the advantage of learning from experienced retrieval failure.
cs.AI:Partially observable Markov decision processes (POMDPs) are a natural model for planning problems where effects of actions are nondeterministic and the state of the world is not completely observable. It is difficult to solve POMDPs exactly. This paper proposes a new approximation scheme. The basic idea is to transform a POMDP into another one where additional information is provided by an oracle. The oracle informs the planning agent that the current state of the world is in a certain region. The transformed POMDP is consequently said to be region observable. It is easier to solve than the original POMDP. We propose to solve the transformed POMDP and use its optimal policy to construct an approximate policy for the original POMDP. By controlling the amount of additional information that the oracle provides, it is possible to find a proper tradeoff between computational time and approximation quality. In terms of algorithmic contributions, we study in details how to exploit region observability in solving the transformed POMDP. To facilitate the study, we also propose a new exact algorithm for general POMDPs. The algorithm is conceptually simple and yet is significantly more efficient than all previous exact algorithms.
cs.AI:The model of a non-Bayesian agent who faces a repeated game with incomplete information against Nature is an appropriate tool for modeling general agent-environment interactions. In such a model the environment state (controlled by Nature) may change arbitrarily, and the feedback/reward function is initially unknown. The agent is not Bayesian, that is he does not form a prior probability neither on the state selection strategy of Nature, nor on his reward function. A policy for the agent is a function which assigns an action to every history of observations and actions. Two basic feedback structures are considered. In one of them -- the perfect monitoring case -- the agent is able to observe the previous environment state as part of his feedback, while in the other -- the imperfect monitoring case -- all that is available to the agent is the reward obtained. Both of these settings refer to partially observable processes, where the current environment state is unknown. Our main result refers to the competitive ratio criterion in the perfect monitoring case. We prove the existence of an efficient stochastic policy that ensures that the competitive ratio is obtained at almost all stages with an arbitrarily high probability, where efficiency is measured in terms of rate of convergence. It is further shown that such an optimal policy does not exist in the imperfect monitoring case. Moreover, it is proved that in the perfect monitoring case there does not exist a deterministic policy that satisfies our long run optimality criterion. In addition, we discuss the maxmin criterion and prove that a deterministic efficient optimal strategy does exist in the imperfect monitoring case under this criterion. Finally we show that our approach to long-run optimality can be viewed as qualitative, which distinguishes it from previous work in this area.
cs.AI:Local search algorithms for combinatorial search problems frequently encounter a sequence of states in which it is impossible to improve the value of the objective function; moves through these regions, called plateau moves, dominate the time spent in local search. We analyze and characterize plateaus for three different classes of randomly generated Boolean Satisfiability problems. We identify several interesting features of plateaus that impact the performance of local search algorithms. We show that local minima tend to be small but occasionally may be very large. We also show that local minima can be escaped without unsatisfying a large number of clauses, but that systematically searching for an escape route may be computationally expensive if the local minimum is large. We show that plateaus with exits, called benches, tend to be much larger than minima, and that some benches have very few exit states which local search can use to escape. We show that the solutions (i.e., global minima) of randomly generated problem instances form clusters, which behave similarly to local minima. We revisit several enhancements of local search algorithms and explain their performance in light of our results. Finally we discuss strategies for creating the next generation of local search algorithms.
cs.AI:The assessment of bidirectional heuristic search has been incorrect since it was first published more than a quarter of a century ago. For quite a long time, this search strategy did not achieve the expected results, and there was a major misunderstanding about the reasons behind it. Although there is still wide-spread belief that bidirectional heuristic search is afflicted by the problem of search frontiers passing each other, we demonstrate that this conjecture is wrong. Based on this finding, we present both a new generic approach to bidirectional heuristic search and a new approach to dynamically improving heuristic values that is feasible in bidirectional search only. These approaches are put into perspective with both the traditional and more recently proposed approaches in order to facilitate a better overall understanding. Empirical results of experiments with our new approaches show that bidirectional heuristic search can be performed very efficiently and also with limited memory. These results suggest that bidirectional heuristic search appears to be better for solving certain difficult problems than corresponding unidirectional search. This provides some evidence for the usefulness of a search strategy that was long neglected. In summary, we show that bidirectional heuristic search is viable and consequently propose that it be reconsidered.
cs.AI:Approximating a general formula from above and below by Horn formulas (its Horn envelope and Horn core, respectively) was proposed by Selman and Kautz (1991, 1996) as a form of ``knowledge compilation,'' supporting rapid approximate reasoning; on the negative side, this scheme is static in that it supports no updates, and has certain complexity drawbacks pointed out by Kavvadias, Papadimitriou and Sideri (1993). On the other hand, the many frameworks and schemes proposed in the literature for theory update and revision are plagued by serious complexity-theoretic impediments, even in the Horn case, as was pointed out by Eiter and Gottlob (1992), and is further demonstrated in the present paper. More fundamentally, these schemes are not inductive, in that they may lose in a single update any positive properties of the represented sets of formulas (small size, Horn structure, etc.). In this paper we propose a new scheme, incremental recompilation, which combines Horn approximation and model-based updates; this scheme is inductive and very efficient, free of the problems facing its constituents. A set of formulas is represented by an upper and lower Horn approximation. To update, we replace the upper Horn formula by the Horn envelope of its minimum-change update, and similarly the lower one by the Horn core of its update; the key fact which enables this scheme is that Horn envelopes and cores are easy to compute when the underlying formula is the result of a minimum-change update of a Horn formula by a clause. We conjecture that efficient algorithms are possible for more complex updates.
cs.AI:An important characteristic of many logics for Artificial Intelligence is their nonmonotonicity. This means that adding a formula to the premises can invalidate some of the consequences. There may, however, exist formulae that can always be safely added to the premises without destroying any of the consequences: we say they respect monotonicity. Also, there may be formulae that, when they are a consequence, can not be invalidated when adding any formula to the premises: we call them conservative. We study these two classes of formulae for preferential logics, and show that they are closely linked to the formulae whose truth-value is preserved along the (preferential) ordering. We will consider some preferential logics for illustration, and prove syntactic characterization results for them. The results in this paper may improve the efficiency of theorem provers for preferential logics.
cs.AI:Existing plan synthesis approaches in artificial intelligence fall into two categories -- domain independent and domain dependent. The domain independent approaches are applicable across a variety of domains, but may not be very efficient in any one given domain. The domain dependent approaches need to be (re)designed for each domain separately, but can be very efficient in the domain for which they are designed. One enticing alternative to these approaches is to automatically synthesize domain independent planners given the knowledge about the domain and the theory of planning. In this paper, we investigate the feasibility of using existing automated software synthesis tools to support such synthesis. Specifically, we describe an architecture called CLAY in which the Kestrel Interactive Development System (KIDS) is used to derive a domain-customized planner through a semi-automatic combination of a declarative theory of planning, and the declarative control knowledge specific to a given domain, to semi-automatically combine them to derive domain-customized planners. We discuss what it means to write a declarative theory of planning and control knowledge for KIDS, and illustrate our approach by generating a class of domain-specific planners using state space refinements. Our experiments show that the synthesized planners can outperform classical refinement planners (implemented as instantiations of UCP, Kambhampati & Srivastava, 1995), using the same control knowledge. We will contrast the costs and benefits of the synthesis approach with conventional methods for customizing domain independent planners.
cs.AI:This paper introduces new algorithms and data structures for quick counting for machine learning datasets. We focus on the counting task of constructing contingency tables, but our approach is also applicable to counting the number of records in a dataset that match conjunctive queries. Subject to certain assumptions, the costs of these operations can be shown to be independent of the number of records in the dataset and loglinear in the number of non-zero entries in the contingency table. We provide a very sparse data structure, the ADtree, to minimize memory use. We provide analytical worst-case bounds for this structure for several models of data distribution. We empirically demonstrate that tractably-sized data structures can be produced for large real-world datasets by (a) using a sparse tree structure that never allocates memory for counts of zero, (b) never allocating memory for counts that can be deduced from other counts, and (c) not bothering to expand the tree fully near its leaves. We show how the ADtree can be used to accelerate Bayes net structure finding algorithms, rule learning algorithms, and feature selection algorithms, and we provide a number of empirical results comparing ADtree methods against traditional direct counting approaches. We also discuss the possible uses of ADtrees in other machine learning methods, and discuss the merits of ADtrees in comparison with alternative representations such as kd-trees, R-trees and Frequent Sets.
cs.AI:In this paper we consider the problem of `theory patching', in which we are given a domain theory, some of whose components are indicated to be possibly flawed, and a set of labeled training examples for the domain concept. The theory patching problem is to revise only the indicated components of the theory, such that the resulting theory correctly classifies all the training examples. Theory patching is thus a type of theory revision in which revisions are made to individual components of the theory. Our concern in this paper is to determine for which classes of logical domain theories the theory patching problem is tractable. We consider both propositional and first-order domain theories, and show that the theory patching problem is equivalent to that of determining what information contained in a theory is `stable' regardless of what revisions might be performed to the theory. We show that determining stability is tractable if the input theory satisfies two conditions: that revisions to each theory component have monotonic effects on the classification of examples, and that theory components act independently in the classification of examples in the theory. We also show how the concepts introduced can be used to determine the soundness and completeness of particular theory patching algorithms.
cs.AI:In this paper we re-investigate windowing for rule learning algorithms. We show that, contrary to previous results for decision tree learning, windowing can in fact achieve significant run-time gains in noise-free domains and explain the different behavior of rule learning algorithms by the fact that they learn each rule independently. The main contribution of this paper is integrative windowing, a new type of algorithm that further exploits this property by integrating good rules into the final theory right after they have been discovered. Thus it avoids re-learning these rules in subsequent iterations of the windowing process. Experimental evidence in a variety of noise-free domains shows that integrative windowing can in fact achieve substantial run-time gains. Furthermore, we discuss the problem of noise in windowing and present an algorithm that is able to achieve run-time gains in a set of experiments in a simple domain with artificial noise.
cs.AI:This paper presents a comprehensive approach for model-based diagnosis which includes proposals for characterizing and computing preferred diagnoses, assuming that the system description is augmented with a system structure (a directed graph explicating the interconnections between system components). Specifically, we first introduce the notion of a consequence, which is a syntactically unconstrained propositional sentence that characterizes all consistency-based diagnoses and show that standard characterizations of diagnoses, such as minimal conflicts, correspond to syntactic variations on a consequence. Second, we propose a new syntactic variation on the consequence known as negation normal form (NNF) and discuss its merits compared to standard variations. Third, we introduce a basic algorithm for computing consequences in NNF given a structured system description. We show that if the system structure does not contain cycles, then there is always a linear-size consequence in NNF which can be computed in linear time. For arbitrary system structures, we show a precise connection between the complexity of computing consequences and the topology of the underlying system structure. Finally, we present an algorithm that enumerates the preferred diagnoses characterized by a consequence. The algorithm is shown to take linear time in the size of the consequence if the preference criterion satisfies some general conditions.
cs.AI:One of the most common mechanisms used for speeding up problem solvers is macro-learning. Macros are sequences of basic operators acquired during problem solving. Macros are used by the problem solver as if they were basic operators. The major problem that macro-learning presents is the vast number of macros that are available for acquisition. Macros increase the branching factor of the search space and can severely degrade problem-solving efficiency. To make macro learning useful, a program must be selective in acquiring and utilizing macros. This paper describes a general method for selective acquisition of macros. Solvable training problems are generated in increasing order of difficulty. The only macros acquired are those that take the problem solver out of a local minimum to a better state. The utility of the method is demonstrated in several domains, including the domain of NxN sliding-tile puzzles. After learning on small puzzles, the system is able to efficiently solve puzzles of any size.
cs.AI:We examine the computational complexity of testing and finding small plans in probabilistic planning domains with both flat and propositional representations. The complexity of plan evaluation and existence varies with the plan type sought; we examine totally ordered plans, acyclic plans, and looping plans, and partially ordered plans under three natural definitions of plan value. We show that problems of interest are complete for a variety of complexity classes: PL, P, NP, co-NP, PP, NP^PP, co-NP^PP, and PSPACE. In the process of proving that certain planning problems are complete for NP^PP, we introduce a new basic NP^PP-complete problem, E-MAJSAT, which generalizes the standard Boolean satisfiability problem to computations involving probabilistic quantities; our results suggest that the development of good heuristics for E-MAJSAT could be important for the creation of efficient algorithms for a wide variety of problems.
cs.AI:In this paper we describe SYNERGY, which is a highly parallelizable, linear planning system that is based on the genetic programming paradigm. Rather than reasoning about the world it is planning for, SYNERGY uses artificial selection, recombination and fitness measure to generate linear plans that solve conjunctive goals. We ran SYNERGY on several domains (e.g., the briefcase problem and a few variants of the robot navigation problem), and the experimental results show that our planner is capable of handling problem instances that are one to two orders of magnitude larger than the ones solved by UCPOP. In order to facilitate the search reduction and to enhance the expressive power of SYNERGY, we also propose two major extensions to our planning system: a formalism for using hierarchical planning operators, and a framework for planning in dynamic environments.
cs.AI:We show that several constraint propagation algorithms (also called (local) consistency, consistency enforcing, Waltz, filtering or narrowing algorithms) are instances of algorithms that deal with chaotic iteration. To this end we propose a simple abstract framework that allows us to classify and compare these algorithms and to establish in a uniform way their basic properties.
cs.AI:This paper examines the phenomenon of daydreaming: spontaneously recalling or imagining personal or vicarious experiences in the past or future. The following important roles of daydreaming in human cognition are postulated: plan preparation and rehearsal, learning from failures and successes, support for processes of creativity, emotion regulation, and motivation.   A computational theory of daydreaming and its implementation as the program DAYDREAMER are presented. DAYDREAMER consists of 1) a scenario generator based on relaxed planning, 2) a dynamic episodic memory of experiences used by the scenario generator, 3) a collection of personal goals and control goals which guide the scenario generator, 4) an emotion component in which daydreams initiate, and are initiated by, emotional states arising from goal outcomes, and 5) domain knowledge of interpersonal relations and common everyday occurrences.   The role of emotions and control goals in daydreaming is discussed. Four control goals commonly used in guiding daydreaming are presented: rationalization, failure/success reversal, revenge, and preparation. The role of episodic memory in daydreaming is considered, including how daydreamed information is incorporated into memory and later used. An initial version of DAYDREAMER which produces several daydreams (in English) is currently running.
cs.AI:Real world combinatorial optimization problems such as scheduling are typically too complex to solve with exact methods. Additionally, the problems often have to observe vaguely specified constraints of different importance, the available data may be uncertain, and compromises between antagonistic criteria may be necessary. We present a combination of approximate reasoning based constraints and iterative optimization based heuristics that help to model and solve such problems in a framework of C++ software libraries called StarFLIP++. While initially developed to schedule continuous caster units in steel plants, we present in this paper results from reusing the library components in a shift scheduling system for the workforce of an industrial production plant.
cs.AI:The study of belief change has been an active area in philosophy and AI. In recent years two special cases of belief change, belief revision and belief update, have been studied in detail. In a companion paper (Friedman & Halpern, 1997), we introduce a new framework to model belief change. This framework combines temporal and epistemic modalities with a notion of plausibility, allowing us to examine the change of beliefs over time. In this paper, we show how belief revision and belief update can be captured in our framework. This allows us to compare the assumptions made by each method, and to better understand the principles underlying them. In particular, it shows that Katsuno and Mendelzon's notion of belief update (Katsuno & Mendelzon, 1991a) depends on several strong assumptions that may limit its applicability in artificial intelligence. Finally, our analysis allow us to identify a notion of minimal change that underlies a broad range of belief change operations including revision and update.
cs.AI:How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations," which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations," which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations," grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z").
cs.AI:In tree search problem the best-first search algorithm needs too much of space . To remove such drawbacks of these algorithms the IDA* was developed which is both space and time cost efficient. But again IDA* can give an optimal solution for real valued problems like Flow shop scheduling, Travelling Salesman and 0/1 Knapsack due to their real valued cost estimates. Thus further modifications are done on it and the Iterative Deepening Branch and Bound Search Algorithms is developed which meets the requirements. We have tried using this algorithm for the Flow Shop Scheduling Problem and have found that it is quite effective.
cs.AI:Agents are small programs that autonomously take actions based on changes in their environment or ``state.'' Over the last few years, there have been an increasing number of efforts to build agents that can interact and/or collaborate with other agents. In one of these efforts, Eiter, Subrahmanian amd Pick (AIJ, 108(1-2), pages 179-255) have shown how agents may be built on top of legacy code. However, their framework assumes that agent states are completely determined, and there is no uncertainty in an agent's state. Thus, their framework allows an agent developer to specify how his agents will react when the agent is 100% sure about what is true/false in the world state. In this paper, we propose the concept of a \emph{probabilistic agent program} and show how, given an arbitrary program written in any imperative language, we may build a declarative ``probabilistic'' agent program on top of it which supports decision making in the presence of uncertainty. We provide two alternative semantics for probabilistic agent programs. We show that the second semantics, though more epistemically appealing, is more complex to compute. We provide sound and complete algorithms to compute the semantics of \emph{positive} agent programs.
cs.AI:The assumptions needed to prove Cox's Theorem are discussed and examined. Various sets of assumptions under which a Cox-style theorem can be proved are provided, although all are rather strong and, arguably, not natural.
cs.AI:We revisit the issue of connections between two leading formalisms in nonmonotonic reasoning: autoepistemic logic and default logic. For each logic we develop a comprehensive semantic framework based on the notion of a belief pair. The set of all belief pairs together with the so called knowledge ordering forms a complete lattice. For each logic, we introduce several semantics by means of fixpoints of operators on the lattice of belief pairs. Our results elucidate an underlying isomorphism of the respective semantic constructions. In particular, we show that the interpretation of defaults as modal formulas proposed by Konolige allows us to represent all semantics for default logic in terms of the corresponding semantics for autoepistemic logic. Thus, our results conclusively establish that default logic can indeed be viewed as a fragment of autoepistemic logic. However, as we also demonstrate, the semantics of Moore and Reiter are given by different operators and occupy different locations in their corresponding families of semantics. This result explains the source of the longstanding difficulty to formally relate these two semantics. In the paper, we also discuss approximating skeptical reasoning with autoepistemic and default logics and establish constructive principles behind such approximations.
cs.AI:Randomized algorithms for deciding satisfiability were shown to be effective in solving problems with thousands of variables. However, these algorithms are not complete. That is, they provide no guarantee that a satisfying assignment, if one exists, will be found. Thus, when studying randomized algorithms, there are two important characteristics that need to be considered: the running time and, even more importantly, the accuracy --- a measure of likelihood that a satisfying assignment will be found, provided one exists. In fact, we argue that without a reference to the accuracy, the notion of the running time for randomized algorithms is not well-defined. In this paper, we introduce a formal notion of accuracy. We use it to define a concept of the running time. We use both notions to study the random walk strategy GSAT algorithm. We investigate the dependence of accuracy on properties of input formulas such as clause-to-variable ratio and the number of satisfying assignments. We demonstrate that the running time of GSAT grows exponentially in the number of variables of the input formula for randomly generated 3-CNF formulas and for the formulas encoding 3- and 4-colorability of graphs.
cs.AI:Two different types of agency are discussed based on dynamically coherent and incoherent couplings with an environment respectively. I propose that until a private syntax (syntactic autonomy) is discovered by dynamically coherent agents, there are no significant or interesting types of closure or autonomy. When syntactic autonomy is established, then, because of a process of description-based selected self-organization, open-ended evolution is enabled. At this stage, agents depend, in addition to dynamics, on localized, symbolic memory, thus adding a level of dynamical incoherence to their interaction with the environment. Furthermore, it is the appearance of syntactic autonomy which enables much more interesting types of closures amongst agents which share the same syntax. To investigate how we can study the emergence of syntax from dynamical systems, experiments with cellular automata leading to emergent computation to solve non-trivial tasks are discussed. RNA editing is also mentioned as a process that may have been used to obtain a primordial biological code necessary open-ended evolution.
cs.AI:This paper presents a method of computing a revision of a function-free normal logic program. If an added rule is inconsistent with a program, that is, if it leads to a situation such that no stable model exists for a new program, then deletion and addition of rules are performed to avoid inconsistency. We specify a revision by translating a normal logic program into an abductive logic program with abducibles to represent deletion and addition of rules. To compute such deletion and addition, we propose an adaptation of our top-down abductive proof procedure to compute a relevant abducibles to an added rule. We compute a minimally revised program, by choosing a minimal set of abducibles among all the sets of abducibles computed by a top-down proof procedure.
cs.AI:This is a system description for the OSCAR defeasible reasoner.
cs.AI:Diagnostic reasoning has been characterized logically as consistency-based reasoning or abductive reasoning. Previous analyses in the literature have shown, on the one hand, that choosing the (in general more restrictive) abductive definition may be appropriate or not, depending on the content of the knowledge base [Console&Torasso91], and, on the other hand, that, depending on the choice of the definition the same knowledge should be expressed in different form [Poole94].   Since in Model-Based Diagnosis a major problem is finding the right way of abstracting the behavior of the system to be modeled, this paper discusses the relation between modeling, and in particular abstraction in the model, and the notion of diagnosis.
cs.AI:ACLP is a system which combines abductive reasoning and constraint solving by integrating the frameworks of Abductive Logic Programming (ALP) and Constraint Logic Programming (CLP). It forms a general high-level knowledge representation environment for abductive problems in Artificial Intelligence and other areas. In ACLP, the task of abduction is supported and enhanced by its non-trivial integration with constraint solving facilitating its application to complex problems. The ACLP system is currently implemented on top of the CLP language of ECLiPSe as a meta-interpreter exploiting its underlying constraint solver for finite domains. It has been applied to the problems of planning and scheduling in order to test its computational effectiveness compared with the direct use of the (lower level) constraint solving framework of CLP on which it is built. These experiments provide evidence that the abductive framework of ACLP does not compromise significantly the computational efficiency of the solutions. Other experiments show the natural ability of ACLP to accommodate easily and in a robust way new or changing requirements of the original problem.
cs.AI:We present a method for relevance sensitive non-monotonic inference from belief sequences which incorporates insights pertaining to prioritized inference and relevance sensitive, inconsistency tolerant belief revision.   Our model uses a finite, logically open sequence of propositional formulas as a representation for beliefs and defines a notion of inference from maxiconsistent subsets of formulas guided by two orderings: a temporal sequencing and an ordering based on relevance relations between the conclusion and formulas in the sequence. The relevance relations are ternary (using context as a parameter) as opposed to standard binary axiomatizations. The inference operation thus defined easily handles iterated revision by maintaining a revision history, blocks the derivation of inconsistent answers from a possibly inconsistent sequence and maintains the distinction between explicit and implicit beliefs. In doing so, it provides a finitely presented formalism and a plausible model of reasoning for automated agents.
cs.AI:We propose a combination of probabilistic reasoning from conditional constraints with approaches to default reasoning from conditional knowledge bases. In detail, we generalize the notions of Pearl's entailment in system Z, Lehmann's lexicographic entailment, and Geffner's conditional entailment to conditional constraints. We give some examples that show that the new notions of z-, lexicographic, and conditional entailment have similar properties like their classical counterparts. Moreover, we show that the new notions of z-, lexicographic, and conditional entailment are proper generalizations of both their classical counterparts and the classical notion of logical entailment for conditional constraints.
cs.AI:This paper describes a system, called PLP, for compiling ordered logic programs into standard logic programs under the answer set semantics. In an ordered logic program, rules are named by unique terms, and preferences among rules are given by a set of dedicated atoms. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed theory correspond with the preferred answer sets of the original theory. Since the result of the translation is an extended logic program, existing logic programming systems can be used as underlying reasoning engine. In particular, PLP is conceived as a front-end to the logic programming systems dlv and smodels.
cs.AI:The SLDNFA-system results from the LP+ project at the K.U.Leuven, which investigates logics and proof procedures for these logics for declarative knowledge representation. Within this project inductive definition logic (ID-logic) is used as representation logic. Different solvers are being developed for this logic and one of these is SLDNFA. A prototype of the system is available and used for investigating how to solve efficiently problems represented in ID-logic.
cs.AI:We describe an approach for compiling preferences into logic programs under the answer set semantics. An ordered logic program is an extended logic program in which rules are named by unique terms, and in which preferences among rules are given by a set of dedicated atoms. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed theory correspond with the preferred answer sets of the original theory. Our approach allows both the specification of static orderings (as found in most previous work), in which preferences are external to a logic program, as well as orderings on sets of rules. In large part then, we are interested in describing a general methodology for uniformly incorporating preference information in a logic program. Since the result of our translation is an extended logic program, we can make use of existing implementations, such as dlv and smodels. To this end, we have developed a compiler, available on the web, as a front-end for these programming systems.
cs.AI:This paper proposes two kinds of fuzzy abductive inference in the framework of fuzzy rule base. The abductive inference processes described here depend on the semantic of the rule. We distinguish two classes of interpretation of a fuzzy rule, certainty generation rules and possible generation rules. In this paper we present the architecture of abductive inference in the first class of interpretation. We give two kinds of problem that we can resolve by using the proposed models of inference.
cs.AI:The goal of the LP+ project at the K.U.Leuven is to design an expressive logic, suitable for declarative knowledge representation, and to develop intelligent systems based on Logic Programming technology for solving computational problems using the declarative specifications. The ID-logic is an integration of typed classical logic and a definition logic. Different abductive solvers for this language are being developed. This paper is a report of the integration of high order aggregates into ID-logic and the consequences on the solver SLDNFA.
cs.AI:We propose a new approach to belief revision that provides a way to change knowledge bases with a minimum of effort. We call this way of revising belief states optimal belief revision. Our revision method gives special attention to the fact that most belief revision processes are directed to a specific informational objective. This approach to belief change is founded on notions such as optimal context and accessibility. For the sentential model of belief states we provide both a formal description of contexts as sub-theories determined by three parameters and a method to construct contexts. Next, we introduce an accessibility ordering for belief sets, which we then use for selecting the best (optimal) contexts with respect to the processing effort involved in the revision. Then, for finitely axiomatizable knowledge bases, we characterize a finite accessibility ranking from which the accessibility ordering for the entire base is generated and show how to determine the ranking of an arbitrary sentence in the language. Finally, we define the adjustment of the accessibility ranking of a revised base of a belief set.
cs.AI:High-level robot controllers in realistic domains typically deal with processes which operate concurrently, change the world continuously, and where the execution of actions is event-driven as in ``charge the batteries as soon as the voltage level is low''. While non-logic-based robot control languages are well suited to express such scenarios, they fare poorly when it comes to projecting, in a conspicuous way, how the world evolves when actions are executed. On the other hand, a logic-based control language like \congolog, based on the situation calculus, is well-suited for the latter. However, it has problems expressing event-driven behavior. In this paper, we show how these problems can be overcome by first extending the situation calculus to support continuous change and event-driven behavior and then presenting \ccgolog, a variant of \congolog which is based on the extended situation calculus. One benefit of \ccgolog is that it narrows the gap in expressiveness compared to non-logic-based control languages while preserving a semantically well-founded projection mechanism.
cs.AI:The Smodels system implements the stable model semantics for normal logic programs. It handles a subclass of programs which contain no function symbols and are domain-restricted but supports extensions including built-in functions as well as cardinality and weight constraints. On top of this core engine more involved systems can be built. As an example, we have implemented total and partial stable model computation for disjunctive logic programs. An interesting application method is based on answer set programming, i.e., encoding an application problem as a set of rules so that its solutions are captured by the stable models of the rules. Smodels has been applied to a number of areas including planning, model checking, reachability analysis, product configuration, dynamic constraint satisfaction, and feature interaction.
cs.AI:E-RES is a system that implements the Language E, a logic for reasoning about narratives of action occurrences and observations. E's semantics is model-theoretic, but this implementation is based on a sound and complete reformulation of E in terms of argumentation, and uses general computational techniques of argumentation frameworks. The system derives sceptical non-monotonic consequences of a given reformulated theory which exactly correspond to consequences entailed by E's model-theory. The computation relies on a complimentary ability of the system to derive credulous non-monotonic consequences together with a set of supporting assumptions which is sufficient for the (credulous) conclusion to hold. E-RES allows theories to contain general action laws, statements about action occurrences, observations and statements of ramifications (or universal laws). It is able to derive consequences both forward and backward in time. This paper gives a short overview of the theoretical basis of E-RES and illustrates its use on a variety of examples. Currently, E-RES is being extended so that the system can be used for planning.
cs.AI:In this paper, we outline the prototype of an automated inference tool, called QUIP, which provides a uniform implementation for several nonmonotonic reasoning formalisms. The theoretical basis of QUIP is derived from well-known results about the computational complexity of nonmonotonic logics and exploits a representation of the different reasoning tasks in terms of quantified boolean formulae.
cs.AI:Over the past decade a considerable amount of research has been done to expand logic programming languages to handle incomplete information. One such language is the language of epistemic specifications. As is usual with logic programming languages, the problem of answering queries is intractable in the general case. For extended disjunctive logic programs, an idea that has proven useful in simplifying the investigation of answer sets is the use of splitting sets. In this paper we will present an extended definition of splitting sets that will be applicable to epistemic specifications. Furthermore, an extension of the splitting set theorem will be presented. Also, a characterization of stratified epistemic specifications will be given in terms of splitting sets. This characterization leads us to an algorithmic method of computing world views of a subclass of epistemic logic programs.
cs.AI:The US Data Encryption Standard, DES for short, is put forward as an interesting benchmark problem for nonmonotonic reasoning systems because (i) it provides a set of test cases of industrial relevance which shares features of randomly generated problems and real-world problems, (ii) the representation of DES using normal logic programs with the stable model semantics is simple and easy to understand, and (iii) this subclass of logic programs can be seen as an interesting special case for many other formalizations of nonmonotonic reasoning. In this paper we present two encodings of DES as logic programs: a direct one out of the standard specifications and an optimized one extending the work of Massacci and Marraro. The computational properties of the encodings are studied by using them for DES key search with the Smodels system as the implementation of the stable model semantics. Results indicate that the encodings and Smodels are quite competitive: they outperform state-of-the-art SAT-checkers working with an optimized encoding of DES into SAT and are comparable with a SAT-checker that is customized and tuned for the optimized SAT encoding.
cs.AI:We generalize a theorem by Francois Fages that describes the relationship between the completion semantics and the answer set semantics for logic programs with negation as failure. The study of this relationship is important in connection with the emergence of answer set programming. Whenever the two semantics are equivalent, answer sets can be computed by a satisfiability solver, and the use of answer set solvers such as smodels and dlv is unnecessary. A logic programming representation of the blocks world due to Ilkka Niemelae is discussed as an example.
cs.AI:We introduced decomposable negation normal form (DNNF) recently as a tractable form of propositional theories, and provided a number of powerful logical operations that can be performed on it in polynomial time. We also presented an algorithm for compiling any conjunctive normal form (CNF) into DNNF and provided a structure-based guarantee on its space and time complexity. We present in this paper a linear-time algorithm for converting an ordered binary decision diagram (OBDD) representation of a propositional theory into an equivalent DNNF, showing that DNNFs scale as well as OBDDs. We also identify a subclass of DNNF which we call deterministic DNNF, d-DNNF, and show that the previous complexity guarantees on compiling DNNF continue to hold for this stricter subclass, which has stronger properties. In particular, we present a new operation on d-DNNF which allows us to count its models under the assertion, retraction and flipping of every literal by traversing the d-DNNF twice. That is, after such traversal, we can test in constant-time: the entailment of any literal by the d-DNNF, and the consistency of the d-DNNF under the retraction or flipping of any literal. We demonstrate the significance of these new operations by showing how they allow us to implement linear-time, complete truth maintenance systems and linear-time, complete belief revision systems for two important classes of propositional theories.
cs.AI:The paper reports on first preliminary results and insights gained in a project aiming at implementing the fluent calculus using methods and techniques based on binary decision diagrams. After reporting on an initial experiment showing promising results we discuss our findings concerning various techniques and heuristics used to speed up the reasoning process.
cs.AI:Planning is a natural domain of application for frameworks of reasoning about actions and change. In this paper we study how one such framework, the Language E, can form the basis for planning under (possibly) incomplete information. We define two types of plans: weak and safe plans, and propose a planner, called the E-Planner, which is often able to extend an initial weak plan into a safe plan even though the (explicit) information available is incomplete, e.g. for cases where the initial state is not completely known. The E-Planner is based upon a reformulation of the Language E in argumentation terms and a natural proof theory resulting from the reformulation. It uses an extension of this proof theory by means of abduction for the generation of plans and adopts argumentation-based techniques for extending weak plans into safe plans. We provide representative examples illustrating the behaviour of the E-Planner, in particular for cases where the status of fluents is incompletely known.
cs.AI:In an earlier work, we have presented operations of belief change which only affect the relevant part of a belief base. In this paper, we propose the application of the same strategy to the problem of model-based diangosis. We first isolate the subset of the system description which is relevant for a given observation and then solve the diagnosis problem for this subset.
cs.AI:We present a general, consistency-based framework for belief change. Informally, in revising K by A, we begin with A and incorporate as much of K as consistently possible. Formally, a knowledge base K and sentence A are expressed, via renaming propositions in K, in separate languages. Using a maximization process, we assume the languages are the same insofar as consistently possible. Lastly, we express the resultant knowledge base in a single language. There may be more than one way in which A can be so extended by K: in choice revision, one such ``extension'' represents the revised state; alternately revision consists of the intersection of all such extensions.   The most general formulation of our approach is flexible enough to express other approaches to revision and update, the merging of knowledge bases, and the incorporation of static and dynamic integrity constraints. Our framework differs from work based on ordinal conditional functions, notably with respect to iterated revision. We argue that the approach is well-suited for implementation: the choice revision operator gives better complexity results than general revision; the approach can be expressed in terms of a finite knowledge base; and the scope of a revision can be restricted to just those propositions mentioned in the sentence for revision A.
cs.AI:SATEN is an object-oriented web-based extraction and belief revision engine. It runs on any computer via a Java 1.1 enabled browser such as Netscape 4. SATEN performs belief revision based on the AGM approach. The extraction and belief revision reasoning engines operate on a user specified ranking of information. One of the features of SATEN is that it can be used to integrate mutually inconsistent commensuate rankings into a consistent ranking.
cs.AI:Answer-set programming (ASP) has emerged recently as a viable programming paradigm. We describe here an ASP system, DATALOG with constraints or DC, based on non-monotonic logic. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules. The semantics is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax, use and implementation of DC and provide experimental results.
cs.AI:Answer-set programming (ASP) has emerged recently as a viable programming paradigm well attuned to search problems in AI, constraint satisfaction and combinatorics. Propositional logic is, arguably, the simplest ASP system with an intuitive semantics supporting direct modeling of problem constraints. However, for some applications, especially those requiring that transitive closure be computed, it requires additional variables and results in large theories. Consequently, it may not be a practical computational tool for such problems. On the other hand, ASP systems based on nonmonotonic logics, such as stable logic programming, can handle transitive closure computation efficiently and, in general, yield very concise theories as problem representations. Their semantics is, however, more complex. Searching for the middle ground, in this paper we introduce a new nonmonotonic logic, DATALOG with constraints or DC. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules. The semantics is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax and semantics of DC, and study its properties. We discuss an implementation of DC and present results of experimental study of the effectiveness of DC, comparing it with CSAT, a satisfiability checker and SMODELS implementation of stable logic programming. Our results show that DC is competitive with the other two approaches, in case of many search problems, often yielding much more efficient solutions.
cs.AI:We study here the well-known propagation rules for Boolean constraints. First we propose a simple notion of completeness for sets of such rules and establish a completeness result. Then we show an equivalence in an appropriate sense between Boolean constraint propagation and unit propagation, a form of resolution for propositional logic.   Subsequently we characterize one set of such rules by means of the notion of hyper-arc consistency introduced in (Mohr and Masini 1988). Also, we clarify the status of a similar, though different, set of rules introduced in (Simonis 1989a) and more fully in (Codognet and Diaz 1996).
cs.AI:A general notion of algebraic conditional plausibility measures is defined. Probability measures, ranking functions, possibility measures, and (under the appropriate definitions) sets of probability measures can all be viewed as defining algebraic conditional plausibility measures. It is shown that algebraic conditional plausibility measures can be represented using Bayesian networks.
cs.AI:In this paper we present a rule based formalism for filtering variables domains of constraints. This formalism is well adapted for solving dynamic CSP. We take diagnosis as an instance problem to illustrate the use of these rules. A diagnosis problem is seen like finding all the minimal sets of constraints to be relaxed in the constraint network that models the device to be diagnosed
cs.AI:Despite the effort of many researchers in the area of multi-agent systems (MAS) for designing and programming agents, a few years ago the research community began to take into account that common features among different MAS exists. Based on these common features, several tools have tackled the problem of agent development on specific application domains or specific types of agents. As a consequence, their scope is restricted to a subset of the huge application domain of MAS. In this paper we propose a generic infrastructure for programming agents whose name is Brainstorm/J. The infrastructure has been implemented as an object oriented framework. As a consequence, our approach supports a broader scope of MAS applications than previous efforts, being flexible and reusable.
cs.AI:In fuzzy propositional logic, to a proposition a partial truth in [0,1] is assigned. It is well known that under certain circumstances, fuzzy logic collapses to classical logic. In this paper, we will show that under dual conditions, fuzzy logic collapses to four-valued (relevance) logic, where propositions have truth-value true, false, unknown, or contradiction. As a consequence, fuzzy entailment may be considered as ``in between'' four-valued (relevance) entailment and classical entailment.
cs.AI:We propose a new definition of actual cause, using structural equations to model counterfactuals. We show that the definition yields a plausible and elegant account of causation that handles well examples which have caused problems for other definitions and resolves major difficulties in the traditional account.
cs.AI:Many logic programming based approaches can be used to describe and solve combinatorial search problems. On the one hand there is constraint logic programming which computes a solution as an answer substitution to a query containing the variables of the constraint satisfaction problem. On the other hand there are systems based on stable model semantics, abductive systems, and first order logic model generators which compute solutions as models of some theory. This paper compares these different approaches from the point of view of knowledge representation (how declarative are the programs) and from the point of view of performance (how good are they at solving typical problems).
cs.AI:In this paper, we introduce a new machine learning theory based on multi-channel parallel adaptation for rule discovery. This theory is distinguished from the familiar parallel-distributed adaptation theory of neural networks in terms of channel-based convergence to the target rules. We show how to realize this theory in a learning system named CFRule. CFRule is a parallel weight-based model, but it departs from traditional neural computing in that its internal knowledge is comprehensible. Furthermore, when the model converges upon training, each channel converges to a target rule. The model adaptation rule is derived by multi-level parallel weight optimization based on gradient descent. Since, however, gradient descent only guarantees local optimization, a multi-channel regression-based optimization strategy is developed to effectively deal with this problem. Formally, we prove that the CFRule model can explicitly and precisely encode any given rule set. Also, we prove a property related to asynchronous parallel convergence, which is a critical element of the multi-channel parallel adaptation theory for rule learning. Thanks to the quantizability nature of the CFRule model, rules can be extracted completely and soundly via a threshold-based mechanism. Finally, the practical application of the theory is demonstrated in DNA promoter recognition and hepatitis prognosis prediction.
cs.AI:We present an approach for modelling the structure and coarse content of legal documents with a view to providing automated support for the drafting of contracts and contract database retrieval. The approach is designed to be applicable where contract drafting is based on model-form contracts or on existing examples of a similar type. The main features of the approach are: (1) the representation addresses the structure and the interrelationships between the constituent parts of contracts, but not the text of the document itself; (2) the representation of documents is separated from the mechanisms that manipulate it; and (3) the drafting process is subject to a collection of explicitly stated constraints that govern the structure of the documents. We describe the representation of document instances and of 'generic documents', which are data structures used to drive the creation of new document instances, and we show extracts from a sample session to illustrate the features of a prototype system implemented in MacProlog.
cs.AI:One influential approach to assessing the "goodness" of arguments is offered by the Pragma-Dialectical school (p-d) (Eemeren & Grootendorst 1992). This can be compared with Rhetorical Structure Theory (RST) (Mann & Thompson 1988), an approach that originates in discourse analysis. In p-d terms an argument is good if it avoids committing a fallacy, whereas in RST terms an argument is good if it is coherent. RST has been criticised (Snoeck Henkemans 1997) for providing only a partially functional account of argument, and similar criticisms have been raised in the Natural Language Generation (NLG) community-particularly by Moore & Pollack (1992)- with regards to its account of intentionality in text in general. Mann and Thompson themselves note that although RST can be successfully applied to a wide range of texts from diverse domains, it fails to characterise some types of text, most notably legal contracts. There is ongoing research in the Artificial Intelligence and Law community exploring the potential for providing electronic support to contract negotiators, focusing on long-term, complex engineering agreements (see for example Daskalopulu & Sergot 1997). This paper provides a brief introduction to RST and illustrates its shortcomings with respect to contractual text. An alternative approach for modelling argument structure is presented which not only caters for contractual text, but also overcomes the aforementioned limitations of RST.
cs.AI:Information Integration is a young and exciting field with enormous research and commercial significance in the new world of the Information Society. It stands at the crossroad of Databases and Artificial Intelligence requiring novel techniques that bring together different methods from these fields. Information from disparate heterogeneous sources often with no a-priori common schema needs to be synthesized in a flexible, transparent and intelligent way in order to respond to the demands of a query thus enabling a more informed decision by the user or application program. The field although relatively young has already found many practical applications particularly for integrating information over the World Wide Web. This paper gives a brief introduction of the field highlighting some of the main current and future research issues and application areas. It attempts to evaluate the current and potential role of Computational Logic in this and suggests some of the problems where logic-based techniques could be used.
cs.AI:Constraint propagation is a general algorithmic approach for pruning the search space of a CSP. In a uniform way, K. R. Apt has defined a computation as an iteration of reduction functions over a domain. He has also demonstrated the need for integrating static properties of reduction functions (commutativity and semi-commutativity) to design specialized algorithms such as AC3 and DAC. We introduce here a set of operators for modeling compositions of reduction functions. Two of the major goals are to tackle parallel computations, and dynamic behaviours (such as slow convergence).
cs.AI:We consider an approach to update nonmonotonic knowledge bases represented as extended logic programs under answer set semantics. New information is incorporated into the current knowledge base subject to a causal rejection principle enforcing that, in case of conflicts, more recent rules are preferred and older rules are overridden. Such a rejection principle is also exploited in other approaches to update logic programs, e.g., in dynamic logic programming by Alferes et al. We give a thorough analysis of properties of our approach, to get a better understanding of the causal rejection principle. We review postulates for update and revision operators from the area of theory change and nonmonotonic reasoning, and some new properties are considered as well. We then consider refinements of our semantics which incorporate a notion of minimality of change. As well, we investigate the relationship to other approaches, showing that our approach is semantically equivalent to inheritance programs by Buccafurri et al. and that it coincides with certain classes of dynamic logic programs, for which we provide characterizations in terms of graph conditions. Therefore, most of our results about properties of causal rejection principle apply to these approaches as well. Finally, we deal with computational complexity of our approach, and outline how the update semantics and its refinements can be implemented on top of existing logic programming engines.
cs.AI:We introduce a learning method called ``gradient-based reinforcement planning'' (GREP). Unlike traditional DP methods that improve their policy backwards in time, GREP is a gradient-based method that plans ahead and improves its policy before it actually acts in the environment. We derive formulas for the exact policy gradient that maximizes the expected future reward and confirm our ideas with numerical experiments.
cs.AI:Much work in computer science has adopted competitive analysis as a tool for decision making under uncertainty. In this work we extend competitive analysis to the context of multi-agent systems. Unlike classical competitive analysis where the behavior of an agent's environment is taken to be arbitrary, we consider the case where an agent's environment consists of other agents. These agents will usually obey some (minimal) rationality constraints. This leads to the definition of rational competitive analysis. We introduce the concept of rational competitive analysis, and initiate the study of competitive analysis for multi-agent systems. We also discuss the application of rational competitive analysis to the context of bidding games, as well as to the classical one-way trading problem.
cs.AI:This article aims at clarifying the language and practice of scientific experiment, mainly by hooking observability on calculability.
cs.AI:Many systems that exhibit nonmonotonic behavior have been described and studied already in the literature. The general notion of nonmonotonic reasoning, though, has almost always been described only negatively, by the property it does not enjoy, i.e. monotonicity. We study here general patterns of nonmonotonic reasoning and try to isolate properties that could help us map the field of nonmonotonic reasoning by reference to positive properties. We concentrate on a number of families of nonmonotonic consequence relations, defined in the style of Gentzen. Both proof-theoretic and semantic points of view are developed in parallel. The former point of view was pioneered by D. Gabbay, while the latter has been advocated by Y. Shoham in. Five such families are defined and characterized by representation theorems, relating the two points of view. One of the families of interest, that of preferential relations, turns out to have been studied by E. Adams. The "preferential" models proposed here are a much stronger tool than Adams' probabilistic semantics. The basic language used in this paper is that of propositional logic. The extension of our results to first order predicate calculi and the study of the computational complexity of the decision problems described in this paper will be treated in another paper.
cs.AI:This paper presents a logical approach to nonmonotonic reasoning based on the notion of a nonmonotonic consequence relation. A conditional knowledge base, consisting of a set of conditional assertions of the type "if ... then ...", represents the explicit defeasible knowledge an agent has about the way the world generally behaves. We look for a plausible definition of the set of all conditional assertions entailed by a conditional knowledge base. In a previous paper, S. Kraus and the authors defined and studied "preferential" consequence relations. They noticed that not all preferential relations could be considered as reasonable inference procedures. This paper studies a more restricted class of consequence relations, "rational" relations. It is argued that any reasonable nonmonotonic inference procedure should define a rational relation. It is shown that the rational relations are exactly those that may be represented by a "ranked" preferential model, or by a (non-standard) probabilistic model. The rational closure of a conditional knowledge base is defined and shown to provide an attractive answer to the question of the title. Global properties of this closure operation are proved: it is a cumulative operation. It is also computationally tractable. This paper assumes the underlying language is propositional.
cs.AI:It is shown that Darwiche and Pearl's postulates imply an interesting property, not noticed by the authors.
cs.AI:A vast and interesting family of natural semantics for belief revision is defined. Suppose one is given a distance d between any two models. One may then define the revision of a theory K by a formula a as the theory defined by the set of all those models of a that are closest, by d, to the set of models of K. This family is characterized by a set of rationality postulates that extends the AGM postulates. The new postulates describe properties of iterated revisions.
cs.AI:We give a semantics to iterated update by a preference relation on possible developments. An iterated update is a sequence of formulas, giving (incomplete) information about successive states of the world. A development is a sequence of models, describing a possible trajectory through time. We assume a principle of inertia and prefer those developments, which are compatible with the information, and avoid unnecessary changes. The logical properties of the updates defined in this way are considered, and a representation result is proved.
cs.AI:A. Tarski proposed the study of infinitary consequence operations as the central topic of mathematical logic. He considered monotonicity to be a property of all such operations. In this paper, we weaken the monotonicity requirement and consider more general operations, inference operations. These operations describe the nonmonotonic logics both humans and machines seem to be using when infering defeasible information from incomplete knowledge. We single out a number of interesting families of inference operations. This study of infinitary inference operations is inspired by the results of Kraus, Lehmann and Magidor on finitary nonmonotonic operations, but this paper is self-contained.
cs.AI:The Expansion property considered by researchers in Social Choice is shown to correspond to a logical property of nonmonotonic consequence relations that is the {\em pure}, i.e., not involving connectives, version of a previously known weak rationality condition. The assumption that the union of two definable sets of models is definable is needed for the soundness part of the result.
cs.AI:The lexicographic closure of any given finite set D of normal defaults is defined. A conditional assertion "if a then b" is in this lexicographic closure if, given the defaults D and the fact a, one would conclude b. The lexicographic closure is essentially a rational extension of D, and of its rational closure, defined in a previous paper. It provides a logic of normal defaults that is different from the one proposed by R. Reiter and that is rich enough not to require the consideration of non-normal defaults. A large number of examples are provided to show that the lexicographic closure corresponds to the basic intuitions behind Reiter's logic of defaults.
cs.AI:We provide a characterization of those nonmonotonic inference operations C for which C(X) may be described as the set of all logical consequences of X together with some set of additional assumptions S(X) that depends anti-monotonically on X (i.e., X is a subset of Y implies that S(Y) is a subset of S(X)). The operations represented are exactly characterized in terms of properties most of which have been studied in Freund-Lehmann(cs.AI/0202031). Similar characterizations of right-absorbing and cumulative operations are also provided. For cumulative operations, our results fit in closely with those of Freund. We then discuss extending finitary operations to infinitary operations in a canonical way and discuss co-compactness properties. Our results provide a satisfactory notion of pseudo-compactness, generalizing to deductive nonmonotonic operations the notion of compactness for monotonic operations. They also provide an alternative, more elegant and more general, proof of the existence of an infinitary deductive extension for any finitary deductive operation (Theorem 7.9 of Freund-Lehmann).
cs.AI:Stereotypical reasoning assumes that the situation at hand is one of a kind and that it enjoys the properties generally associated with that kind of situation. It is one of the most basic forms of nonmonotonic reasoning. A formal model for stereotypical reasoning is proposed and the logical properties of this form of reasoning are studied. Stereotypical reasoning is shown to be cumulative under weak assumptions.
cs.AI:We introduce a methodology and framework for expressing general preference information in logic programming under the answer set semantics. An ordered logic program is an extended logic program in which rules are named by unique terms, and in which preferences among rules are given by a set of atoms of form s < t where s and t are names. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed program correspond with the preferred answer sets of the original program. Our approach allows the specification of dynamic orderings, in which preferences can appear arbitrarily within a program. Static orderings (in which preferences are external to a logic program) are a trivial restriction of the general dynamic case. First, we develop a specific approach to reasoning with preferences, wherein the preference ordering specifies the order in which rules are to be applied. We then demonstrate the wide range of applicability of our framework by showing how other approaches, among them that of Brewka and Eiter, can be captured within our framework. Since the result of each of these transformations is an extended logic program, we can make use of existing implementations, such as dlv and smodels. To this end, we have developed a publicly available compiler as a front-end for these programming systems.
cs.AI:Prioritized default reasoning has illustrated its rich expressiveness and flexibility in knowledge representation and reasoning. However, many important aspects of prioritized default reasoning have yet to be thoroughly explored. In this paper, we investigate two properties of prioritized logic programs in the context of answer set semantics. Specifically, we reveal a close relationship between mutual defeasibility and uniqueness of the answer set for a prioritized logic program. We then explore how the splitting technique for extended logic programs can be extended to prioritized logic programs. We prove splitting theorems that can be used to simplify the evaluation of a prioritized logic program under certain conditions.
cs.AI:The (extended) AGM postulates for belief revision seem to deal with the revision of a given theory K by an arbitrary formula, but not to constrain the revisions of two different theories by the same formula. A new postulate is proposed and compared with other similar postulates that have been proposed in the literature. The AGM revisions that satisfy this new postulate stand in one-to-one correspondence with the rational, consistency-preserving relations. This correspondence is described explicitly. Two viewpoints on iterative revisions are distinguished and discussed.
cs.AI:We study fixpoints of operators on lattices. To this end we introduce the notion of an approximation of an operator. We order approximations by means of a precision ordering. We show that each lattice operator O has a unique most precise or ultimate approximation. We demonstrate that fixpoints of this ultimate approximation provide useful insights into fixpoints of the operator O.   We apply our theory to logic programming and introduce the ultimate Kripke-Kleene, well-founded and stable semantics. We show that the ultimate Kripke-Kleene and well-founded semantics are more precise then their standard counterparts We argue that ultimate semantics for logic programming have attractive epistemological properties and that, while in general they are computationally more complex than the standard semantics, for many classes of theories, their complexity is no worse.
cs.AI:Representing defeasibility is an important issue in common sense reasoning. In reasoning about action and change, this issue becomes more difficult because domain and action related defeasible information may conflict with general inertia rules. Furthermore, different types of defeasible information may also interfere with each other during the reasoning. In this paper, we develop a prioritized logic programming approach to handle defeasibilities in reasoning about action. In particular, we propose three action languages {\cal AT}^{0}, {\cal AT}^{1} and {\cal AT}^{2} which handle three types of defeasibilities in action domains named defeasible constraints, defeasible observations and actions with defeasible and abnormal effects respectively. Each language with a higher superscript can be viewed as an extension of the language with a lower superscript. These action languages inherit the simple syntax of {\cal A} language but their semantics is developed in terms of transition systems where transition functions are defined based on prioritized logic programs. By illustrating various examples, we show that our approach eventually provides a powerful mechanism to handle various defeasibilities in temporal prediction and postdiction. We also investigate semantic properties of these three action languages and characterize classes of action domains that present more desirable solutions in reasoning about action within the underlying action languages.
cs.AI:An anticipatory system for guiding plot development in interactive narratives is described. The executable model is a finite automaton that provides the implemented system with a look-ahead. The identification of undesirable future states in the model is used to guide the player, in a transparent manner. In this way, too radical twists of the plot can be avoided. Since the player participates in the development of the plot, such guidance can have many forms, depending on the environment of the player, on the behavior of the other players, and on the means of player interaction. We present a design method for interactive narratives which produces designs suitable for the implementation of anticipatory mechanisms. Use of the method is illustrated by application to our interactive computer game Kaktus.
cs.AI:Open logic programs and open entailment have been recently proposed as an abstract framework for the verification of incomplete specifications based upon normal logic programs and the stable model semantics. There are obvious analogies between open predicates and abducible predicates. However, despite superficial similarities, there are features of open programs that have no immediate counterpart in the framework of abduction and viceversa. Similarly, open programs cannot be immediately simulated with answer set programming (ASP). In this paper we start a thorough investigation of the relationships between open inference, abduction and ASP. We shall prove that open programs generalize the other two frameworks. The generalized framework suggests interesting extensions of abduction under the generalized stable model semantics. In some cases, we will be able to reduce open inference to abduction and ASP, thereby estimating its computational complexity. At the same time, the aforementioned reduction opens the way to new applications of abduction and ASP.
cs.AI:In this paper we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set semantics (AnsProlog*). AnsProlog* is designed to plan without control knowledge. We show how temporal, procedural and HTN-based control knowledge can be incorporated into AnsProlog* by the modular addition of a small number of domain-dependent rules, without the need to modify the planner. We formally prove the correctness of our planner, both in the absence and presence of the control knowledge. Finally, we perform some initial experimentation that demonstrates the potential reduction in planning time that can be achieved when procedural domain knowledge is used to solve planning problems with large plan length.
cs.AI:Dung's abstract framework for argumentation enables a study of the interactions between arguments based solely on an ``attack'' binary relation on the set of arguments. Various ways to solve conflicts between contradictory pieces of information have been proposed in the context of argumentation, nonmonotonic reasoning or logic programming, and can be captured by appropriate semantics within Dung's framework. A common feature of these semantics is that one can always maximize in some sense the set of acceptable arguments. We propose in this paper to extend Dung's framework in order to allow for the representation of what we call ``restricted'' arguments: these arguments should only be used if absolutely necessary, that is, in order to support other arguments that would otherwise be defeated. We modify Dung's preferred semantics accordingly: a set of arguments becomes acceptable only if it contains a minimum of restricted arguments, for a maximum of unrestricted arguments.
cs.AI:We address a general representation problem for belief change, and describe two interrelated representations for iterative non-prioritized change: a logical representation in terms of persistent epistemic states, and a constructive representation in terms of flocks of bases.
cs.AI:An extension of an abstract argumentation framework, called collective argumentation, is introduced in which the attack relation is defined directly among sets of arguments. The extension turns out to be suitable, in particular, for representing semantics of disjunctive logic programs. Two special kinds of collective argumentation are considered in which the opponents can share their arguments.
cs.AI:Logic programs with ordered disjunction (LPODs) combine ideas underlying Qualitative Choice Logic (Brewka et al. KR 2002) and answer set programming. Logic programming under answer set semantics is extended with a new connective called ordered disjunction. The new connective allows us to represent alternative, ranked options for problem solutions in the heads of rules: A \times B intuitively means: if possible A, but if A is not possible then at least B. The semantics of logic programs with ordered disjunction is based on a preference relation on answer sets. LPODs are useful for applications in design and configuration and can serve as a basis for qualitative decision making.
cs.AI:In this paper, we investigate the extent to which knowledge compilation can be used to improve inference from propositional weighted bases. We present a general notion of compilation of a weighted base that is parametrized by any equivalence--preserving compilation function. Both negative and positive results are presented. On the one hand, complexity results are identified, showing that the inference problem from a compiled weighted base is as difficult as in the general case, when the prime implicates, Horn cover or renamable Horn cover classes are targeted. On the other hand, we show that the inference problem becomes tractable whenever DNNF-compilations are used and clausal queries are considered. Moreover, we show that the set of all preferred models of a DNNF-compilation of a weighted base can be computed in time polynomial in the output size. Finally, we sketch how our results can be used in model-based diagnosis in order to compute the most probable diagnoses of a system.
cs.AI:This paper studies the problem of modeling complex domains of actions and change within high-level action description languages. We investigate two main issues of concern: (a) can we represent complex domains that capture together different problems such as ramifications, non-determinism and concurrency of actions, at a high-level, close to the given natural ontology of the problem domain and (b) what features of such a representation can affect, and how, its computational behaviour. The paper describes the main problems faced in this representation task and presents the results of an empirical study, carried out through a series of controlled experiments, to analyze the computational performance of reasoning in these representations. The experiments compare different representations obtained, for example, by changing the basic ontology of the domain or by varying the degree of use of indirect effect laws through domain constraints. This study has helped to expose the main sources of computational difficulty in the reasoning and suggest some methodological guidelines for representing complex domains. Although our work has been carried out within one particular high-level description language, we believe that the results, especially those that relate to the problems of representation, are independent of the specific modeling language.
cs.AI:This paper introduces the notion of value-based argumentation frameworks, an extension of the standard argumentation frameworks proposed by Dung, which are able toshow how rational decision is possible in cases where arguments derive their force from the social values their acceptance would promote.
cs.AI:We analyze the problem of defining well-founded semantics for ordered logic programs within a general framework based on alternating fixpoint theory. We start by showing that generalizations of existing answer set approaches to preference are too weak in the setting of well-founded semantics. We then specify some informal yet intuitive criteria and propose a semantical framework for preference handling that is more suitable for defining well-founded semantics for ordered logic programs. The suitability of the new approach is convinced by the fact that many attractive properties are satisfied by our semantics. In particular, our semantics is still correct with respect to various existing answer sets semantics while it successfully overcomes the weakness of their generalization to well-founded semantics. Finally, we indicate how an existing preferred well-founded semantics can be captured within our semantical framework.
cs.AI:In this paper we present a transformation of finite propositional default theories into so-called propositional argumentation systems. This transformation allows to characterize all notions of Reiter's default logic in the framework of argumentation systems. As a consequence, computing extensions, or determining wether a given formula belongs to one extension or all extensions can be answered without leaving the field of classical propositional logic. The transformation proposed is linear in the number of defaults.
cs.AI:In the present paper, the existence and multiplicity problems of extensions are addressed. The focus is on extension of the stable type. The main result of the paper is an elegant characterization of the existence and multiplicity of extensions in terms of the notion of dialectical justification, a close cousin of the notion of admissibility. The characterization is given in the context of the particular logic for dialectical argumentation DEFLOG. The results are of direct relevance for several well-established models of defeasible reasoning (like default logic, logic programming and argumentation frameworks), since elsewhere dialectical argumentation has been shown to have close formal connections with these models.
cs.AI:Recently, it has been shown that probabilistic entailment under coherence is weaker than model-theoretic probabilistic entailment. Moreover, probabilistic entailment under coherence is a generalization of default entailment in System P. In this paper, we continue this line of research by presenting probabilistic generalizations of more sophisticated notions of classical default entailment that lie between model-theoretic probabilistic entailment and probabilistic entailment under coherence. That is, the new formalisms properly generalize their counterparts in classical default reasoning, they are weaker than model-theoretic probabilistic entailment, and they are stronger than probabilistic entailment under coherence. The new formalisms are useful especially for handling probabilistic inconsistencies related to conditioning on zero events. They can also be applied for probabilistic belief revision. More generally, in the same spirit as a similar previous paper, this paper sheds light on exciting new formalisms for probabilistic reasoning beyond the well-known standard ones.
cs.AI:We seek to find normative criteria of adequacy for nonmonotonic logic similar to the criterion of validity for deductive logic. Rather than stipulating that the conclusion of an inference be true in all models in which the premises are true, we require that the conclusion of a nonmonotonic inference be true in ``almost all'' models of a certain sort in which the premises are true. This ``certain sort'' specification picks out the models that are relevant to the inference, taking into account factors such as specificity and vagueness, and previous inferences. The frequencies characterizing the relevant models reflect known frequencies in our actual world. The criteria of adequacy for a default inference can be extended by thresholding to criteria of adequacy for an extension. We show that this avoids the implausibilities that might otherwise result from the chaining of default inferences. The model proportions, when construed in terms of frequencies, provide a verifiable grounding of default rules, and can become the basis for generating default rules from statistics.
cs.AI:About ten years ago, various notions of preferential entailment have been introduced. The main reference is a paper by Kraus, Lehmann and Magidor (KLM), one of the main competitor being a more general version defined by Makinson (MAK). These two versions have already been compared, but it is time to revisit these comparisons. Here are our three main results: (1) These two notions are equivalent, provided that we restrict our attention, as done in KLM, to the cases where the entailment respects logical equivalence (on the left and on the right). (2) A serious simplification of the description of the fundamental cases in which MAK is equivalent to KLM, including a natural passage in both ways. (3) The two previous results are given for preferential entailments more general than considered in some of the original texts, but they apply also to the original definitions and, for this particular case also, the models can be simplified.
cs.AI:This work analyses main features that should be present in knowledge representation. It suggests a model for representation and a way to implement this model in software. Representation takes care of both low-level sensor information and high-level concepts.
cs.AI:We propose new definitions of (causal) explanation, using structural equations to model counterfactuals. The definition is based on the notion of actual cause, as defined and motivated in a companion paper. Essentially, an explanation is a fact that is not known for certain but, if found to be true, would constitute an actual cause of the fact to be explained, regardless of the agent's initial uncertainty. We show that the definition handles well a number of problematic examples from the literature.
cs.AI:Recently, several approaches to updating knowledge bases modeled as extended logic programs have been introduced, ranging from basic methods to incorporate (sequences of) sets of rules into a logic program, to more elaborate methods which use an update policy for specifying how updates must be incorporated. In this paper, we introduce a framework for reasoning about evolving knowledge bases, which are represented as extended logic programs and maintained by an update policy. We first describe a formal model which captures various update approaches, and we define a logical language for expressing properties of evolving knowledge bases. We then investigate semantical and computational properties of our framework, where we focus on properties of knowledge states with respect to the canonical reasoning task of whether a given formula holds on a given evolving knowledge base. In particular, we present finitary characterizations of the evolution for certain classes of framework instances, which can be exploited for obtaining decidability results. In more detail, we characterize the complexity of reasoning for some meaningful classes of evolving knowledge bases, ranging from polynomial to double exponential space complexity.
cs.AI:In this thesis I present a virtual laboratory which implements five different models for controlling animats: a rule-based system, a behaviour-based system, a concept-based system, a neural network, and a Braitenberg architecture. Through different experiments, I compare the performance of the models and conclude that there is no "best" model, since different models are better for different things in different contexts.   The models I chose, although quite simple, represent different approaches for studying cognition. Using the results as an empirical philosophical aid,   I note that there is no "best" approach for studying cognition, since different approaches have all advantages and disadvantages, because they study different aspects of cognition from different contexts. This has implications for current debates on "proper" approaches for cognition: all approaches are a bit proper, but none will be "proper enough". I draw remarks on the notion of cognition abstracting from all the approaches used to study it, and propose a simple classification for different types of cognition.
cs.AI:This paper deals with the revision of partially ordered beliefs. It proposes a semantic representation of epistemic states by partial pre-orders on interpretations and a syntactic representation by partially ordered belief bases. Two revision operations, the revision stemming from the history of observations and the possibilistic revision, defined when the epistemic state is represented by a total pre-order, are generalized, at a semantic level, to the case of a partial pre-order on interpretations, and at a syntactic level, to the case of a partially ordered belief base. The equivalence between the two representations is shown for the two revision operations.
cs.AI:This is the first in a series of connected papers discussing the problem of a dynamically reconfigurable universal learning neurocomputer that could serve as a computational model for the whole human brain. The whole series is entitled "The Brain Zero Project. My Brain as a Dynamically Reconfigurable Universal Learning Neurocomputer." (For more information visit the website www.brain0.com.) This introductory paper is concerned with general methodology. Its main goal is to explain why it is critically important for both neural modeling and cognitive modeling to pay much attention to the basic requirements of the whole brain as a complex computing system. The author argues that it can be easier to develop an adequate computational model for the whole "unprogrammed" (untrained) human brain than to find adequate formal representations of some nontrivial parts of brain's performance. (In the same way as, for example, it is easier to describe the behavior of a complex analytical function than the behavior of its real and/or imaginary part.) The "curse of dimensionality" that plagues purely phenomenological ("brainless") cognitive theories is a natural penalty for an attempt to represent insufficiently large parts of brain's performance in a state space of insufficiently high dimensionality. A "partial" modeler encounters "Catch 22." An attempt to simplify a cognitive problem by artificially reducing its dimensionality makes the problem more difficult.
cs.AI:As a part of our effort for studying the evolution and development of cognition, we present results derived from synthetic experimentations in a virtual laboratory where animats develop koncepts adaptively and ground their meaning through action. We introduce the term "koncept" to avoid confusions and ambiguity derived from the wide use of the word "concept". We present the models which our animats use for abstracting koncepts from perceptions, plastically adapt koncepts, and associate koncepts with actions. On a more philosophical vein, we suggest that knowledge is a property of a cognitive system, not an element, and therefore observer-dependent.
cs.AI:This paper presents a model for dynamic adjustment of the motivation degree, using a reinforcement learning approach, in an action selection mechanism previously developed by the authors. The learning takes place in the modification of a parameter of the model of combination of internal and external stimuli. Experiments that show the claimed properties are presented, using a VR simulation developed for such purposes. The importance of adaptation by learning in action selection is also discussed.
cs.AI:This article analyses the properties of the Internal Behaviour network, an action selection mechanism previously proposed by the authors, with the aid of a simulation developed for such ends. A brief review of the Internal Behaviour network is followed by the explanation of the implementation of the simulation. Then, experiments are presented and discussed analysing the properties of the action selection in the proposed model.
cs.AI:This paper proposes a model for combination of external and internal stimuli for the action selection in an autonomous agent, based in an action selection mechanism previously proposed by the authors. This combination model includes additive and multiplicative elements, which allows to incorporate new properties, which enhance the action selection. A given parameter a, which is part of the proposed model, allows to regulate the degree of dependence of the observed external behaviour from the internal states of the entity.
cs.AI:Reinforcement learning (RL) involves sequential decision making in uncertain environments. The aim of the decision-making agent is to maximize the benefit of acting in its environment over an extended period of time. Finding an optimal policy in RL may be very slow. To speed up learning, one often used solution is the integration of planning, for example, Sutton's Dyna algorithm, or various other methods using macro-actions.   Here we suggest to separate plannable, i.e., close to deterministic parts of the world, and focus planning efforts in this domain. A novel reinforcement learning method called plannable RL (pRL) is proposed here. pRL builds a simple model, which is used to search for macro actions. The simplicity of the model makes planning computationally inexpensive. It is shown that pRL finds an optimal policy, and that plannable macro actions found by pRL are near-optimal. In turn, it is unnecessary to try large numbers of macro actions, which enables fast learning. The utility of pRL is demonstrated by computer simulations.
cs.AI:Optimization of decision problems in stochastic environments is usually concerned with maximizing the probability of achieving the goal and minimizing the expected episode length. For interacting agents in time-critical applications, learning of the possibility of scheduling of subtasks (events) or the full task is an additional relevant issue. Besides, there exist highly stochastic problems where the actual trajectories show great variety from episode to episode, but completing the task takes almost the same amount of time. The identification of sub-problems of this nature may promote e.g., planning, scheduling and segmenting Markov decision processes. In this work, formulae for the average duration as well as the standard deviation of the duration of events are derived. The emerging Bellman-type equation is a simple extension of Sobel's work (1982). Methods of dynamic programming as well as methods of reinforcement learning can be applied for our extension. Computer demonstration on a toy problem serve to highlight the principle.
cs.AI:Much work has been done on extending the well-founded semantics to general disjunctive logic programs and various approaches have been proposed. However, these semantics are different from each other and no consensus is reached about which semantics is the most intended. In this paper we look at disjunctive well-founded reasoning from different angles. We show that there is an intuitive form of the well-founded reasoning in disjunctive logic programming which can be characterized by slightly modifying some exisitng approaches to defining disjunctive well-founded semantics, including program transformations, argumentation, unfounded sets (and resolution-like procedure). We also provide a bottom-up procedure for this semantics. The significance of our work is not only in clarifying the relationship among different approaches, but also shed some light on what is an intended well-founded semantics for disjunctive logic programs.
q-bio.BM:We consider the regime in which the bands of the torsional acoustic (TA) and the hydrogen-bond-stretch (HBS) modes of the DNA interpenetrate each other. Within the framework of a model that accommodates the structure of the double helix, we find the three-wave interaction between the TA- and the HBS-modes, and show that microwave radiation could bring about torsional vibrations that could serve as a pump mode for maintaining the HBS-one. Rayleigh's threshold condition for the parametric resonance provides an estimate for the power density of the mw-field necessary for generating the HBS-mode.
q-bio.BM:Identifying the driving forces and the mechanism of association of huntingtin-exon1, a close marker for the progress of Huntington's disease, is an important prerequisite towards finding potential drug targets, and ultimately a cure. We introduce here a modelling framework based on a key analogy of the physico-chemical properties of the exon1 fragment to block copolymers. We use a systematic mesoscale methodology, based on Dissipative Particle Dynamics, which is capable of overcoming kinetic barriers, thus capturing the dynamics of significantly larger systems over longer times than considered before. Our results reveal that the relative hydrophobicity of the poly-glutamine block as compared to the rest of the (proline-based) exon1 fragment, ignored to date, constitutes a major factor in the initiation of the self-assembly process. We find that the assembly is governed by both the concentration of exon1 and the length of the poly-glutamine stretch, with a low length threshold for association even at the lowest volume fractions we considered. Moreover, this self-association occurs irrespective of whether the glutamine stretch is in random coil or hairpin configuration, leading to spherical or cylindrical assemblies, respectively. We discuss the implications of these results for reinterpretation of existing research within this context, including that the routes towards aggregation of exon1 may be distinct to those of the widely studied homopolymeric poly-glutamine peptides.
q-bio.BM:The molecular mechanism of the solvent motion that is required to instigate the protein structural relaxation above a critical hydration level or transition temperature has yet to be determined. In this work we use quasi-elastic neutron scattering (QENS) and molecular dynamics simulation to investigate hydration water dynamics near a greatly simplified protein surface. We consider the hydration water dynamics near the completely deuterated N-acetyl-leucine-methylamide (NALMA) solute, a hydrophobic amino acid side chain attached to a polar blocked polypeptide backbone, as a function of concentration between 0.5M-2.0M, under ambient conditions. In this Communication, we focus our results of hydration dynamics near a model protein surface on the issue of how enzymatic activity is restored once a critical hydration level is reached, and provide a hypothesis for the molecular mechanism of the solvent motion that is required to trigger protein structural relaxation when above the hydration transition.
q-bio.BM:We analyze the dependence of thermal denaturation transition and folding rates of globular proteins on the number of amino acid residues, N. Using lattice Go models we show that DeltaT/T_F ~ N^-1, where T_F is the folding transition temperature and DeltaT is the folding transition width. This finding is consistent with finite size effects expected for the systems undergoing a phase transition from a disordered to an ordered phase. The dependence of the folding rates k_F on N for lattice models and the dataset of 57 proteins and peptides shows that k_F = k_F^0 exp(-CN^beta) provides a good fit, if 0 < beta <= 2/3 and C is a constant. We find that k_F = k_F^0 exp(-1.1N^0.5) with k_F^0 =(0.4x10^-6 s)^-1 can estimate optimal protein folding rates to within an order of magnitude in most cases. By using this fit for a set of proteins with beta-sheet topology we find that k_F^0 is approximately equal to k_U^0, the prefactor for unfolding rates. The maximum ratio of k_U^0/k_F^0 is 10 for this class of proteins.
q-bio.BM:The asymmetry in the shapes of folded and unfolded states are probed using two parameters, one being a measure of the sphericity and the other that describes the shape. For the folded states, whose interiors are densely packed, the radii of gyration (Rg) and these two parameters are calculated using the coordinates of the experimentally determined structures. Although Rg scales as expected for maximally compact structures, the distributions of the shape parameters show that there is considerable asymmetry in the shapes of folded structures. The degree of asymmetry is greater for proteins that form oligomers. Analysis of the two- and three-body contacts in the native structures shows that the presence of near equal number of contacts between backbone and side-chains and between side-chains gives rise to dense packing. We suggest that proteins with relatively large values of shape parameters can tolerate volume mutations without greatly affecting the network of contacts or their stability. To probe shape characteristics of denatured states we have developed a model of a WW-like domain. The shape parameters, which are calculated using Langevin simulations, change dramatically in the course of coil to globule transition. Comparison of the values of shape parameters between the globular state and the folded state of WW domain shows that both energetic (especially dispersion in the hydrophobic interactions) and steric effects are important in determining packing in proteins.
q-bio.BM:Instead of conformation states of single residues, refined conformation states of quintuplets are proposed to reflect conformation correlation. Simple hidden Markov models combining with sliding window scores are used for predicting secondary structure of a protein from its amino acid sequence. Since the length of protein conformation segments varies in a narrow range, we ignore the duration effect of the length distribution. The window scores for residues are a window version of the Chou-Fasman propensities estimated under an approximation of conditional independency. Different window widths are examined, and the optimal width is found to be 17. A high accuracy about 70% is achieved.
q-bio.BM:Is protein secondary structure primarily determined by local interactions between residues closely spaced along the amino acid backbone, or by non-local tertiary interactions? To answer this question we have measured the entropy densities of primary structure and secondary structure sequences, and the local inter-sequence mutual information density. We find that the important inter-sequence interactions are short ranged, that correlations between neighboring amino acids are essentially uninformative, and that only 1/4 of the total information needed to determine the secondary structure is available from local inter-sequence correlations. Since the remaining information must come from non-local interactions, this observation supports the view that the majority of most proteins fold via a cooperative process where secondary and tertiary structure form concurrently. To provide a more direct comparison to existing secondary structure prediction methods, we construct a simple hidden Markov model (HMM) of the sequences. This HMM achieves a prediction accuracy comparable to other single sequence secondary structure prediction algorithms, and can extract almost all of the inter-sequence mutual information. This suggests that these algorithms are almost optimal, and that we should not expect a dramatic improvement in prediction accuracy. However, local correlations between secondary and primary structure are probably of under-appreciated importance in many tertiary structure prediction methods, such as threading.
q-bio.BM:The determination of the folding mechanisms of proteins is critical to understand the topological change that can propagate Alzheimer and Creutzfeld-Jakobs diseases, among others. The computational community has paid considerable attention to this problem; however, the associated time scale, typically on the order of milliseconds or more, represents a formidable challenge. Ab initio protein folding from long molecular dynamics (MD) simulations or ensemble dynamics is not feasible with ordinary computing facilities and new techniques must be introduced. Here we present a detailed study of the folding of a 16-residue beta-hairpin, described by a generic energy model and using the activation-relaxation technique. From a total of 90 trajectories at 300 K, three folding pathways emerge. All involve a simultaneous optimization of the complete hydrophobic and hydrogen bonding interactions. The first two follow closely those observed by previous theoretical studies. The third pathway, never observed by previous all-atom folding, unfolding and equilibrium simulations, can be described as a reptation move of one strand of the beta-sheet with respect to the other. This reptation move indicates that non-native interactions can play a dominant role in the folding of secondary structures. These results point to a more complex folding picture than expected for a simple beta-hairpin.
q-bio.BM:Analytic estimates for the forces and free energy generated by bilayer deformation reveal a compelling and intuitive model for MscL channel gating analogous to the nucleation of a second phase. We argue that the competition between hydrophobic mismatch and tension results in a surprisingly rich story which can provide both a quantitative comparison to measurements of opening tension for MscL when reconstituted in bilayers of different thickness and qualitative insights into the function of the MscL channel and other transmembrane proteins.
q-bio.BM:It is important to understand how protein folding and evolution influences each other. Several studies based on entropy calculation correlating experimental measurement of residue participation in folding nucleus and sequence conservation have reached different conclusions. Here we report analysis of conservation of folding nucleus using an evolutionary model alternative to entropy based approaches. We employ a continuous time Markov model of codon substitution to distinguish mutation fixed by evolution and mutation fixed by chance. This model takes into account bias in codon frequency, bias favoring transition over transversion, as well as explicit phylogenetic information. We measure selection pressure using the ratio $\omega$ of synonymous vs. non-synonymous substitution at individual residue site. The $\omega$-values are estimated using the {\sc Paml} method, a maximum-likelihood estimator. Our results show that there is little correlation between the extent of kinetic participation in protein folding nucleus as measured by experimental $\phi$-value and selection pressure as measured by $\omega$-value. In addition, two randomization tests failed to show that folding nucleus residues are significantly more conserved than the whole protein. These results suggest that at the level of codon substitution, there is no indication that folding nucleus residues are significantly more conserved than other residues. We further reconstruct candidate ancestral residues of the folding nucleus and suggest possible test tube mutation studies of ancient folding nucleus.
q-bio.BM:Many signalling functions in molecular biology require proteins bind to substrates such as DNA in response to environmental signals such as the simultaneous binding to a small molecule. Examples are repressor proteins which may transmit information via a conformational change in response to the ligand binding. An alternative entropic mechanism of ``allostery'' suggests that the inducer ligand changes the intramolecular vibrational entropy not just the static structure. We present a quantitative, coarse-grained model of entropic allostery that suggests design rules for internal cohesive potentials in proteins employing this effect. It also addresses the issue of how the signal information to bind or unbind is transmitted through the protein. The model may be applicable to a wide range of repressors and also to signalling in transmembrane proteins.
q-bio.BM:How DNA repair enzymes find the relatively rare sites of damage is not known in great detail. Recent experiments and molecular data suggest that the individual repair enzymes do not work independently of each other, but rather interact with each other through currents exchanged along DNA. A damaged site in DNA hinders this exchange and this makes it possible to quickly free up resources from error free stretches of DNA. Here the size of the speedup gained from this current exchange mechanism is calculated and the characteristic length and time scales are identified. In particular for Escherichia coli we estimate the speedup to be 50000/N, where N is the number of repair enzymes participating in the current exchange mechanism. Even though N is not exactly known a speedup of order 10 is not entirely unreasonable. Furthermore upon over expression of repair enzymes the detection time only varies as one over the squareroot of N and not as 1/N. This behavior is of interest in assessing the impact of stress full and radioactive environments on individual cell mutation rates.
q-bio.BM:We study DNA adsorption and renaturation in a water-phenol two-phase system, with or without shaking. In very dilute solutions, single-stranded DNA is adsorbed at the interface in a salt-dependent manner. At high salt concentrations the adsorption is irreversible. The adsorption of the single-stranded DNA is specific to phenol and relies on stacking and hydrogen bonding. We establish the interfacial nature of a DNA renaturation at a high salt concentration. In the absence of shaking, this reaction involves an efficient surface diffusion of the single-stranded DNA chains. In the presence of a vigorous shaking, the bimolecular rate of the reaction exceeds the Smoluchowski limit for a three-dimensional diffusion-controlled reaction. DNA renaturation in these conditions is known as the Phenol Emulsion Reassociation Technique or PERT. Our results establish the interfacial nature of PERT. A comparison of this interfacial reaction with other approaches shows that PERT is the most efficient technique and reveals similarities between PERT and the renaturation performed by single-stranded nucleic acid binding proteins. Our results lead to a better understanding of the partitioning of nucleic acids in two-phase systems, and should help design improved extraction procedures for damaged nucleic acids. We present arguments in favor of a role of phenol and water-phenol interface in prebiotic chemistry. The most efficient renaturation reactions (in the presence of condensing agents or with PERT) occur in heterogeneous systems. This reveals the limitations of homogeneous approaches to the biochemistry of nucleic acids. We propose a heterogeneous approach to overcome the limitations of the homogeneous viewpoint.
q-bio.BM:Hydrophobicity is thought to be one of the primary forces driving the folding of proteins. On average, hydrophobic residues occur preferentially in the core, whereas polar residues tends to occur at the surface of a folded protein. By analyzing the known protein structures, we quantify the degree to which the hydrophobicity sequence of a protein correlates with its pattern of surface exposure. We have assessed the statistical significance of this correlation for several hydrophobicity scales in the literature, and find that the computed correlations are significant but far from optimal. We show that this less than optimal correlation arises primarily from the large degree of mutations that naturally occurring proteins can tolerate. Lesser effects are due in part to forces other than hydrophobicity and we quantify this by analyzing the surface exposure distributions of all amino acids. Lastly we show that our database findings are consistent with those found from an off-lattice hydrophobic-polar model of protein folding.
q-bio.BM:The approach for the description of the DNA conformational transformations on the mesoscopic scales in the frame of the double helix is presented. Due to consideration of the joint motions of DNA structural elements along the conformational pathways the models for different transformations may be constructed in the unifying two-component form. One component of the model is the degree of freedom of the elastic rod and another component -- the effective coordinate of the conformational transformation. The internal and external model components are interrelated, as it is characteristic for the DNA structure organization. It is shown that the kinetic energy of the conformational transformation of heterogeneous DNA may be put in homogeneous form. In the frame of the developed approach the static excitations of the DNA structure under the transitions between the stable states are found for internal and external components. The comparison of the data obtained with the experiment on intrinsic DNA deformability shows good qualitative agreement. The conclusion is made that the found excitations in the DNA structure may be classificated as the static conformational solitons.
q-bio.BM:Molecular combing is a powerful and simple method for aligning DNA molecules onto a surface. Using this technique combined with fluorescence microscopy, we observed that the length of lambda-DNA molecules was extended to about 1.6 times their contour length (unextended length, 16.2 micrometers) by the combing method on hydrophobic polymethylmetacrylate (PMMA) coated surfaces. The effects of sodium and magnesium ions and pH of the DNA solution were investigated. Interestingly, we observed force-induced melting of single DNA molecules.
q-bio.BM:Using a Brownian dynamics simulation, we numerically studied the interaction of DNA with histone and proposed an octamer-rotation model to describe the process of nucleosome formation. Nucleosome disruption under stretching was also simulated. The theoretical curves of extension versus time as well as of force versus extension are consistent with previous experimental results.
q-bio.BM:We propose a two-dimensional model for a complete description of the dynamics of molecular motors, including both the processive movement along track filaments and the dissociation from the filaments. The theoretical results on the distributions of the run length and dwell time at a given ATP concentration, the dependences of mean run length, mean dwell time and mean velocity on ATP concentration and load are in good agreement with the previous experimental results.
q-bio.BM:Kinesin motors have been studied extensively both experimentally and theoretically. However, the microscopic mechanism of the processive movement of kinesin is still an open question. In this paper, we propose a hand-over-hand model for the processivity of kinesin, which is based on chemical, mechanical, and electrical couplings. In the model the processive movement does not need to rely on the two heads' coordination in their ATP hydrolysis and mechanical cycles. Rather, the ATP hydrolyses at the two heads are independent. The much higher ATPase rate at the trailing head than the leading head makes the motor walk processively in a natural way, with one ATP being hydrolyzed per step. The model is consistent with the structural study of kinesin and the measured pathway of the kinesin ATPase. Using the model the estimated driving force of ~ 5.8 pN is in agreements with the experimental results (5~7.5 pN). The prediction of the moving time in one step (~10 microseconds) is also consistent with the measured values of 0~50 microseconds. The previous observation of substeps within the 8-nm step is explained. The shapes of velocity-load (both positive and negative) curves show resemblance to previous experimental results.
q-bio.BM:Myosin V and myosin VI are two classes of two-headed molecular motors of the myosin superfamily that move processively along helical actin filaments in opposite directions. Here we present a hand-over-hand model for their processive movements. In the model, the moving direction of a dimeric molecular motor is automatically determined by the relative orientation between its two heads at free state and its head's binding orientation on track filament. This determines that myosin V moves toward the barbed end and myosin VI moves toward the pointed end of actin. During the moving period in one step, one head remains bound to actin for myosin V whereas two heads are detached for myosin VI: The moving manner is determined by the length of neck domain. This naturally explains the similar dynamic behaviors but opposite moving directions of myosin VI and mutant myosin V (the neck of which is truncated to only one-sixth of the native length). Because of different moving manners, myosin VI and mutant myosin V exhibit significantly broader step-size distribution than native myosin V. However, all three motors give the same mean step size of 36 nm (the pseudo-repeat of actin helix). Using the model we study the dynamics of myosin V quantitatively, with theoretical results in agreement with previous experimental ones.
q-bio.BM:We describe a faster and more accurate algorithm for computing the statistical mechanics of DNA denaturation according to the Poland-Scheraga type. Nearest neighbor thermodynamics is included in a complete and general way. The algorithm represents an optimization with respect to algorithmic complexity of the partition function algorithm of Yeramian et al.: We reduce the computation time for a base-pairing probability profile from O(N2) to O(N). This speed-up comes in addition to the speed-up due to a multiexponential approximation of the loop entropy factor as introduced by Fixman and Freire. The speed-up, however, is independent of the multiexponential approximation and reduces time from O(N3) to O(N2) in the exact case. In addition to calculating the standard base-pairing probability profiles, we propose to use the algorithm to calculate various other probabilities (loops, helices, tails) for a more direct view of the melting regions and their positions and sizes.
q-bio.BM:A joint experimental / theoretical investigation of the elastin-like octapeptide GVG(VPGVG) was carried out. In this paper a comprehensive molecular dynamics study of the temperature dependent folding and unfolding of the octapeptide is presented. The current study, as well as its experimental counterpart find that this peptide undergoes an "inverse temperature transition", ITT, leading to a folding at about 310-330 K. In addition, an unfolding transition is identified at unusually high temperatures approaching the boiling point of water. Due to the small size of the system two broad temperature regimes are found: the "ITT regime" (at about 280-320 K) and the "unfolding regime" at about T > 330 K, where the peptide has a maximum probability of being folded at approximately 330 K. A detailed molecular picture involving a thermodynamic order parameter, or reaction coordinate, for this process is presented along with a time-correlation function analysis of the hydrogen bond dynamics within the peptide as well as between the peptide and solvating water molecules. Correlation with experimental evidence and ramifications on the properties of elastin are discussed.
q-bio.BM:A simplified model for the closed circular DNA (ccDNA) is proposed to describe some specific features of the helix-coil transition in such molecule. The Hamiltonian of ccDNA is related to the one introduced earlier for the linear DNA. The basic assumption is that the reduced energy of the hydrogen bond is not constant through the transition process but depends effectively on the fraction of already broken bonds. A transformation formula is obtained which relates the temperature of ccDNA at a given degree of helicity during the transition to the temperature of the corresponding linear chain at the same degree of helicity. The formula provides a simple method to calculate the melting curve for the ccDNA from the experimental melting curve of the linear DNA with the same nucleotide sequence.
q-bio.BM:We develop a simple but rigorous model of protein-protein association kinetics based on diffusional association on free energy landscapes obtained by sampling configurations within and surrounding the native complex binding funnels. Guided by results obtained on exactly solvable model problems, we transform the problem of diffusion in a potential into free diffusion in the presence of an absorbing zone spanning the entrance to the binding funnel. The free diffusion problem is solved using a recently derived analytic expression for the rate of association of asymmetrically oriented molecules. Despite the required high steric specificity and the absence of long-range attractive interactions, the computed rates are typically on the order of 10^4-10^6 M-1 s-1, several orders of magnitude higher than rates obtained using a purely probabilistic model in which the association rate for free diffusion of uniformly reactive molecules is multiplied by the probability of a correct alignment of the two partners in a random collision. As the association rates of many protein-protein complexes are also in the 10^5-10^6 M-1 s-1, our results suggest that free energy barriers arising from desolvation and/or side-chain freezing during complex formation or increased ruggedness within the binding funnel, which are completely neglected in our simple diffusional model, do not contribute significantly to the dynamics of protein-protein association. The transparent physical interpretation of our approach that computes association rates directly from the size and geometry of protein-protein binding funnels makes it a useful complement to Brownian dynamics simulations.
q-bio.BM:Functional proteins must fold with some minimal stability to a structure that can perform a biochemical task. Here we use a simple model to investigate the relationship between the stability requirement and the capacity of a protein to evolve the function of binding to a ligand. Although our model contains no built-in tradeoff between stability and function, proteins evolved function more efficiently when the stability requirement was relaxed. Proteins with both high stability and high function evolved more efficiently when the stability requirement was gradually increased than when there was constant selection for high stability. These results show that in our model, the evolution of function is enhanced by allowing proteins to explore sequences corresponding to marginally stable structures, and that it is easier to improve stability while maintaining high function than to improve function while maintaining high stability. Our model also demonstrates that even in the absence of a fundamental biophysical tradeoff between stability and function, the speed with which function can evolve is limited by the stability requirement imposed on the protein.
q-bio.BM:Using the model for the processive movement of a dimeric kinesin we proposed before, we study the dynamics of a number of mutant homodimeric and heterodimeric kinesins that were constructed by Kaseda et al. (Kaseda, K., Higuchi, H. and Hirose, K. PNAS 99, 16058 (2002)). The theoretical results of ATPase rate per head, moving velocity, and stall force of the motors show good agreement with the experimental results by Kaseda et al.: The puzzling dynamic behaviors of heterodimeric kinesin that consists of two distinct heads compared with its parent homodimers can be easily explained by using independent ATPase rates of the two heads in our model. We also study the collective kinetic behaviors of kinesins in MT-gliding motility. The results explains well that the average MT-gliding velocity is independent of the number of bound motors and is equal to the moving velocity of a single kinesin relative to MT.
q-bio.BM:The simplest approximation of interaction potential between amino-acids in proteins is the contact potential, which defines the effective free energy of a protein conformation by a set of amino acid contacts formed in this conformation. Finding a contact potential capable of predicting free energies of protein states across a variety of protein families will aid protein folding and engineering in silico on a computationally tractable time-scale. We test the ability of contact potentials to accurately and transferably (across various protein families) predict stability changes of proteins upon mutations. We develop a new methodology to determine the contact potentials in proteins from experimental measurements of changes in protein thermodynamic stabilities (ddG) upon mutations. We apply our methodology to derive sets of contact interaction parameters for a hierarchy of interaction models including solvation and multi-body contact parameters. We test how well our models reproduce experimental measurements by statistical tests. We evaluate the maximum accuracy of predictions obtained by using contact potentials and the correlation between parameters derived from different data-sets of experimental ddG values. We argue that it is impossible to reach experimental accuracy and derive fully transferable contact parameters using the contact models of potentials. However, contact parameters can yield reliable predictions of ddG for datasets of mutations confined to specific amino-acid positions in the sequence of a single protein.
q-bio.BM:We first review how to determine the rate of vibrational energy relaxation (VER) using perturbation theory. We then apply those theoretical results to the problem of VER of a CD stretching mode in the protein cytochrome c. We model cytochrome c in vacuum as a normal mode system with the lowest-order anharmonic coupling elements. We find that, for the ``lifetime'' width parameter $\gamma=3 \sim 30$ cm$^{-1}$, the VER time is $0.2 \sim 0.3$ ps, which agrees rather well with the previous classical calculation using the quantum correction factor method, and is consistent with spectroscopic experiments by Romesberg's group. We decompose the VER rate into separate contributions from two modes, and find that the most significant contribution, which depends on the ``lifetime'' width parameter, comes from those modes most resonant with the CD vibrational mode.
q-bio.BM:The three-dimensional structures of two common repeat motifs Val$^1$-Pro$^2$-Gly$^3$-Val$^4$-Gly$^5$ and Val$^1$-Gly$^2$-Val$^3$-Pro$^4$-Gly$^5$-Val$^6$-Gly$^7$-Val$^8$-Pro$^9$ of tropoelastin are investigated by using the multicanonical simulation procedure. By minimizing the energy structures along the trajectory the thermodynamically most stable low-energy microstates of the molecule are determined. The structural predictions are in good agreement with X-ray diffraction experiments.
q-bio.BM:We address the controversial hot question concerning the validity of the loose-coupling versus the lever-arm models in the actomyosin dynamics by re-interpreting and extending the washboard potential model proposed by some of us in a previous paper. In the new theory, a loose-coupling mechanism co-exists with the deterministic lever-arm model. The synergetic action of a random component, originating from the harnessed thermal energy, and of the power-stroke generated by the lever-arm classical mechanism is seen to yield an excellent fit of the set of data obtained in T. Yanagida's laboratory on the sliding of Myosin II heads on actin filaments under various load conditions. Our theoretical arguments are complemented by accurate numerical simulations, and the robustness of theory is tested via different combination of parameters and potential profiles.
q-bio.BM:In simple models side chains are often represented implicitly (e.g., by spin-states) or simplified as one atom. We study side chain effects using square lattice and tetrahedral lattice models, with explicitly side chains of two atoms. We distinguish effects due to chirality and effects due to side chain flexibilities, since residues in proteins are L-residues, and their side chains adopt different rotameric states. Short chains are enumerated exhaustively. For long chains, we sample effectively rare events (eg, compact conformations) and obtain complete pictures of ensemble properties of these models at all compactness region. We find that both chirality and reduced side chain flexibility lower the folding entropy significantly for globally compact conformations, suggesting that they are important properties of residues to ensure fast folding and stable native structure. This corresponds well with our finding that natural amino acid residues have reduced effective flexibility, as evidenced by analysis of rotamer libraries and side chain rotatable bonds. We further develop a method calculating the exact side-chain entropy for a given back bone structure. We show that simple rotamer counting often underestimates side chain entropy significantly, and side chain entropy does not always correlate well with main chain packing. Among compact backbones with maximum side chain entropy, helical structures emerges as the dominating configurations. Our results suggest that side chain entropy may be an important factor contributing to the formation of alpha helices for compact conformations.
q-bio.BM:We show that the contact map of the native structure of globular proteins can be reconstructed starting from the sole knowledge of the contact map's principal eigenvector, and present an exact algorithm for this purpose. Our algorithm yields a unique contact map for all 221 globular structures of PDBselect25 of length $N \le 120$. We also show that the reconstructed contact maps allow in turn for the accurate reconstruction of the three-dimensional structure. These results indicate that the reduced vectorial representation provided by the principal eigenvector of the contact map is equivalent to the protein structure itself. This representation is expected to provide a useful tool in bioinformatics algorithms for protein structure comparison and alignment, as well as a promising intermediate step towards protein structure prediction.
q-bio.BM:Function of proteins or a network of interacting proteins often involves communication between residues that are well separated in sequence. The classic example is the participation of distant residues in allosteric regulation. Bioinformatic and structural analysis methods have been introduced to infer residues that are correlated. Recently, increasing attention has been paid to obtain the sequence properties that determine the tendency of disease related proteins (Abeta peptides, prion proteins, transthyretin etc.) to aggregate and form fibrils. Motivated in part by the need to identify sequence characteristics that indicate a tendency to aggregate, we introduce a general method that probes covariations in charged residues along the sequence in a given protein family. The method, which involves computing the Sequence Correlation Entropy (SCE) using the quenched probability Psk(i,j) of finding a residue pair at a given sequence separation sk, allows us to classify protein families in terms of their SCE. Our general approach may be a useful way in obtaining evolutionary covariations of amino acid residues on a genome wide level.
q-bio.BM:We present an analysis of the effects of global topology on the structural stability of folded proteins in thermal equilibrium with a heat bath. For a large class of single domain proteins, we computed the harmonic spectrum within the Gaussian Network Model (GNM) and determined the spectral dimension, a parameter describing the low frequency behaviour of the density of modes. We find a surprisingly strong correlation between the spectral dimension and the number of amino acids of the protein. Considering that larger spectral dimension value relate to more topologically compact folded state, our results indicate that for a given temperature and length of the protein, the folded structure corresponds to the less compact folding compatible with thermodynamic stability.
q-bio.BM:We present a simple physical model which demonstrates that the native state folds of proteins can emerge on the basis of considerations of geometry and symmetry. We show that the inherent anisotropy of a chain molecule, the geometrical and energetic constraints placed by the hydrogen bonds and sterics, and hydrophobicity are sufficient to yield a free energy landscape with broad minima even for a homopolymer. These minima correspond to marginally compact structures comprising the menu of folds that proteins choose from to house their native-states in. Our results provide a general framework for understanding the common characteristics of globular proteins.
q-bio.BM:With the aim to study the relationship between protein sequences and their native structures, we adopt vectorial representations for both sequence and structure. The structural representation is based on the Principal Eigenvector of the fold's contact matrix (PE). As recently shown, the latter encodes sufficient information for reconstructing the whole contact matrix. The sequence is represented through a Hydrophobicity Profile (HP), using a generalized hydrophobicity scale that we obtain from the principal eigenvector of a residue-residue interaction matrix and denote it as interactivity scale. Using this novel scale, we define the optimal HP of a protein fold, and predict, by means of stability arguments, that it is strongly correlated with the PE of the fold's contact matrix. This prediction is confirmed through an evolutionary analysis, which shows that the PE correlates with the HP of each individual sequence adopting the same fold and, even more strongly, with the average HP of this set of sequences. Thus, protein sequences evolve in such a way that their average HP is close to the optimal one, implying that neutral evolution can be viewed as a kind of motion in sequence space around the optimal HP. Our results indicate that the correlation coefficient between N-dimensional vectors constitutes a natural metric in the vectorial space in which we represent both protein sequences and protein structures, which we call Vectorial Protein Space. In this way, we define a unified framework for sequence to sequence, sequence to structure, and structure to structure alignments. We show that the interactivity scale is nearly optimal both for the comparison of sequences with sequences and sequences with structures.
q-bio.BM:We fit the Fourier transforms of solvent accessibility and hydrophobicity profiles of a representative set of proteins to a joint multi-variable Gaussian. This allows us to separate the intrinsic tendencies of sequence and structure profiles from the interactions that correlate them; for example, the $\alpha$-helix periodicity in sequence hydrophobicity is dictated by the solvent accessibility of structures. The distinct intrinsic tendencies of sequence and structure profiles are most pronounced at long periods, where sequence hydrophobicity fluctuates more, while solvent accessibility fluctuations are less than average. Interestingly, correlations between the two profiles can be interpreted as the Boltzmann weight of the solvation energy at room temperature.
q-bio.BM:In this paper, we examine the mechanical role of the lipid bilayer in ion channel conformation and function with specific reference to the case of the mechanosensitive channel of large conductance (MscL). In a recent paper (Wiggins and Phillips, 2004), we argued that mechanotransduction very naturally arises from lipid-protein interactions by invoking a simple analytic model of the MscL channel and the surrounding lipid bilayer. In this paper, we focus on improving and expanding this analytic framework for studying lipid-protein interactions with special attention to MscL. Our goal is to generate simple scaling relations which can be used to provide qualitative understanding of the role of membrane mechanics in protein function and to quantitatively interpret experimental results. For the MscL channel, we find that the free energies induced by lipid-protein interaction are of the same order as the free energy differences between conductance states measured by Sukharev et al. (1999). We therefore conclude that the mechanics of the bilayer plays an essential role in determining the conformation and function of the channel. Finally, we compare the predictions of our model to experimental results from the recent investigations of the MscL channel by Perozo et al. (2002), Powl et al. (2003), Yoshimura et al. (2004), and others and suggest a suite of new experiments.
q-bio.BM:The conjunction of insights from structural biology, solution biochemistry, genetics and single molecule biophysics has provided a renewed impetus for the construction of quantitative models of biological processes. One area that has been a beneficiary of these experimental techniques is the study of viruses. In this paper we describe how the insights obtained from such experiments can be utilized to construct physical models of processes in the viral life cycle. We focus on dsDNA bacteriophages and show that the bending elasticity of DNA and its electrostatics in solution can be combined to determine the forces experienced during packaging and ejection of the viral genome. Furthermore, we quantitatively analyze the effect of fluid viscosity and capsid expansion on the forces experienced during packaging. Finally, we present a model for DNA ejection from bacteriophages based on the hypothesis that the energy stored in the tightly packed genome within the capsid leads to its forceful ejection. The predictions of our model can be tested through experiments in vitro where DNA ejection is inhibited by the application of external osmotic pressure.
q-bio.BM:Amyloid fibers are aggregates of proteins. They are built out of a peptide called $\beta$--amyloid (A$\beta$) containing between 41 and 43 residues, produced by the action of an enzyme which cleaves a much larger protein known as the Amyloid Precursor Protein (APP). X-ray diffraction experiments have shown that these fibrils are rich in $\beta$--structures, whereas the shape of the peptide displays an $\alpha$--helix structure within the APP in its biologically active conformation. A realistic model of fibril formation is developed based on the seventeen residues A$\beta$12--28 amyloid peptide, which has been shown to form fibrils structurally similar to those of the whole A$\beta$ peptide. With the help of physical arguments and in keeping with experimental findings, the A$\beta$12--28 monomer is assumed to be in four possible states (i.e., native helix conformation, $\beta$--hairpin, globular low--energy state and unfolded state). Making use of these monomeric states, oligomers (dimers, tertramers and octamers) were constructed. With the help of short, detailed Molecular Dynamics (MD) calculations of the three monomers and of a variety of oligomers, energies for these structures were obtained. Making use of these results within the framework of a simple yet realistic model to describe the entropic terms associated with the variety of amyloid conformations, a phase diagram can be calculated of the whole many--body system, leading to a thermodynamical picture in overall agreement with the experimental findings. In particular, the existence of micellar metastable states seem to be a key issue to determine the thermodynamical properties of the system.
q-bio.BM:The possibility of deriving the contact potentials between amino acids from their frequencies of occurence in proteins is discussed in evolutionary terms. This approach allows the use of traditional thermodynamics to describe such frequencies and, consequently, to develop a strategy to include in the calculations correlations due to the spatial proximity of the amino acids and to their overall tendency of being conserved in proteins. Making use of a lattice model to describe protein chains and defining a "true" potential, we test these strategies by selecting a database of folding model sequences, deriving the contact potentials from such sequences and comparing them with the "true" potential. Taking into account correlations allows for a markedly better prediction of the interaction potentials.
q-bio.BM:While all the information required for the folding of a protein is contained in its amino acid sequence, one has not yet learned how to extract this information to predict the three--dimensional, biologically active, native conformation of a protein whose sequence is known. Using insight obtained from simple model simulations of the folding of proteins, in particular of the fact that this phenomenon is essentially controlled by conserved (native) contacts among (few) strongly interacting ("hot"), as a rule hydrophobic, amino acids, which also stabilize local elementary structures (LES, hidden, incipient secondary structures like $\alpha$--helices and $\beta$--sheets) formed early in the folding process and leading to the postcritical folding nucleus (i.e., the minimum set of native contacts which bring the system pass beyond the highest free--energy barrier found in the whole folding process) it is possible to work out a succesful strategy for reading the native structure of designed proteins from the knowledge of only their amino acid sequence and of the contact energies among the amino acids. Because LES have undergone millions of years of evolution to selectively dock to their complementary structures, small peptides made out of the same amino acids as the LES are expected to selectively attach to the newly expressed (unfolded) protein and inhibit its folding, or to the native (fluctuating) native conformation and denaturate it. These peptides, or their mimetic molecules, can thus be used as effective non--conventional drugs to those already existing (and directed at neutralizing the active site of enzymes), displaying the advantage of not suffering from the uprise of resistance.
q-bio.BM:Methods for alignment of protein sequences typically measure similarity by using substitution matrix with scores for all possible exchanges of one amino acid with another. Although widely used, the matrices derived from homologous sequence segments, such as Dayhoff's PAM matrices and Henikoff's BLOSUM matrices, are not specific for protein conformation identification. Using a different approach, we got many amino acid segment blocks. For each of them, the protein secondary structure is identical. Based on these blocks, we have derived new amino acid substitution matrices. The application of these matrices led to marked improvements in conformation segment search and homologues detection in twilight zone.
q-bio.BM:The advent of new experimental genomic technologies and the massive increase of DNA sequence information is helping researchers better understand how our genes work. Recently, experiments on mRNA abundance (gene expression) have revealed that gene expression shows a stationary organization described by a power-law distribution (scale-free organization) (i.e., gene expression $k$ decays as $k^{-\gamma}$), which is highly conserved in all the major five kingdoms of life, from Bacteria to Human. An underlying gene expression dynamics "rich-travel-more" was suggested to recover that evolutional conservation of transcriptional organization. Here we propose a constructive approach to gene expression dynamics with larger scope. Our gene expression construction restores the stationary state, predicts the power-law exponent for different organisms with natural explanation for small correction at high and low expression levels, describes the intermediate state dynamics (time finite) and elucidates the gene expression stability. This approach requires only one assumption: Markov property.
q-bio.BM:Proteins are minimally frustrated polymers. However, for realistic protein models non-native interactions must be taken into account. In this paper we analyze the effect of non-native interactions on the folding rate and on the folding free energy barrier. We present an analytic theory to account for the modification on the free energy landscape upon introduction of non-native contacts, added as a perturbation to the strong native interactions driving folding. Our theory predicts a rate-enhancement regime at fixed temperature, under the introduction of weak, non-native interactions. We have thoroughly tested this theoretical prediction with simulations of a coarse-grained protein model, by employing an off-lattice $C_\alpha$ model of the src-SH3 domain. The strong agreement between results from simulations and theory confirm the non trivial result that a relatively small amount of non-native interaction energy can actually assist the folding to the native structure.
q-bio.BM:An effective potential function is critical for protein structure prediction and folding simulation. For simplified models of proteins where coordinates of only $C_\alpha$ atoms need to be specified, an accurate potential function is important. Such a simplified model is essential for efficient search of conformational space. In this work, we present a formulation of potential function for simplified representations of protein structures. It is based on the combination of descriptors derived from residue-residue contact and sequence-dependent local geometry. The optimal weight coefficients for contact and local geometry is obtained through optimization by maximizing margins among native and decoy structures. The latter are generated by chain growth and by gapless threading. The performance of the potential function in blind test of discriminating native protein structures from decoys is evaluated using several benchmark decoy sets. This potential function have comparable or better performance than several residue-based potential functions that require in addition coordinates of side chain centers or coordinates of all side chain atoms.
q-bio.BM:Circular permutation connects the N and C termini of a protein and concurrently cleaves elsewhere in the chain, providing an important mechanism for generating novel protein fold and functions. However, their in genomes is unknown because current detection methods can miss many occurances, mistaking random repeats as circular permutation. Here we develop a method for detecting circularly permuted proteins from structural comparison. Sequence order independent alignment of protein structures can be regarded as a special case of the maximum-weight independent set problem, which is known to be computationally hard. We develop an efficient approximation algorithm by repeatedly solving relaxations of an appropriate intermediate integer programming formulation, we show that the approximation ratio is much better then the theoretical worst case ratio of $r = 1/4$. Circularly permuted proteins reported in literature can be identified rapidly with our method, while they escape the detection by publicly available servers for structural alignment.
q-bio.BM:Motivation. Protein design aims to identify sequences compatible with a given protein fold but incompatible to any alternative folds. To select the correct sequences and to guide the search process, a design scoring function is critically important. Such a scoring function should be able to characterize the global fitness landscape of many proteins simultaneously.   Results. To find optimal design scoring functions, we introduce two geometric views and propose a formulation using mixture of nonlinear Gaussian kernel functions. We aim to solve a simplified protein sequence design problem. Our goal is to distinguish each native sequence for a major portion of representative protein structures from a large number of alternative decoy sequences, each a fragment from proteins of different fold. Our scoring function discriminate perfectly a set of 440 native proteins from 14 million sequence decoys. We show that no linear scoring function can succeed in this task. In a blind test of unrelated proteins, our scoring function misclassfies only 13 native proteins out of 194. This compares favorably with about 3-4 times more misclassifications when optimal linear functions reported in literature are used. We also discuss how to develop protein folding scoring function.
q-bio.BM:Being HIV-1-PR an essential enzyme in the viral life cycle, its inhibition can control AIDS. Because the folding of single domain proteins, like HIV-1-PR is controlled by local elementary structures (LES, folding units stabilized by strongly interacting, highly conserved amino acids) which have evolved over myriads of generations to recognize and strongly attract each other so as to make the protein fold fast, we suggest a novel type of HIV-1-PR inhibitors which interfere with the folding of the protein: short peptides displaying the same amino acid sequence of that of LES. Theoretical and experimental evidence for the specificity and efficiency of such inhibitors are presented.
q-bio.BM:Vibrational energy relaxation (VER) of a selected mode in cytochrome c (hemeprotein) in vacuum is studied using two theoretical approaches: One is the equilibrium simulation approach with quantum correction factors, and the other is the reduced model approach which describes the protein as an ensemble of normal modes coupled with nonlinear coupling elements. Both methods result in estimates of VER time (sub ps) for a CD stretching mode in the protein at room temperature, that are in accord with the experimental data of Romesberg's group. The applicability of the two methods is examined through a discussion of the validity of Fermi's golden rule on which the two methods are based.
q-bio.BM:The 16-22 amino acid fragment of the beta-amyloid peptide associated with the Alzheimer's disease, Abeta, is capable of forming amyloid fibrils. Here we study the aggregation mechanism of Abeta(16-22) peptides by unbiased thermodynamic simulations at the atomic level for systems of one, three and six Abeta(16-22) peptides. We find that the isolated Abeta(16-22) peptide is mainly a random coil in the sense that both the alpha-helix and beta-strand contents are low, whereas the three- and six-chain systems form aggregated structures with a high beta-sheet content. Furthermore, in agreement with experiments on Abeta(16-22) fibrils, we find that large parallel beta-sheets are unlikely to form. For the six-chain system, the aggregated structures can have many different shapes, but certain particularly stable shapes can be identified.
q-bio.BM:We identified latent periodicity in catalytic domains of approximately 85% of serine/threonine and tyrosine protein kinases. Similar results were obtained for other 22 protein domains. We also designed the method of noise decomposition, which is aimed to distinguish between different periodicity types of the same period length. The method is to be used in conjunction with the cyclic profile alignment, and this combination is able to reveal structure-related or function-related patterns of latent periodicity. Possible origins of the periodic structure of protein kinase active sites are discussed. Summarizing, we presume that latent periodicity is the common property of many catalytic protein domains.
q-bio.BM:We found latent periodicity of 150 protein families now. We suppose that latent periodicity can determine a spectrum of resonance oscillations in proteins.
q-bio.BM:Proteins have regular tertiary structures but irregular amino acid sequences. This made it very difficult to decode the structural information in the protein sequences. Here we demonstrate that many small alpha protein domains have hidden sequence symmetries characteristic of their pseudo-symmetric tertiary structures. We also present a modified method of recurrent plot to reveal this kind of the hidden sequence symmetry. The results may enable us understand parts of the relations between protein sequences and their tertiary structures, i.e, how the primary sequence of a protein determines its tertiary structure.
q-bio.BM:Summary: The F2CS server provides access to the software, F2CS2.00, that implements an automated prediction method of SCOP and CATH classifications of proteins, based on their FSSP Z-scores (Getz et al., 2002), Availability: Free, at http://www.weizmann.ac.il/physics/complex/compphys/f2cs/. Contact: eytan.domany@weizmann.ac.il Supplementary information: The site contains links to additional figures and tables.
q-bio.BM:Activated processes such as protein unfolding are highly sensitive to heterogeneity in the environment. We study a highly simplified model of a protein in a random heterogeneous environment, a model of the in vivo environment. It is found that if the heterogeneity is sufficiently large the total rate of the process is essentially a random variable; this may be the cause of the species-to-species variability in the rate of prion protein conversion found by Deleault et al. [Nature, 425 (2003) 717].
q-bio.BM:Water molecules and molecular chaperones efficiently help the protein folding process. Here we describe their action in the context of the energy and topological networks of proteins. In energy terms water and chaperones were suggested to decrease the activation energy between various local energy minima smoothing the energy landscape, rescuing misfolded proteins from conformational traps and stabilizing their native structure. In kinetic terms water and chaperones may make the punctuated equilibrium of conformational changes less punctuated and help protein relaxation. Finally, water and chaperones may help the convergence of multiple energy landscapes during protein-macromolecule interactions. We also discuss the possibility of the introduction of protein games to narrow the multitude of the energy landscapes when a protein binds to another macromolecule. Both water and chaperones provide a diffuse set of rapidly fluctuating weak links (low affinity and low probability interactions), which allow the generalization of all these statements to a multitude of networks.
q-bio.BM:Nucleosomes organize the folding of DNA into chromatin and significantly influence transcription, replication, regulation and repair. All atom molecular dynamics simulations of a nucleosome and of its 146 basepairs of DNA free in solution have been conducted. DNA helical parameters are extracted from each trajectory to compare the conformation, effective force constants, persistence length measures, and fluctuations of nucleosomal DNA to free DNA. A method for disassembling and reconstructing the conformation and dynamics of the nucleosome using Fourier analysis is presented. Results indicate that the superhelical path of DNA in the nucleosome is irregular. Long length variations in the conformation of nucleosomal DNA are identified other than those associated with helix repeat. These variations are required to create a proposed tetrasome conformation or to qualitatively reconstruct the 1.75 turns of the nuclesomal superhelix. Free DNA achieves enough bend and shear in solution to create an ideal nucleosome superhelix, but these deformations are not organized so the conformation is essentially linear. Reconstruction of free DNA using selected long wavelength variations in conformation can produce either a left-handed or a right-handed superhelix. DNA is less flexible in the nucleosome than when free in solution, however such measures are length scale dependent.
q-bio.BM:Gene expression analysis by means of microarrays is based on the sequence specific binding of mRNA to DNA oligonucleotide probes and its measurement using fluorescent labels. The binding of RNA fragments involving other sequences than the intended target is problematic because it adds a "chemical background" to the signal, which is not related to the expression degree of the target gene. The paper presents a molecular signature of specific and non specific hybridization with potential consequences for gene expression analysis. We analyzed the signal intensities of perfect match (PM) and mismatch (MM) probes of GeneChip microarrays to specify the effect of specific and non specific hybridization. We found that these events give rise to different relations between the PM and MM intensities as function of the middle base of the PMs, namely a triplet- (C>G=T>A>0) and a duplet-like (C=T>0>G=A) pattern of the PM-MM log-intensity difference upon binding of specific and non specific RNA fragments, respectively. The systematic behaviour of the intensity difference can be rationalized on the level of base pairings of DNA/RNA oligonucleotide duplexes in the middle of the probe sequence. Non-specific binding is characterized by the reversal of the central Watson Crick (WC) pairing for each PM/MM probe pair, whereas specific binding refers to the combination of a WC and a self complementary (SC) pairing in PM and MM probes, respectively. The intensity of complementary MM introduces a systematic source of variation which decreases the precision of expression measures based on the MM intensities.
q-bio.BM:We implement the replica exchange molecular dynamics algorithm to study the interactions of a model peptide (WALP-16) with an explicitly represented DPPC membrane bilayer. We observe the spontaneous, unbiased insertion of WALP-16 into the DPPC bilayer and its folding into an a-helix with a trans-bilayer orientation. We observe that the insertion of the peptide into the DPPC bilayer precedes secondary structure formation. Although the peptide has some propensity to form a partially helical structure in the interfacial region of the DPPC/water system, this state is not a productive intermediate but rather an off-pathway trap for WALP-16 insertion. Equilibrium simulations show that the observed insertion/folding pathway mirrors the potential of mean force (PMF). Calculation of the enthalpic and entropic contributions to this PMF show that the surface bound conformation of WALP-16 is significantly lower in energy than other conformations, and that the insertion of WALP-16 into the bilayer without regular secondary structure is enthalpically unfavorable by 5-10 kcal/mol/residue. The observed insertion/folding pathway disagrees with the dominant conceptual model, which is that a surface bound helix is an obligatory intermediate for the insertion of a-helical peptides into lipid bilayers. In our simulations, the observed insertion/folding pathway is favored because of a large (> 100 kcal/mol) increase in system entropy that occurs when the unstructured WALP-16 peptide enters the lipid bilayer interior. The insertion/folding pathway that is lowest in free energy depends sensitively on the near cancellation of large enthalpic and entropic terms. This suggests that intrinsic membrane peptides may have a diversity of insertion/folding behaviors depending on the exact system of peptide and lipid under consideration.
q-bio.BM:Analysis of data from an Affymetrix Latin Square spike-in experiment indicates that measured fluorescence intensities of features on an oligonucleotide microarray are related to spike-in RNA target concentrations via a hyperbolic response function, generally identified as a Langmuir adsorption isotherm. Furthermore the asymptotic signal at high spike-in concentrations is almost invariably lower for a mismatch feature than for its partner perfect match feature. We survey a number of theoretical adsorption models of hybridization at the microarray surface and find that in general they are unable to explain the differing saturation responses of perfect and mismatch features. On the other hand, we find that a simple and consistent explanation can be found in a model in which equilibrium hybridization followed by partial dissociation of duplexes during the post-hybridization washing phase.
q-bio.BM:A model for the processive movement of dynein is presented based on experimental observations available. In the model, the change from strong microtubule-binding to weak binding of dynein is determined naturally by the variation of the relative orientation between the two interacting surfaces of the stalk tip and the microtubule as the stalk rotates from the ADP.Vi-state orientation to the apo-state orientation. This means that the puzzling communication from the ATP binding site in the globular head to the MT-binding site in the tip of the stalk, which is prerequisite in the conventional model, is not required. Using the present model, the previous experimental results, such as (i) the step size of a dynein being an integer times of the period of the MT lattice, (ii) the dependence of the step size on load, i.e., the step size decreasing with the increase of load, and (iii) the stall force being proportional to [ATP] at low [ATP] and becoming saturated at high [ATP], are well explained.
q-bio.BM:We address the controversial hot question concerning the validity of the loose coupling versus the lever-arm theories in the actomyosin dynamics by re-interpreting and extending the phenomenological washboard potential model proposed by some of us in a previous paper. In this new model a Brownian motion harnessing thermal energy is assumed to co-exist with the deterministic swing of the lever-arm, to yield an excellent fit of the set of data obtained by some of us on the sliding of Myosin II heads on immobilized actin filaments under various load conditions. Our theoretical arguments are complemented by accurate numerical simulations, and the robustness of the model is tested via different choices of parameters and potential profiles.
q-bio.BM:In this paper we investigate the role of native geometry on the kinetics of protein folding based on simple lattice models and Monte Carlo simulations. Results obtained within the scope of the Miyazawa-Jernigan indicate the existence of two dynamical folding regimes depending on the protein chain length. For chains larger than 80 amino acids the folding performance is sensitive to the native state's conformation. Smaller chains, with less than 80 amino acids, fold via two-state kinetics and exhibit a significant correlation between the contact order parameter and the logarithmic folding times. In particular, chains with N=48 amino acids were found to belong to two broad classes of folding, characterized by different cooperativity, depending on the contact order parameter. Preliminary results based on the G\={o} model show that the effect of long range contact interaction strength in the folding kinetics is largely dependent on the native state's geometry.
q-bio.BM:Monte Carlo simulations show that long-range interactions play a major role in determining the folding rates of 48-mer three-dimensional lattice polymers modelled by the Go potential. For three target structures with different native geometries we found a sharp increase in the folding time when the relative contribution of the long-range interactions to the native state's energy is decreased from ~50% towards zero. However, the dispersion of the simulated folding times depends strongly on the native geometry and Go polymers folding to one of the target structures exhibit folding times spanning three orders of magnitude. We have also found that, depending on the target geometry, a strong geometric coupling may exist between local and long-range contacts meaning that, when this coupling exists, the formation of long-range contacts is forced by the previous formation of local contacts. The absence of a strong geometric coupling leads to kinetics that are more sensitive to the interaction energy parameters; in this case the formation of local contacts is not sufficient to promote the establishment of long-range ones when these are strongly penalized energetically, leading to longer folding times.
q-bio.BM:A simplified interaction potential for protein folding studies at the atomic level is discussed and tested on a set of peptides with about 20 residues each. The test set contains both alpha-helical (Trp cage, Fs) and beta-sheet (GB1p, GB1m2, GB1m3, Betanova, LLM) peptides. The model, which is entirely sequence-based, is able to fold these different peptides for one and the same choice of model parameters. Furthermore, the melting behavior of the peptides is in good quantitative agreement with experimental data. Apparent folded populations obtained using different observables are compared, and are found to be very different for some of the peptides (e.g., Betanova). In other cases (in particular, GB1m2 and GB1m3), the different estimates agree reasonably well, indicating a more two-state-like melting behavior.
q-bio.BM:Single molecule FRET (fluorescence resonance energy transfer) is a powerful technique for detecting real-time conformational changes and molecular interactions during biological reactions. In this review, we examine different techniques of extending observation times via immobilization and illustrate how useful biological information can be obtained from single molecule FRET time trajectories with or without absolute distance information.
q-bio.BM:An ensemble of directed macromolecules on a lattice is considered, where the constituting molecules are chosen as a random sequence of N different types. The same type of molecules experiences a hard-core (exclusion) interaction. We study the robustness of the macromolecules with respect to breaking and substituting individual molecules, using a 1/N expansion. The properties depend strongly on the density of macromolecules. In particular, the macromolecules are robust against breaking and substituting at high densities.
q-bio.BM:The vibrational dynamics of a DNA molecule with counterions neutralizing the charged phosphate groups have been studied. With the help of elaborated model the conformational vibrations of the DNA double helix with alkaline metal ions have been described both qualitatively and quantitatively. For the complexes of DNA with counterions Li+, Na+, K+, Rb+ and Cs+ the normal modes have been found, and a mode characterized by the most notable ion displacements with respect to the DNA backbone has been determined. The frequency of counterion vibrations has been established to decrease as the ion mass increases. The results of theoretical calculation have been showed to be in good agreement with the experimental data of Raman spectroscopy.
q-bio.BM:To understand the mechanism of TATA-box conformational transformations we model structure mobility and find the types of conformational excitations of DNA macromolecule in heteronomous conformation. We have constructed the two-component model for describing DNA conformational transformation with simultaneous transitions in the furanos rings of the monomer link. Internal component describes the change of the base pair position in the double helix. External component describes the displacement of mass center of the monomer link. Nonlinearity of the system is accounted with a form of potential energy describing C3'-C2' and C2'-C3' sugars transitions in monomer link, and interrelation between monomer conformational transition and macromolecule deformation. The comparison of our results with experimental data allows to confirm that the localized conformational excitations may realise in DNA TATA-box. These excitations cause the deformation of the macromolecule fragment.
q-bio.BM:A simple approach is proposed to investigate the protein structure. Using a low complexity model, a simple pairwise interaction and the concept of global optimization, we are able to calculate ground states of proteins, which are in agreement with experimental data. All possible model structures of small proteins are available below a certain energy threshold. The exact lowenergy landscapes for the trp cage protein (1L2Y) is presented showing the connectivity of all states and energy barriers.
q-bio.BM:The effective DNA-DNA interaction force is calculated by computer simulations with explicit tetravalent counterions and monovalent salt. For overcharged DNA molecules, the interaction force shows a double-minimum structure. The positions and depths of these minima are regulated by the counterion density in the bulk. Using two-dimensional lattice sum and free energy perturbation theories, the coexisting phases for DNA bundles are calculated. A DNA-condensation and redissolution transition and a stable mesocrystal with an intermediate lattice constant for high counterion concentration are obtained.
q-bio.BM:By using a mixture model for the density distribution of the three pseudobond angles formed by $C_\alpha$ atoms of four consecutive residues, the local structural states are discretized as 17 conformational letters of a protein structural alphabet. This coarse-graining procedure converts a 3D structure to a 1D code sequence. A substitution matrix between these letters is constructed based on the structural alignments of the FSSP database.
q-bio.BM:An overview of theories related to vibrational energy relaxation (VER) in proteins is presented. VER of a selected mode in cytochrome c is studied using two theoretical approaches. One is the equilibrium simulation approach with quantum correction factors, and the other is the reduced model approach which describes the protein as an ensemble of normal modes interacting through nonlinear coupling elements. Both methods result in estimates of the VER time (sub ps) for a CD stretching mode in the protein at room temperature. The theoretical predictions are in accord with the experimental data of Romesberg's group. A perspective on future directions for the detailed study of time scales and mechanisms for VER in proteins is presented.
q-bio.BM:Protein one-dimensional (1D) structures such as secondary structure and contact number provide intuitive pictures to understand how the native three-dimensional (3D) structure of a protein is encoded in the amino acid sequence. However, it has not been clear whether a given set of 1D structures contains sufficient information for recovering the underlying 3D structure. Here we show that the 3D structure of a protein can be recovered from a set of three types of 1D structures, namely, secondary structure, contact number and residue-wise contact order which is introduced here for the first time. Using simulated annealing molecular dynamics simulations, the structures satisfying the given native 1D structural restraints were sought for 16 proteins of various structural classes and of sizes ranging from 56 to 146 residues. By selecting the structures best satisfying the restraints, all the proteins showed a coordinate RMS deviation of less than 4\AA{} from the native structure, and for most of them, the deviation was even less than 2\AA{}. The present result opens a new possibility to protein structure prediction and our understanding of the sequence-structure relationship.
q-bio.BM:The lack of specificity in microarray experiments due to non-specific hybridization raises a serious problem for the analysis of microarray data because the residual chemical background intensity is not related to the expression degree of the gene of interest. We analyzed the concentration dependence of the signal intensity of perfect match (PM) and mismatch (MM) probes in terms using a microscopic binding model using a combination of mean hybridization isotherms and single base related affinity terms. The signal intensities of the PM and MM probes and their difference are assessed with regard to their sensitivity, specificity and resolution for gene expression measures. The presented theory implies the refinement of existing algorithms of probe level analysis to correct microarray data for non-specific background intensities.
q-bio.BM:Residue-wise contact order (RWCO) is a new kind of one-dimensional protein structures which represents the extent of long-range contacts. We have recently shown that a set of three types of one-dimensional structures (secondary structure, contact number, and RWCO) contains sufficient information for reconstructing the three-dimensional structure of proteins. Currently, there exist prediction methods for secondary structure and contact number from amino acid sequence, but none exists for RWCO. Also, the properties of amino acids that affect RWCO is not clearly understood. Here, we present a linear regression-based method to predict RWCO from amino acid sequence, and analyze the regression parameters to identify the properties that correlates with the RWCO. The present method achieves the significant correlation of 0.59 between the native and predicted RWCOs on average. An unusual feature of the RWCO prediction is the remarkably large optimal half window size of 26 residues. The regression parameters for the central and near-central residues of the local sequence segment highly correlate with those of the contact number prediction, and hence with hydrophobicity.
q-bio.BM:In this paper the heat signaling in microtubules (MT) is investigated. It is argued that for the description of the heat signaling phenomena in MT, the hyperbolic heat transport (HHT) equation must be used. It is shown that HHT is the Klein-Gordon (K-G) equation. The general solution for the K-G equation for MT is obtained. For the undistorted signal propagation in MT the Heisenberg uncertainty principle is formulated and discussed.   Key words: Microtubules; Heat signaling; Klein-Gordon equation; Heisenberg principle.
q-bio.BM:In the last years, tens of thousands gene expression profiles for cells of several organisms have been monitored. Gene expression is a complex transcriptional process where mRNA molecules are translated into proteins, which control most of the cell functions. In this process, the correlation among genes is crucial to determine the specific functions of genes. Here, we propose a novel multi-dimensional stochastic approach to deal with the gene correlation phenomena. Interestingly, our stochastic framework suggests that the study of the gene correlation requires only one theoretical assumption -Markov property- and the experimental transition probability, which characterizes the gene correlation system. Finally, a gene expression experiment is proposed for future applications of the model.
q-bio.BM:The importance of understanding the mechanism of protein aggregation into insoluble amyloid fibrils relies not only on its medical consequences, but also on its more basic properties of self--organization. The discovery that a large number of uncorrelated proteins can form, under proper conditions, structurally similar fibrils has suggested that the underlying mechanism is a general feature of polypeptide chains. In the present work, we address the early events preceeding amyloid fibril formation in solutions of zinc--free human insulin incubated at low pH and high temperature. Aside from being a easy--to--handle model for protein fibrillation, subcutaneous aggregation of insulin after injection is a nuisance which affects patients with diabetes. Here, we show by time--lapse atomic force microscopy (AFM) that a steady-state distribution of protein oligomers with an exponential tail is reached within few minutes after heating. This metastable phase lasts for few hours until aggregation into fibrils suddenly occurs. A theoretical explanation of the oligomer pre--fibrillar distribution is given in terms of a simple coagulation--evaporation kinetic model, in which concentration plays the role of a critical parameter. Due to high resolution and sensitivity of AFM technique, the observation of a long-lasting latency time should be considered an actual feature of the aggregation process, and not simply ascribed to instrumental inefficency. These experimental facts, along with the kinetic model used, claim for a critical role of thermal concentration fluctuations in the process of fibril nucleation.
q-bio.BM:Identical objects, regularly assembled, form a helix, which is the principal motif of nucleic acids, proteins, and viral capsids.
q-bio.BM:The ambitious and ultimate research purpose in Systems Biology is the understanding and modelling of the cell's system. Although a vast number of models have been developed in order to extract biological knowledge from complex systems composed of basic elements as proteins, genes and chemical compounds, a need remains for improving our understanding of dynamical features of the systems (i.e., temporal-dependence).   In this article, we analyze the gene expression dynamics (i.e., how the genes expression fluctuates in time) by using a new constructive approach. This approach is based on only two fundamental ingredients: symmetry and the Markov property of dynamics. First, by using experimental data of human and yeast gene expression time series, we found a symmetry in short-time transition probability from time $t$ to time $t+1$. We call it self-similarity symmetry (i.e., surprisingly, the gene expression short-time fluctuations contain a repeating pattern of smaller and smaller parts that are like the whole, but different in size). Secondly, the Markov property of dynamics reflects that the short-time fluctuation governs the full-time behaviour of the system. Here, we succeed in reconstructing naturally the global behavior of the observed distribution of gene expression (i.e., scaling-law) and the local behaviour of the power-law tail of this distribution, by using only these two ingredients: symmetry and the Markov property of dynamics. This approach may represent a step forward toward an integrated image of the basic elements of the whole cell.
q-bio.BM:In this work, the dynamics of fluctuations in gene expression time series is investigated. By using collected data of gene expression from yeast and human organisms, we found that the fluctuations of gene expression level and its average value over time are strongly correlated and obey a scaling law. As this feature is found in yeast and human organisms, it suggests that probably this coupling is a common dynamical organizing property of all living systems. To understand these observations, we propose a stochastic model which can explain these collective fluctuations, and predict the scaling exponent. Interestingly, our results indicate that the observed scaling law emerges from the self-similarity symmetry embedded in gene expression fluctuations.
q-bio.BM:We study the mechanism underlying the attraction between nucleosomes, the fundamental packaging units of DNA inside the chromatin complex. We introduce a simple model of the nucleosome, the eight-tail colloid, consisting of a charged sphere with eight oppositely charged, flexible, grafted chains that represent the terminal histone tails. We demonstrate that our complexes are attracted via the formation of chain bridges and that this attraction can be tuned by changing the fraction of charged monomers on the tails. This suggests a physical mechanism of chromatin compaction where the degree of DNA condensation can be controlled via biochemical means, namely the acetylation and deacetylation of lysines in the histone tails.
q-bio.BM:The effects of monovalent (Na+, K+) and divalent (Mg2+, Ca2+, Mn2+) ions on the interaction between DNA and histone are studied using the molecular combing technique. Lamda-DNA molecules and DNA-histone complexes incubated with metal cations (Na+, K+, Mg2+, Ca2+, Mn2+) are stretched on hydrophobic surfaces, and directly observed by fluorescence microscopy. The results indicate that when these cations are added into the DNA solution, the fluorescence intensities of the stained DNA are reduced differently. The monovalent cations (Na+, K+) inhibit binding of histone to DNA. The divalent cations (Mg2+, Ca2+, Mn2+) enhance significantly the binding of histone to DNA and the binding of the DNA-histone complex to the hydrophobic surface. Mn2+ also induces condensation and aggregation of the DNA-histone complex.
q-bio.BM:PDZ (Post-synaptic density-95/discs large/zonula occludens-1) domains are relatively small (80 to 120 residues) protein binding modules central in the organization of receptor clusters and in the association of cellular proteins. Their main function is to bind C-terminals of selected proteins that are recognized through specific amino-acids in their carboxyl end. Binding is associated with a deformation of the PDZ native structure and is responsible for dynamical changes in regions not in direct contact with the target. We investigate how this deformation is related to the harmonic dynamics of the PDZ structure and show that one low-frequency collective normal mode, characterized by the concerted movements of different secondary structures, is involved in the binding process. Our results suggest that even minimal structural changes are responsible of communication between distant regions of the protein, in agreement with recent Nuclear Magnetic Resonance (NMR) experiments. Thus PDZ domains are a very clear example of how collective normal modes are able to characterize the relation between function and dynamics of proteins, and to provide indications on the precursors of binding/unbonding events.
q-bio.BM:We introduce a new measure of antigenic distance between influenza A vaccine and circulating strains. The measure correlates well with efficacies of the H3N2 influenza A component of the annual vaccine between 1971 and 2004, as do results of a theory of the immune response to influenza following vaccination. This new measure of antigenic distance is correlated with vaccine efficacy to a greater degree than are current state-of-the-art phylogenetic sequence analyzes or ferret antisera inhibition assays. We suggest that this new measure of antigenic distance be used in the design of the annual influenza vaccine and in the interpretation of vaccine efficacy monitoring.
q-bio.BM:Prediction of one-dimensional protein structures such as secondary structures and contact numbers is useful for the three-dimensional structure prediction and important for the understanding of sequence-structure relationship. Here we present a new machine-learning method, critical random networks (CRNs), for predicting one-dimensional structures, and apply it, with position-specific scoring matrices, to the prediction of secondary structures (SS), contact numbers (CN), and residue-wise contact orders (RWCO). The present method achieves, on average, $Q_3$ accuracy of 77.8% for SS, correlation coefficients of 0.726 and 0.601 for CN and RWCO, respectively. The accuracy of the SS prediction is comparable to other state-of-the-art methods, and that of the CN prediction is a significant improvement over previous methods. We give a detailed formulation of critical random networks-based prediction scheme, and examine the context-dependence of prediction accuracies. In order to study the nonlinear and multi-body effects, we compare the CRNs-based method with a purely linear method based on position-specific scoring matrices. Although not superior to the CRNs-based method, the surprisingly good accuracy achieved by the linear method highlights the difficulty in extracting structural features of higher order from amino acid sequence beyond that provided by the position-specific scoring matrices.
q-bio.BM:We describe the results obtained from an improved model for protein folding. We find that a good agreement with the native structure of a 46 residue long, five-letter protein segment is obtained by carefully tuning the parameters of the self-avoiding energy. In particular we find an improved free-energy profile. We also compare the efficiency of the multidimensional replica exchange method with the widely used parallel tempering.
q-bio.BM:We use single-particle tracking to study the elastic properties of single microtubules grafted to a substrate. Thermal fluctuations of the free microtubule's end are recorded, in order to measure position distribution functions from which we calculate the persistence length of microtubules with contour lengths between 2.6 and 48 micrometers. We find the persistence length to vary by more than a factor of 20 over the total range of contour lengths. Our results support the hypothesis that shearing between protofilaments contributes significantly to the mechanics of microtubules.
q-bio.BM:Optimal structure of proteins is described by linear stochastic differential equation with mean decrease of free energy and volatility. Structure determining strategy is given by a twin of stochastic variables for which empirical conditions are not postulated. Optimal structure determination will be deformed to be adoptive to trading strategy employing martingale property where stochastic integral w.r.t. analytical solution of stochastic differential equation will be employed.
q-bio.BM:One of the main problems of drug design is that of optimizing the drug--target interaction. In the case in which the target is a viral protein displaying a high mutation rate, a second problem arises, namely the eventual development of resistance. We wish to suggest a scheme for the design of non--conventional drugs which do not face any of these problems and apply it to the case of HIV--1 protease. It is based on the knowledge that the folding of single--domain proteins, like e.g. each of the monomers forming the HIV--1--PR homodimer, is controlled by local elementary structures (LES), stabilized by local contacts among hydrophobic, strongly interacting and highly conserved amino acids which play a central role in the folding process. Because LES have evolved over myriads of generations to recognize and strongly interact with each other so as to make the protein fold fast as well as to avoid aggregation with other proteins, highly specific (and thus little toxic) as well as effective folding--inhibitor drugs suggest themselves: short peptides (or eventually their mimetic molecules), displaying the same amino acid sequence of that of LES (p--LES). Aside from being specific and efficient, these inhibitors are expected not to induce resistance: in fact, mutations which successfully avoid their action imply the destabilization of one or more LES and thus should lead to protein denaturation. Making use of Monte Carlo simulations within the framework of a simple although not oversimplified model, which is able to reproduce the main thermodynamic as well as dynamic properties of monoglobular proteins, we first identify the LES of the HIV--1--PR and then show that the corresponding p--LES peptides act as effective inhibitors of the folding of the protease which do not create resistance.
q-bio.BM:Protein structure is generally conceptualized as the global arrangement or of smaller, local motifs of helices, sheets, and loops. These regular, recurring secondary structural elements have well-understood and standardized definitions in terms of amino acid backbone geometry and the manner in which hydrogen bonding requirements are satisfied. Recently, "tube" models have been proposed to explain protein secondary structure in terms of the geometrically optimal packing of a featureless cylinder. However, atomically detailed simulations demonstrate that such packing considerations alone are insufficient for defining secondary structure; both excluded volume and hydrogen bonding must be explicitly modeled for helix formation. These results have fundamental implications for the construction and interpretation of realistic and meaningful biomacromolecular models.
q-bio.BM:Structure predictions of helical membrane proteins have been designed to take advantage of the structural autonomy of secondary structure elements, as postulated by the two-stage model of Engelman and Popot. In this context, we investigate structure calculation strategies for two membrane proteins with different functions, sizes, aminoacid compositions, and topologies: the glycophorin A homodimer (a paradigm for close inter-helical packing in membrane proteins) and aquaporin (a channel protein). Our structure calculations are based on two alternative folding schemes: a one-step simulated annealing from an extended chain conformation, and a two-step procedure inspired by the grid-search methods traditionally used in membrane protein predictions. In this framework, we investigate rationales for the utilization of sparse NMR data such as distance-based restraints and residual dipolar couplings in structure calculations of helical membrane proteins.
q-bio.BM:Proteins created by combinatorial methods in vitro are an important source of information for understanding sequence-structure-function relationships. Alignments of folded proteins from combinatorial libraries can be analyzed using methods developed for naturally occurring proteins, but this neglects the information contained in the unfolded sequences of the library. We introduce two algorithms, logistic regression and excess information analysis, that use both the folded and unfolded sequences and compare them against contingency table and statistical coupling analysis, which only use the former. The test set for this benchmark study is a library of fictitious proteins that fold according to a hypothetical energy model. Of the four methods studied, only logistic regression is able to correctly recapitulate the energy model from the sequence alignment. The other algorithms predict spurious interactions between alignment positions with strong but individual influences on protein stability. When present in the same protein, stabilizing amino acids tend to lower the energy below the threshold needed for folding. As a result, their frequencies in the alignment can be correlated even if the positions do not interact. We believe any algorithm that neglects the nonlinear relationship between folding and energy is susceptible to this error.
q-bio.BM:In order to extend the results obtained with minimal lattice models to more realistic systems, we study a model where proteins are described as a chain of 20 kinds of structureless amino acids moving in a continuum space and interacting through a contact potential controlled by a 20x20 quenched random matrix. The goal of the present work is to design and characterize amino acid sequences folding to the SH3 conformation, a 60-residues recognition domain common to many regulatory proteins. We show that a number of sequences can fold, starting from a random conformation, to within a distance root mean square deviation (dRMSD) of 2.6A from the native state. Good folders are those sequences displaying in the native conformation an energy lower than a sequence--independent threshold energy.
q-bio.BM:We recently introduced a physical model [Hoang et al., P. Natl. Acad. Sci. USA (2004), Banavar et al., Phys. Rev. E (2004)] for proteins which incorporates, in an approximate manner, several key features such as the inherent anisotropy of a chain molecule, the geometrical and energetic constraints placed by the hydrogen bonds and sterics, and the role played by hydrophobicity. Within this framework, marginally compact conformations resembling the native state folds of proteins emerge as broad competing minima in the free energy landscape even for a homopolymer. Here we show how the introduction of sequence heterogeneity using a simple scheme of just two types of amino acids, hydrophobic (H) and polar (P), and sequence design allows a selected putative native fold to become the free energy minimum at low temperature. The folding transition exhibits thermodynamic cooperativity, if one neglects the degeneracy between two different low energy conformations sharing the same fold topology.
q-bio.BM:In eukaryote nucleosome, DNA wraps around a histone octamer in a left-handed way. We study the process of chirality formation of nucleosome with Brownian dynamics simulation. We model the histone octamer with a quantitatively adjustable chirality: left-handed, right-handed or non-chiral, and simulate the dynamical wrapping process of a DNA molecule on it. We find that the chirality of a nucleosome formed is strongly dependent on that of the histone octamer, and different chiralities of the histone octamer induce its different rotation directions in the wrapping process of DNA. In addition, a very weak chirality of the histone octamer is quite enough for sustaining the correct chirality of the nucleosome formed. We also show that the chirality of a nucleosome may be broken at elevated temperature.
q-bio.BM:Trypsin and chymotrypsin are both serine proteases with high sequence and structural similarities, but with different substrate specificity. Previous experiments have demonstrated the critical role of the two loops outside the binding pocket in controlling the specificity of the two enzymes. To understand the mechanism of such a control of specificity by distant loops, we have used the Gaussian Network Model to study the dynamic properties of trypsin and chymotrypsin and the roles played by the two loops. A clustering method was introduced to analyze the correlated motions of residues. We have found that trypsin and chymotrypsin have distinct dynamic signatures in the two loop regions which are in turn highly correlated with motions of certain residues in the binding pockets. Interestingly, replacing the two loops of trypsin with those of chymotrypsin changes the motion style of trypsin to chymotrypsin-like, whereas the same experimental replacement was shown necessary to make trypsin have chymotrypsin's enzyme specificity and activity. These results suggest that the cooperative motions of the two loops and the substrate-binding sites contribute to the activity and substrate specificity of trypsin and chymotrypsin.
q-bio.BM:The emergence and spreading of chirality on the early Earth is considered by studying a set of reaction-diffusion equations based on a polymerization model. It is found that effective mixing of the early oceans is necessary to reach the present homochiral state. The possibility of introducing mass extinctions and modifying the emergence rate of life is discussed.
q-bio.BM:The differences between uni-directional and bi-directional polymerization are considered. The uni-directional case is discussed in the framework of the RNA world. Similar to earlier models of this type, where polymerization was assumed to proceed in a bi-directional fashion (presumed to be relevant to peptide nucleic acids), left-handed and right-handed monomers are produced via an autocatalysis from an achiral substrate. The details of the bifurcation from a racemic solution to a homochiral state of either handedness is shown to be remarkably independent of whether the polymerization in uni-directional or bi-directional. Slightly larger differences are seen when dissociation is allowed and the dissociation fragments are being recycled into the achiral substrate.
q-bio.BM:A variety of viruses tightly pack their genetic material into protein capsids that are barely large enough to enclose the genome. In particular, in bacteriophages, forces as high as 60 pN are encountered during packaging and ejection, produced by DNA bending elasticity and self-interactions. The high forces are believed to be important for the ejection process, though the extent of their involvement is not yet clear. As a result, there is a need for quantitative models and experiments that reveal the nature of the forces relevant to DNA ejection. Here we report measurements of the ejection forces for two different mutants of bacteriophage lambda, lambda b221cI26 and lambda cI60, which differ in genome length by ~30%. As expected for a force-driven ejection mechanism, the osmotic pressure at which DNA release is completely inhibited varies with the genome length: we find inhibition pressures of 15 atm and 25 atm, respectively, values that are in agreement with our theoretical calculations.
q-bio.BM:The correlations of primary and secondary structures were analyzed using proteins with known structure from Protein Data Bank. The correlation values of amino acid type and the eight secondary structure types at distant position were calculated for distances between -25 and 25. Shapes of the diagrams indicate that amino acids polarity and capability for hydrogen bonding have influence on the secondary structure at some distances. Clear preference of most of the amino acids towards certain secondary structure type classifies amino acids into four groups: alpha-helix admirers, strand admirers, turn and bend admirers and the others. Group four consists of His and Cis, the amino acids that do not show clear preference for any secondary structure. Amino acids from a group have similar physicochemical properties, and the same structural characteristics. The results suggest that amino acid preference for secondary structure type is based on the structural characteristics at Cb and Cg atoms of amino acid. alpha-helix admirers do not have polar heteroatoms on Cb and Cg atoms, nor branching or aromatic group on Cb atom. Amino acids that have aromatic groups or branching on Cb atom are strand admirers. Turn and bend admirers have polar heteroatom on Cb or Cg atoms or do not have Cb atom at all. Our results indicate that polarity and capability for hydrogen bonding have influence on the secondary structure at some distance, and that amino acid preference for secondary structure is caused by structural properties at Cb or Cg atoms.
q-bio.BM:The functionality of proteins is related to their structure in the native state. Protein structures are made up of emergent building blocks of helices and almost planar sheets. A simple coarse-grained geometrical model of a flexible tube barely subject to compaction provides a unified framework for understanding the common character of globular proteins.We argue that a recent critique of the tube idea is not well founded.
q-bio.BM:To gain a deeper insight into cellular processes such as transcription and translation, one needs to uncover the mechanisms controlling the configurational changes of nucleic acids. As a step toward this aim, we present here a novel mesoscopic-level computational model that provides a new window into nucleic acid dynamics. We model a single-stranded nucleic as a polymer chain whose monomers are the nucleosides. Each monomer comprises a bead representing the sugar molecule and a pin representing the base. The bead-pin complex can rotate about the backbone of the chain. We consider pairwise stacking and hydrogen-bonding interactions. We use a modified Monte Carlo dynamics that splits the dynamics into translational bead motion and rotational pin motion. By performing a number of tests we first show that our model is physically sound. We then focus on the study of a the kinetics of a DNA hairpin--a single-stranded molecule comprising two complementary segments joined by a non-complementary loop--studied experimentally. We find that results from our simulations agree with experimental observations, demonstrating that our model is a suitable tool for the investigation of the hybridization of single strands.
q-bio.BM:We investigate the folding behavior of protein sequences by numerically studying all sequences with maximally compact lattice model through exhaustive enumeration. We get the prion-like behavior of protein folding. Individual proteins remaining stable in the isolated native state may change their conformations when they aggregate. We observe the folding properties as the interfacial interaction strength changes, and find that the strength must be strong enough before the propagation of the most stable structures happens.
q-bio.BM:We review some of our recent results obtained within the scope of simple lattice models and Monte Carlo simulations that illustrate the role of native geometry in the folding kinetics of two state folders.
q-bio.BM:Ion channels are proteins with a hole down the middle embedded in cell membranes. Membranes form insulating structures and the channels through them allow and control the movement of charged particles, spherical ions, mostly Na+, K+, Ca++, and Cl-. Membranes contain hundreds or thousands of types of channels, fluctuating between open conducting, and closed insulating states. Channels control an enormous range of biological function by opening and closing in response to specific stimuli using mechanisms that are not yet understood in physical language. Open channels conduct current of charged particles following laws of Brownian movement of charged spheres rather like the laws of electrodiffusion of quasi-particles in semiconductors. Open channels select between similar ions using a combination of electrostatic and 'crowded charge' (Lennard-Jones) forces. The specific location of atoms and the exact atomic structure of the channel protein seems much less important than certain properties of the structure, namely the volume accessible to ions and the effective density of fixed and polarization charge. There is no sign of other chemical effects like delocalization of electron orbitals between ions and the channel protein. Channels play a role in biology as important as transistors in computers, and they use rather similar physics to perform part of that role. Understanding their fluctuations awaits physical insight into the source of the variance and mathematical analysis of the coupling of the fluctuations to the other components and forces of the system.
q-bio.BM:We propose a criterion for optimal parameter selection in coarse-grained models of proteins, and develop a refined elastic network model (ENM) of bovine trypsinogen. The unimodal density-of-states distribution of the trypsinogen ENM disagrees with the bimodal distribution obtained from an all-atom model; however, the bimodal distribution is recovered by strengthening interactions between atoms that are backbone neighbors. We use the backbone-enhanced model to analyze allosteric mechanisms of trypsinogen, and find relatively strong communication between the regulatory and active sites.
q-bio.BM:The protonation of N2 bound to the active center of nitrogenase has been investigated using state-of-the-art DFT calculations. Dinitrogen in the bridging mode is activated by forming two bonds to Fe sites, which results in a reduction of the energy for the first hydrogen transfer by 123 kJ/mol. The axial binding mode with open sulfur bridge is less reactive by 30 kJ/mol and the energetic ordering of the axial and bridged binding mode is reversed in favor of the bridging dinitrogen during the first protonation. Protonation of the central ligand is thermodynamically favorable but kinetically hindered. If the central ligand is protonated, the proton is transferred to dinitrogen following the second protonation. Protonation of dinitrogen at the Mo site does not lead to low-energy intermediates.
q-bio.BM:The ejection of DNA from a bacterial virus (``phage'') into its host cell is a biologically important example of the translocation of a macromolecular chain along its length through a membrane. The simplest mechanism for this motion is diffusion, but in the case of phage ejection a significant driving force derives from the high degree of stress to which the DNA is subjected in the viral capsid. The translocation is further sped up by the ratcheting and entropic forces associated with proteins that bind to the viral DNA in the host cell cytoplasm. We formulate a generalized diffusion equation that includes these various pushing and pulling effects and make estimates of the corresponding speed-ups in the overall translocation process. Stress in the capsid is the dominant factor throughout early ejection, with the pull due to binding particles taking over at later stages. Confinement effects are also investigated, in the case where the phage injects its DNA into a volume comparable to the capsid size. Our results suggest a series of in vitro experiments involving the ejection of DNA into vesicles filled with varying amounts of binding proteins from phage whose state of stress is controlled by ambient salt conditions or by tuning genome length.
q-bio.BM:We present a base-pairing model of oligonuleotide duplex formation and show in detail its equivalence to the Nearest-Neighbour dimer methods from fits to free energy of duplex formation data for short DNA-DNA and DNA-RNA hybrids containing only Watson Crick pairs. In this approach the connection between rank-deficient polymer and rank-determinant oligonucleotide parameter, sets for DNA duplexes is transparent. The method is generalised to include RNA/DNA hybrids where the rank-deficient model with 11 dimer parameters in fact provides marginally improved predictions relative to the standard method with 16 independent dimer parameters ($\Delta G$ mean errors of 4.5 and 5.4 % respectively).
q-bio.BM:A formalism is developed which allows to determine the locations of all local symmetry axes of three-dimensional particles with overall icosahedral symmetry. It relies on the fact that the root system of the non-crystallographic Coxeter group H_3 encodes the locations of the planes of reflection that generate the discrete rotational symmetries of the particles. Via an appropriate extension of the root system, new planes of reflection are introduced which determine local axes of rotational symmetry. An easy-to-implement formalism is derived that allows to compute the surface structure of any three-dimensional icosahedral particle with local symmetries. It can be used also for particles with overall octahedral and tetrahedral symmetry in conjunction with the root systems of the corresponding reflection groups.   Applications to viruses are discussed explicitly. It is shown that the concept of quasi-equivalence in Caspar-Klug Theory corresponds to the special case of local six-fold symmetry axes contained in the theory developed here, and the corresponding geometries can hence be obtained with this formalism based on the root system of H_3.   Moreover, as a by-product, the theory answers the long-standing open question why only certain types of capsomeres, i.e. clusters of protein subunits, are observed in the surface structures of viruses. Since the types of the capsomeres are determined by the orders of the local symmetry axes on which they are located, the possible types of capsomeres are restricted by the spectrum of local symmetry axes allowed by the theory. Based on this we determine the spectrum of all capsomere types that may occur in viral capsids and give explicit examples for the lower-order cases.
q-bio.BM:The tethered-particle method is a single-molecule technique that has been used to explore the dynamics of a variety of macromolecules of biological interest. We give a theoretical analysis of the particle motions in such experiments. Our analysis reveals that the proximity of the tethered bead to a nearby surface (the microscope slide) gives rise to a volume-exclusion effect, resulting in an entropic force on the molecule. This force stretches the molecule, changing its statistical properties. In particular, the proximity of bead and surface brings about intriguing scaling relations between key observables (statistical moments of the bead) and parameters such as the bead size and contour length of the molecule. We present both approximate analytic solutions and numerical results for these effects in both flexible and semiflexible tethers. Finally, our results give a precise, experimentally-testable prediction for the probability distribution of the distance between the polymer attachment point and the center of the mobile bead.
q-bio.BM:The distribution of inequivalent geometries occurring during self-assembly of the major capsid protein in thermodynamic equilibrium is determined based on a master equation approach. These results are implemented to characterize the assembly of SV40 virus and to obtain information on the putative pathways controlling the progressive build-up of the SV40 capsid. The experimental testability of the predictions is assessed and an analysis of the geometries of the assembly intermediates on the dominant pathways is used to identify targets for antiviral drug design.
q-bio.BM:A vital constituent of a virus is its protein shell, called the viral capsid, that encapsulates and hence provides protection for the viral genome. Assembly models are developed for viral capsids built from protein building blocks that can assume different local bonding structures in the capsid. This situation occurs, for example, for viruses in the family of Papovaviridae, which are linked to cancer and are hence of particular interest for the health sector. More specifically, the viral capsids of the (pseudo-) T=7 particles in this family consist of pentamers that exhibit two different types of bonding structures. While this scenario cannot be described mathematically in terms of Caspar-Klug Theory (Caspar and Klug 1962), it can be modelled via tiling theory (Twarock 2004). The latter is used to encode the local bonding environment of the building blocks in a combinatorial structure, called the assembly tree, which is a basic ingredient in the derivation of assembly models for Papovaviridae along the lines of the equilibrium approach of Zlotnick (Zlotnick 1994). A phase space formalism is introduced to characterize the changes in the assembly pathways and intermediates triggered by the variations in the association energies characterizing the bonds between the building blocks in the capsid. Furthermore, the assembly pathways and concentrations of the statistically dominant assembly intermediates are determined. The example of Simian Virus 40 is discussed in detail.
q-bio.BM:We calculate the equation of state of DNA under tension for the case that the DNA features loops. Such loops occur transiently during DNA condensation in the presence of multivalent ions or sliding cationic protein linkers. The force-extension relation of such looped DNA modelled as a wormlike chain is calculated via path integration in the semiclassical limit. This allows us to determine rigorously the high stretching asymptotics. Notably the functional form of the force-extension curve resembles that of straight DNA, yet with a strongly renormalized apparent persistence length. That means that the experimentally extracted single molecule elasticity does not necessarily reflect the bare DNA stiffness only, but can also contain additional contributions that depend on the overall chain conformation and length.
q-bio.BM:A generalized computational method for folding proteins with a fully transferable potential and geometrically realistic all-atom model is presented and tested on seven different helix bundle proteins. The protocol, which includes graph-theoretical analysis of the ensemble of resulting folded conformations, was systematically applied and consistently produced structure predictions of approximately 3 Angstroms without any knowledge of the native state. To measure and understand the significance of the results, extensive control simulations were conducted. Graph theoretic analysis provides a means for systematically identifying the native fold and provides physical insight, conceptually linking the results to modern theoretical views of protein folding. In addition to presenting a method for prediction of structure and folding mechanism, our model suggests that a accurate all-atom amino acid representation coupled with a physically reasonable atomic interaction potential (that does not require optimization to the test set) and hydrogen bonding are essential features for a realistic protein model.
q-bio.BM:Being the HIV-1 Protease (HIV-1-PR) an essential enzyme in the viral life cycle, its inhibition can control AIDS. The folding of single domain proteins, like each of the monomers forming the HIV-1-PR homodimer, is controlled by local elementary structures (LES, folding units stabilized by strongly interacting, highly conserved, as a rule hydrophobic, amino acids). These LES have evolved over myriad of generations to recognize and strongly attract each other, so as to make the protein fold fast and be stable in its native conformation. Consequently, peptides displaying a sequence identical to those segments of the monomers associated with LES are expected to act as competitive inhibitors and thus destabilize the native structure of the enzyme. These inhibitors are unlikely to lead to escape mutants as they bind to the protease monomers through highly conserved amino acids which play an essential role in the folding process. The properties of one of the most promising inhibitors of the folding of the HIV-1-PR monomers found among these peptides is demonstrated with the help of spectrophotometric assays and CD spectroscopy.
q-bio.BM:It is shown that a small subset of modes which are likely to be involved in protein functional motions of large amplitude can be determined by retaining the most robust normal modes obtained using different protein models. This result should prove helpful in the context of several applications proposed recently, like for solving difficult molecular replacement problems or for fitting atomic structures into low-resolution electron density maps. Moreover, it may also pave the way for the development of methods allowing to predict such motions accurately.
q-bio.BM:A new formalism for calculation of the partition function of single stranded nucleic acids is presented. Secondary structures and the topology of structure elements are the level of resolution that is used. The folding model deals with matches, mismatches, symmetric and asymmetric interior loops, stacked pairs in loop and dangling end regions, multi-branched loops, bulges and single base stacking that might exist at duplex ends or at the ends of helices. Calculations on short and long sequences show, that for short oligonucleotides, a duplex formation often displays a two-state transition. However, for longer oligonucleotides, the thermodynamic properties of the single self-folding transition affects the transition nature of the duplex formation, resulting in a population of intermediate hairpin species in the solution. The role of intermediate hairpin species is analyzed in the case when a short oligonucleotides (molecular beacons) have to reliably identify and hybridize to accessible nucleotides within their targeted mRNA sequences. It is shown that the enhanced specificity of the molecular beacons is a result of their constrained conformational flexibility and the all-or-none mechanism of their hybridization to the target sequence.
q-bio.BM:A vital constituent of a virus is its protein shell, called the viral capsid, that encapsulates and hence provides protection for the viral genome. Viral capsids are usually spherical, and for a significant number of viruses exhibit overall icosahedral symmetry. The corresponding surface lattices, that encode the locations of the capsid proteins and intersubunit bonds, can be modelled by Viral Tiling Theory.   It has been shown in vitro that under a variation of the experimental boundary conditions, such as the pH value and salt concentration, tubular particles may appear instead of, or in addition to, spherical ones. In order to develop models that describe the simultaneous assembly of both spherical and tubular variants, and hence study the possibility of triggering tubular malformations as a means of interference with the replication mechanism, Viral Tiling Theory has to be extended to include tubular lattices with end caps. This is done here for the case of Papovaviridae, which play a distinguished role from the viral structural point of view as they correspond to all pentamer lattices, i.e. lattices formed from clusters of five protein subunits throughout. These results pave the way for a generalisation of recently developed assembly models.
q-bio.BM:Experimental investigations of the biosynthesis of a number of proteins have pointed out that part of the native structure can be acquired already during translation. We carried out a comprehensive statistical analysis of some average structural properties of proteins that have been put forward as possible signatures of this progressive buildup process. Contrary to a widespread belief, it is found that there is no major propensity of the amino acids to form contacts with residues that are closer to the N terminus. Moreover, it is found that the C terminus is significantly more compact and locally-organized than the N one. Also this bias, though, is unlikely to be related to vectorial effects, since it correlates with subtle differences in the primary sequence. These findings indicate that even if proteins aquire their structure vectorially no signature of this seems to be detectable in their average structural properties.
q-bio.BM:The aim of this article is to present a developed method that decomposes the autofluorescence spectrum into the spectra of naturally occurring biochemical components of biotissue. It requires knowledge of detailed spectrum behaviour of different endogenous fluorophores. We have studied the main bio-markers in human tissue and proposed a simple modelling algorithm for their spectra shapes. The empirical method was tested theoretically by quantum-mechanical calculations of the spectra in the unharmonic Morse potential approach.
q-bio.BM:Experimental evidence suggests that the folding and aggregation of the amyloid $\beta$-protein (A$\beta$) into oligomers is a key pathogenetic event in Alzheimer's disease (AD). Inhibiting the pathologic folding and oligomerization of A$\beta$ could be effective in the prevention and treatment of AD. Here, using all-atom molecular dynamics simulations in explicit solvent, we probe the initial stages of folding of a decapeptide segment of A$\beta$, A$\beta_{21-30}$, shown experimentally to nucleate the folding process. In addition, we examine the folding of a homologous decapeptide containing an amino acid substitution linked to hereditary cerebral hemorrhage with amyloidosis--Dutch type, [Gln22]A$\beta_{21-30}$. We find that: (i) when the decapeptide is in water, hydrophobic interactions and transient salt bridges between Lys28 and either Glu22 or Asp23 are important in the formation of a loop in the Val24--Lys28 region of the wild type decapeptide; (ii) in the presence of salt ions, salt bridges play a more prominent role in the stabilization of the loop; (iii) in water with a reduced density, the decapeptide forms a helix, indicating the sensitivity of folding to different aqueous environments; (iv) the ``Dutch'' peptide in water, in contrast to the wild type peptide, fails to form a long-lived Val24--Lys28 loop, suggesting that loop stability is a critical factor in determining whether A$\beta$ folds into pathologic structures. Our results are relevant to understand the mechanism of A$\beta$ peptide folding in different environments, such as intra- and extracellular milieus or cell membranes, and how amino acid substitutions linked to familial forms of amyloidosis cause disease.
q-bio.BM:This paper was withdrawn by the authors.
q-bio.BM:We develop a class of models with which we simulate the assembly of particles into T1 capsid-like objects using Newtonian dynamics. By simulating assembly for many different values of system parameters, we vary the forces that drive assembly. For some ranges of parameters, assembly is facile, while for others, assembly is dynamically frustrated by kinetic traps corresponding to malformed or incompletely formed capsids. Our simulations sample many independent trajectories at various capsomer concentrations, allowing for statistically meaningful conclusions. Depending on subunit (i.e., capsomer) geometries, successful assembly proceeds by several mechanisms involving binding of intermediates of various sizes. We discuss the relationship between these mechanisms and experimental evaluations of capsid assembly processes.
q-bio.BM:In this paper the heat transport in microtubules (MT) is investigated. When the dimension of the structure is of the order of the de Broglie wave length the transport phenomena must be analyzed within quantum mechanics. In this paper we developed the Dirac type thermal equation for MT .The solution of the equation-the temperature fields for electrons can be wave type or diffusion type depending on the dynamics of the scattering. Key words: Microtubules ultrashort laser pulses, Dirac thermal equation, temperature fields.
q-bio.BM:Mouse prion protein PrP106-126 is a peptide corresponding to the residues 107-127 of human prion protein. It has been shown that PrP106-126 can reproduce the main neuropathological features of prionrelated transmissible spongiform encephalopathies and can form amyloid-like fibrils in vitro. The conformational characteristics of PrP106-126 fibril have been investigated by electron microscopy, CD spectroscopy, NMR and molecular dynamics simulations. Recent researches have found out that PrP106-126 in water assumes a stable structure consisting of two parallel beta-sheets that are tightly packed against each other. In this work we perform molecular dynamics simulation to reveal the elongation mechanism of PrP106-126 fibril. Influenced by the edge strands of the fibril which already adopt beta-sheets conformation, single PrP106-126 peptide forms beta-structure and becomes a new element of the fibril. Under acidic condition, single PrP106-126 peptide adopts a much larger variety of conformations than it does under neural condition, which makes a peptide easier to be influenced by the edge strands of the fibril. However, acidic condition dose not largely affect the stability of PrP106-126 peptide fibril. Thus, the speed of fibril elongation can be dramatically increased by lowering the pH value of the solution. The pH value was adjusted by either changing the protonation state of the residues or adding hydronium ions (acidic solution) or hydroxyl ions (alkaline solution). The differences between these two approaches are analyzed here.
q-bio.BM:The thermodynamics of the small SH3 protein domain is studied by means of a simplified model where each bead-like amino acid interacts with the others through a contact potential controlled by a 20x20 random matrix. Good folding sequences, characterized by a low native energy, display three main thermodynamical phases, namely a coil-like phase, an unfolded globule and a folded phase (plus other two phases, namely frozen and random coil, populated only at extremes temperatures). Interestingly, the unfolded globule has some regions already structured. Poorly designed sequences, on the other hand, display a wide transition from the random coil to a frozen state. The comparison with the analytic theory of heteropolymers is discussed.
q-bio.BM:In a seminal paper Caspar and Klug established a theory that provides a family of polyhedra as blueprints for the structural organisation of viral capsids. In particular, they encode the locations of the proteins in the shells that encapsulate, and hence provide protection for, the viral genome. Despite of its huge success and numerous applications in virology experimental results have provided evidence for the fact that the theory is too restrictive to describe all known viruses. Especially, the family of Papovaviridae, which contains cancer-causing viruses, falls out of the scope of this theory.   In a recent paper we have shown that certain members of the family of Papovaviridae can be described via tilings. In this paper, we develop a comprehensive mathematical framework for the derivation of all surface structures of viral particles in this family. We show that this formalism fixes the structure and relative sizes of all particles collectively so that there exists only one scaling factor that relates the sizes of all particles with their biological counterparts.   The series of polyhedra derived here complements the Caspar-Klug family of polyhedra. It is the first mathematical result that provides a common organisational principle for different types of viral particles in the family of Papovaviridae and paves the way for an understanding of Papovaviridae polymorphism. Moreover, it provides crucial input for the construction of assembly models.
q-bio.BM:The amino acid sequences of proteins provide rich information for inferring distant phylogenetic relationships and for predicting protein functions. Estimating the rate matrix of residue substitutions from amino acid sequences is also important because the rate matrix can be used to develop scoring matrices for sequence alignment. Here we use a continuous time Markov process to model the substitution rates of residues and develop a Bayesian Markov chain Monte Carlo method for rate estimation. We validate our method using simulated artificial protein sequences. Because different local regions such as binding surfaces and the protein interior core experience different selection pressures due to functional or stability constraints, we use our method to estimate the substitution rates of local regions. Our results show that the substitution rates are very different for residues in the buried core and residues on the solvent exposed surfaces. In addition, the rest of the proteins on the binding surfaces also have very different substitution rates from residues. Based on these findings, we further develop a method for protein function prediction by surface matching using scoring matrices derived from estimated substitution rates for residues located on the binding surfaces. We show with examples that our method is effective in identifying functionally related proteins that have overall low sequence identity, a task known to be very challenging.
q-bio.BM:This chapter discusses geometric models of biomolecules and geometric constructs, including the union of ball model, the weigthed Voronoi diagram, the weighted Delaunay triangulation, and the alpha shapes. These geometric constructs enable fast and analytical computaton of shapes of biomoleculres (including features such as voids and pockets) and metric properties (such as area and volume). The algorithms of Delaunay triangulation, computation of voids and pockets, as well volume/area computation are also described. In addition, applications in packing analysis of protein structures and protein function prediction are also discussed.
q-bio.BM:This chapter discusses theoretical framework and methods for developing knowledge-based potential functions essential for protein structure prediction, protein-protein interaction, and protein sequence design. We discuss in some details about the Miyazawa-Jernigan contact statistical potential, distance-dependent statistical potentials, as well as geometric statistical potentials. We also describe a geometric model for developing both linear and non-linear potential functions by optimization. Applications of knowledge-based potential functions in protein-decoy discrimination, in protein-protein interactions, and in protein design are then described. Several issues of knowledge-based potential functions are finally discussed.
q-bio.BM:$\beta$-barrel membrane proteins are found in the outer membrane of gram-negative bacteria, mitochondria, and chloroplasts. We have developed probabilistic models to quantify propensities of residues for different spatial locations and for interstrand pairwise contact interactions involving strong H-bonds, side-chain interactions, and weak H-bonds. The propensity values and p-values measuring statistical significance are calculated exactly by analytical formulae we have developed. Contrary to the ``positive-inside'' rule for helical membrane proteins, $\beta$-barrel membrane proteins follow a significant albeit weaker ``positive-outside'' rule, in that the basic residues Arg and Lys are disproportionately favored in the extracellular cap region and disfavored in the periplasmic cap region. Different residue pairs prefer strong backbone H-bonded interstrand pairings (e.g. Gly-Aromatic) or non-H-bonded pairings (e.g. Aromatic-Aromatic). In addition, Tyr and Phe participate in aromatic rescue by shielding Gly from polar environments. These propensities can be used to predict the registration of strand pairs, an important task for the structure prediction of $\beta$-barrel membrane proteins. Our accuracy of 44% is considerably better than random (7%) and other studies. Our results imply several experiments that can help to elucidate the mechanisms of in vitro and in vivo folding of $\beta$-barrel membrane proteins. See supplementary material after the bibliography for detailed techniques.
q-bio.BM:An effective potential function is critical for protein structure prediction and folding simulation. Simplified protein models such as those requiring only $C_\alpha$ or backbone atoms are attractive because they enable efficient search of the conformational space. We show residue specific reduced discrete state models can represent the backbone conformations of proteins with small RMSD values. However, no potential functions exist that are designed for such simplified protein models. In this study, we develop optimal potential functions by combining contact interaction descriptors and local sequence-structure descriptors. The form of the potential function is a weighted linear sum of all descriptors, and the optimal weight coefficients are obtained through optimization using both native and decoy structures. The performance of the potential function in test of discriminating native protein structures from decoys is evaluated using several benchmark decoy sets. Our potential function requiring only backbone atoms or $C_\alpha$ atoms have comparable or better performance than several residue-based potential functions that require additional coordinates of side chain centers or coordinates of all side chain atoms. By reducing the residue alphabets down to size 5 for local structure-sequence relationship, the performance of the potential function can be further improved. Our results also suggest that local sequence-structure correlation may play important role in reducing the entropic cost of protein folding.
q-bio.BM:Without invoking the Markov approximation, we derive formulas for vibrational energy relaxation (VER) and dephasing for an anharmonic system oscillator using a time-dependent perturbation theory. The system-bath Hamiltonian contains more than the third order coupling terms since we take a normal mode picture as a zeroth order approximation. When we invoke the Markov approximation, our theory reduces to the Maradudin-Fein formula which is used to describe VER properties of glass and proteins. When the system anharmonicity and the renormalization effect due to the environment vanishes, our formulas reduce to those derived by Mikami and Okazaki invoking the path-integral influence functional method [J. Chem. Phys. 121 (2004) 10052]. We apply our formulas to VER of the amide I mode of a small amino-acide like molecule, N-methylacetamide, in heavy water.
q-bio.BM:Simplified Go models, where only native contacts interact favorably, have proven useful to characterize some aspects of the folding of small proteins. The success of these models is limited by the fact that all residues interact in the same way, so that the folding features of a protein are determined only by the geometry of its native conformation. We present an extended version of a C-alpha based Go model where different residues interact with different energies. The model is used to calculate the thermodynamics of three small proteins (Protein G, SrcSH3 and CI2) and the effect of mutations on the wildtype sequence. The model allows to investigate some of the most controversial areas in protein folding such as its earliest stages, a subject which has lately received particular attention. The picture which emerges for the three proteins under study is that of a hierarchical process, where local elementary structures (LES) (not necessarily coincident with elements of secondary structure) are formed at the early stages of the folding and drive the protein, through the transition state and the postcritical folding nucleus (FN), resulting from the docking of the LES, to the native conformation.
q-bio.BM:The chiral nature of DNA plays a crucial role in cellular processes. Here we use magnetic tweezers to explore one of the signatures of this chirality, the coupling between stretch and twist deformations. We show that the extension of a stretched DNA molecule increases linearly by 0.42 nm per excess turn applied to the double helix. This result contradicts the intuition that DNA should lengthen as it is unwound and get shorter with overwinding. We then present numerical results of energy minimizations of torsionally restrained DNA that display a behaviour similar to the experimental data and shed light on the molecular details of this surprising effect.
q-bio.BM:PCR (Polymerase Chain Reaction), a method which replicates a selected sequence of DNA, has revolutionized the study of genomic material, but mathematical study of the process has been limited to simple deterministic models or descriptions relying on stochastic processes. In this paper we develop a suite of deterministic models for the reactions of quantitative PCR (Polymerase Chain Reaction) based on the law of mass action. Maps are created from DNA copy number in one cycle to the next, with ordinary differential equations describing the evolution of difference molecular species during each cycle. Qualitative analysis is preformed at each stage and parameters are estimated by fitting each model to data from Roche LightCycler (TM) runs.
q-bio.BM:Kinetics of folding of a protein held in a force-clamp are compared to an unconstrained folding. The comparison is made within a simple topology-based dynamical model of ubiquitin. We demonstrate that the experimentally observed variations in the end-to-end distance reflect microscopic events during folding. However, the folding scenarios in and out of the force-clamp are distinct.
q-bio.BM:In the template-assistance model, normal prion protein (PrPC), the pathogenic cause of prion diseases such as Creutzfeldt-Jakob (CJD) in human, Bovine Spongiform Encephalopathy (BSE) in cow, and scrapie in sheep, converts to infectious prion (PrPSc) through an autocatalytic process triggered by a transient interaction between PrPC and PrPSc. Conventional studies suggest the S1-H1-S2 region in PrPC to be the template of S1-S2 $\beta$-sheet in PrPSc, and the conformational conversion of PrPC into PrPSc may involve an unfolding of H1 in PrPC and its refolding into the $\beta$-sheet in PrPSc. Here we conduct a series of simulation experiments to test the idea of transient interaction of the template-assistance model. We find that the integrity of H1 in PrPC is vulnerable to a transient interaction that alters the native dihedral angles at residue Asn$^{143}$, which connects the S1 flank to H1, but not to interactions that alter the internal structure of the S1 flank, nor to those that alter the relative orientation between H1 and the S2 flank.
q-bio.BM:The Yakushevich model of DNA torsion dynamics supports soliton solutions, which are supposed to be of special interest for DNA transcription. In the discussion of the model, one usually adopts the approximation $\ell_0 \to 0$, where $\ell_0$ is a parameter related to the equilibrium distance between bases in a Watson-Crick pair. Here we analyze the Yakushevich model without $\ell_0 \to 0$. The model still supports soliton solutions indexed by two winding numbers $(n,m)$; we discuss in detail the fundamental solitons, corresponding to winding numbers (1,0) and (0,1) respectively.
q-bio.BM:The Yakushevich (Y) model provides a very simple pictures of DNA torsion dynamics, yet yields remarkably correct predictions on certain physical characteristics of the dynamics. In the standard Y model, the interaction between bases of a pair is modelled by a harmonic potential, which becomes anharmonic when described in terms of the rotation angles; here we substitute to this different types of improved potentials, providing a more physical description of the H-bond mediated interactions between the bases. We focus in particular on soliton solutions; the Y model predicts the correct size of the nonlinear excitations supposed to model the ``transcription bubbles'', and this is essentially unchanged with the improved potential. Other features of soliton dynamics, in particular curvature of soliton field configurations and the Peierls-Nabarro barrier, are instead significantly changed.
q-bio.BM:Simple coarse-grained models, such as the Gaussian Network Model, have been shown to capture some of the features of equilibrium protein dynamics. We extend this model by using atomic contacts to define residue interactions and introducing more than one interaction parameter between residues. We use B-factors from 98 ultra-high resolution X-ray crystal structures to optimize the interaction parameters. The average correlation between GNM fluctuation predictions and the B-factors is 0.64 for the data set, consistent with a previous large-scale study. By separating residue interactions into covalent and noncovalent, we achieve an average correlation of 0.74, and addition of ligands and cofactors further improves the correlation to 0.75. However, further separating the noncovalent interactions into nonpolar, polar, and mixed yields no significant improvement. The addition of simple chemical information results in better prediction quality without increasing the size of the coarse-grained model.
q-bio.BM:Background: One-dimensional protein structures such as secondary structures or contact numbers are useful for three-dimensional structure prediction and helpful for intuitive understanding of the sequence-structure relationship. Accurate prediction methods will serve as a basis for these and other purposes. Results: We implemented a program CRNPRED which predicts secondary structures, contact numbers and residue-wise contact orders. This program is based on a novel machine learning scheme called critical random networks. Unlike most conventional one-dimensional structure prediction methods which are based on local windows of an amino acid sequence, CRNPRED takes into account the whole sequence. CRNPRED achieves, on average per chain, Q3 = 81% for secondary structure prediction, and correlation coefficients of 0.75 and 0.61 for contact number and residue-wise contact order predictions, respectively. Conclusion: CRNPRED will be a useful tool for computational as well as experimental biologists who need accurate one-dimensional protein structure predictions.
q-bio.BM:To confer high specificity and affinity in binding, contacts at interfaces between two interacting macromolecules are expected to exhibit pair preferences for types of atoms or residues. Here we quantify these preferences by measuring the mutual information of contacts for 895 protein-protein interfaces. The information content is significant and is highest at the atomic resolution. A simple phenomenological theory reveals a connection between information at interfaces and the free energy spectrum of association. The connection is presented in the form of a relation between mutual information and the energy gap of the native bound state to off-target bound states. Measurement of information content in designed lattice interfaces show the predicted scaling behavior to the energy gap. Our theory also suggests that mutual information in contacts emerges by a selection mechanism, and that strong selection, or high conservation, of residues should lead to correspondingly high mutual information. Amino acids which contribute more heavily to information content are then expected to be more conserved. We verify this by showing a statistically significant correlation between the conservation of each of the twenty amino acids and their individual contribution to the information content at protein-protein interfaces
q-bio.BM:It was first suggested by Englander et al to model the nonlinear dynamics of DNA relevant to the transcription process in terms of a chain of coupled pendulums. In a related paper [q-bio.BM/0604014] we argued for the advantages of an extension of this approach based on considering a chain of double pendulums with certain characteristics. Here we study a simplified model of this kind, focusing on its general features and nonlinear travelling wave excitations; in particular, we show that some of the degrees of freedom are actually slaved to others, allowing for an effective reduction of the relevant equations.
q-bio.BM:The Fast Fourier Transform (FFT) correlation approach to protein-protein docking can evaluate the energies of billions of docked conformations on a grid if the energy is described in the form of a correlation function. Here, this restriction is removed, and the approach is efficiently used with pairwise interactions potentials that substantially improve the docking results. The basic idea is approximating the interaction matrix by its eigenvectors corresponding to the few dominant eigenvalues, resulting in an energy expression written as the sum of a few correlation functions, and solving the problem by repeated FFT calculations. In addition to describing how the method is implemented, we present a novel class of structure based pairwise intermolecular potentials. The DARS (Decoys As the Reference State) potentials are extracted from structures of protein-protein complexes and use large sets of docked conformations as decoys to derive atom pair distributions in the reference state. The current version of the DARS potential works well for enzyme-inhibitor complexes. With the new FFT-based program, DARS provides much better docking results than the earlier approaches, in many cases generating 50\% more near-native docked conformations. Although the potential is far from optimal for antibody-antigen pairs, the results are still slightly better than those given by an earlier FFT method. The docking program PIPER is freely available for non-commercial applications.
q-bio.BM:We investigated the structural relaxation of myosin motor domain from the pre-power stroke state to the near-rigor state using molecular dynamics simulation of a coarse-grained protein model. To describe the structural change, we propose a "dual Go-model," a variant of the Go-like model that has two reference structures. The nucleotide dissociation process is also studied by introducing a coarse-grained nucleotide in the simulation. We found that the myosin structural relaxation toward the near-rigor conformation cannot be completed before the nucleotide dissociation. Moreover, the relaxation and the dissociation occurred cooperatively when the nucleotide was tightly bound to the myosin head. The result suggested that the primary role of the nucleotide is to suppress the structural relaxation.
q-bio.BM:Self-similar properties of the ribosome in terms of the mass fractal dimension are investigated. We find that both the 30S subunit and the 16S rRNA have fractal dimensions of 2.58 and 2.82, respectively; while the 50S subunit as well as the 23S rRNA has the mass fractal dimension close to 3, implying a compact three dimensional macromolecule. This finding supports the dynamic and active role of the 30S subunit in the protein synthesis, in contrast to the pass role of the 50S subunit.
q-bio.BM:We present an extremely simplified model of multiple-domains polymer stretching in an atomic force microscopy experiment. We portray each module as a binary set of contacts and decompose the system energy into a harmonic term (the cantilever) and long-range interactions terms inside each domain. Exact equilibrium computations and Monte Carlo simulations qualitatively reproduce the experimental saw-tooth pattern of force-extension profiles, corresponding (in our model) to first-order phase transitions. We study the influence of the coupling induced by the cantilever and the pulling speed on the relative heights of the force peaks. The results suggest that the increasing height of the critical force for subsequent unfolding events is an out-of-equilibrium effect due to a finite pulling speed. The dependence of the average unfolding force on the pulling speed is shown to reproduce the experimental logarithmic law.
q-bio.BM:Phi-values are experimental measures of the effects of mutations on the folding kinetics of a protein. A central question is which structural information Phi-values contain about the transition state of folding. Traditionally, a Phi-value is interpreted as the 'nativeness' of a mutated residue in the transition state. However, this interpretation is often problematic because it assumes a linear relation between the nativeness of the residue and its free-energy contribution. We present here a better structural interpretation of Phi-values for mutations within a given helix. Our interpretation is based on a simple physical model that distinguishes between secondary and tertiary free-energy contributions of helical residues. From a linear fit of our model to the experimental data, we obtain two structural parameters: the extent of helix formation in the transition state, and the nativeness of tertiary interactions in the transition state. We apply our model to all proteins with well-characterized helices for which more than 10 Phi-values are available: protein A, CI2, and protein L. The model captures nonclassical Phi-values <0 or >1 in these helices, and explains how different mutations at a given site can lead to different Phi-values.
q-bio.BM:A model for the unidirectional movement of dynein is presented based on structural observations and biochemical experimental results available. In this model, the binding affinity of dynein for microtubule is independent of its nucleotide state and the change between strong and weak microtubule-binding is determined naturally by the variation of relative orientation between the stalk and microtubule as the stalk rotates following nucleotide-state transition. Thus the enigmatic communication from the ATP binding site in the globular domain to the far MT-binding site in the tip of the stalk, which is prerequisite in conventional models, is not required. Using the present model, the previous experimental results such as the effect of ATP and ADP bindings on dissociation of dynein from microtubule, the processive movement of single-headed axonemal dyneins at saturating ATP concentration, the load dependence of step size for the processive movement of two-headed cytoplasmic dyneins and the dependence of stall force on ATP concentration can be well explained.
q-bio.BM:Over the last 10-15 years a general understanding of the chemical reaction of protein folding has emerged from statistical mechanics. The lessons learned from protein folding kinetics based on energy landscape ideas have benefited protein structure prediction, in particular the development of coarse grained models. We survey results from blind structure prediction. We explore how second generation prediction energy functions can be developed by introducing information from an ensemble of previously simulated structures. This procedure relies on the assumption of a funnelled energy landscape keeping with the principle of minimal frustration. First generation simulated structures provide an improved input for associative memory energy functions in comparison to the experimental protein structures chosen on the basis of sequence alignment.
q-bio.BM:The precise details of how myosin-V coordinates the biochemical reactions and mechanical motions of its two head elements to engineer effective processive molecular motion along actin filaments remain unresolved. We compare a quantitative kinetic model of the myosin-V walk, consisting of five basic states augmented by two further states to allow for futile hydrolysis and detachments, with experimental results for run lengths, velocities, and dwell times and their dependence on bulk nucleotide concentrations and external loads in both directions. The model reveals how myosin-V can use the internal strain in the molecule to synchronise the motion of the head elements. Estimates for the rate constants in the reaction cycle and the internal strain energy are obtained by a computational comparison scheme involving an extensive exploration of the large parameter space. This scheme exploits the fact that we have obtained analytic results for our reaction network, e.g. for the velocity but also the run length, diffusion constant and fraction of backward steps. The agreement with experiment is often reasonable but some open problems are highlighted, in particular the inability of such a general model to reproduce the reported dependence of run length on ADP. The novel way that our approach explores parameter space means that any confirmed discrepancies should give new insights into the reaction network model.
q-bio.BM:The prion protein (PrP) binds Cu2+ ions in the octarepeat domain of the N-terminal tail up to full occupancy at pH=7.4. Recent experiments show that the HGGG octarepeat subdomain is responsible for holding the metal bound in a square planar coordination. By using first principle ab initio molecular dynamics simulations of the Car-Parrinello type, the Cu coordination mode to the binding sites of the PrP octarepeat region is investigated. Simulations are carried out for a number of structured binding sites. Results for the complexes Cu(HGGGW)+(wat), Cu(HGGG) and the 2[Cu(HGGG)] dimer are presented. While the presence of a Trp residue and a H2O molecule does not seem to affect the nature of the Cu coordination, high stability of the bond between Cu and the amide Nitrogens of deprotonated Gly's is confirmed in the case of the Cu(HGGG) system. For the more interesting 2[Cu(HGGG)] dimer a dynamically entangled arrangement of the two monomers, with intertwined N-Cu bonds, emerges. This observation is consistent with the highly packed structure seen in experiments at full Cu occupancy.
q-bio.BM:We formulate a simple solvation potential based on a coarsed-grain representation of amino acids with two spheres modeling the $C_\alpha$ atom and an effective side-chain centroid. The potential relies on a new method for estimating the buried area of residues, based on counting the effective number of burying neighbours in a suitable way. This latter quantity shows a good correlation with the buried area of residues computed from all atom crystallographic structures. We check the discriminatory power of the solvation potential alone to identify the native fold of a protein from a set of decoys and show the potential to be considerably selective.
q-bio.BM:The aim of this work is to elucidate how physical principles of protein design are reflected in natural sequences that evolved in response to the thermal conditions of the environment. Using an exactly solvable lattice model, we design sequences with selected thermal properties. Compositional analysis of designed model sequences and natural proteomes reveals a specific trend in amino acid compositions in response to the requirement of stability at elevated environmental temperature, i.e. the increase of fractions of hydrophobic and charged amino acid residues at the expense of polar ones. We show that this from both ends of hydrophobicity scale trend is due to positive (to stabilize the native state) and negative (to destabilize misfolded states) components of protein design. Negative design strengthens specific repulsive nonnative interactions that appear in misfolded structures. A pressure to preserve specific repulsive interactions in non-native conformations may result in correlated mutations between amino acids which are far apart in the native state but may be in contact in misfolded conformations. Such correlated mutations are indeed found in TIM barrel and other proteins.
q-bio.BM:F-actin bundles constitute principal components of a multitude of cytoskeletal processes including stereocilia, filopodia, microvilli, neurosensory bristles, cytoskeletal stress fibers, and the sperm acrosome. The bending, buckling, and stretching behaviors of these processes play key roles in cellular functions ranging from locomotion to mechanotransduction and fertilization. Despite their central importance to cellular function, F-actin bundle mechanics remain poorly understood. Here, we demonstrate that bundle bending stiffness is a state-dependent quantity with three distinct regimes that are mediated by bundle dimensions in addition to crosslink properties. We calculate the complete state-dependence of the bending stiffness and elucidate the mechanical origin of each. A generic set of design parameters delineating the regimes in state-space is derived and used to predict the bending stiffness of a variety of F-actin bundles found in cells. Finally, the broad and direct implications that the isolated state-dependence of F-actin bundle stiffness has on the interpretation of the bending, buckling, and stretching behavior of cytoskeletal bundles is addressed.
q-bio.BM:In this work we develop a theory of interaction of randomly patterned surfaces as a generic prototype model of protein-protein interactions. The theory predicts that pairs of randomly superimposed identical (homodimeric) random patterns have always twice as large magnitude of the energy fluctuations with respect to their mutual orientation, as compared with pairs of different (heterodimeric) random patterns. The amplitude of the energy fluctuations is proportional to the square of the average pattern density, to the square of the amplitude of the potential and its characteristic length, and scales linearly with the area of surfaces. The greater dispersion of interaction energies in the ensemble of homodimers implies that strongly attractive complexes of random surfaces are much more likely to be homodimers, rather than heterodimers. Our findings suggest a plausible physical reason for the anomalously high fraction of homodimers observed in real protein interaction networks.
q-bio.BM:We extend our previously developed general approach (1) to study a phenomenological model in which the simulated packing of hard, attractive spheres on a prolate spheroid surface with convexity constraints produces structures identical to those of prolate virus capsid structures. Our simulation approach combines the traditional Monte Carlo method with the method of random sampling on an ellipsoidal surface and a convex hull searching algorithm. Using this approach we study the assembly and structural origin of non-icosahedral, elongated virus capsids, such as two aberrant flock house virus (FHV) particles and the prolate prohead of bacteriophage phi29, and discuss the implication of our simulation results in the context of recent experimental findings.
q-bio.BM:The need to understand the assembly kinetics of fibril formation has become urgent because of the realization that soluble oligomers of amyloidogenic peptides may be even more neurotoxic than the end product, namely, the amyloid fibrils. In order to fully understand the routes to fibril formation one has to characterize the major species in the assembly pathways. The characterization of the energetics and dynamics of oligomers (dimers, trimers etc) is difficult using experiments alone because they undergo large conformational fluctuations. In this context, carefully planned molecular dynamics simulation studies, computations using coarse-grained models, and bioinformatic analysis have given considerable insights into the early events in the route to fibril formation. Here, we describe progress along this direction using examples taken largely from our own work. In this chapter, we focus on aspects of protein aggregation using Abeta-peptides and prion proteins as examples.
q-bio.BM:The native three dimensional structure of a single protein is determined by the physico chemical nature of its constituent amino acids. The twenty different types of amino acids, depending on their physico chemical properties, can be grouped into three major classes - hydrophobic, hydrophilic and charged. We have studied the anatomy of the weighted and unweighted networks of hydrophobic, hydrophilic and charged residues separately for a large number of proteins. Our results show that the average degree of the hydrophobic networks has significantly larger value than that of hydrophilic and charged networks. The average degree of the hydrophilic networks is slightly higher than that of charged networks. The average strength of the nodes of hydrophobic networks is nearly equal to that of the charged network; whereas that of hydrophilic networks has smaller value than that of hydrophobic and charged networks. The average strength for each of the three types of networks varies with its degree. The average strength of a node in charged networks increases more sharply than that of the hydrophobic and hydrophilic networks. Each of the three types of networks exhibits the 'small-world' property. Our results further indicate that the all amino acids' networks and hydrophobic networks are of assortative type. While maximum of the hydrophilic and charged networks are of assortative type, few others have the characteristics of disassortative mixing of the nodes. We have further observed that all amino acids' networks and hydrophobic networks bear the signature of hierarchy; whereas the hydrophilic and charged networks do not have any hierarchical signature.
q-bio.BM:We study statistical properties of interacting protein-like surfaces and predict two strong, related effects: (i) statistically enhanced self-attraction of proteins; (ii) statistically enhanced attraction of proteins with similar structures. The effects originate in the fact that the probability to find a pattern self-match between two identical, even randomly organized interacting protein surfaces is always higher compared with the probability for a pattern match between two different, promiscuous protein surfaces. This theoretical finding explains statistical prevalence of homodimers in protein-protein interaction networks reported earlier. Further, our findings are confirmed by the analysis of curated database of protein complexes that showed highly statistically significant overrepresentation of dimers formed by structurally similar proteins with highly divergent sequences (superfamily heterodimers). We predict that significant fraction of heterodimers evolved from homodimers with the negative design evolutionary pressure applied against promiscuous homodimer formation. This is achieved through the formation of highly specific contacts formed by charged residues as demonstrated both in model and real superfamily heterodimers
q-bio.BM:Stretching of a protein by a fluid flow is compared to that in a force-clamp apparatus. The comparison is made within a simple topology-based dynamical model of a protein in which the effects of the flow are implemented using Langevin dynamics. We demonstrate that unfolding induced by a uniform flow shows a richer behavior than that in the force clamp. The dynamics of unfolding is found to depend strongly on the selection of the amino acid, usually one of the termini, which is anchored. These features offer potentially wider diagnostic tools to investigate structure of proteins compared to experiments based on the atomic force microscopy.
q-bio.BM:Secretion and role of autotaxin and lysophosphatidic acid in adipose tissue In obesity, adipocyte hypertrophy is often associated with recrutement of new fat cells (adipogenesis) under the control of circulating and local regulatory factors. Among the different lipids released in the extracellular compartment of adipocytes, our group found the presence of lysophosphatidic acid (LPA). LPA is a bioactive phospholipid able to regulate several cell responses via the activation of specific G-protein coupled membrane receptors. Our group found that LPA increases preadipocyte proliferation and inhibits adipogenesis via the activation of LPA1 receptor subtype. Extracellular LPA-synthesis is catalyzed by a lysophospholipase D secreted by adipocytes : autotaxin (ATX). Adipocyte ATX expression strongly increases with adipogenesis as well as in individuals exhibiting type 2 diabetes associated with massive obesity. A possible contribution of ATX and LPA as paracrine regulators of adipogenesis and obesity associated diabetes is proposed.
q-bio.BM:A recently proposed model of non-autocatalytic reactions in dipeptide reactions leading to spontaneous symmetry breaking and homochirality is examined. The model is governed by activation, polymerization, epimerization and depolymerization of amino acids. Symmetry breaking is primarily a consequence of the fact that the rates of reactions involving homodimers and heterodimers are different, i.e., stereoselective, and on the fact that epimerization can only occur on the N-terminal residue and not on the Cterminal residue. This corresponds to an auto-inductive cyclic process that works only in one sense. It is argued that epimerization mimics both autocatalytic behavior as well as mutual antagonism - both of which were known to be crucial for producing full homochirality.
q-bio.BM:The structural organisation of the viral genome within its protein container, called the viral capsid, is an important aspect of virus architecture. Many single-stranded (ss) RNA viruses organise a significant part of their genome in a dodecahedral cage as a RNA duplex structure that mirrors the symmetry of the capsid. Bruinsma and Rudnick have suggested a model for the structural organisation of the RNA in these cages. It is the purpose of this paper to further develop their approach based on results from the areas of graph theory and DNA network engineering. We start by suggesting a scenario for pariacoto virus, a representative of this class of viruses, that is energetically more favorable than those derived previously. We then show that it is a representative of a whole family of cage structures that abide to the same construction principle, and then derive the energetically optimal configuration for a second family of cage structures along similar lines. Finally, we give reasons for the conjecture that these two families are more likely to occur in nature than other scenarios.
q-bio.BM:The sequence-dependent elasticity of double-helical DNA on a nm length scale can be captured by the rigid base-pair model, whose strains are the relative position and orientation of adjacent base-pairs. Corresponding elastic potentials have been obtained from all-atom MD simulation and from high-resolution structural data. On the scale of a hundred nm, DNA is successfully described by a continuous worm-like chain model with homogeneous elastic properties characterized by a set of four elastic constants, which have been directly measured in single-molecule experiments. We present here a theory that links these experiments on different scales, by systematically coarse-graining the rigid base-pair model for random sequence DNA to an effective worm-like chain description. The average helical geometry of the molecule is exactly taken into account in our approach. We find that the available microscopic parameters sets predict qualitatively similar mesoscopic parameters. The thermal bending and twisting persistence lengths computed from MD data are 42 and 48 nm, respectively. The static persistence lengths are generally much higher, in agreement with cyclization experiments. All microscopic parameter sets predict negative twist-stretch coupling. The variability and anisotropy of bending stiffness in short random chains lead to non-Gaussian bend angle distributions, but become unimportant after two helical turns.
q-bio.BM:Processive molecular motors take more-or-less uniformly sized steps, along spatially periodic tracks, mostly forwards but increasingly backwards under loads. Experimentally, the major steps can be resolved clearly within the noise but one knows biochemically that one or more mechanochemical substeps remain hidden in each enzymatic cycle. In order to properly interpret experimental data for back/forward step ratios, mean conditional step-to-step dwell times, etc., a first-passage analysis has been developed that takes account of hidden substeps in $N$-state sequential models. The explicit, general results differ significantly from previous treatments that identify the observed steps with complete mechanochemical cycles; e.g., the mean dwell times $\tau_+$ and $\tau_-$ prior to forward and back steps, respectively, are normally {\it unequal} although the dwell times $\tau_{++}$ and $\tau_{--}$ between {\it successive} forward and back steps are equal. Illustrative (N=2)-state examples display a wide range of behavior. The formulation extends to the case of two or more detectable transitions in a multistate cycle with hidden substeps.
q-bio.BM:For the vast majority of naturally occurring, small, single domain proteins folding is often described as a two-state process that lacks detectable intermediates. This observation has often been rationalized on the basis of a nucleation mechanism for protein folding whose basic premise is the idea that after completion of a specific set of contacts forming the so-called folding nucleus the native state is achieved promptly. Here we propose a methodology to identify folding nuclei in small lattice polymers and apply it to the study of protein molecules with chain length N=48. To investigate the extent to which protein topology is a robust determinant of the nucleation mechanism we compare the nucleation scenario of a native-centric model with that of a sequence specific model sharing the same native fold. To evaluate the impact of the sequence's finner details in the nucleation mechanism we consider the folding of two non- homologous sequences. We conclude that in a sequence-specific model the folding nucleus is, to some extent, formed by the most stable contacts in the protein and that the less stable linkages in the folding nucleus are solely determined by the fold's topology. We have also found that independently of protein sequence the folding nucleus performs the same `topological' function. This unifying feature of the nucleation mechanism results from the residues forming the folding nucleus being distributed along the protein chain in a similar and well-defined manner that is determined by the fold's topological features.
q-bio.BM:The folding of naturally occurring, single domain proteins is usually well-described as a simple, single exponential process lacking significant trapped states. Here we further explore the hypothesis that the smooth energy landscape this implies, and the rapid kinetics it engenders, arises due to the extraordinary thermodynamic cooperativity of protein folding. Studying Miyazawa-Jernigan lattice polymers we find that, even under conditions where the folding energy landscape is relatively optimized (designed sequences folding at their temperature of maximum folding rate), the folding of protein-like heteropolymers is accelerated when their thermodynamic cooperativity enhanced by enhancing the non-additivity of their energy potentials. At lower temperatures, where kinetic traps presumably play a more significant role in defining folding rates, we observe still greater cooperativity-induced acceleration. Consistent with these observations, we find that the folding kinetics of our computational models more closely approximate single-exponential behavior as their cooperativity approaches optimal levels. These observations suggest that the rapid folding of naturally occurring proteins is, at least in part, consequences of their remarkably cooperative folding.
q-bio.BM:An increasing number of proteins are being discovered with a remarkable and somewhat surprising feature, a knot in their native structures. How the polypeptide chain is able to knot itself during the folding process to form these highly intricate protein topologies is not known. Here, we perform a computational study on the 160-amino acid homodimeric protein YibK which, like other proteins in the SpoU family of MTases, contains a deep trefoil knot in its C-terminal region. In this study, we use a coarse-grained C-alpha-chain representation and Langevin dynamics to study folding kinetics. We find that specific, attractive nonnative interactions are critical for knot formation. In the absence of these interactions, i.e. in an energetics driven entirely by native interactions, knot formation is exceedingly unlikely. Further, we find, in concert with recent experimental data on YibK, two parallel folding pathways which we attribute to an early and a late formation of the trefoil knot, respectively. For both pathways, knot formation occurs before dimerization. A bioinformatics analysis of the SpoU family of proteins reveals further that the critical nonnative interactions may originate from evolutionary conserved hydrophobic segments around the knotted region.
q-bio.BM:The structure of the self-cleaving hairpin ribozyme is well characterized, and its folding has been examined in bulk and by single-molecule fluorescence, establishing the importance of cations, especially magnesium in the stability of the native fold. Here we describe the first all-atom folding simulations of the hairpin ribozyme, using a version of a Go potential with separate secondary and tertiary structure energetic contributions. The ratio of tertiary/secondary interaction energies serves as a proxy for non-specific cation binding: a high ratio corresponds to a high concentration, while a low one mimics low concentration. By studying the unfolding behavior of the RNA over a range of temperature and tertiary/secondary energies, a three-state phase diagram emerges, with folded, unfolded (coil) and transient folding/unfolding tertiary structure species. The thermodynamics were verified by paired folding simulations in each region of the phase diagram. The three phase behaviors correspond with experimentally observed states, so this simple model captures the essential aspect of thermodynamics in RNA folding.
q-bio.BM:The refolding from stretched initial conformations of ubiquitin (PDB ID: 1ubq) under the quenched force is studied using the Go model and the Langevin dynamics. It is shown that the refolding decouples the collapse and folding kinetics. The force quench refolding times scale as tau_F ~ exp(f_q*x_F/k_B*T), where f_q is the quench force and x_F = 0.96 nm is the location of the average transition state along the reaction coordinate given by the end-to-end distance. This value is close to x_F = 0.8 nm obtained from the force-clamp experiments. The mechanical and thermal unfolding pathways are studied and compared with the experimental and all-atom simulation results in detail. The sequencing of thermal unfolding was found to be markedly different from the mechanical one. It is found that fixing the N-terminus of ubiquitin changes its mechanical unfolding pathways much more drastically compared to the case when the C-end is anchored. We obtained the distance between the native state and the transition state x_UF=0.24 nm which is in reasonable agreement with the experimental data.
q-bio.BM:Natural proteins fold to a unique, thermodynamically dominant state. Modeling of the folding process and prediction of the native fold of proteins are two major unsolved problems in biophysics. Here, we show successful all-atom ab initio folding of a representative diverse set of proteins, using a minimalist transferable energy model that consists of two-body atom-atom interactions, hydrogen-bonding, and a local sequence energy term that models sequence-specific chain stiffness. Starting from a random coil, the native-like structure was observed during replica exchange Monte Carlo (REMC) simulation for most proteins regardless of their structural classes; the lowest energy structure was close to native- in the range of 2-6 A root-mean-square deviation (RMSD). Our results demonstrate that the successful all-atom folding of a protein chain to its native state is governed by only a few crucial energetic terms.
q-bio.BM:Protein-DNA interactions are vital for many processes in living cells, especially transcriptional regulation and DNA modification. To further our understanding of these important processes on the microscopic level, it is necessary that theoretical models describe the macromolecular interaction energetics accurately. While several methods have been proposed, there has not been a careful comparison of how well the different methods are able to predict biologically important quantities such as the correct DNA binding sequence, total binding free energy, and free energy changes caused by DNA mutation. In addition to carrying out the comparison, we present two important theoretical models developed initially in protein folding that have not yet been tried on protein-DNA interactions. In the process, we find that the results of these knowledge-based potentials show a strong dependence on the interaction distance and the derivation method. Finally, we present a knowledge-based potential that gives comparable or superior results to the best of the other methods, including the molecular mechanics force field AMBER99.
q-bio.BM:The folding of the alpha-helice domain hbSBD of the mammalian mitochondrial branched-chain alpha-ketoacid dehydrogenase (BCKD) complex is studied by the circular dichroism technique in absence of urea. Thermal denaturation is used to evaluate various thermodynamic parameters defining the equilibrium unfolding, which is well described by the two-state model with the folding temperature T_f = 317.8 K and the enthalpy change Delta H_g = 19.67 kcal/mol. The folding is also studied numerically using the off-lattice coarse-grained Go model and the Langevin dynamics. The obtained results, including the population of the native basin, the free energy landscape as a function of the number of native contacts and the folding kinetics, also suggest that the hbSBD domain is a two-state folder. These results are consistent with the biological function of hbSBD in BCKD.
q-bio.BM:We analyze the dependence of cooperativity of the thermal denaturation transition and folding rates of globular proteins on the number of amino acid residues, $N$, using lattice models with side chains,off-lattice Go models and the available experimental data. A dimensionless measure of cooperativity, $\Omega_c$ ($0 < \Omega_c < \infty$), scales as $\Omega_c \sim N^{\zeta}$. The results of simulations and the analysis of experimental data further confirm the earlier prediction that $\zeta$ is universal with $\zeta = 1 +\gamma$, where exponent $\gamma$ characterizes the susceptibility of a self-avoiding walk. This finding suggests that the structural characteristics in the denaturated state are manifested in the folding cooperativity at the transition temperature. The folding rates $k_F$ for the Go models and a dataset of 69 proteins can be fit using $k_F = k_F^0 \exp(-cN^\beta)$. Both $\beta = 1/2$ and 2/3 provide a good fit of the data. We find that $k_F = k_F^0 \exp(-cN^{{1/2}})$, with the average (over the dataset of proteins) $k_F^0 \approx (0.2\mu s)^{-1}$ and $c \approx 1.1$, can be used to estimate folding rates to within an order of magnitude in most cases. The minimal models give identical $N$ dependence with $c \approx 1$. The prefactor for off-lattice Go models is nearly four orders of magnitude larger than the experimental value.
q-bio.BM:The didemnins represent a versatile class of depsipeptides of marine origin and hold a great deal of potential for biomedical application. The biological and geographical origins of the didemnins are reviewed in addition to the chemical structures of the major didemnins. The biological mechanisms behind the antiviral and anticancer effects of selected didemnins are summarized and the special case of dehydrodidemnin B (Aplidin) is expounded upon including structural characteristics, synthesis, pharmacological mechanism and a discussion of its current clinical trials as an anticancer agent.
q-bio.BM:TThe paper had many errors.
q-bio.BM:Pathological folding and oligomer formation of the amyloid beta-protein (Abeta) are widely perceived as central to Alzheimer's disease (AD). Experimental approaches to study Abeta self-assembly are problematic, because most relevant aggregates are quasi-stable and inhomogeneous. We apply a discrete molecular dynamics (DMD) approach combined with a four-bead protein model to study oligomer formation of the amyloid beta-protein (Abeta). We address the differences between the two most common Abeta alloforms, Abeta40 and Abeta42, which oligomerize differently in vitro. We study how the presence of electrostatic interactions (EIs) between pairs of charged amino acids affects Abeta40 and Abeta42 oligomer formation. Our results indicate that EIs promote formation of larger oligomers in both Abeta40 and Abeta42. The Abeta40 size distribution remains unimodal, whereas the Abeta42 distribution is trimodal, as observed experimentally. Abeta42 folded structure is characterized by a turn in the C-terminus that is not present in Abeta40. We show that the same C-terminal region is also responsible for the strongest intermolecular contacts in Abeta42 pentamers and larger oligomers. Our results suggest that this C-terminal region plays a key role in the formation of Abeta42 oligomers and the relative importance of this region increases in the presence of EIs. These results suggest that inhibitors targeting the C-terminal region of Abeta42 oligomers may be able to prevent oligomer formation or structurally modify the assemblies to reduce their toxicity.
q-bio.BM:The results of Brownian dynamics simulations of a single DNA molecule in shear flow are presented taking into account the effect of internal viscosity. The dissipative mechanism of internal viscosity is proved necessary in the research of DNA dynamics. A stochastic model is derived on the basis of the balance equation for forces acting on the chain. The Euler method is applied to the solution of the model. The extensions of DNA molecules for different Weissenberg numbers are analyzed. Comparison with the experimental results available in the literature is carried out to estimate the contribution of the effect of internal viscosity.
q-bio.BM:The network paradigm is increasingly used to describe the topology and dynamics of complex systems. Here we review the results of the topological analysis of protein structures as molecular networks describing their small-world character, and the role of hubs and central network elements in governing enzyme activity, allosteric regulation, protein motor function, signal transduction and protein stability. We summarize available data how central network elements are enriched in active centers and ligand binding sites directing the dynamics of the entire protein. We assess the feasibility of conformational and energy networks to simplify the vast complexity of rugged energy landscapes and to predict protein folding and dynamics. Finally, we suggest that modular analysis, novel centrality measures, hierarchical representation of networks and the analysis of network dynamics will soon lead to an expansion of this field.
q-bio.BM:Annealed importance sampling is a means to assign equilibrium weights to a nonequilibrium sample that was generated by a simulated annealing protocol. The weights may then be used to calculate equilibrium averages, and also serve as an ``adiabatic signature'' of the chosen cooling schedule. In this paper we demonstrate the method on the 50-atom dileucine peptide, showing that equilibrium distributions are attained for manageable cooling schedules. For this system, as naively implemented here, the method is modestly more efficient than constant temperature simulation. However, the method is worth considering whenever any simulated heating or cooling is performed (as is often done at the beginning of a simulation project, or during an NMR structure calculation), as it is simple to implement and requires minimal additional CPU expense. Furthermore, the naive implementation presented here can be improved.
q-bio.BM:Conformational transitions in macromolecular complexes often involve the reorientation of lever-like structures. Using a simple theoretical model, we show that the rate of such transitions is drastically enhanced if the lever is bendable, e.g. at a localized "hinge''. Surprisingly, the transition is fastest with an intermediate flexibility of the hinge. In this intermediate regime, the transition rate is also least sensitive to the amount of "cargo'' attached to the lever arm, which could be exploited by molecular motors. To explain this effect, we generalize the Kramers-Langer theory for multi-dimensional barrier crossing to configuration dependent mobility matrices.
q-bio.BM:We report 10 successfully folding events of trpzip2 by molecular dynamics simulation. It is found that the trizip2 can fold into its native state through different zipper pathways, depending on the ways of forming hydrophobic core. We also find a very fast non-zipper pathway. This indicates that there may be no inconsistencies in the current pictures of beta-hairpin folding mechanisms. These pathways occur with different probabilities. zip-out is the most probable one. This may explain the recent experiment that the turn formation is the rate-limiting step for beta-hairpin folding.
q-bio.BM:Structural fluctuations in the thermal equilibrium of the kinesin motor domain are studied using a lattice protein model with Go interactions. By means of the multi-self-overlap ensemble (MSOE) Monte Carlo method and the principal component analysis (PCA), the free-energy landscape is obtained. It is shown that kinesins have two subdomains that exhibit partial folding/unfolding at functionally important regions: one is located around the nucleotide binding site and the other includes the main microtubule binding site. These subdomains are consistent with structural variability that was reported recently based on experimentally-obtained structures. On the other hand, such large structural fluctuations have not been captured by B-factor or normal mode analyses. Thus, they are beyond the elastic regime, and it is essential to take into account chain connectivity for studying the function of kinesins.
q-bio.BM:We introduce a topology-based nonlinear network model of protein dynamics with the aim of investigating the interplay of spatial disorder and nonlinearity. We show that spontaneous localization of energy occurs generically and is a site-dependent process. Localized modes of nonlinear origin form spontaneously in the stiffest parts of the structure and display site-dependent activation energies. Our results provide a straightforward way for understanding the recently discovered link between protein local stiffness and enzymatic activity. They strongly suggest that nonlinear phenomena may play an important role in enzyme function, allowing for energy storage during the catalytic process.
q-bio.BM:We incorporate hydrodynamic interactions in a structure-based model of ubiquitin and demonstrate that the hydrodynamic coupling may reduce the peak force when stretching the protein at constant speed, especially at larger speeds. Hydrodynamic interactions are also shown to facilitate unfolding at constant force and inhibit stretching by fluid flows.
q-bio.BM:We demonstrate a new algorithm for finding protein conformations that minimize a non-bonded energy function. The new algorithm, called the difference map, seeks to find an atomic configuration that is simultaneously in two constraint spaces. The first constraint space is the space of atomic configurations that have a valid peptide geometry, while the second is the space of configurations that have a non-bonded energy below a given target. These two constraint spaces are used to define a deterministic dynamical system, whose fixed points produce atomic configurations in the intersection of the two constraint spaces. The rate at which the difference map produces low energy protein conformations is compared with that of a contemporary search algorithm, parallel tempering. The results indicate the difference map finds low energy protein conformations at a significantly higher rate then parallel tempering.
q-bio.BM:Vibrational energy transfer of the amide I mode of N-methylacetamide (NMA) is studied theoretically using the vibrational configuration interaction method. A quartic force field of NMA is constructed at the B3LYP/6-31G+(d) level of theory and its accuarcy is checked by comparing the resulting anharmonic frequencies with available theoretical and experimental values. Quantum dynamics calculations for the amide I mode excitation clarify the dominant energy transfer pathways, which sensitively depend on the anharmonic couplings among vibrational modes. A ratio of the anharmonic coupling to the frequency mismatch is employed to predict and interpret the dominant energy flow pathways.
q-bio.BM:It previously has been discovered that visible light irradiation of crystalline substrates can lead to enhancement of subsequent enzymatic reaction rates as sharply peaked oscillatory functions of irradiation time. The particular activating irradiation times can vary with source of a given enzyme and thus, presumably, its molecular structure. The experiments reported here demonstrate that the potential for this anomalous enzyme reaction rate enhancement can be transferred from one bacterial species to another coincident with transfer of the genetic determinant for the relevant enzyme. In particular, the effect of crystal-irradiated chloramphenicol on growth of bacterial strains in which a transferable R-factor DNA plasmid coding for chloramphenicol resistance was or was not present (S. panama R+, E. coli R+, and E. coli R-) was determined. Chloramphenicol samples irradiated 10, 35 and 60 sec produced increased growth rates (diminished inhibition) for the resistant S. panama and E. coli strains, while having no such effect on growth rate of the sensitive E. coli strain. Consistent with past findings, chloramphenicol samples irradiated 5, 30 and 55 sec produced decreased growth rates (increased inhibition) for all three strains.
q-bio.BM:Inherent structure theory is used to discover strong connections between simple characteristics of protein structure and the energy landscape of a Go model. The potential energies and vibrational free energies of inherent structures are highly correlated, and both reflect simple measures of networks of native contacts. These connections have important consequences for models of protein dynamics and thermodynamics.
q-bio.BM:The free-energy landscape of the alpha-helix of protein G is studied by means of metadynamics coupled with a solute tempering algorithm. Metadynamics allows to overcome large energy barriers, whereas solute tempering improves the sampling with an affordable computational effort. From the sampled free-energy surface we are able to reproduce a number of experimental observations, such as the fact that the lowest minimum corresponds to a globular conformation displaying some degree of beta-structure, that the helical state is metastable and involves only 65% of the chain. The calculations also show that the system populates consistently a pi-helix state and that the hydrophobic staple motif is present only in the free-energy minimum associated with the helices, and contributes to their stabilization. The use of metadynamics coupled with solute tempering results then particularly suitable to provide the thermodynamics of a short peptide, and its computational efficiency is promising to deal with larger proteins.
q-bio.BM:Using a time-dependent perturbation theory, vibrational energy relaxation (VER) of isotopically labeled amide I modes in cytochrome c solvated with water is investigated. Contributions to the VER are decomposed into two contributions from the protein and water. The VER pathways are visualized using radial and angular excitation functions for resonant normal modes. Key differences of VER among different amide I modes are demonstrated, leading to a detailed picture of the spatial anisotropy of the VER. The results support the experimental observation that amide I modes in proteins relax with sub picosecond timescales, while the relaxation mechanism turns out to be sensitive to the environment of the amide I mode.
q-bio.BM:Local minima and the saddle points separating them in the energy landscape are known to dominate the dynamics of biopolymer folding. Here we introduce a notion of a "folding funnel" that is concisely defined in terms of energy minima and saddle points, while at the same time conforming to a notion of a "folding funnel" as it is discussed in the protein folding literature.
q-bio.BM:Using magnetic tweezers to investigate the mechanical response of single chromatin fibers, we show that fibers submitted to large positive torsion transiently trap positive turns, at a rate of one turn per nucleosome. A comparison with the response of fibers of tetrasomes (the (H3-H4)2 tetramer bound with ~50 bp of DNA) obtained by depletion of H2A-H2B dimers, suggests that the trapping reflects a nucleosome chiral transition to a metastable form built on the previously documented righthanded tetrasome. In view of its low energy, <8 kT, we propose this transition is physiologically relevant and serves to break the docking of the dimers on the tetramer which in the absence of other factors exerts a strong block against elongation of transcription by the main RNA polymerase.
q-bio.BM:We perform extensive Monte Carlo simulations of a lattice model and the Go potential to investigate the existence of folding pathways at the level of contact cluster formation for two native structures with markedly different geometries. Our analysis of folding pathways revealed a common underlying folding mechanism, based on nucleation phenomena, for both protein models. However, folding to the more complex geometry (i.e. that with more non-local contacts) is driven by a folding nucleus whose geometric traits more closely resemble those of the native fold. For this geometry folding is clearly a more cooperative process.
physics.optics:A numerical study of the properties of Gaussian pulses propagating in planar waveguide under the combined effect of positive Kerr-type nonlinearity, diffraction in planar waveguides and anomalous or normal dispersion, is presented. It is demonstrated how the relative strength of dispersion and diffraction, the strength of nonlinearity and the initial spatial and temporal pulse chirps effect on the parameters of pulse compression, such as the maximal compression factor and the distance to the point of maximal compression.
physics.optics:We report on a theoretical and numerical investigation of the switching of power in new hybrid models of nonlinear coherent couplers consisting of optical slab waveguides with various orders of nonlinearity. The first model consists of two guides with second-order instead of the usual third-order susceptibilities as typified by the Jensen coupler. This second-order system is shown to have a power self-trapping transition at a critical power greater than the third-order susceptibility coupler. Next, we consider a mixed coupler composed of a second-order guide coupled to a third-order guide and show that, although it does not display a rigorous self-trapping transition, for a particular choice of parameters it does show a fairly abrupt trapping of power at a lower power than in the third-order coupler. By coupling this mixed nonlinear pair to a third, purely linear guide, the power trapping can be brought to even lower levels and in this way a satisfactory switching profile can be achieved at less than one sixth the input power needed in the Jensen coupler.
physics.optics:It is noted that the Jones-matrix formalism for polarization optics is a six-parameter two-by-two representation of the Lorentz group. It is shown that the four independent Stokes parameters form a Minkowskian four-vector, just like the energy-momentum four-vector in special relativity. The optical filters are represented by four-by-four Lorentz-transformation matrices. This four-by-four formalism can deal with partial coherence described by the Stokes parameters. A four-by-four matrix formulation is given for decoherence effects on the Stokes parameters, and a possible experiment is proposed. It is shown also that this Lorentz-group formalism leads to optical filters with a symmetry property corresponding to that of two-dimensional Euclidean transformations.
physics.optics:We study the electromagnetic scattering by multilayered biperiodic aggregates of dielectric layers and gratings of conducting plates. We show that the characteristic lengths of such structures provide a good control of absorption bands. The influence of the physical parameters of the problem (sizes, impedances) is discussed.
physics.optics:The propagation of an electromagnetic pulse in a plasma is studied for pulse durations that are comparable to the plasma period. When the carrier frequency of the incident pulse is much higher than the plasma frequency, the pulse propagates without distortion at its group speed. When the carrier frequency is comparable to the plasma frequency, the pulse is distorted and leaves behind it an electromagnetic wake.
physics.optics:We present scattering from many body systems in a new light. In place of the usual van Hove treatment, (applicable to a wide range of scattering processes using both photons and massive particles) based on plane waves, we calculate the scattering amplitude as a space-time integral over the scattering sample for an incident wave characterized by its correlation function which results from the shaping of the wave field by the apparatus. Instrument resolution effects - seen as due to the loss of correlation caused by the path differences in the different arms of the instrument are automatically included and analytic forms of the resolution function for different instruments are obtained. The intersection of the moving correlation volumes (those regions where the correlation functions are significant) associated with the different elements of the apparatus determines the maximum correlation lengths (times) that can be observed in a sample, and hence, the momentum (energy) resolution of the measurement. This geometrical picture of moving correlation volumes derived by our technique shows how the interaction of the scatterer with the wave field shaped by the apparatus proceeds in space and time. Matching of the correlation volumes so as to maximize the intersection region yields a transparent, graphical method of instrument design. PACS: 03.65.Nk, 3.80 +r, 03.75, 61.12.B
physics.optics:In this paper we extend for the case of Maxwell equations the "X-shaped" solutions previously found in the case of scalar (e.g., acoustic) wave equations. Such solutions are localized in theory, i.e., diffraction-free and particle-like (wavelets), in that they maintain their shape as they propagate. In the electromagnetic case they are particularly interesting, since they are expected to be Superluminal. We address also the problem of their practical, approximate production by finite (dynamic) radiators. Finally, we discuss the appearance of the X-shaped solutions from the purely geometric point of view of the Special Relativity theory.   [PACS nos.: 03.50.De; 1.20.Jb; 03.30.+p; 03.40.Kf; 14.80.-j.   Keywords: X-shaped waves; localized solutions to Maxwell equations; Superluminal waves; Bessel beams; Limited-dispersion beams; electromagnetic wavelets; Special Relativity; Extended Relativity].
physics.optics:This paper has been withdrawn by the authors until some changes are made.
physics.optics:The effect of dispersion or diffraction on zero-velocity solitons is studied for the generalized massive Thirring model describing a nonlinear optical fiber with grating or parallel-coupled planar waveguides with misaligned axes. The Thirring solitons existing at zero dispersion/diffraction are shown numerically to be separated by a finite gap from three isolated soliton branches. Inside the gap, there is an infinity of multi-soliton branches. Thus, the Thirring solitons are structurally unstable. In another parameter region (far from the Thirring limit), solitons exist everywhere.
physics.optics:We theoretically study reflection of light by a phase-conjugating mirror preceded by a partially reflecting normal mirror. The presence of a suitably chosen normal mirror in front of the phase conjugator is found to greatly enhance the total phase-conjugate reflected power, even up to an order of magnitude. Required conditions are that the phase-conjugating mirror itself amplifies upon reflection and that constructive interference of light in the region between the mirrors takes place. We show that the phase-conjugate reflected power then exhibits a maximum as a function of the transmittance of the normal mirror.
physics.optics:Reliable control of the deposition process of optical films and coatings frequently requires monitoring of the refractive index profile throughout the layer. In the present work a simple in situ approach is proposed which uses a WKBJ matrix representation of the optical transfer function of a single thin film on a substrate. Mathematical expressions are developed which represent the minima and maxima envelopes of the curves transmittance-vs-time and reflectance-vs-time. The refractive index and extinction coefficient depth profiles of different films are calculated from simulated spectra as well as from experimental data obtained during PECVD of silicon-compound films. Variation of the deposition rate with time is also evaluated from the position of the spectra extrema as a function of time. The physical and mathematical limitations of the method are discussed.
physics.optics:A new definition for the electromagnetic field velocity is proposed. The velocity depends on the physical fields.
physics.optics:We have fabricated light emitting diodes (LEDs) with Schottky contacts on Si-nanocrystals formed by simple techniques as used for standard Si devices. Orange electroluminescence (EL) from these LEDs could be seen with the naked eye at room temperature when a reverse bias voltage was applied. The EL spectrum has a major peak with a photon energy of 1.9 eV and a minor peak with a photon energy of 2.2 eV. Since the electrons and holes are injected into the radiative recombination centers related to nanocrystals through avalanche breakdown, the voltage needed for a visible light emission is reduced to 4.0 - 4.5 V, which is low enough to be applied by a standard Si transistor.
physics.optics:A general model is presented for coupling of high-$Q$ whispering-gallery modes in optical microsphere resonators with coupler devices possessing discrete and continuous spectrum of propagating modes. By contrast to conventional high-Q optical cavities, in microspheres independence of high intrinsic quality-factor and controllable parameters of coupling via evanescent field offer variety of regimes earlier available in RF devices. The theory is applied to the earlier-reported data on different types of couplers to microsphere resonators and complemented by experimental demonstration of enhanced coupling efficiency (about 80%) and variable loading regimes with Q>10^8 fused silica microspheres.
physics.optics:The mechanism of DC-Electric-Field-Induced Second-Harmonic (EFISH) generation at weakly nonlinear buried Si(001)-SiO$_2$ interfaces is studied experimentally in planar Si(001)-SiO$_2$-Cr MOS structures by optical second-harmonic generation (SHG) spectroscopy with a tunable Ti:sapphire femtosecond laser. The spectral dependence of the EFISH contribution near the direct two-photon $E_1$ transition of silicon is extracted. A systematic phenomenological model of the EFISH phenomenon, including a detailed description of the space charge region (SCR) at the semiconductor-dielectric interface in accumulation, depletion, and inversion regimes, has been developed. The influence of surface quantization effects, interface states, charge traps in the oxide layer, doping concentration and oxide thickness on nonlocal screening of the DC-electric field and on breaking of inversion symmetry in the SCR is considered. The model describes EFISH generation in the SCR using a Green function formalism which takes into account all retardation and absorption effects of the fundamental and second harmonic (SH) waves, optical interference between field-dependent and field-independent contributions to the SH field and multiple reflection interference in the SiO$_2$ layer. Good agreement between the phenomenological model and our recent and new EFISH spectroscopic results is demonstrated. Finally, low-frequency electromodulated EFISH is demonstrated as a useful differential spectroscopic technique for studies of the Si-SiO$_2$ interface in silicon-based MOS structures.
physics.optics:The new mechanism for obtaining a nonlinear phase shift has been proposed and the schemes are described for its implementation. As it is shown, the interference of two waves with intensity-dependent amplitude ratio coming from the second harmonic generation should produce the nonlinear phase shift. The sign and amount of nonlinear distortion of a beam wavefront is dependent of the relative phase of the waves that is introduced by the phase element. Calculated value of $n_2^{eff}$ exceeds that connected with cascaded quadratic nonlinearity, at the same conditions.
physics.optics:We analyze the guiding problem in a realistic photonic crystal fiber using a novel full-vector modal technique, a biorthogonal modal method based on the nonselfadjoint character of the electromagnetic propagation in a fiber. Dispersion curves of guided modes for different fiber structural parameters are calculated along with the 2D transverse intensity distribution of the fundamental mode. Our results match those achieved in recent experiments, where the feasibility of this type of fiber was shown.
physics.optics:A new method for investigation of x-ray propagation in a rough narrow dielectric waveguide is proposed on the basis of the numerical integration of the quazioptical equation. In calculations a model rough surface was used with the given statistical properties. It was shown that the losses in the narrow waveguides strongly depend on the wall roughness and on the input angle. The losses are not zero even at zero input angle if the width of the waveguide is smaller or about 1 mkm. The effect is accounted for as the influence of diffraction. The angular spread of the transmitted X-ray radiation is much more narrow than the Fresnel angle of the total external reflection.
physics.optics:We study a generalized notion of two-mode squeezing for the Stokes and anti-Stokes fields in a model of a cavity Raman laser, which leads to a significant reduction in decoherence or quantum noise. The model comprises a loss-less cavity with classical pump, unsaturated medium and arbitrary homogeneous broadening and dispersion. Allowing for arbitrary linear combinations of the two modes in the definition of quadrature variables, we find that there always exists a combination of the two output modes which exhibits quadrature squeezing with noise reduction below the vacuum level. The number of noise photons for this combination mode is proportional to the square root of the number of Stokes noise photons.
physics.optics:We study the effects of higher order transversal modes in a model of a singly-resonant OPO, using both numerical solutions and mode expansions including up to two radial modes. The numerical and two-mode solutions predict lower threshold and higher conversion than the single-mode solution at negative dispersion. Relative power in the zero order radial mode ranges from about 88% at positive and small negative dispersion to 48% at larger negative dispersion, with most of the higher mode content in the first mode, and less than 2% in higher modes.
physics.optics:This paper presents a detailed numerical study of the effect of focusing on the conversion efficiency of low-loss singly-resonant parametric oscillators with collinear focusing of pump and signal. Results are given for the maximal pump depletion and for pump power levels required for various amounts of depletion, as functions of pump and signal confocal parameters, for kI/kP=0.33 and 0.50. It is found that the ratio of pump depletion to maximal depletion as a function of the ratio of pump power to threshold power agrees with the plane-wave prediction to within 5%, for a wide range of focusing conditions. The observed trends are explained as resulting from intensity and phase dependent mechanisms.
physics.optics:Via solution of appropriate variational problem it is shown that light beams with Gaussian spatial profile and sufficiently short duration provide maximal destruction of global coherence under nonlinear self-modulation.
physics.optics:The dynamics of Fabry-Perot cavity with suspended mirrors is described. The suspended mirrors are nonlinear oscillators interacting with each other through the laser circulating in the cavity. The degrees of freedom decouple in normal coordinates, which are the position of the center of mass and the length of the cavity. We introduce two parameters and study how the dynamics changes with respect to these parameters. The first parameter specifies how strong the radiation pressure is. It determines whether the cavity is multistable or not. The second parameter is the control parameter, which determines location of the cavity equilibrium states. The equilibrium state shows hysteresis if the control parameter varies within a wide range. We analyze stability of the equilibrium states and identify the instability region. The instability is explained in terms of the effective potential: the stable states correspond to local minima of the effective potential and unstable states correspond to local maxima. The minima of the effective potential defines the resonant frequencies for the oscillations of the cavity length. We find the frequencies, and analyze how to tune them. Multistability of the cavity with a feedback control system is analyzed in terms of the servo potential. The results obtained in this paper are general and apply to all Fabry-Perot cavities with suspended mirrors.
physics.optics:We show that an azimuthally-periodically-modulated bright ring "necklace" beam can self-trap in self-focusing Kerr media and can exhibit stable propagation for very large distances. These are the first bright (2+1) D beams to exhibit stable self-trapping in a system described by the cubic (2+1) D Nonlinear Schrodinger Equation (NLSE).
physics.optics:We present a new class of micro lasers based on nanoporous molecular sieve host-guest systems. Organic dye guest molecules of 1-Ethyl-4-(4-(p-Dimethylaminophenyl)-1,3-butadienyl)-pyridinium Perchlorat were inserted into the 0.73-nm-wide channel pores of a zeolite AlPO$_4$-5 host. The zeolitic micro crystal compounds where hydrothermally synthesized according to a particular host-guest chemical process. The dye molecules are found not only to be aligned along the host channel axis, but to be oriented as well. Single mode laser emission at 687 nm was obtained from a whispering gallery mode oscillating in a 8-$\mu$m-diameter monolithic micro resonator, in which the field is confined by total internal reflection at the natural hexagonal boundaries inside the zeolitic microcrystals.
physics.optics:We report a quantum ring-like toroidal cavity naturally formed in a vertical-cavity-like active microdisk plane due to Rayleigh's band of whispering gallery modes. The $\sqrt{T}$-dependent redshift and a square-law property of microampere-range threshold currents down to 2 $\mu$A are consistent with a photonic quantum wire view, due to whispering gallery mode-induced dimensional reduction.
physics.optics:The effect of capture of X-ray beam into narrow submicron capillary was investigated with account for diffraction and decay of coherency by roughness scattering in transitional boundary layer. In contrast to well-known Andronov-Leontovich approach the losses do not vanish at zero gliding angle and scale proportional to the first power of roughness amplitude for small gliding angles. It was shown that for small correlation radius of roughness the scattering decay of coherency can be made of the same order as absorption decay of lower channeling modes to produce angular collimation of X-ray beams. Estimates were given for optimum capillary length at different roughness amplitudes for angular sensitivity of X-ray transmission and chenneling effects that can be usefull for designing of detector systems.
physics.optics:We report the measurement of the photons flux produced in parametric down-conversion, performed in photon counting regime with actively quenched silicon avalanche photodiodes as single photon detectors. Measurements are done with the detector in a well defined geometrical and spectral situation. By comparison of the experimental data with the theory, a value for the second order susceptibilities of the non linear crystal can be inferred.
physics.optics:In a frame of quasi-crystal approximation the dispersion equations are obtained for the wave vector of a coherent electromagnetic wave propagating in a media which contains a random set of parallel dielectric cylinders with possible overlapping. The results are compared with that for the case when a regularity at the cylinder placement exists.
physics.optics:Accurate calculation of internal and surface scattering losses in fused silica microspheres is done. We show that in microspheres internal scattering is partly inhibited as compared to losses in the bulk material. We pay attention on the effect of frozen thermodynamical capillary waves on surface roughness. We calculate also the value of mode splitting due to backscattering and other effects of this backscattering.
physics.optics:We analytically compute a localization criterion in double scattering approximation for a set of dielectric spheres or perfectly conducting disks uniformly distributed in a spatial volume which can be either spherical or layered. For every disordered medium, we numerically investigate a localization criterion, and examine the influence of the system parameters on the wavelength localization domains.
physics.optics:The use of specific symmetry properties of the optical second-harmonic generation (the s,s-exclusion rule) has allowed us to observe high-contrast hyper-Rayleigh interference patterns in a completely diffuse light - an effect having no analog in case of linear (Rayleigh) scattering.
physics.optics:We report detailed measurements of the pump-current dependency of the self-pulsating frequency of semiconductor CD lasers. A distinct kink in this dependence is found and explained using rate-equation model. The kink denotes a transition between a region where the self-pulsations are weakly sustained relaxation oscillations and a region where Q-switching takes place. Simulations show that spontaneous emission noise plays a crucial role for the cross-over.
physics.optics:A new method is proposed to produce population inversion on transitions involving the ground state of atoms. The method is realized experimentally with sodium atoms. Lasing at the frequency corresponding to the sodium D_2 line is achieved in the presence of pump radiation resonant to the D_1 line with helium as a buffer gas.
physics.optics:A moving dielectric appears to light as an effective gravitational field. At low flow velocities the dielectric acts on light in the same way as a magnetic field acts on a charged matter wave. We develop in detail the geometrical optics of moving dispersionless media. We derive a Hamiltonian and a Lagrangian to describe ray propagation. We elucidate how the gravitational and the magnetic model of light propagation are related to each other. Finally, we study light propagation around a vortex flow. The vortex shows an optical Aharonov--Bohm effect at large distances from the core, and, at shorter ranges, the vortex may resemble an optical black hole.
physics.optics:We report the first observation of a nonlinear mode in a cylindrical nonlinear Fabry-Perot cavity. The field enhancement from cavity buildup, as well as the large chi3 optical nonlinearity due to resonantly-excited Rb-85 vapor, allows the nonlinear mode to form at low incident optical powers of less than a milliwatt. The mode is observed to occur for both the self-focusing and self-defocusing nonlinearity.
physics.optics:Optical second harmonic generation (SHG) is used as a noninvasive probe of two-dimensional (2D) ferroelectricity in Langmuir-Blodgett (LB) films of copolymer vinylidene fluoride with trifluorethylene. The surface 2D ferroelectric-paraelectric phase transition in the topmost layer of LB films and a thickness independent (almost 2D) transition in the bulk of these films are observed in temperature studies of SHG.
physics.optics:An all optical set-reset flip flop is presented that is based on two coupled identical laser diodes. The lasers are coupled so that when one of the lasers lases it quenches lasing in the other laser. The state of the flip flop is determined by which laser is currently lasing. Rate equations are used to model the flip flop and obtain steady state characteristics. The flip flop is experimentally demonstrated by use of antireflection coated laser diodes and free space optics.
physics.optics:We report on the fabrication of what we believe is the first example of a two dimensional nonlinear periodic crystal\cite{berger}, where the refractive index is constant but in which the 2nd order nonlinear susceptibility is spatially periodic. Such a crystal allows for efficient quasi-phase matched 2nd harmonic generation using multiple reciprocal lattice vectors of the crystal lattice. External 2nd harmonic conversion efficiencies > 60% were measured with picosecond pulses. The 2nd harmonic light can be simultaneously phase matched by multiple reciprocal lattice vectors, resulting in the generation of multiple coherent beams. The fabrication technique is extremely versatile and allows for the fabrication of a broad range of 2-D crystals including quasi-crystals.
physics.optics:The influence of linearly and circularly polarized laser fields on the dynamics of fast electron-impact excitation in atomic helium is discussed. A detailed analysis is made in the excitation of 2^1S, 3^1S and 3^1D dressed states of helium target.
physics.optics:The nonlinear dynamics of dissipative quantum systems in incoherent laser fields is studied in the framework of master equation with random model describing the laser noise and Markovian approximation for dealing with the system-bath couplings.
physics.optics:We present a theoretical study of strong laser-atom interactions, when the laser field parameters are subjected to random processes. The atom is modelled by a two-level and three-level systems, while the statistical fluctuations of the laser field are described by a pre-Gaussian model.
physics.optics:We consider the effect of spatial correlations on sources of polarized electromagnetic radiation. The sources, assumed to be monochromatic, are constructed out of dipoles aligned along a line such that their orientation is correlated with their position. In one representative example, the dipole orientations are prescribed by a generalized form of the standard von Mises distribution for angular variables such that the azimuthal angle of dipoles is correlated with their position. In another example the tip of the dipole vector traces a helix around the symmetry axis of the source, thereby modelling the DNA molecule. We study the polarization properties of the radiation emitted from such sources in the radiation zone. For certain ranges of the parameters we find a rather striking angular dependence of polarization. This may find useful applications in certain biological systems as well as in astrophysical sources.
physics.optics:We study the dynamics of the reduced density matrix(RDM) of the field in the micromaser. The resonator is pumped by N-atomic clusters of two-level atoms. At each given instant there is only one cluster in the cavity. We find the conditions of the independent evolution of the matrix elements of RDM belonging to a (sub)diagonal of the RDM, i.e. conditions of the diagonal invariance for the case of pumping by N-atomic clusters. We analyze the spectrum of the evolution operator of the RDM and discover the existence of the quasitrapped states of the field mode. These states exist for a wide range of number of atoms in the cluster as well as for a broad range of relaxation rates. We discuss the hierarchy of dynamical processes in the micromaser and find an important property of the field states corresponding to the quasi-equilibrium: these states are close to either Fock states or to a superposition of the Fock states. A possibility to tune the distribution function of photon numbers is discussed.
physics.optics:Temporal and angular correlations in atom-mediated photon-photon scattering are measured. Good agreement is found with the theory presented in Part~I.
physics.optics:The mediated photon-photon interaction due to the resonant Kerr nonlinearity in an inhomogeneously broadened atomic vapor is considered. The time-scale for photon-photon scattering is computed and found to be determined by the inhomogeneous broadening and the magnitude of the momentum transfer. This time can be shorter than the atomic relaxation time. Effects of atom statistics are included and the special case of small-angle scattering is considered. In the latter case the time-scale of the nonlinear response remains fast, even though the linear response slows as the inverse of the momentum transfer.
physics.optics:A simple variation of the traditional Young's double slit experiment can demonstrate several subtleties of interference with polarized light, including Berry and Pancharatnam's phase. Since the position of the fringes depends on the polarization state of the light at the input, the apparatus can also be used to measure the light's polarization without a quarter-wave plate or an accurate measurement of the light's intensity. In principle this technique can be used for any wavelength of photon as long as one can effectively polarize the incoming radiation.
physics.optics:The combination of charge separation induced by the formation of a single photorefractive screening soliton and an applied external bias field in a paraelectric is shown to lead to a family of useful electro-optic guiding patterns and properties.
physics.optics:The nonlinear pulse propagation in an optical fibers with varying parameters is investigated. The capture of moving in the frequency domain femtosecond colored soliton by a dispersive trap formed in an amplifying fiber makes it possible to accumulate an additional energy and to reduce significantly the soliton pulse duration. Nonlinear dynamics of the chirped soliton pulses in the dispersion managed systems is also investigated. The methodology developed does provide a systematic way to generate infinite ``ocean'' of the chirped soliton solutions of the nonlinear Schr\"odinger equation (NSE) with varying coefficients.
physics.optics:The Jaynes-Cummings model describing the interaction of a single linearly- polarized mode of the quantized electromagnetic field with an isolated two- level atom is generalized to the case of atomic levels degenerate in the projections of the angular momenta on the quantization axis, which is a usual case in the experiments. This generalization, like the original model, obtains the explicit solution. The model is applied to calculate the dependence of the atomic level populations on the angle between the polarization of cavity field mode and that of the laser excitation pulse in the experiment with one-atom micromaser.
physics.optics:We deduce the simplest form for an axicon Gaussian laser beam, i.e., one with radial polarization of the electric field.
physics.optics:We consider a linearly polarized electromagnetic wave incident on an opaque screen with square aperture of edge a. An application of Faraday's law to a loop parallel to the screen, on the side away from the source, shows that the wave must have longitudinal components there. The ratio of the longitudinal to transverse field is a measure of the diffraction angle.
physics.optics:We show that a time-reversed formulation of Huygens-Kirchhoff diffraction can be used to deduce the transverse and longitudinal fields of a Gaussian laser beam, starting from a simple assumption of a Gaussian beam profile in the far field. An attempt to apply this technique to the far fields of a Hertzian dipole shows how the laws of diffraction do not permit a wave to be focused to a volume smaller than a cubic wavelength in a charge-free region.
physics.optics:Slow light generated by Electromagnetically Induced Transparency is extremely susceptible with respect to Doppler detuning. Consequently, slow-light gyroscopes should have ultrahigh sensitivity.
physics.optics:The second-harmonic interferometric spectroscopy (SHIS) which combines both amplitude (intensity) and phase spectra of the second-harmonic (SH) radiation is proposed as a new spectroscopic technique being sensitive to the type of critical points (CP's) of combined density of states at semiconductor surfaces. The increased sensitivity of SHIS technique is demonstrated for the buried Si(111)-SiO$_2$ interface for SH photon energies from 3.6 eV to 5 eV and allows to separate the resonant contributions from $E^\prime_0/E_1$, $E_2$ and $E^\prime_1$ CP's of silicon.
physics.optics:The frequency of a 700mW monolithic non-planar Nd:YAG ring laser (NPRO) depends with a large coupling coefficient (some MHz/mW) on the power of its laser-diode pump source. Using this effect we demonstrate the frequency stabilization of an NPRO to a frequency reference by feeding back to the current of its pump diodes. We achieved an error point frequency noise smaller than 1mHz/sqrt(Hz), and simultaneously a reduction of the power noise of the NPRO by 10dB without an additional power stabilization feed-back system.
physics.optics:We deduce the emissivity of radiation from a metallic surface as a function of angle and polarization. This effect has found application in the calibration of detectors for cosmic microwave background radiation.
physics.optics:We present the first experimental observation of modulation instability of partially spatially incoherent light beams in non-instantaneous nonlinear media. We show that even in such a nonlinear partially coherent system (of weakly-correlated particles) patterns can form spontaneously. Incoherent MI occurs above a specific threshold that depends on the beams' coherence properties (correlation distance), and leads to a periodic train of one-dimensional (1D) filaments. At a higher value of nonlinearity, incoherent MI displays a two-dimensional (2D) instability and leads to self-ordered arrays of light spots.
physics.optics:We study the polarization of light emitted by spatially correlated sources. We show that in general polarization acquires nontrivial spectral dependence due to spatial correlations. The spectral dependence is found to be absent only for a special class of sources where the correlation length scales as the wavelength of light. We further study the cross correlations between two spatially distinct points that are generated due to propagation. It is found that such cross correlation leads to sufficiently strong spectral dependence of polarization which can be measured experimentally.
physics.optics:We demonstrate experimentally that in a centrosymmetric paraelectric non-stationary boundary conditions can dynamically halt the intrinsic instability of quasi-steady-state photorefractive self-trapping, driving beam evolution into a stable oscillating two-soliton-state configuration.
physics.optics:Mugnai et al. have reported an experiment in which microwave packets appear to travel in air with a speed substantially greater than c. They calculate the group velocity of their packets and find that it agrees with their experimental result. That calculation is incorrect. A correct calculation gives a group velocity less than c. The reported experimental result cannot be reconciled with the Maxwell equations.
physics.optics:Scalar Bessel beams are derived both via the wave equation and via diffraction theory. While such beams have a group velocity that exceeds the speed of light, this is a manifestation of the "scissors paradox" of special relativty. The signal velocity of a modulated Bessel beam is less than the speed of light. Forms of Bessel beams that satisfy Maxwell's equations are also given.
physics.optics:Various algebraic structures of degenerate four-wave mixing equations of optical phase conjugation are analyzed. Two approaches (the spinorial and the Lax-pair based), complementary to each other, are utilized for a systematic derivation of conserved quantities. Symmetry groups of both the equations and the conserved quantities are determined, and the corresponding generators are written down explicitly. Relation between these two symmetry groups is found. Conserved quantities enable the introduction of new methods for integration of the equations in the cases when the coupling $\Gamma$ is either purely real or purely imaginary. These methods allow for both geometries of the process, namely the transmission and the reflection, to be treated on an equal basis. One approach to introduction of Hamiltonian and Lagrangian structures for the 4WM systems is explored, and the obstacles in successful implementation of that programe are identified. In case of real coupling these obstacles are removable, and full Hamiltonian and Lagrangian formulations of the initial system are possible.
physics.optics:Instead of using frequency dependent refractive index, we propose to use the extinction theorem to describe reflection and transmission of an ultrashort pulse passing through the boundary. When the duration of the pulse is comparable with the relaxation time, the results differ significantly from those given by the traditional method, especially if the carrier frequency is close to an absorbtion line. We compare the two approaches using the data of GaAs in the infrared domain.
physics.optics:The Classification of Polarization elements, the polarization affecting optical devices which have a Jones matrix representation, according to the types of eigenvectors they possess, is given a new visit through the Group-theoretical connection of polarization elements. The diattenuators and retarders are recognized as the elements corresponding to boosts and rotations respectively. The structure of homogeneous elements other than diattenuators and retarders are identified by giving the quaternion corresponding to these elements. The set of degenerate polarization elements is identified with the so called `null' elements of the Lorentz Group. Singular polarization elements are examined in their more illustrative Mueller matrix representation and finally the eigenstructure of a special class of singular Mueller matrices is studied.
physics.optics:Complex photonic band structures (CPBS) of transmission metallic gratings with rectangular slits are shown to exhibit strong discontinuities that are not evidenced in the usual energetic band structures. These discontinuities are located on Wood's anomalies and reveal unambiguously two different types of resonances, which are identified as horizontal and vertical surface-plasmon resonances. Spectral position and width of peaks in the transmission spectrum can be directly extracted from CPBS for both kinds of resonances.
physics.optics:We present a brief classical discussion of a process to reduce the group velocity of an electromagnetic pulse by many orders of magnitude.
physics.optics:The properties of pulse propagation in a nonlinear fiber including linear damped term added in the usual nonlinear Schr\"odinger equation is analyzed analytically. We apply variational modified approach based on the lagrangian that describe the dynamic of system and with a trial function we obtain a solution which is more accuracy when compared with a pertubative solution. As a result, the problem of pulse propagation in a fiber with loss can be described in good agreement with exact results.
physics.optics:The group velocity for pulses in an optical medium can be negative at frequencies between those of a pair of laser-pumped spectral lines. The gain medium then can amplify the leading edge of a pulse resulting in a time advance of the pulse when it exits the medium, as has been recently demonstrated in the laboratory. This effect has been called superluminal, but, as a classical analysis shows, it cannot result in signal propgation at speeds greater than that of light in vacuum.
physics.optics:In two models it is shown that a light pulse propagates from a vacuum into certain media with velocity greater than that of a light in a vacuum (c). By numerical calculation the propagating properties of such a light are given.
physics.optics:The results of the study of ultra-short pulse generation in continuous-wave Kerr-lens mode-locked (KLM) solid-state lasers with semiconductor saturable absorbers are presented. The issues of extremely short pulse generation are addressed in the frames of the theory that accounts for the coherent nature of the absorber-pulse interaction. We developed an analytical model that bases on the coupled generalized Landau-Ginzburg laser equation and Bloch equations for a coherent absorber. We showed, that in the absence of KLM semiconductor absorber produces 2pi - non-sech-pulses of self-induced transparency, while the KLM provides an extremely short sech-shaped pulse generation. 2pi- and pi-sech-shaped solutions and variable-area chirped pulses have been found. It was shown, that the presence of KLM removes the limitation on the minimal modulation depth in absorber. An automudulational stability and self-starting ability were analyzed, too.
physics.optics:Based on self - consistent field theory we study a soliton generation in cw solid-state lasers with semiconductor saturable absorber. Various soliton destabilizations, i.e. the switch from femtosecond to picosecond generation (''picosecond collapse''), an automodulation regime, breakdown of soliton generation and hysteresis behavior, are predicted.
physics.optics:The effect of transmission of x-ray beams through submicron capillaries was investigated with account for diffraction and roughness scattering. Possible explanation of anomalous energy dependence of transmission through thin Cr/C/Cr channeles was given due to effect of periodic deformations.
physics.optics:Nonstationary pulse regimes associated with self modulation of a Kerr-lens modelocked Ti:sapphire laser have been studied experimentally and theoretically. Such laser regimes occur at an intracavity group delay dispersion that is smaller or larger than what is required for stable modelocking and exhibit modulation in pulse amplitude and spectra at frequencies of several hundred kHz. Stabilization of such modulations, leading to an increase in the pulse peak power by a factor of ten, were accomplished by weakly modulating the pump laser with the self-modulation frequency. The main experimental observations can be explained with a round trip model of the fs laser taking into account gain saturation, Kerr lensing, and second- and third-order dispersion.
physics.optics:The theoretical calculation for nonlinear refractive index in Cr: ZnSe - active medium predicts the strong defocusing cascaded second-order nonlinearity within 2000 - 3000 nm spectral range. On the basis of this result the optimal cavity configuration for Kerr-lens mode locking is proposed that allows to achieve a sub-100 fs pulse duration. The numerical simulations testify about strong destabilizing processes in the laser resulting from a strong self-phase modulation. The stabilization of the ultrashort pulse generation is possible due to spectral filtering that increases the pulse duration up to 300 fs.
physics.optics:The influence of nonlinear properties of semiconductor saturable absorbers on ultrashort pulse generation was investigated. It was shown, that linewidth enhancement, quadratic and linear ac Stark effect contribute essentially to the mode locking in cw solid-state lasers, that can increase the pulse stability, decrease pulse duration and reduce the mode locking threshold
physics.optics:We demonstrate that the shift of the stop band position with increasing oblique angle in periodic structures results in a wide transverse exponential field distribution corresponding to strong angular confinement of the radiation. The beam expansion follows an effective diffusive equation depending only upon the spectral mode width. In the presence of gain, the beam cross section is limited only by the size of the gain area. As an example of an active periodic photonic medium, we calculate and measure laser emission from a dye-doped cholesteric liquid crystal film.
physics.optics:The frequency of the Calcium ^3P_1--^1S_0 intercombination line at 657 nm is phase-coherently measured in terms of the output of a primary cesium frequency standard using an optical frequency comb generator comprising a sub-10 fs Kerr-lens mode-locked Ti:Sapphire laser and an external microstructure fiber for self-phase-modulation. The measured frequency of \nu_Ca = 455 986 240 494 276 Hz agrees within its relative uncertainty of 4 10^-13 with the values previously measured with a conceptually different harmonic frequency chain and with the value recommended for the realization of the SI unit of length.
physics.optics:Accurate phase-locked 3:1 division of an optical frequency was achieved, by using a continuous-wave (cw) doubly resonant optical parametric oscillator. A fractional frequency stability of 2*10^(-17) of the division process has been achieved for 100s integration time. The technique developed in this work can be generalized to the accurate phase and frequency control of any cw optical parametric oscillator.
physics.optics:It was usually assumed that the resonator based on a waveguide has the eigen oscillations that are formed by interference of two waves which propagate in different directions and have equal amplitudes. These patterns are usually called standing waves. We have shown that the eigen oscillations of a resonator which is filled by a layered dielectric can be base on the evanescent (non-propagating) waves. In some cases we need only one eigen wave to compose the eigen oscillation of a closed cavity.
physics.optics:The plane-wave dynamics of 3*omega => (2*omega, omega) subharmonic optical parametric oscillators containing a second harmonic generator of the idler wave omega is analyzed analytically by using the meanfield approximation and numerically by taking into account the field propagation inside the media. The resonant Chi(2):Chi(2) cascaded second-order nonlinearities induce a mutual injection-locking of the signal and idler waves that leads to coherent self phase-locking of the pump and subharmonic waves, freezing the phase diffusion noise. In case of signal-and-idler resonant devices, largely detuned sub-threshold states occur due to a subcritical bifurcation, broadening out the self-locking frequency range to a few cavity linewidths.
physics.optics:For the first time an all optical flip-flop is demonstrated based on two coupled Mach-Zehnder interferometers which contain semiconductor optical amplifiers in their arms. The flip-flop operation is discussed and it is demonstrated using commercially available fiber pigtailed devices. Being based on Mach-Zehnder interferometers, the flip-flop has potential for very high speed operation.
physics.optics:The strong asymmetry in charge distribution supporting a single non-interacting spatial needle soliton in a paraelectric photorefractive is directly observed by means of electroholographic readout. Whereas in trapping conditions a quasi-circular wave is supported, the underlying double-dipolar structure can be made to support two distinct propagation modes.
physics.optics:I present a theoretical treatment of parametric scattering in strong coupling semiconductor microcavities to model experiments in which parametric oscillator behaviour has been observed. The model consists of a non-linear excitonic oscillator coupled to a cavity mode which is driven by the external fields, and predicts the output power, below threshold gain and spectral blue shifts of the parametric oscillator. The predictions are found to be in excellent agreement with the experimental data.
physics.optics:A number of factors that influence spectral position of the femtosecond pulse in a Kerr-lens modelocked Cr:LiSGaF laser have been identified: high-order dispersion, gain saturation, reabsorption from the ground state, and stimulated Raman scattering. Using the one-dimensional numerical model for the simulation of the laser cavity, the relative contributions of different factors have been compared. The Raman effect provides the largest self-frequency shift from the gain peak (up to 60 nm), followed by the gain saturation (25 nm), while the high-order dispersion contribution is insignificant (5 nm). Comparison with the experimental data confirm that the stimulated Raman scattering is a main cause of the ultrashort pulse self-frequency shift observed in Cr:LiSGaF and Cr:LiSAF lasers
physics.optics:Simultaneous measurements of the intensity and phase of a probe wave reflected from an interface between silica and elemental alpha-gallium reveal its very strong optical nonlinearity, affecting both these parameters of the reflected wave. The data corroborate with a non-thermal mechanism of optical response which assumes appearance of a homogeneous highly metallic layer, only a few nanometer thick, between the silica and bulk alpha-gallium.
physics.optics:We consider pulse propagation in a linear anomalously dispersive medium where the group velocity exceeds the speed of light in vacuum (c) or even becomes negative. A signal velocity is defined operationally based on the optical signal-to-noise ratio, and is computed for cases appropriate to the recent experiment where such a negative group velocity was observed. It is found that quantum fluctuations limit the signal velocity to values less than c.
physics.optics:Polarization dynamics of femtosecond light pulses propagating in air is studied by computer simulation. A rich variety of dynamics is found that depends on the initial polarization state and power of the pulse. Effects of polarization on the plasma and supercontinuum generation are also discussed.
physics.optics:We report measurements of thermal self-locking of a Fabry-Perot cavity containing a potassium niobate (KNbO3) crystal. We develop a method to determine linear and nonlinear optical absorption coefficients in intracavity crystals by detailed analysis of the transmission lineshapes. These lineshapes are typical of optical bistability in thermally loaded cavities. For our crystal, we determine the one-photon absorption coefficient at 846 nm to be (0.0034 \pm 0.0022) per m and the two-photon absorption coefficient at 846 nm to be (3.2 \pm 0.5) \times 10^{-11} m/W and the one-photon absorption coefficient at 423 nm to be (13 \pm 2) per m. We also address the issue of blue-light-induced-infrared-absorption (BLIIRA), and determine a coefficient for this excited state absorption process. Our method is particularly well suited to bulk absorption measurements where absorption is small compared to scattering. We also report new measurements of the temperature dependence of the index of refraction at 846 nm, and compare to values in the literature.
physics.optics:We review and extend the analogies between Gaussian pulse propagation and Gaussian beam diffraction. In addition to the well-known parallels between pulse dispersion in optical fiber and CW beam diffraction in free space, we review temporal lenses as a way to describe nonlinearities in the propagation equations, and then introduce further concepts that permit the description of pulse evolution in more complicated systems. These include the temporal equivalent of a spherical dielectric interface, which is used by way of example to derive design parameters used in a recent dispersion-mapped soliton transmission experiment. Our formalism offers a quick, concise and powerful approach to analyzing a variety of linear and nonlinear pulse propagation phenomena in optical fibers.
physics.optics:We have measured the frequency of the $6s^2S_{1/2} - 5d^2D_{3/2}$ electric-quadrupole transition of $^{171}$Yb$^+$ with a relative uncertainty of $1\times 10^{-14}$, $\nu_{Yb}$ = 688 358 979 309 312 Hz $\pm$ 6 Hz. A femtosecond frequency comb generator was used to phase-coherently link the optical frequency derived from a single trapped ion to a cesium fountain controlled hydrogen maser. This measurement is one of the most accurate measurements of optical frequencies ever reported, and it represents a contribution to the development of optical clocks based on an $^{171}$Yb$^+$ ion standard.
physics.optics:The time behaviour of microwaves undergoing partial reflection by photonic barriers was measured in the time and in the frequency domain. It was observed that unlike the duration of partial reflection by dielectric layers, the measured reflection duration of barriers is independent of their length. The experimental results point to a nonlocal behaviour of evanescent modes at least over a distance of some ten wavelengths. Evanescent modes correspond to photonic tunnelling in quantum mechanics.
physics.optics:We study the conditions for soliton-like wave propagation in the Photorefractive (PR) and electro-optic (i.e., Pockels) material, by using Nonlinear Schrodinger (NLS) equation. The complete NLS equation is solved analytically and numerically by transforming it into the phase space. Our results clearly show the existence of both the dark and bright solitary solutions for the PR medium. Interestingly, however, we find only one bright solitary solution in the Pockels case and there is no evidence of any dark solitary solution.
physics.optics:In the theory of optical gap solitons, slowly-moving finite-amplitude Lorentzian solutions are found to mediate the transition from bright to coexistent dark-antidark solitary wave pairs when the laser frequency is detuned out of the proper edge of a dynamical photonic bandgap. Catastrophe theory is applied to give a geometrical description of this strongly asymmetrical 'morphing' process.
physics.optics:Harmonic and Intermodulation distortions occur when a physical system is excited with a single or several frequencies and when the relationship between the input and output is non-linear. Working with non-linearities in the Frequency domain is not straightforward specially when the relationship between the input and output is not trivial. We outline the complete derivation of the Harmonic and Intermodulation distortions from basic principles to a general physical system. For illustration, the procedure is applied to the Single Mode laser diode where the relationship of input to output is non-trivial. The distortions terms are extracted directly from the Laser Diode rate equations and the method is tested by comparison to many results cited in the literature. This methodology is general enough to be applied to the extraction of distortion terms to any desired order in many physical systems in a general and systematic way.
physics.optics:We reelaborate on the basic properties of lossless multilayers. We show that the transfer matrices for these multilayers have essentially the same algebraic properties as the Lorentz group SO(2,1) in a (2+1)-dimensional spacetime, as well as the group SL(2,R) underlying the structure of the ABCD law in geometrical optics. By resorting to the Iwasawa decomposition, we represent the action of any multilayer as the product of three matrices of simple interpretation. This group-theoretical structure allows us to introduce bilinear transformations in the complex plane. The concept of multilayer transfer function naturally emerges and its corresponding properties in the unit disc are studied. We show that the Iwasawa decomposition reflects at this geometrical level in three simple actions that can be considered the basic pieces for a deeper undestanding of the multilayer behavior. We use the method to analyze in detail a simple practical example.
physics.optics:A method is presented to investigate diffraction of an electromagnetic plane wave by an infinitely thin infinitely conducting circular cylinder with longitudinal slots. It is based on the use of the combined boundary conditions method that consists on expressing the continuity of the tangential components of both the electric and the magnetic fields in a single equation. This method proves to be very efficient for this kind of problems and leads to fast numerical codes.
physics.optics:We present a reliable, narrow linewidth (100 kHz) continuous-wave optical parametric oscillator (OPO) suitable for high-resolution spectroscopy applications. The OPO is based on a periodically-poled lithium-niobate crystal and features a specially designed intracavity etalon which permits its continuous tuning and stable operation at any desired wavelength in a wide operation range. We demonstrate Doppler-free spectroscopy on a rovibrational transition of methane at 3.39 um.
physics.optics:We describe the action of a plane interface between two semi-infinite media in terms of a transfer matrix. We find a remarkably simple factorization of this matrix, which enables us to express the Fresnel coefficients as a hyperbolic rotation.
physics.optics:We report on a methodology for the evaluation of the DC characteristics, small-signal frequency response and large-signal dynamic response of carrier and photon density responses in semiconductor laser diodes. A single mode laser is considered and described with a pair of rate equations containing a novel non-linear gain compensation term depending on a single parameter that can be chosen arbitrarily. This approach can be applied to any type of solid-state laser as long as it is described by a set of rate equations.
physics.optics:We report the discovery of a "dark area theorem," a new quantum optical relation for propagation of unmatched pulses in thick three-level $\Lambda$-type media. We define dark area and derive the dark area theorem for a coherently prepared and inhomogeneously broadened lambda medium. We also obtain the first equation for the spatial evolution of the dark state amplitude prior to pulse-matching.
physics.optics:We propose experimentally simplified schemes of an optically dispersive interface region between two coupled free electron lasers (FELs), aimed at achieving a much broader gain bandwidth than in a conventional FEL or a conventional optical klystron composed of two separated FELs. The proposed schemes can {\it universally} enhance the gain of FELs, regardless of their design when operated in the short pulsed regime.
physics.optics:As a light beam is produced by an amplification of modes of the zero point field in its source, this field cannot be distinguished; consequently a nonlinear optical effect is a function of the total field. However, we generally prefer to use a conventional field which excludes the zero point field; for a low conventional field, the total field may be developed to the first order, so that the effect appears linear.   This nearly trivial remark allows a correct computation of the signal of a photocell used for photon counting and shows that the "impulsive stimulated Raman scattering" (ISRS), a nonlinear, without threshold effect, which shifts the frequencies, becomes linear at low light levels, so that the shifted spectra are not distorted.
physics.optics:The effect of thermal fluctuations in the resonance fluorescence of a three-level system is studied. The damped three-level system is driven by two strong incident classical fields near resonances frequencies. The simulation of a thermal bath is obtained with a large system of harmonic oscillators that represent the normal modes of the thermal radiation field. The time evolution of the fluorescent light intensities are obtained solving by a iterative method the Heisenberg equations of motion in the integral form. The results show that the time development of the intensity of the fluorescence light is strongly affected by the interaction of the system with the thermal bath.
physics.optics:The dynamical response of a relativistic bunch of electrons injected in a planar magnetic undulator and interacting with a counterpropagating electromagnetic wave is studied. We demonstrate a resonance condition for which the free electron laser (FEL) dynamics is strongly influenced by the presence of the external field. It opens up the possibility of control of short wavelength FEL emission characteristics by changing the parameters of the microwave field without requiring change in the undulator's geometry or configuration. Numerical examples, assuming realistic parameter values analogous to those of the TTF-FEL, currently under development at DESY, are given for possible control of the amplitude or the polarization of the emitted radiation.
physics.optics:We have operated a CW triply resonant OPO using a PPLN crystal pumped by a Nd:YAG laser at 1.06 micron and generating signal and idler modes in the 2-2.3 micron range. The OPO was operated stably in single mode operation over large periods of time with a pump threshold as low as 500 microwatts.
physics.optics:We extend a modal theory of diffraction by a set of parallel fibers to deal with the case of a hard boundary: that is a structure made for instance of air-holes inside a dielectric matrix. Numerical examples are given concerning some resonant phenomena.
physics.optics:We report observation of lasing in the scarred modes in an asymmetrically deformed microcavity made of liquid jet. The observed scarred modes correspond to morphology-dependent resonance of radial mode order 3 with their Q values in the range of 10^6. Emission directionality is also observed, corresponding to a hexagonal unstable periodic orbit.
physics.optics:We have demonstrated an ultrahigh-Q whispering-gallery-mode (WGM) microsphere laser based on the evanescent-wave-coupled gain. Dye molecules outside the sphere near the equator were excited, resulting in WGM lasing in the lowest radial mode order. The loaded quality factor of the lasing WGM was 8(2)\times 10^9, the highest ever achieved in the microlaser.
physics.optics:An extended cavity diode laser operating in the Littrow configuration emitting near 657 nm is stabilized via its injection current to a reference cavity with a finesse of more than 10^5 and a corresponding resonance linewidth of 14 kHz. The laser linewidth is reduced from a few MHz to a value below 30 Hz. The compact and robust setup appears ideal for a portable optical frequency standard using the Calcium intercombination line.
physics.optics:We introduce a novel concept for optical frequency measurement and division which employs a Kerr-lens mode-locked laser as a transfer oscillator whose noise properties do not enter the measurement process. We experimentally demonstrate, that this method opens up the route to phase-link signals with arbitrary frequencies in the optical or microwave range while their frequency stability is preserved.
physics.optics:We investigate the self-phase modulation of intense femtosecond laser pulses propagating in an ionizing gas and its effects on collective properties of high-order harmonics generated in the medium. Plasmas produced in the medium are shown to induce a positive frequency chirp on the leading edge of the propagating laser pulse, which subsequently drives high harmonics to become positively chirped. In certain parameter regimes, the plasma-induced positive chirp can help to generate sharply peaked high harmonics, by compensating for the dynamically-induced negative chirp that is caused by the steep intensity profile of intense short laser pulses.
physics.optics:We developed a novel technique for frequency measurement and synthesis, based on the operation of a femtosecond comb generator as transfer oscillator. The technique can be used to measure frequency ratios of any optical signals throughout the visible and near-infrared part of the spectrum. Relative uncertainties of $10^{-18}$ for averaging times of 100 s are possible. Using a Nd:YAG laser in combination with a nonlinear crystal we measured the frequency ratio of the second harmonic $\nu_{SH}$ at 532 nm to the fundamental $\nu_0$ at 1064 nm, $\nu_{SH}/\nu_0 = 2.000 000 000 000 000 001 \times (1 \pm 7 \times 10^{-19})$.
physics.optics:The mixed crystal of a para-dibromobenzene with a para-chloronitrobenzene is investigated at concentration of components from 0% up to 60% of a para-chloronitrobenzene by the method of Low-Frequency Raman spectroscopy. It is shown, that in range of concentrations from 25% up to 50% of a para-chloronitrobenzene the spectrum of the mixed crystal would consist of the sum of spectrums a and b phases which relation of intensities depends on concentration of components. It is also found, that the single crystal in this range has rod frame.
physics.optics:The stability of polarization, areas, and number of self-induced transparency (SIT)-solitons at the output from the LaF_3:Pr^{3+} crystal is theoretically studied versus the polarization direction and the area of the input linearly polarized laser pulse. For this purpose the Vector Area Theorem is rederived and two-dimensional Vector Area Theorem map is obtained. The map is governed by the crystal symmetry and takes into account directions of the dipole matrix element vectors of the different site subgroups of optically excited ions. The Vector Area Theorem mapping of the time evolution of the laser pulse allows one to highlight soliton polarization properties.
physics.optics:The dynamics of light in Fabry-Perot cavities with varying length and input laser frequency are analyzed and the exact condition for resonance is derived. This dynamic resonance depends on the light transit time in the cavity and the Doppler effect due to the mirror motions. The response of the cavity to length variations is very different from its response to laser frequency variations. If the frequency of these variations is equal to multiples of the cavity free spectral range, the response to length is maximized while the response to the laser frequency is zero. Implications of these results for the detection of gravitational waves using kilometer-scale Fabry-Perot cavities are discussed.
physics.optics:Numerical simulation of the National Ignition Facility (NIF) laser performance and automated control of the laser setup process are crucial to the project's success. These functions will be performed by two closely coupled computer code: the virtual beamline (VBL) and the laser performance operations model (LPOM).
physics.optics:Since its birth, the laser has been extraordinarily effective in the study and applications of laser-matter interaction at the atomic and molecular level and in the nonlinear optics of the bound electron. In its early life, the laser was associated with the physics of electron volts and of the chemical bond. Over the past fifteen years, however, we have seen a surge in our ability to produce high intensities, five to six orders of magnitude higher than was possible before. At these intensities, particles, electrons and protons, acquire kinetic energy in the mega-electron-volt range through interaction with intense laser fields. This opens a new age for the laser, the age of nonlinear relativistic optics coupling even with nuclear physics. We suggest a path to reach an extremely high-intensity level $10^{26-28} $W/cm$^2$ in the coming decade, much beyond the current and near future intensity regime $10^{23} $W/cm$^2$, taking advantage of the megajoule laser facilities. Such a laser at extreme high intensity could accelerate particles to frontiers of high energy, tera-electron-volt and peta-electron-volt, and would become a tool of fundamental physics encompassing particle physics, gravitational physics, nonlinear field theory, ultrahigh-pressure physics, astrophysics, and cosmology. We focus our attention on high-energy applications in particular and the possibility of merged reinforcement of high-energy physics and ultraintense laser.
physics.optics:A simple and intuitive geometical method to analyze Fresnel formulas is presented. It applies to transparent media and is valid for perpendicular and parallel polarizations. The approach gives a graphical characterization particularly simple of the critical and Brewster angles. It also provides an interpretation of the relation between the reflection coefficients for both basic polarizations as a symmetry in the plane.
physics.optics:The tunnel effect is considered here within the framework of electromagnetic propagation. The classical problem of a plane gap of dielectric, surrounded on both sides by a medium with larger refraction index, is studied in the case in which an electromagnetic plane wave impinges into the gap with an incidence angle larger than the critical angle. In this condition (total reflection), the gap acts as a classically forbidden region and behaves like a tunnel. The field inside the forbidden gap consists of two evanescent waves, each one having its wavefronts normal to the interface. In the present paper we study the total field derived as a superposition of two such evanescent waves, its wavefronts, and the directions of propagation of both phase and energy.
physics.optics:The motion of an electromagnetic wave, through a classically-forbidden region, has recently attracted renewed interest because of its implication with regard to the theoretical and experimental problems of superluminality. From an experimental point of view, many papers provide an evidence of superluminality in different physical systems. Theoretically, the problem of a passage through a forbidden gap has been treated by considering plane waves at oblique incidence into a plane parallel layer of a medium with a refractive index smaller than the index of the surrounding medium, and also confined (Gaussian) beams, still at oblique incidence. In the present paper the case of a Bessel beam is examined, at normal incidence into the layer (Secs. II and III), in the scalar approximation (Sec. IV) and by developing also a vectorial treatment (Sec. V). Conclusions are reported in Sic. VI.
physics.optics:The tunneling time is here investigated by means of an electromagnetic model, for a system where a gap, between two parallel planes, acts as a classically-forbidden region for an impinging pulse with incidence angle larger than the critical angle. In all cases of frustrated total reflection we obtain a superluminal behavior both for phase and group delays.
physics.optics:We report an injection-locked cw titanium:sapphire ring laser at 846 nm. It produces 1.00 W in a single frequency when pumped with 5.5 W. Single frequency operation requires only a few milliwatts of injected power.
physics.optics:Accurate knowledge of absorption coefficient of a sample is a prerequisite for measuring the third order optical nonlinearity of materials, which could become a serious limitation for unknown samples. We introduce a new method, which measures both the absorption coefficient and the third order optical nonlinearity of materials with high sensitivity in a single experimental setup. We use a dual-beam pump-probe experiment under different conditions to achieve this goal. We also demonstrate a counterintuitive coupling of the non-interacting probe-beam with the pump-beam in pump-probe z-scan experiment.
physics.optics:We obtain gain of the probe field at multiple frequencies in a closed three-level V-type system using frequency modulated pump field. There is no associated population inversion among the atomic states of the probe transition. We describe both the steady-state and transient dynamics of this system. Under suitable conditions, the system exhibits large gain simultaneously at series of frequencies far removed from resonance. Moreover, the system can be tailored to exhibit multiple frequency regimes where the probe experiences anomalous dispersion accompanied by negligible gain-absorption over a large bandwidth, a desirable feature for obtaining superluminal propagation of pulses with negligible distortion.
physics.optics:An undoped double quantum well (DQW) was driven with a terahertz (THz) electric field of frequency \omega_{THz} polarized in the growth direction, while simultaneously illuminated with a near-infrared (NIR) laser at frequency \omega_{NIR}. The intensity of NIR upconverted sidebands \omega_{sideband}=\omega_{NIR} + \omega_{THz} was maximized when a dc voltage applied in the growth direction tuned the excitonic states into resonance with both the THz and NIR fields. There was no detectable upconversion far from resonance. The results demonstrate the possibility of using gated DQW devices for all-optical wavelength shifting between optical communication channels separated by up to a few THz.
physics.optics:Driving a double-quantum-well excitonic intersubband resonance with a terahertz (THz) electric field of frequency \omega_{THz} generated terahertz optical sidebands \omega=\omega_{THz}+\omega_{NIR} on a weak NIR probe. At high THz intensities, the intersubband dipole energy which coupled two excitons was comparable to the THz photon energy. In this strong-field regime the sideband intensity displayed a non-monotonic dependence on the THz field strength. The oscillating refractive index which gives rise to the sidebands may be understood by the formation of Floquet states, which oscillate with the same periodicity as the driving THz field.
physics.optics:We elaborate on the consequences of the factorization of the transfer matrix of any lossless multilayer in terms of three basic matrices of simple interpretation. By considering the bilinear transformation that this transfer matrix induces in the complex plane, we introduce the concept of multilayer transfer function and study its properties in the unit disk. In this geometrical setting, our factorization translates into three actions that can be viewed as the basic pieces for understanding the multilayer behavior. Additionally, we introduce a simple trace criterion that allows us to classify multilayers in three types with properties closely related to one (and only one) of these three basic matrices. We apply this approach to analyze some practical examples that are representative of these types of matrices.
physics.optics:We consider the problem of radiation into free space from the end-facet of a single-mode photonic crystal fiber (PCF). We calculate the numerical aperture NA=sin theta from the half-divergence angle theta ~ tan^{-1}(lambda/pi w) with pi w^2 being the effective area of the mode in the PCF. For the fiber first presented by Knight et al. we find a numerical aperture NA ~ 0.07 which compares to standard fiber technology. We also study the effect of different hole sizes and demonstrate that the PCF technology provides a large freedom for NA-engineering. Comparing to experiments we find good agreement.
physics.optics:Polarized and azimuthal dependencies of optical second harmonics generation (SHG) at the surface of noncentrosymmetric semiconductor crystals have been measured on polished surfaces of ZnSe(100), using a fundamental wavelength of 1.06$\mu m$. The SHG intensity patterns were analyzed for all four combination of p- and s-polarized incidence and output, considering both the bulk and surface optical nonlinearities in the electric dipole approximation. We found that the measurement using $S_{in}-S_{out}$ is particularly useful in determining the symmetry of the oxdized layer interface, which would lower the effective symmetry of the surface from $C_{4v}$ to $C_{2v}.$ We also have shown that the [011] and [0$\bar{1}$1] directions can be distinguished through the analysis of p-incident and p-output confugration.
physics.optics:Fundamental rules and definitions of Fractional Differintegrals are outlined. Factorizing 1-D and 2-D Helmholtz equations four fractional eigenfunctions are determined. The functions exhibit incident and reflected plane waves as well as diffracted incident and reflected waves of the half-plane edge. They allow to construct the Sommerfeld half-plane diffraction solutions. Parabolic-Wave Equation (PWE, Leontovich-Fock) for paraxial propagation is factorized and differetial fractional solutions of Fresnel-integral type are derived. We arrived at two solutions, which are the mothers of known and new solutions.
physics.optics:In the classical theory, an electromagnetic field obeying Maxwell's equations cannot be absorbed quickly by matter, so that it remains a zero point field. Splitting the total, genuine electromagnetic field into the sum of a conventional field and a zero point field is physically meaningless until a receiver attenuates the genuine field down to the zero point field, or studying the amplification of the zero point field by a source.   In classical optics all optical effects must be written using the genuine field, so that at low light levels the nonlinear effects become linear in relation to the conventional field. The result of the interpretation of all observations, even at low light levels, is exactly the same in quantum electrodynamics and in the semi- classical theory.   The zero point field is stochastic only far from the sources and the receivers; elsewhere, it is shaped by matter, it may be studied through fields visible before an absorption or after an amplification.   A classical study of the reduction of the wave packet extends the domain of equivalence of the classical and quantum zero point field; using both interpretations of this field makes the results more reliable, because the traps are different.
physics.optics:The smaller the size of a light-emitting microcavity, the more important it becomes to understand the effects of the cavity boundary on the optical mode profile. Conventional methods of laser physics, such as the paraxial approximation, become inapplicable in many of the more exotic cavity designs to be discussed here. Cavities in the shape of microdisks, pillars and rings can yield low lasing thresholds in a wide variety of gain media: quantum wells, wires and even dots, as well as quantum cascade superlattices and GaN. An overview of the experimental and theoretical status is provided, with special emphasis on the light extraction problem.
physics.optics:The stationary states of a microlaser are related to the decaying quasibound states of the corresponding passive cavity. These are interpreted classically as originating from sequential escape attempts of an ensemble of rays obeying a curvature-corrected Fresnel formula. Polarization-dependent predictions of this model, and its limitations for stable orbits in partially chaotic systems are discussed.
physics.optics:We measured and calculated transmission spectra of two-dimensional quasiperiodic photonic crystals (PCs) based on a 5-fold (Penrose) or 8-fold (octagonal) symmetric quasiperiodic pattern. The photonic crystal consisted of dielectric cylindrical rods in air placed normal to the basal plane on vertices of tiles composing the quasiperiodic pattern. An isotropic photonic band gap (PBG) appeared in the TM mode, where electric fields were parallel to the rods, even when the real part of a dielectric constant of the rod was as small as 2.4. An isotropic PBG-like dip was seen in tiny Penrose and octagonal PCs with only 6 and 9 rods, respectively. These results indicate that local multiple light scattering within the tiny PC plays an important role in the PBG formation. Besides the isotropic PBG, we found dips depending on the incident angle of the light. This is the first report of anisotropic structures clearly observed in transmission spectra of quasiperiodic PCs. Based on rod-number and rod-arrangement dependence, it is thought that the shapes and positions of the anisotropic dips are determined by global multiple light scattering covering the whole system. In contrast to the isotropic PBG due to local light scattering, we could not find any PBGs due to global light scattering even though we studied transmission spectra of a huge Penrose PC with 466 rods.
physics.optics:A perfect focus telescope is one in which all rays parallel to the axis meet at a point and give equal magnification there. It is shown that these two conditions define the shapes of both primary and secondary mirrors. Apart from scale, the solution depends upon two parameters, $s$, which gives the mirror separation in terms of the effective focal length, and $K$, which gives the relative position of the final focus in that unit. The two conditions ensure that the optical systems have neither spherical aberration nor coma, no matter how fast the $f$ ratio. All known coma--free systems emerge as approximate special cases. In his classical paper, K. Schwarzschild studied all two mirror systems whose profiles were conic sections. We make no such a priori shape conditions but demand a perfect focus and solve for the mirrors' shapes.
physics.optics:The results of experimental testing the existence of intense Lorentzian--like wings with FWHM $\sim 4.5 cm^{-1}$ in the absorption spectra of polyatomic molecules in a gas phase are presented. Two independent experimental methods were used for evaluating the integral intensity of the line wings for a number of substances. In the first case, the cross--section of the far wings of absorption bands in a gas phase spectrum were measured. Then, these band wings were extrapolated inside the contour of absorption band. In the second case, the saturation degree of the linear spectrum of molecules was determined. Radiation of a pulsed $CO_2$--laser was used at low gas pressure ($\sim 16$ mtorr) and averaged excitation level of molecules ${<n>}\sim 0.1$ quanta/molecule. The values obtained by these two independent methods coincide for a variety of molecules. The average relative integral intensity of the line wings varied from $\sim 0.6%$ for $SF_6$ and $SiF_4$ to $\sim 90%$ for $(CF_3)_2O$ and $(CF_3)_2CO$.
physics.optics:It is shown that the direct Fourier synthesization of light beams allows one to create polarity-asymmetric waves, which are able, in the process of nonlinear interaction with a medium, to break its inversion symmetry. As a result, these "polar" waves may show the effect of optical rectification in nonlinear centrosymmetric media by generating light-induced dc electric polarization. At the same time, the waves of this type, due to their unusual symmetry properties, can be used for detecting the direction and sign of a dc electric field applied to the medium. The prospects of application of polar waves to data recording and processing are discussed.
physics.optics:Presented is an analysis of general scaling perturbations in a transmitting fiber. For elliptical perturbations, under some conditions an intermode dispersion parameter characterizing modal PMD is shown to be directly proportional to the mode dispersion.
physics.optics:Extensive Bose-Einstein condensation research activities have recently led to studies of fermionic atoms and optical confinements. Here we present a case of micro-optical fermionic electron phase transition. Optically confined ordering and phase transitions of a fermionic cloud in dynamic steady state are associated with Rayleigh emissions from photonic quantum ring manifold which are generated by nature without any ring lithography. The whispering gallery modes, produced in a semiconductor Rayleigh-Fabry-Perot toroidal cavity at room temperature, exhibit novel properties of ultralow thresholds open to nano-ampere regime, thermal stabilities from square-root-T-dependent spectral shift, and angularly varying intermode spacings. The photonic quantum ring phenomena are associated with a photonic field-driven phase transition of quantum-well-to-quantum-wire and hence the photonic (non-de Broglie) quantum corral effect on the Rayleigh cavity-confined carriers in dynamic steady state. Based upon the intra-cavity fermionic condensation we also offer a prospect for an electrically driven few-quantum dot single photon source from the photonic quantum ring laser for quantum information processors.
physics.optics:Nonlinear optical media that are normally dispersive, support a new type of localized (nondiffractive and nondispersive) wavepackets that are X-shaped in space and time and have slower than exponential decay. High-intensity X-waves, unlike linear ones, can be formed spontaneously through a trigger mechanism of conical emission, thus playing an important role in experiments.
physics.optics:We report three-dimensional laser microfabrication, which enables microstructuring of materials on the scale of 0.2-1 micrometers. The two different types of microfabrication demonstrated and discussed in this work are based on holographic recording, and light-induced damage in transparent dielectric materials. Both techniques use nonlinear optical excitation of materials by ultrashort laser pulses (duration < 1 ps).
physics.optics:We propose a concept for production of high power coherent attosecond pulses in X-ray range. An approach is based on generation of 8th harmonic of radiation in a multistage HGHG FEL (high gain high harmonic free electron laser) configuration starting from shot noise. Single-spike phenomena occurs when electron bunch is passed through the sequence of four relatively short undulators. The first stage is a conventional "long" wavelength (0.8 nm) SASE FEL which operates in the high-gain linear regime. The 0.1 nm wavelength range is reached by successive multiplication (0.8 nm $\to$ 0.4 nm $\to$ 0.2 nm $\to$ 0.1 nm) in a stage sequence. Our study shows that the statistical properties of the high-harmonic radiation from the SASE FEL, operating in linear regime, can be used for selection of radiation pulses with a single spike in time domain. The duration of the spikes is in attosecond range. Selection of single-spike high-harmonic pulses is achieved by using a special trigger in data acquisition system. The potential of X-ray SASE FEL at TESLA at DESY for generating attosecond pulses is demonstrated. Since the design of XFEL laboratory at TESLA is based on the use of long SASE undulators with tunable gap, no special place nor additional FEL undulators are required for attophysics experiments. The use of a 10 GW-level attosecond X-ray pulses at X-ray SASE FEL facility will enable us to track processes inside atoms.
physics.optics:We present an algorithm for the maximization of photonic bandgaps in two-dimensional crystals. Once the translational symmetries of the underlying structure have been imposed, our algorithm finds a global maximal (and complete, if one exists) bandgap. Additionally, we prove two remarkable results related to maximal bandgaps: the so-called `maximum contrast' rule, and about the location in the Brillouin zone of band edges.
physics.optics:We investigate the propagation of electromagnetic waves in finite photonic band gap structures. We analyze the phenomenon of conduction and forbidden bands and we show that two regimes are to be distinguished with respect to the existence of a strong field near the interfaces. We precise the domain for which an effective medium theory is sounded.
physics.optics:The maximum bit-rate of a slab waveguide is ultimately determined by the waveguide dispersion. We show that while the maximum bit rate in a waveguide is inversely proportional to the waveguide's width, bit rate per unit width (i.e., spatial capacity) decreases, and in the limit of a zero-width waveguide it converges to a value, which is independent of the waveguide's refractive indices. This value is qualitatively equivalent to the transmission rate per unit of width in free space. We also show that in a 3D waveguide (e.g., fibers), unlike free space, the spatial capacity vanishes in the same limit.
physics.optics:The photonic band dispersion and density of states (DOS) are calculated for the three-dimensional (3D) hexagonal structure corresponding to a distributed Bragg reflector patterned with a 2D triangular lattice of circular holes. Results for the Si/SiO$_2$ and GaAs/AlGaAs systems determine the optimal parameters for which a gap in the 2D plane occurs and overlaps the 1D gap of the multilayer. The DOS is considerably reduced in correspondence with the overlap of 2D and 1D gaps. Also, the local density of states (i.e., the DOS weighted with the squared electric field at a given point) has strong variations depending on the position. Both results imply substantial changes of spontaneous emission rates and patterns for a local emitter embedded in the structure and make this system attractive for the fabrication of a 3D photonic crystal with controlled radiative properties.
physics.optics:We present a Fourier transform methodology for all-order polarization mode dispersion (PMD) analysis, based on the first Born approximation to the coupled-mode equation solution. Our method predicts wavelength-dependent PMD effects and allows design of filters for their mitigation.
physics.optics:We demonstrate the combination of a hemispherical solid immersion lens with a micro-photoluminescence setup. Two advantages introduced by the SIL, an improved resolution of 0.4 times the wavelength in vacuum and a 5 times enhancement of the collection efficiency, make it an ideal system for spatially resolved spectroscopy applications. The influence of the air gap between the SIL and the sample surface is investigated in detail. We confirm the tolerance of the set--up to an air gap of several micrometers. Such a system is proven to be ideal system in the studies of exciton transport and polarization dependent single quantum dot spectroscopy.
physics.optics:It is assumed, that the clumps of lines do not connected with states mixing and IVR, but they are the result of breaking (destruction) of the process of averaging of momentum of inertia of molecules during the vibration motion of atoms. Rough estimates of the widths of clumps of lines in absorption spectra of some acetylenic derivatives were made with this model. Obtained results are in a satisfactory agreement with the available experimental data. This idea allows also in principle to explain the origin of intensive wings of lines, the existence of which was discussed earlier.
physics.optics:The origin of the Kerr type nonlinearity of the medium as a result of the interaction between photons via the Dirac delta-potential is presented in the formalism adopted from the photon wave function approach. In the view of the result the optical soliton may be treated as a bound state (cluster) of many photons.
physics.optics:The propagation of photon in a dielectric may be described with the help of the scalar and vector potentials of the medium. The main novelty of the paper is that the concept of the vector potential (which is connected with the velocity of the medium) can be extended to relativistic velocities of the medium. The position-dependent photon wave function was used to describe the propagation of the photon. The new concepts of the velocity of photon as particle and the photon mass in the dielectric medium were proposed.
physics.optics:Mathematical aspects of the SU(1,1) group parameter x dynamics governed by Hamiltonians exhibiting some special types of time dependence has been presented on an elementary level from the point of view of Moebius transformation of complex plane. The trajectories of x in continuous and mappings in discrete dynamics are considered. Some simple examples have been examined. Analytical considerations and numerical results have been given.
physics.optics:Propagation of the TE electromagnetic waves in self-focusing medium is governed by the nonlinear Schroedinger equation. In this paper the stationary solutions of this equation have been systematically presented. The phase-plane method, qualitative analysis, and mechanical interpretation of the differential equations are widely used. It is well known that TE waves can be guided by the single interface between two semi-infinite media, providing that one of the media has a self-focusing (Kerr type) nonlinearity. This special solution is called a spatial soliton. In this paper our interests are not restricted to the soliton solutions. In the context of the nonlinear substrate and cladding we have found solutions which could be useful to describe also the incident light in nonlinear medium. This result is the main point of the paper. Some of the presented stationary solutions were already used in similar optical context in literature but we show a little wider class of solutions. In the last section we review and illustrate some results concerning the spatial soliton solution.
physics.optics:We present angle- and polarization-resolved measurements of the optical transmission of a subwavelength hole array. These results give a (far-field) visualization of the corresponding (near-field) propagation of the excited surface plasmons and allow for a simple analysis of their polarization properties.
physics.optics:A monochromatic linear source of light is rotated with certain angular frequency and when such light is analysed after reflection then a change of frequency or wavelength may be observed depending on the location of the observer. This change of frequency or wavelength is different from the classical Doppler effect [1] or relativistic Doppler effect [2]. The reason behind this shift in wavelength is that a certain time interval observed by an observer in the rotating frame is different from that of a stationary observer.
physics.optics:We investigate the spectral response of a Brillouin amplifier in the frequency regime within the SBS bandwidth. This is done by amplitude modulating the pump with a low frequency, and therefore, unlike previous studies, the spectrum of the modulated pump is, in all cases, smaller than the SBS bandwidth. We show both theoretically and experimentally that unlike phase modulation, which was reported in the literature, the amplitude modulation increases the Brillouin amplifier gain, and that this effect has a very narrow bandwidth. Only modulation frequencies that are lower than a certain cut-off frequency increase the gain. This cut-off frequency is inversely proportional to the fiber's length, and can therefore be arbitrarily small.
physics.optics:The Phase Diverse Speckle (PDS) problem is formulated mathematically as Multi Frame Blind Deconvolution (MFBD) together with a set of Linear Equality Constraints (LECs) on the wavefront expansion parameters. This MFBD-LEC formulation is quite general and, in addition to PDS, it allows the same code to handle a variety of different data collection schemes specified as data, the LECs, rather than in the code. It also relieves us from having to derive new expressions for the gradient of the wavefront parameter vector for each type of data set. The idea is first presented with a simple formulation that accommodates Phase Diversity, Phase Diverse Speckle, and Shack-Hartmann wavefront sensing. Then various generalizations are discussed, that allows many other types of data sets to be handled.
physics.optics:A Monte Carlo simulation has been performed to track light rays in cylindrical fibres by ray optics. The trapping efficiencies for skew and meridional rays in active fibres and distributions of characteristic quantities for all trapped light rays have been calculated. The simulation provides new results for curved fibres, where the analytical expressions are too complex to be solved. The light losses due to sharp bending of fibres are presented as a function of the ratio of curvature to fibre radius and bending angle. It is shown that a radius of curvature to fibre radius ratio of greater than 65 results in a loss of less than 10% with the loss occuring in the initial stage of the bend (at bending angles Phi circa pi/8 rad).
physics.optics:We have measured the photonic bandgap in the transmission of microwaves through a two-dimensional photonic crystal slab. The structure was constructed by cementing acrylic rods in a hexagonal closed-packed array to form rectangular stacks. We find a bandgap centered at approximately 11 GHz, whose depth, width and center frequency vary with the number of layers in the slab, angle of incidence and microwave polarization.
physics.optics:We study forward stimulated Raman emission from weakly fluorescent dye 4'-diethylamino-N-methyl-4-stilbazolium tosylate (DEST) in 1,2,dichloroethane solution excited by a 28 ps, 532 nm Nd: YAG laser. Neat 1, 2, dichloroethane emits the first Stokes line at 631 nm with a spectral width of 1.6 nm corresponding to a Raman shift of 2956 per cm. We observe reduction of spectral width with the addition of DEST in 1, 2, dichloroethane solution. The single pass conversion efficiency for forward Raman emission is as high as 20 percent in a 1 cm path length sample. The pulse duration of forward stimulated Raman emission measured by a third order autocorrelation technique is 10 ps in neat 1, 2, dichloroethane, whereas it is nearly 3 ps for 0.04 mM of DEST solution.
physics.optics:Distribution of centrosymmetrical molecules of an impurity (p-diclorobenzene) in monocrystals of solid solutions in two different matrixes with centrosymmetrical (p-dibrombenzene) and noncentrosymmetrical (p-bromchlorbenzene) molecules by the method of a Raman Effect is determined.
physics.optics:We demonstrate that twisting one part of a chiral photonic structure about its helical axis produces a single circularly polarized localized mode that gives rise to an anomalous crossover in propagation. Up to a crossover thickness, this defect results in a peak in transmission and exponential scaling of the linewidth for a circularly polarized wave with the same handedness as structure. Above the crossover, however, the linewidth saturates and the defect mode can be excited only by the oppositely polarized wave, resulting in a peak in reflection instead of transmission.
physics.optics:We study experimentally and theoretically the polarization alternation during the switch-on transient of a quasi-isotropic CO$_2$ laser emitting on the fundamental mode. The observed transient dynamics is well reproduced by means of a model which provides a quantitative discrimination between the intrinsic asymmetry due to the kinetic coupling of molecules with different angular momenta, and the extrinsic anisotropies, due to a tilted intracavity window. Furthermore, the experiment provides a numerical assignment for the decay rate of the coherence term for a CO$_2$ laser.
physics.optics:In this paper we present an analysis of information transfer time based on holomorphism, causality and the classical principle of stationary phase. We also make a preliminary study of the effect of noise on information transfer time, and find that noise tends to increase transfer times. Noise and information signals are both essentially acausal, such that analytic continuation (i.e. prediction) is impossible, which also implies that their frequency spectra cannot be holomorphic. This leads to the paradox of a non-holomorphic information-bearing light signal, yet whose underlying Maxwell equations governing the propagation of the EM wave describe a holomorphic function in spacetime. We find that application of stationary phase and entropy arguments circumvents this difficulty, with stationary phase only suggesting the most likely transfer times of an information signal in the presence of noise. Faster transit times are not excluded, but are highly improbable. Stationary phase solutions, by definition, do not include signal forerunners, whose detection in the presence of noise is also unreliable. Hence a finite information capacity ensues, as expected from Shannon's law, and information cannot be transferred faster than c. We also find that the method of stationary phase implies complex transfer times. However, by considering spacetime to be isomorphic with the complex temporal plane, we find that an imaginary time is equivalent to a real distance, and can be interpreted as the uncertainty in the spatial position of the information pulse. Finally, we apply our theory to a photonic band gap crystal, and find that information transfer speed and tunneling is always subluminal.
physics.optics:Enhancement of optical Kerr nonlinearity for self-action by electro-magnetically induced transparency in a four-level atomic system including dephasing between the ground states is studied in detail by solving the density matrix equations for the atomic levels. We discern three major contributions, from energy shifts of the ground states induced by the probe light, to the third-order susceptibility in the four-level system. In this four-level system with the frequency-degenerate probes, quantum interference amongst the three contributions can, not only enhance the third-order susceptibility more effectively than in the three-level system with the same characteristic parameters, but also make the ratio between its real and imaginary part controllable. Due to dephasing between the two ground states and constructive quantum interference, the most effective enhancement generally occurs at an offset that is determined by the atomic transition frequency difference and the coupling Rabi frequency.
physics.optics:We numerically study supercontinuum (SC) generation in photonic crystal fibers pumped with low-power 30-ps pulses close to the zero dispersion wavelength 647nm. We show how the efficiency is significantly improved by designing the dispersion to allow widely separated spectral lines generated by degenerate four-wave-mixing (FWM) directly from the pump to broaden and merge. By proper modification of the dispersion profile the generation of additional FWM Stokes and anti-Stokes lines results in efficient generation of an 800nm wide SC. Simulations show that the predicted efficient SC generation is more robust and can survive fiber imperfections modelled as random fluctuations of the dispersion coefficients along the fiber length.
physics.optics:We numerically study the possibilities for improved large-mode area endlessly single mode photonic crystal fibers for use in high-power delivery applications. By carefully choosing the optimal hole diameter we find that a triangular core formed by three missing neighboring air holes considerably improves the mode area and loss properties compared to the case with a core formed by one missing air hole. In a realized fiber we demonstrate an enhancement of the mode area by ~30 % without a corresponding increase in the attenuation.
physics.optics:A new type of perturbative expansion is built in order to give a rigorous derivation and to clarify the range of validity of some commonly used model equations.   This model describes the evolution of the modulation of two short and localized pulses, fundamental and second harmonic, propagating together in a bulk uniaxial crystal with non-vanishing second order susceptibility $\chi^(2)$ and interacting through the nonlinear effect known as ``cascading'' in nonlinear optics.   The perturbative method mixes a multi-scale expansion with a power series expansion of the susceptibility, and must be carefully adapted to the physical situation. It allows the determination of the physical conditions under which the model is valid: the order of magnitude of the walk-off, phase-mismatch,and anisotropy must have determined values.
physics.optics:Nonlinear phase noise, often called the Gordon-Mollenauer effect, can be compensated electronically by subtracting from the received phase a correction proportional to the received intensity. The optimal scaling factor is derived analytically and found to be approximately equal to half of the ratio of mean nonlinear phase noise and the mean received intensity. Using optimal compensation, the standard deviation of residual phase noise is halved, doubling the transmission distance in systems limited by nonlinear phase noise.
physics.optics:On the basis of the data given in the works of different authors a criterion of phase-photometric method of measurement of energy angle of divergence has been formulated. Validity of application of the obtained relations for a ray beam with an arbitrary diameter and an arbitrary shape of the wave front has been proved. Advantages of the proposed phase-photometric method in comparison with the focal-spot method have been confirmed. Necessity and possibility of building a standard solid angle has been proved.
physics.optics:This document contains my detailed calculation of the Generalised Few-cycle Envelope Approximation (GFEA) propagation equation reported and used in Phys. Rev. A (submitted) and its associated longer version at arXiv.org. This GFEA propagation equation is intended to be applicable to optical pulses only a few cycles long, a regime where the standard Slowly Varying Envelope Approximation (SVEA) fails.
physics.optics:We present a comprehensive framework for treating the nonlinear interaction of few-cycle pulses using an envelope description that goes beyond the traditional SVEA method. This is applied to a range of simulations that demonstrate how the effect of a $\chi^{(2)}$ nonlinearity differs between the many-cycle and few-cycle cases. Our approach, which includes diffraction, dispersion, multiple fields, and a wide range of nonlinearities, builds upon the work of Brabec and Krausz[1] and Porras[2]. No approximations are made until the final stage when a particular problem is considered.   The original version (v1) of this arXiv paper is close to the published Phys.Rev.A. version, and much smaller in size.
physics.optics:Broadband noise on supercontinuum spectra generated in microstructure fiber is shown to lead to amplitude fluctuations as large as 50 % for certain input laser pulse parameters. We study this noise using both experimental measurements and numerical simulations with a generalized stochastic nonlinear Schroedinger equation, finding good quantitative agreement over a range of input pulse energies and chirp values. This noise is shown to arise from nonlinear amplification of two quantum noise inputs: the input pulse shot noise and the spontaneous Raman scattering down the fiber.
physics.optics:The probability density function of Kerr effect phase noise, often called the Gordon-Mollenauer effect, is derived analytically. The Kerr effect phase noise can be accurately modeled as the summation of a Gaussian random variable and a noncentral chi-square random variable with two degrees of freedom. Using the received intensity to correct for the phase noise, the residual Kerr effect phase noise can be modeled as the summation of a Gaussian random variable and the difference of two noncentral chi-square random variables with two degrees of freedom. The residual phase noise can be approximated by Gaussian distribution better than the Kerr effect phase noise without correction.
physics.optics:Steady-state and dynamics of the self-phase-locked (3\omega ==> 2\omega, \omega) subharmonic optical parametric oscillator are analyzed in the pump-and-signal resonant configuration, using an approximate analytical model and a full propagation model. The upper branch solutions are found always stable, regardless of the degree of pump enhancement. The domain of existence of stationary states is found to critically depend on the phase-mismatch of the competing second-harmonic process.
physics.optics:In the present paper we investigate the transmission and reflection band behavior for a plane electromagnetic wave falling obliquely on an ideal layered structure. The dependence of this behavior on the problem parameters and wave incident angle is considered. It is shown, that in general case the band width is a non-monotonous function of the problem parameters. A condition is found, which defines the possibility of the contact of the transmission bands. This condition has the same form for s and p waves. It is also shown that irrespective of the wave polarization, the transmission coefficient equals to the unit at the contact points.
physics.optics:The problem of determination of the maximum of second harmonic generation in the potential well containing a rectangular barrier is considered. It is shown that, in general, the problem of finding the ensemble of structures with equidistant first three levels has two types of solutions.   For the first type the second and third energy levels are located above a rectangular barrier, and for the second type the third level is located above the barrier only. It is also shown, that generation corresponding to the second type of solution always is less than generation for the first one. Taking into account the effective mass changes the problem of finding the generation maximum for a finite depth well is exactly solved.
physics.optics:We investigate numerically optical properties of novel two-dimensional photonic materials where parallel dielectric rods are randomly placed with the restriction that the distance between rods is larger than a certain value. A large complete photonic gap (PG) is found when rods have sufficient density and dielectric contrast. Our result shows that neither long-range nor short-range order is an essential prerequisite to the formation of PGs. A universal principle is proposed for designing arbitrarily shaped waveguides, where waveguides are fenced with side walls of periodic rods and surrounded by the novel photonic materials. We observe highly efficient transmission of light for various waveguides. Due to structural uniformity, the novel photonic materials are best suited for filling up the outer region of waveguides of arbitrary shape and dimension comparable with the wavelength.
physics.optics:We suggest an effective method for controlling nonlinear switching in arrays of weakly coupled optical waveguides. We demonstrate the digitized switching of a narrow input beam for up to eleven waveguides in the engineered waveguide arrays.
physics.optics:Plane waves in Kerr media spontaneously generate paraxial X-waves (i.e. non-dispersive and non-diffractive pulsed beams) that get amplified along propagation. This effect can be considered a form of conical emission (i.e. spatio-temporal modulational instability), and can be used as a key for the interpretation of the out of axis energy emission in the splitting process of focused pulses in normally dispersive materials. A new class of spatio-temporal localized wave patterns is identified. X-waves instability, and nonlinear X-waves, are also expected in periodical Bose condensed gases.
physics.optics:The Dicke superradiance on vibronic transitions of impurity crystals is considered. It is shown that parameters of the superradiance (duration and intensity of the superradiance pulse and delay times) on each vibronic transition depend on the strength of coupling of electronic states with the intramolecular impurity vibration (responsible for the vibronic structure of the optical spectrum in the form of vibrational replicas of the pure electronic line) and on the crystal temperature through the Debye-Waller factor of the lattice vibrations. Theoretical estimates of the ratios of the time delays, as well as of the superradiance pulse intensities for different vibronic transitions well agree with the results of experimental observations of two-color superradiance in the polar dielectric KCl:O2-. In addition, the theory describes qualitatively correctly the critical temperature dependence of the superradiance effect.
physics.optics:This work is concerned with the propagation of electromagnetic waves in isotropic chiral media and with the effects produced by a plane boundary between two such media. In analogy with the phenomena of reflection and refraction of plane electromagnetic waves in ordinary dielectrics, the kinematical and dynamical aspects of these phenomena are studied, such as the intensity of the various wave components and the change in the polarization of the wave as it crosses the boundary. As a prerequisite of this, we show that the plane wave solution must be written as a suitable superposition of the circularly amplitudes on both sides of the interface, we elucidate which is the appropriate set of conditions that the solution must satisfy at the boundary, and we set down the minimal, and complete, set of equations that must be solved for the coefficient amplitudes in order to satisfy the boundary conditions. The equations are solved explicitly for some particular cases and configurations (e.g., normal incidence), the salient features of those solutions are analyzed in some detail, and the general solution to the equations is given as well.
physics.optics:We study the class of endlessly single-mode all-silica photonic crystal fibers with a triangular air-hole cladding. We consider the sensibility to longitudinal nonuniformities and the consequences and limitations for realizing low-loss large-mode area photonic crystal fibers. We also discuss the dominating scattering mechanism and experimentally we confirm that both macro and micro-bending can be the limiting factor.
physics.optics:Some aspects of lasing at vibronic transitions in impurity crystals are theoretically studied. The threshold conditions for a vibronic laser are shown to be dependent on the strength of interaction of optical centers with a local vibration, which forms the vibronic spectrum, and the crystal lattice temperature. The theory can be easily generalized to the spectrum containing a structureless phonon sideband and well agrees with the experimental temperature dependence of the output power of a Mg2SiO4:Cr4+ forsterite laser.
physics.optics:We investigate the characteristics of guided wave modes in planar coupled waveguides. In particular, we calculate the dispersion relations for TM modes in which one or both of the guiding layers consists of negative index media (NIM)-where the permittivity and permeability are both negative. We find that the Poynting vector within the NIM waveguide axis can change sign and magnitude, a feature that is reflected in the dispersion curves.
physics.optics:It has recently been shown that periodic layered media can reflect strongly for all incident angles and polarizations in a given frequency range. The standard treatment gets these band gaps from an eigenvalue equation for the Bloch factor in an infinite periodic structure. We argue that such a procedure may become meaningless when dealing with structures with not very many periods. We propose an alternative approach based on a factorization of the multilayer transfer matrix in terms of three fundamental matrices of simple interpretation. We show that the trace of the transfer matrix sorts the periodic structures into three types with properties closely related to one (and only one) of the three fundamental matrices. We present the reflectance associated to each one of these types, which can be considered as universal features of the reflection in these media.
physics.optics:We study effects of finite height and surrounding material on photonic crystal slabs of one- and two-dimensional photonic crystals with a pseudo-spectral method and finite difference time domain simulation methods. The band gap is shown to be strongly modified by the boundary material. As an application we suggest reflection and guiding of light by patterning the material on top/below the slab.
physics.optics:The characteristics of an imaging system formed by a slab of a lossy left-handed material (LHM) are studied. The transfer function of the LHM imaging system is written in an appropriate product form with each term having a clear physical interpretation. A tiny loss of the LHM may suppress the transmission of evanescent waves through the LHM slab and this is explained physically. An analytical expression for the resolution of the imaging system is derived. It is shown that it is impossible to make a subwavelength imaging by using a realistic LHM imaging system unless the LHM slab is much thinner than the wavelength.
physics.optics:We observe the formation of an intense optical wavepacket fully localized in all dimensions, i.e. both longitudinally (in time) and in the transverse plane, with an extension of a few tens of fsec and microns, respectively. Our measurements show that the self-trapped wave is a X-shaped light bullet spontaneously generated from a standard laser wavepacket via the nonlinear material response (i.e., second-harmonic generation), which extend the soliton concept to a new realm, where the main hump coexists with conical tails which reflect the symmetry of linear dispersion relationship.
physics.optics:The statistical properties of nonlinear phase noise, often called the Gordon-Mollenauer effect, is studied analytically when the number of fiber spans is very large. The joint characteristic functions of the nonlinear phase noise with electric field, received intensity, and the phase of amplifier noise are all derived analytically. Based on the joint characteristic function of nonlinear phase noise with the phase of amplifier noise, the error probability of signal having nonlinear phase noise is calculated using the Fourier series expansion of the probability density function. The error probability is increased due to the dependence between nonlinear phase noise and the phase of amplifier noise. When the received intensity is used to compensate the nonlinear phase noise, the optimal linear and nonlinear minimum mean-square error compensators are derived analytically using the joint characteristic function of nonlinear phase noise and received intensity. Using the joint probability density of received amplitude and phase, the optimal maximum a posteriori probability detector is derived analytically. The nonlinear compensator always performs better than linear compensator.
physics.optics:The exact Green function for the scalar wave equation in a plane with any set of perfectly reflecting straight mirrors, which may be joined to form corners, is given as a diffraction scattering series. Instances would be slit diffraction in optics, or the Schrodinger equation inside (or outside) a general polygonal enclosure ('quantum polygon billiards'). The method is based on the seminal 1896 Riemann helicoid surface solution by Sommerfeld for optical diffraction by a single corner. It is generalised to account for multiple scatter by adapting the analysis of Stovicek for a closely related problem: a collection of magnetic flux lines (points) in a plane, the multi-flux Aharonov-Bohm effect. The short wavelength limit is shown to yield the 'geometrical theory of diffraction'. For slit diffraction the exact series is shown to coincide with that of Schwarzschild in 1902.
physics.optics:We experimentally demonstrate for the first time that a linearly polarized beam is focussed to an asymmetric spot when using a high-numerical aperture focussing system. This asymmetry was predicted by Richards and Wolf [Proc.R.Soc.London A, 253, 358 (1959)] and can only be measured when a polarization insensitive sensor is placed in the focal region. We used a specially modified photodiode in a knife edge type set up to obtain highly resolved images of the total electric energy density distribution at the focus. The results are in good agreement with the predictions of a vectorial focussing theory.
physics.optics:A simple model is used to estimate the Q factor in numerical simulations of differential phase shift keying (DPSK) with optical delay demodulation and balanced detection. It is found that an alternative definition of Q is needed for DPSK in order to have a more accurate prediction of the bit error ratio (BER).
physics.optics:With using of point-dipole model the theoretical calculations of main refractive indices and orientation of indicatrix of 18 minerals are performed. The feature of studied minerals is the statistically disordered arrangement of CO3, SO4, SO2, PO4 groups and also separate ions. The optical characters of uniaxial minerals and orientation of indicatrix of orthorhombic and monoclinic minerals, obtained by results of calculations, agree with experimental definitions.
physics.optics:The features of a compact, single pass, multi-pixel optical parametric generator are discussed. Several hundreds of independent high spatial-quality tunable ultrashort pulses were produced by pumping a bulk lithium triborate crystal with an array of tightly focussed intense beams. The array of beams was produced by shining a microlenses array with a large pump beam. Overall conversion efficiency to signal and idler up to 30% of the pump beam has been reported. Shot-to-shot energy fluctuation down to 3% was achieved for the generated radiation.
physics.optics:We use a spatially resolved cavity ring-down technique to show that the 2D eigenmode of an unstable optical cavity has a fractal pattern, i.e. it looks the same at different length scales. In agreement with theory, we find that this pattern has the maximum conceivable roughness, i.e., its fractal dimension is 3.01 plus\minus 0.04. This insight in the nature of unstable cavity eigenmodes may lead to better understanding of wave dynamics in open systems, for both light and matter waves.
physics.optics:Numerical Calculations are employed to study the modulation of light by surface acoustic waves (SAWs) in photonic band gap (PBG) structures. The on/off contrast ratio in PBG switch based on optical cavity is determined as a function of the SAW induced dielectric modulation. We show that these structures exhibit high contrast ratios even for moderate acousto-optic coupling
physics.optics:By combining the definition of the Wigner distribution function (WDF) and the matrix method of optical system modeling, we can evaluate the transformation of the former in centered systems with great complexity. The effect of stops and lens diameter are also considered and are shown to be responsible for non-linear clipping of the resulting WDF in the case of coherent illumination and non-linear modulation of the WDF when the illumination is incoherent. As an example, the study of a single lens imaging systems illustrates the applicability of the method.
physics.optics:Free-space propagation can be described as a shearing of the Wigner distribution function in the spatial coordinate; this shearing is linear in paraxial approximation but assumes a more complex shape for wide-angle propagation. Integration in the frequency domain allows the determination of near-field diffraction, leading to the well known Fresnel diffraction when small angles are considered and allowing exact prediction of wide-angle diffraction. The authors use this technique to demonstrate evanescent wave formation and diffraction elimination for very small apertures.
astro-ph.GA:The magnetic fields of our Milky Way galaxy are the main agent for cosmic rays to transport. In the last decade, much new knowledge has been gained from measurements of the Galactic magnetic fields. In the Galactic disk, from the RMs of a large number of newly discovered pulsars, the large-scale magnetic fields along the spiral arms have been delineated in a much larger region than ever before, with alternating directions in the arm and interarm regions. The toroidal fields in the Galactic halo were revealed to have opposite directions below and above the Galactic plane, which is an indication of an A0 mode dynamo operating in the halo. The strength of large-scale fields obtained from pulsar RM data has been found to increase exponentially towards the Galactic center. Compared to the steep Kolmogorov spectrum of magnetic energy at small scales, the large-scale magnetic fields show a shallow broken spatial magnetic energy spectrum.
astro-ph.GA:We present a list of interstellar absorption lines in the direction of HD 37061 in the M 43 nebula. Some of the absorption lines arise from atomic excited levels that are uncommon in interstellar clouds. The excited levels of Fe II are populated by fluorescence. We found a large number of H2 molecular absorption lines arising from vibrationally excited levels. The ortho/para H2 ratio is equal to 2.7. The H2 rotational temperature of vibrational levels 1 - 5 exceeds 2000 K.
astro-ph.GA:We present a new multi-fluid, grid MHD code PIERNIK, which is based on the Relaxing TVD scheme (Jin & Xin, 1995). The original scheme (see Trac & Pen (2003) and Pen et al. (2003)) has been extended by an addition of dynamically independent, but interacting fluids: dust and a diffusive cosmic ray gas, described within the fluid approximation, with an option to add other fluids in an easy way. The code has been equipped with shearing-box boundary conditions, and a selfgravity module, Ohmic resistivity module, as well as other facilities which are useful in astrophysical fluid-dynamical simulations. The code is parallelized by means of the MPI library. In this paper we present an extension of PIERNIK, which is designed for simulations of diffusive propagation of the Cosmic-Ray (CR) component in the magnetized ISM.
astro-ph.GA:Aims. High angular resolution N-band imaging is used to discern the torus of active galactic nuclei (AGN) from its environment in order to allow a comparison of its mid-infrared properties to the expectations of the unified scenario for AGN. Methods. We present VLT-VISIR images of 25 low-redshift AGN of different Seyfert types, as well as N-band SEDs of 20 of them. In addition, we compare our results for 19 of them to Spitzer IRS spectra. Results. We find that at a resolution of ~ 0.35", all the nuclei of our observed sources are point-like, except for 2 objects whose extension is likely of instrumental origin. For 3 objects, however, we observed additional extended circumnuclear emission, even though our observational strategy was not designed to detect it. Comparison of the VISIR photometry and Spitzer spectrophotometry indicates that the latter is affected by extended emission in at least 7 out of 19 objects and the level of contamination is (0.20 ~ 0.85) * F_IRS. In particular, the 10 um silicate emission feature seen in the Spitzer spectra of 6 type I AGN, possibly 1 type II AGN and 2 LINERs, also probably originates not solely in the torus but also in extended regions. Conclusions. Our results generally agree with the expectations from the unified scenario, while the relative weakness of the silicate feature supports clumpy torus models. Our VISIR data indicate that, for low-redshift AGN, a large fraction of Spitzer IRS spectra are contaminated by extended emission close to the AGN.
astro-ph.GA:The dark cloud Lynds 1622 is one of a few specific sites in the Galaxy where, relative to observed free-free and vibrational dust emission, there is a clear excess of microwave emission. In order to constrain models for this microwave emission, and to better establish the contribution which it might make to ongoing and near-future microwave background polarization experiments, we have used the Green Bank Telescope to search for linear polarization at 9.65 Ghz towards Lynds 1622. We place a 95.4% upper limit of 88 micro-Kelvin (123 micro-Kelvin at 99.7 confidence) on the total linear polarization of this source averaged over a 1'.3 FWHM beam. Relative to the observed level of anomalous emission in Stokes I these limits correspond to fractional linear polarizations of 2.7% and 3.5%.
astro-ph.GA:Alignment of dust by radiative torques (RATs) has proven to be the most promising mechanism to explain alignment in various astrophysical environments, from comet atmospheres to accretion disks, molecular clouds, and diffuse interstellar gas. We discuss some of the major advances, which include, first of all, formulating of the analytical model of RATs. This model was shown to reproduce well the torques acting on actual irregular dust grains and allowed studies of the parameter space for which the alignment happens with long axes perpendicular and parallel to the magnetic field. Such a study resulted in an important conclusion that, without any paramagnetic relaxation, the RAT alignment always happens for interstellar grains with long axes perpendicular to the magnetic field. We show that the gaseous bombardment in some cases increases the degree of alignment by knocking out grains from the positions of imperfect alignment when the grains rotate slowly to more stable positions of perfect alignment where grains rotate fast. In terms of pinwheel torques, important revisions have been made in the Lazarian and Draine model of grain flipping and thermal trapping. Those, however, do not change the major conclusion that very small grains (i.e. grain size smaller than ~0.03 micron) should be marginally aligned. Recent work made the RAT alignment a predictive theory which is ready for quantitative modeling of astrophysical polarization. We predict that the microwave emission from the Zodiacal dust presents an important contaminant, which should be included into foreground polarization templates.
astro-ph.GA:Bulges are of different types, morphologies and kinematics, from pseudo-bulges, close to disk properties (Sersic index, rotation fraction, flatenning), to classical de Vaucouleurs bulges, close to elliptical galaxies. Secular evolution and bar development can give rise to pseudo-bulges. To ensure prolonged secular evolution, gas flows are required along the galaxy life-time. There is growing evidence for cold gas accretion around spiral galaxies. This can explain the bar cycle of destruction and reformation, together with pseudo-bulge formation. However, bulges can also be formed through major mergers, minor mergers, and massive clumps early in the galaxy evolution. Bulge formation is so efficient that it is difficult to explain the presence of bulgeless galaxies today.
astro-ph.GA:Outward radiation pressure can exceed the inward gravitational pull on gas clouds in the neighbourhood of a luminous Active Galactic Nucleus (AGN). This creates a forbidden region for long-lived dusty clouds in the observed columnn density - Eddington fraction plane. (The Eddington fraction lambda_Edd is the ratio of the bolometric luminosity of an AGN to the Eddington limit for its black hole mass.) The Swift/BAT catalogue is the most complete hard X-ray selected sample of AGN and has 97 low redshift AGN with measured column densities N_H and inferred black hole masses. Eddington fractions for the sources have been obtained using recent bolometric corrections and the sources have been plotted on the N_H - lambda_Edd plane. Only one source lies in the forbidden region and it has a large value of N_H due to an ionized warm absorber, for which radiation pressure is reduced. The effective Eddington limit for the source population indicates that the high column density clouds in the more luminous objects lie within the inner few pc, where the central black hole provides at least half the mass. Our result shows that radiation pressure does affect the presence of gas clouds in the inner galaxy bulge. We discuss briefly how the N_H - lambda_Edd plane may evolve to higher redshift, when feedback due to radiation pressure may have been strong.
astro-ph.GA:We numerically evolve turbulence driven by the magnetorotational instability (MRI) in a 3D, unstratified shearing box and study its structure using two-point correlation functions. We confirm Fromang and Papaloizou's result that shearing box models with zero net magnetic flux are not converged; the dimensionless shear stress $\alpha$ is proportional to the grid scale. We find that the two-point correlation of the magnetic field shows that it is composed of narrow filaments that are swept back by differential rotation into a trailing spiral. The correlation lengths along each of the correlation function principal axes decrease monotonically with the grid scale. For mean azimuthal field models, which we argue are more relevant to astrophysical disks than the zero net field models, we find that: $\alpha$ increases weakly with increasing resolution at fixed box size; $\alpha$ increases slightly as the box size is increased; $\alpha$ increases linearly with net field strength, confirming earlier results; the two-point correlation function of the magnetic field is resolved and converged, and is composed of narrow filaments swept back by the shear; the major axis of the two-point increases slightly as the box size is increased; these results are code independent, based on a comparison of ATHENA and ZEUS runs. The velocity, density, and magnetic fields decorrelate over scales larger than $\sim H$, as do the dynamical terms in the magnetic energy evolution equations. We conclude that MHD turbulence in disks is localized, subject to the limitations imposed by the absence of vertical stratification, the use of an isothermal equation of state, finite box size, finite run time, and finite resolution
astro-ph.GA:We present the first Chandra/ACIS imaging study of the circumnuclear region of the nearby Seyfert galaxy NGC 1365. The X-ray emission is resolved into point-like sources and complex, extended emission. The X-ray morphology of the extended emission shows a biconical soft X-ray emission region extending ~5 kpc in projection from the nucleus, coincident with the high excitation outflow cones seen in optical emission lines particularly to the northwest. Harder X-ray emission is detected from a kpc-diameter circumnuclear ring, coincident with the star-forming ring prominent in the Spitzer mid-infrared images; this X-ray emission is partially obscured by the central dust lane of NGC 1365. Spectral fitting of spatially separated components indicates a thermal plasma origin for the soft extended X-ray emission (kT=0.57 keV). Only a small amount of this emission can be due to photoionization by the nuclear source. Detailed comparison with [OIII]5007 observations shows the hot interstellar medium (ISM) is spatially anticorrelated with the [OIII] emitting clouds and has thermal pressures comparable to those of the [OIII] medium, suggesting that the hot ISM acts as a confining medium for the cooler photoionized clouds. The abundance ratios of the hot ISM are fully consistent with the theoretical values for enrichment from Type II supernovae, suggesting that the hot ISM is a wind from the starburst circumnuclear ring. X-ray emission from a ~450 pc long nuclear radio jet is also detected to the southeast.
astro-ph.GA:A gap in phase-space, the loss cone (LC), is opened up by a supermassive black hole (MBH) as it disrupts or accretes stars in a galactic centre. If a star enters the LC then, depending on its properties, its interaction with the MBH will either generate a luminous electromagnetic flare or give rise to gravitational radiation, both of which are expected to have directly observable consequences. A thorough understanding of loss-cone refilling mechanisms is important for the prediction of astrophysical quantities, such as rates of tidal disrupting main-sequence stars, rates of capturing compact stellar remnants and timescales of merging binary MBHs. In this thesis, we use N-body simulations to investigate how noise from accreted satellites and other substructures in a galaxy's halo can affect the LC refilling rate.   Any N-body model suffers from Poisson noise which is similar to, but much stronger than, the two-body diffusion occurring in real galaxies. To lessen this spurious Poisson noise, we apply the idea of importance sampling to develop a new scheme for constructing N-body realizations of a galaxy model, in which interesting regions of phase-space are sampled by many low-mass particles. We use multimass N-body models of galaxies with centrally-embedded MBHs to study the effects of satellite flybys on LC refilling rates. We find that although the flux of stars into the initially emptied LC is enhanced, but the fuelling rate averaged over the entire subhalos is increased by only a factor 3 over the rate one expects from the Poisson noise due the discreteness of the stellar distribution.
astro-ph.GA:The structure and potential of a complex gravitational lens is reconstructed using the perturbative method presented in Alard 2007, MNRAS, 382L, 58; Alard 2008, MNRAS, 388, 375. This lens is composed of 6 galaxies belonging to a small group. The lens inversion is reduced to the problem of reconstructing non-degenerate quantities: the 2 fields of the perturbative theory of strong gravitational lenses. Since in the perturbative theory the circular source solution is analytical, the general properties of the perturbative solution can be inferred directly from the data. As a consequence, the reconstruction of the perturbative fields is not affected by degeneracy, and finding the best solution is only a matter of numerical refinement. The local shape of the potential and density of the lens are inferred from the perturbative solution, revealing the existence of an independent dark component that does not follow light. The most likely explanation is that the particular shape of the dark halo is due to the merging of cold dark matter halos. This is a new result illustrating the structure of dark halos at the scale of galaxies.
astro-ph.GA:We present kinematic simulations of a galactic dynamo model based on the large scale differential rotation and the small scale helical fluctuations due to supernova explosions. We report for the first time direct numerical simulations of the full galactic dynamo using an unparameterized global approach. We argue that the scale of helicity injection is large enough to be directly resolved rather than parameterized. While the actual superbubble characteristics can only be approached, we show that numerical simulations yield magnetic structures which are close both to the observations and to the previous parameterized mean field models. In particular, the quadrupolar symmetry and the spiraling properties of the field are reproduced. Moreover, our simulations show that the presence of a vertical inflow plays an essential role to increase the magnetic growth rate. This observation could indicate an important role of the downward flow (possibly linked with galactic fountains) in sustaining galactic magnetic fields.
astro-ph.GA:Strong gravitational lensing is a unique tool to model with great accuracy the inner mass distribution of massive galaxy clusters. In particular, clusters with large Einstein radii provide a wealth of multiply imaged systems in the cluster core allowing to determine precisely the shape of the central dark matter profile. This paper presents a spectroscopic survey in the massive cluster Abell 1703, displaying a large Einstein radius (28" at z=2.8) and a high number of strongly-lensed systems including a central ring-like configuration. We used LRIS on Keck to target multiple images and lensed galaxy candidates, and use the measured redshifts to constrain the mass distribution of the cluster using a parametric model. The data enable us to measure accurate redshifts in good agreement with their photometric redshifts, and to update the identification of multiply imaged systems by discovering 3 new systems and a radial counter image. We also report the discovery of a remarkably bright ~3.6 L* i-band dropout at z=5.827 in our mask which is only moderately magnified by the cluster (~3.0+/-0.08). The improved parametric mass model, including 16 multiple systems with 10 spectroscopic redshifts, further constrains the cluster-scale mass distribution with a generalized NFW profile of best-fit logarithmic slope alpha=0.92+/-0.04, concentration c200=4.72+/-0.40 and scale radius rs=476+/-45 kpc. Our strong-lensing model predicts a large scale shear signal consistent with Subaru weak-lensing measurements out to 4 Mpc h^-1. Together with the fact that the strong-lensing modeling requires a single dark matter clump, this suggests that Abell 1703 is a relaxed, unimodal cluster. This unique cluster could be probed further using deep X-ray, SZ and dynamics analysis, for a detailed study of the physics in a relaxed cluster. (abridged)
astro-ph.GA:Newborn neutron stars surrounded by hyperaccreting and neutrino-cooled disks may exist in some gamma-ray bursts (GRBs) and/or supernovae (SNe). In this paper we further study the structure of such a neutron-star disk based on the two-region (i.e., inner & outer) disk scenario following our previous work, and calculate the neutrino annihilation luminosity from the disk in various cases. We investigate the effects of the viscosity parameter, energy parameter (measuring the neutrino cooling efficiency of the inner disk) and outflow strength on the structure of the entire disk as well as the effect of emission from the neutron star surface boundary emission on the total neutrino annihilation rate. The inner disk satisfies the entropy-conservation or the advection-dominated self-similar structure depending on the energy parameter. An outflow from the disk decreases the density and pressure but increases the thickness of the disk. Moreover, compared with the black-hole disk, the neutrino annihilation luminosity above the neutron-star disk is higher, and the neutrino emission from the boundary layer could increase the neutrino annihilation luminosity by about one order of magnitude higher than the disk without boundary emission. The neutron-star disk with the advection-dominated inner disk could produce the highest neutrino luminosity while the disk with an outflow has the lowest. Although a heavily mass-loaded outflow from the neutron star surface at early times of neutron star formation prevents the outflow material from being accelerated to a high bulk Lorentz factor, an energetic ultrarelativistic jet via neutrino annihilation can be produced above the stellar polar region at late times if the disk accretion rate and the neutrino emission luminosity from the surface boundary layer are sufficiently high.
astro-ph.GA:Gas can be used to trace the formation and evolution of galaxies as well as the impact that the nuclear activity has on the surrounding medium. For nearby compact radio sources, we have used observations of neutral hydrogen - that we detected in emission distributed over very large scales - combined with the study of the stellar population and deep optical images to investigate the history of the formation of their host galaxy and the triggering of the activity. For more distant and more powerful compact radio sources, we have used optical spectra and HI - in absorption - to investigate the presence of fast outflows that support the idea that compact radio sources are young radio loud AGN observed during the early stages of their evolution and currently shredding their natal cocoons through extreme circumnuclear outflows. We will review the most recent results obtained from these projects.
astro-ph.GA:In the paradigm of hierarchical galaxy formation, luminous radio galaxies mark mass assembly peaks that should contain clusters of galaxies. Observations of the z=1.53 quasar 3C270.1 with the Spitzer Space Telescope at 3.6-24 micron and with the 6.5-m MMT in the z'- and Y-bands allow detection of potential cluster members via photometric redshifts. Compared with nearby control fields, there is an excess of 11 extremely red objects (EROs) at 1.33 < z_phot < 1.73, consistent with a proto-cluster around the quasar. The spectral energy distributions (SEDs) of 3/4 of the EROs are better fitted with passive elliptical galaxies than withdust-reddened starbursts, and of four sources well-detected on an archival HST snapshot image, all have undisturbed morphologies. However, one ERO, not covered by the HST image, is a double source with 0.8" separation on the z' image and a marginal (2sigma) 24 micron detection indicating a dust-enshrouded starburst. The EROs are more luminous than L* (H = -23.6 AB mag at z=1.5).
astro-ph.GA:We present a newly observed relation between galaxy mass and radial metallicity gradients of early-type galaxies. Our sample of 51 early-type galaxies encompasses a comprehensive mass range from dwarf to brightest cluster galaxies. The metallicity gradients are measured out to one effective radius by comparing nearly all of the Lick absorption-line indices to recent models of single stellar populations. The relation shows very different behaviour at low and high masses, with a sharp transition being seen at a mass of ~ 3.5 x 10^10 M_sun (velocity dispersion of ~140 km/s, M_B ~ -19). Low-mass galaxies form a tight relation with mass, such that metallicity gradients become shallower with decreasing mass and positive at the very low-mass end. Above the mass transition point several massive galaxies have steeper gradients, but a clear downturn is visible marked by a broad scatter. The results are interpreted in comparison with competing model predictions. We find that an early star-forming collapse could have acted as the main mechanism for the formation of low-mass galaxies, with star formation efficiency increasing with galactic mass. The high-mass downturn could be a consequence of merging and the observed larger scatter a natural result of different merger properties. These results suggest that galaxies above the mass threshold of ~ 3.5 x 10^10 M_sun might have formed initially by mergers of gas-rich disc galaxies and then subsequently evolved via dry merger events. The varying efficiency of the dissipative merger-induced starburst and feedback processes have shaped the radial metallicity gradients in these high-mass systems.
astro-ph.GA:We present the results of Spitzer IRS infrared 5-35 micron low-resolution spectroscopic energy diagnostics of ultraluminous infrared galaxies (ULIRGs) at z > 0.15, classified optically as non-Seyferts. Based on the equivalent widths of polycyclic aromatic hydrocarbon emission and the optical depths of silicate dust absorption features, we searched for signatures of intrinsically luminous, but optically elusive, buried AGNs in these optically non-Seyfert ULIRGs. We then combined the results with those of non-Seyfert ULIRGs at z < 0.15 and non-Seyfert galaxies with infrared luminosities L(IR) < 10^12Lsun. We found that the energetic importance of buried AGNs clearly increases with galaxy infrared luminosity, becoming suddenly discernible in ULIRGs with L(IR) > 10{12}Lsun. For ULIRGs with buried AGN signatures, a significant fraction of infrared luminosities can be accounted for by detected buried AGN and modestly-obscured (Av < 20 mag) starburst activity. The implied masses of spheroidal stellar components in galaxies for which buried AGNs become important roughly correspond to the value separating red massive and blue, less-massive galaxies in the local universe. Our results may support the widely-proposed AGN-feedback scenario as the origin of galaxy downsizing phenomena, where galaxies with currently larger stellar masses previously had higher AGN energetic contributions and star-formation-originating infrared luminosities, and have finished their major star-formation more quickly, due to stronger AGN feedback.
astro-ph.GA:We use absolutely calibrated data from the ARCADE 2 flight in July 2006 to model Galactic emission at frequencies 3, 8, and 10 GHz. The spatial structure in the data is consistent with a superposition of free-free and synchrotron emission. Emission with spatial morphology traced by the Haslam 408 MHz survey has spectral index beta_synch = -2.5 +/- 0.1, with free-free emission contributing 0.10 +/- 0.01 of the total Galactic plane emission in the lowest ARCADE 2 band at 3.15 GHz. We estimate the total Galactic emission toward the polar caps using either a simple plane-parallel model with csc|b| dependence or a model of high-latitude radio emission traced by the COBE/FIRAS map of CII emission. Both methods are consistent with a single power-law over the frequency range 22 MHz to 10 GHz, with total Galactic emission towards the north polar cap T_Gal = 0.498 +/- 0.028 K and spectral index beta = -2.55 +/- 0.03 at reference frequency 1 GHz. The well calibrated ARCADE 2 maps provide a new test for spinning dust emission, based on the integrated intensity of emission from the Galactic plane instead of cross-correlations with the thermal dust spatial morphology. The Galactic plane intensity measured by ARCADE 2 is fainter than predicted by models without spinning dust, and is consistent with spinning dust contributing 0.4 +/- 0.1 of the Galactic plane emission at 22 GHz.
astro-ph.GA:We present imaging and spectroscopic observations for six quasars at z>5.9 discovered by the Canada-France High-z Quasar Survey (CFHQS). The CFHQS contains sub-surveys with a range of flux and area combinations to sample a wide range of quasar luminosities at z~6. The new quasars have luminosities 10 to 75 times lower than the most luminous SDSS quasars at this redshift. The least luminous quasar, CFHQS J0216-0455 at z=6.01, has absolute magnitude M_1450=-22.21, well below the likely break in the luminosity function. This quasar is not detected in a deep XMM-Newton survey showing that optical selection is still a very efficient tool for finding high redshift quasars.
astro-ph.GA:We report a search for H2O megamasers in 274 SDSS type-2 AGNs (0.3 < z < 0.83), half of which can be classified as type-2 QSOs from their [OIII] 5007 luminosity, using the Robert C. Byrd Green Bank Telescope (GBT) and the Effelsberg 100-m radio telescope. Apart from the detection of the extremely luminous water vapor megamaser SDSS J080430.99+360718.1, already reported by Barvainis & Antonucci (2005), we do not find any additional line emission. This high rate of non-detections is compared to the water maser luminosity function created from the 78 water maser galaxies known to date and its extrapolation towards the higher luminosities of "gigamasers" that we would have been able to detect given the sensitivity of our survey. The properties of the known water masers are summarized and discussed with respect to the nature of high-z type-2 AGNs and megamasers in general. In the appendix, we list 173 additional objects (mainly radio galaxies, but also QSOs and galaxies) that were observed with the GBT, the Effelsberg 100-m radio telescope, or Arecibo Observatory without leading to the detection of water maser emission.
astro-ph.GA:Above redshift 6, the dominant source of neutral hydrogen in the Universe shifts from localized clumps in and around galaxies and filaments to a pervasive, diffuse component of the intergalactic medium (IGM). This transition tracks the global neutral fraction of hydrogen in the IGM and can be studied, in principle, through the redshifted 21 cm hyperfine transition line. During the last half of the reionization epoch, the mean (global) brightness temperature of the redshifted 21 cm emission is proportional to the neutral fraction, but at earlier times (10 < z < 25), the mean brightness temperature should probe the spin temperature of neutral hydrogen in the IGM. Measuring the (of order 10 mK) mean brightness temperature of the redshifted 21 cm line as a function of frequency (and hence redshift) would chart the early evolution of galaxies through the heating and ionizing of the IGM by their stellar populations. Experiments are already underway to accomplish this task or, at least, provide basic constraints on the evolution of the mean brightness temperature. We provide a brief overview of one of these projects, the Experiment to the Detect the Global EOR Signature (EDGES), and discuss prospects for future results.
astro-ph.GA:We exploit the recent observations of extremely metal-poor (EMP) stars in the Galactic halo and investigate the constraints on the IMF of the stellar population that left these low-mass survivors of [Fe/H]<-2.5 and the chemical evolution that they took part in. A high-mass IMF with the typical mass~10Msun and the overwhelming contribution of low-mass members of binaries to the EMP survivors are derived from the statistics of carbon-enriched EMP stars with and without the enhancement of s-process elements (Komiya et al. 2007). We first examine the analysis to confirm their results for various assumptions on the mass-ratio distribution function. As compared with the uniform distribution, the increase or decrease function of the mass ratio gives a higher- or lower-mass IMF, and a lower-mass IMF results for the independent distribution with the both members in the same IMF, but the derived ranges of typical mass differ less than by a factor of two and overlap for the extreme cases. Furthermore, we prove that the same constraints are placed on the IMF from the surface density of EMP stars estimated from the surveys and the chemical evolution consistent with the metal yields of theoretical supernova models. We then apply the derived high-mass IMF with the binary contribution to show that the observed MDF of EMP stars can be reproduced not only for the shape but also for the number of EMP stars. In particular, the scarcity of stars below [Fe/H]<-4 is naturally explained in terms of the hierarchical structure formation, and there is no indication of significant changes in the IMF for the EMP Population. The present study indicates that 3 HMP stars of [Fe/H]<-4 are the primordial stars that were born as the low-mass members of binaries before the host clouds were polluted by their own supernovae.
astro-ph.GA:The origin of S0 galaxies is discussed in the framework of early mergers in a Cold Dark Matter cosmology, and in a scenario where S0s are assumed to be former spirals stripped of gas. From an analysis of 127 early-type disk galaxies (S0-Sa), we find a clear correlation between the scale parameters of the bulge (r_eff) and the disk (h_R), a correlation which is difficult to explain if these galaxies were formed in mergers of disk galaxies. However, the stripping hypothesis, including quiescent star formation, is not sufficient to explain the origin of S0s either, because it is not compatible with our finding that S0s have a significantly smaller fraction of bars (46$\pm$6 %) than their assumed progenitors, S0/a galaxies (93$\pm$5 %) or spirals (64-69 %). Our conclusion is that even if a large majority of S0s were descendants of spiral galaxies, bars and ovals must play an important role in their evolution. The smaller fraction particularly of strong bars in S0 galaxies is compensated by a larger fraction of ovals/lenses (97$\pm$2 % compared to 82-83 % in spirals), many of which might be weakened bars. We also found massive disk-like bulges in nine of the S0 galaxies, bulges which might have formed at an early gas-rich stage of galaxy evolution.
astro-ph.GA:Statistics of the weak lensing of galaxies can be used to constrain cosmology if the galaxy shear can be estimated accurately. In general this requires accurate modelling of unlensed galaxy shapes and the point spread function (PSF). I discuss suboptimal but potentially robust methods for estimating galaxy shear by stacking images such that the stacked image distribution is closely Gaussian by the central limit theorem. The shear can then be determined by radial fitting, requiring only an accurate model of the PSF rather than also needing to model each galaxy accurately. When noise is significant asymmetric errors in the centroid must be corrected, but the method may ultimately be able to give accurate un-biased results when there is a high galaxy density with constant shear. It provides a useful baseline for more optimal methods, and a test-case for estimating biases, though the method is not directly applicable to realistic data. I test stacking methods on the simple toy simulations with constant PSF and shear provided by the GREAT08 project, on which most other existing methods perform significantly more poorly, and briefly discuss generalizations to more realistic cases. In the appendix I discuss a simple analytic galaxy population model where stacking gives optimal errors in a perfect ideal case.
astro-ph.GA:The analysis of the broad iron line profile in the X-ray spectra of active galactic nuclei and black hole X-ray binaries allows us to constrain the spin parameter of the black hole. We compare the constraints on the spin value for two X-ray sources, MCG-6-30-15 and GX 339-4, with a broad iron line using present relativistic line models in XSPEC - LAOR and KYRLINE. The LAOR model has the spin value set to the extremal value a=0.9982, while the KYRLINE model enables direct fitting of the spin parameter. The spin value is constrained mainly by the lower boundary of the broad line, which depends on the inner boundary of the disc emission where the gravitational redshift is maximal. The position of the inner disc boundary is usually identified with the marginally stable orbit which is related to the spin value. In this way the LAOR model can be used to estimate the spin value. We investigate the consistency of the LAOR and KYRLINE models. We find that the spin values evaluated by both models agree within the general uncertainties when applied on the current data. However, the results are apparently distinguishable for higher quality data, such as those simulated for the International X-ray Observatory (IXO) mission. We find that the LAOR model tends to overestimate the spin value and furthermore, it has insufficient resolution which affects the correct determination of the high-energy edge of the broad line.
astro-ph.GA:We report the results of interferometric HCN(1-0) and HCO+(1-0) observations of four luminous infrared galaxies (LIRGs), NGC 2623, Mrk 266, Arp 193, and NGC 1377, as a final sample of our systematic survey using the Nobeyama Millimeter Array. Our survey contains the most systematic interferometric, spatially-resolved, simultaneous HCN(1-0) and HCO+(1-0) observations of LIRGs. Ground-based infrared spectra of these LIRGs are also presented to elucidate the nature of the energy sources at the nuclei. We derive the HCN(1-0)/HCO+(1-0) brightness-temperature ratios of these LIRGs and confirm the previously discovered trend that LIRG nuclei with luminous buried AGN signatures in infrared spectra tend to show high HCN(1-0)/HCO+(1-0) brightness-temperature ratios, as seen in AGNs, while starburst-classified LIRG nuclei in infrared spectra display small ratios, as observed in starburst-dominated galaxies. Our new results further support the argument that the HCN(1-0)/HCO+(1-0) brightness-temperature ratio can be used to observationally separate AGN-important and starburst-dominant galaxy nuclei.
astro-ph.GA:We present WHAM observations of Halpha, [N II], and [S II] in the Smith Cloud. A map of Halpha emission from the cloud shows ionized gas coincident with the brightest H I emission, but nearly-as-bright Halpha in some regions with faint H I. The ionized mass of the cloud is at least as large as the neutral mass, > 10^6 M_sun. Ionized gas in the core of the Smith Cloud has an electron temperature 6000 K < T < 16000 K. The observed ratio [N II] / Halpha = 0.39 \pm 0.09 shows that the cloud has a non-primordial nitrogen abundance, 0.1 - 1 times solar.
astro-ph.GA:We model the large kinematic data sets for the four Milky Way dwarf spheroidal (dSph) satellites: Carina, Fornax, Sculptor and Sextans, recently published by Walker et al. The member stars are selected using a reliable dynamical interloper removal scheme tested on simulated data. Our member selection is more restrictive than the one based on metallicity indicators as it removes not only contamination due to Milky Way stars but also the unbound stars from the tidal tails. We model the cleaned data sets by adjusting the solutions of the Jeans equations to the profiles of the projected velocity dispersion and kurtosis. The data are well reproduced by models where mass follows light and the best-fitting stellar orbits are isotropic to weakly tangential, as expected from the tidal stirring scenario. The Fornax dwarf, with more than 2400 member stars, is a dSph galaxy with the most accurately determined mass to date: its 1 sigma error following from the sampling errors of the velocity moments is below 5 percent. With mass-to-light ratio of 97 solar units, Sextans seems to be the most dark matter dominated of the four dSph galaxies.
astro-ph.GA:Abreg: By combining HST/UDF imagery with kinematics from VLT/GIRAFFE we derive a physical model of distant galaxy J033245.11-274724.0 in a way similar to what can be done in the nearby Universe. Here we study the properties of a distant compact LIRGs galaxy. Given the photometric and spectro photometric accuracies, we can decompose the galaxy in sub components and correct them for reddening. The galaxy is dominated by a dust enshrouded disk revealed by UDF imagery. The disk radius is half that of the Milky Way and the galaxy have a SFR=20Mo/yr. Morphology and kinematics show that gas and stars together spiral inwards rapidly to feed the disk and the central regions. A combined system of a bar and two non rotating spiral arms regulates the material accretion, induces large sigma, with sigma larger than 100 km/s and redistributes the angular momentum (AM). The detailed physical properties resemble to the expectations from modeling a merger of two equal mass, gaseous rich galaxies, 0.5 Gyr after the merger. In its later evolution, this galaxy could become a late type galaxy which falls on the T-F relation, with an AM mostly induced by the orbital AM of the merger.
astro-ph.GA:We analyse new deep g and i-band imaging with the CFHT of 16 QSOs in the redshift range 0.9 to 1.3. The principal points of interest are the symmetry and signs of tidal effects in the QSO hosts and nearby (`companion') galaxies. The sample measures are compared with similar measures on randomly selected field galaxy samples. Asymmetry measures are made for all objects to g ~22, and magnitudes of all galaxies 2 magnitudes fainter. The QSOs are found in denser environments than the field, and are somewhat offset from the centroid of their surrounding galaxies. The QSO hosts appear more disturbed than other galaxies. While the QSO companions and field galaxies have the same average asymmetry, the distribution of asymmetry values is different. QSO companions within 15 arcsec are fainter than average field galaxies. We discuss scenarios that are consistent with these and other measured quantities.
astro-ph.GA:We present an analysis of far-infrared dust emission from diffuse cirrus clouds. This study is based on serendipitous observations at 160 microns at high galactic latitude with the Multiband Imaging Photometer (MIPS) onboard the Spitzer Space Telescope by the Spitzer Infrared Nearby Galaxies Survey (SINGS). These observations are complemented with IRIS data at 100 and 60 microns and constitute one of the most sensitive and unbiased samples of far infrared observations at small scale of diffuse interstellar clouds. Outside regions dominated by the cosmic infrared background fluctuations, we observe a substantial scatter in the 160/100 colors from cirrus emission. We compared the 160/100 color variations to 60/100 colors in the same fields and find a trend of decreasing 60/100 with increasing 160/100. This trend can not be accounted for by current dust models by changing solely the interstellar radiation field. It requires a significant change of dust properties such as grain size distribution or emissivity or a mixing of clouds in different physical conditions along the line of sight. These variations are important as a potential confusing foreground for extragalactic studies.
astro-ph.GA:Several recent studies have shown that the star cluster initial mass function (CIMF) can be well approximated by a power law, with indications for a steepening or truncation at high masses. This contribution considers the evolution of such a mass function due to cluster disruption, with emphasis on the part of the mass function that is observable in the first ~Gyr. A Schechter type function is used for the CIMF, with a power law index of -2 at low masses and an exponential truncation at M*. Cluster disruption due to the tidal field of the host galaxy and encounters with giant molecular clouds flattens the low-mass end of the mass function, but there is always a part of the `evolved Schechter function' that can be approximated by a power law with index -2. The mass range for which this holds depends on age, t, and shifts to higher masses roughly as t^0.6. Mean cluster masses derived from luminosity limited samples increase with age very similarly due to the evolutionary fading of clusters. Empirical mass functions are, therefore, approximately power laws with index -2, or slightly steeper, at all ages. The results are illustrated by an application to the star cluster population of the interacting galaxy M51, which can be well described by a model with M*=(1.9+/-0.5)x10^5 M_sun and a short (mass-dependent) disruption time destroying M* clusters in roughly a Gyr.
astro-ph.GA:Polarization carries information about the magnetic fields in interstellar clouds. The observations of polarized dust emission are used to study the role of magnetic fields in the evolution of molecular clouds and the initial phases of star-formation. We study the grain alignment with realistic simulations, assuming the radiative torques to be the main mechanism that spins the grains up. The aim is to study the efficiency of the grain alignment as a function of cloud position and to study the observable consequences of these spatial variations. Our results are based on the analysis of model clouds derived from MHD simulations. The continuum radiative transfer problem is solved with Monte Carlo methods to estimate the 3D distribution of dust emission and the radiation field strength affecting the grain alignment. We also examine the effect of grain growth in cores. We are able to reproduce the results of Cho & Lazarian using their assumptions. However, the anisotropy factor even in the 1D case is lower than their assumption of $\gamma = 0.7$, and thus we get less efficient radiative torques. Compared with our previous paper, the polarization degree vs. intensity relation is steeper because of less efficient grain alignment within dense cores. Without grain growth, the magnetic field of the cores is poorly recovered above a few $A_{\rm V}$. If grain size is doubled in the cores, the polarization of dust emission can trace the magnetic field lines possibly up to $A_{\rm V} \sim 10$ magnitudes. However, many of the prestellar cores may be too young for grain coagulation to play a major role. The inclusion of direction dependent radiative torque efficiency weakens the alignment. Even with doubled grain size, we would not expect to probe the magnetic field past a few magnitudes in $A_{\rm V}$.
astro-ph.GA:The very young open cluster (OC) NGC 2244 in the Rosette Nebula was studied with field-star-decontaminated 2MASS photometry, which shows the main-sequence (MS) stars and an abundant pre-MS (PMS) population. Fundamental and structural parameters were derived with colour-magnitude diagrams (CMDs), stellar radial density profiles (RDPs) and mass functions (MFs). Most previous studies centred NGC 2244 close to the bright K0V star 12 Monocerotis, which is not a cluster member. Instead, the near-IR RDP indicates a pronounced core near the O5 star HD 46150. We derive an age within 1--6 Myr, an absorption $\aV=1.7\pm0.2$, a distance from the Sun $\ds=1.6\pm0.2$ kpc ($\approx1.5$ kpc outside the Solar circle), an MF slope $\chi=0.91\pm0.13$ and a total (MS+PMS) stellar mass of $\sim625 \ms$. Its RDP is characterised by the core and cluster radii $\rc\approx5.6\arcmin$ ($\approx2.6$ pc) and $\rl\approx10\arcmin$ ($\approx4.7$ pc), respectively. Departure from dynamical equilibrium is suggested by the abnormally large core radius and the marked central stellar excess. We also investigate the elusive neighbouring OC NGC 2239, which is low-mass ($m_{MS+PMS}\approx301 \ms$), young ($5\pm4$ Myr) rather absorbed ($\aV=3.4\pm0.2$), and located in the background of NGC 2244 at $\ds=3.9\pm0.4$ kpc. Its RDP follows a King-like function of $\rc\approx0.5\arcmin\approx0.5$ pc and $\rl\approx5.0\arcmin\approx5.6$ pc. The MF slope, $\chi=1.24\pm0.06$, is essentially Salpeter's IMF. NGC 2244 is probably doomed to dissolution in a few $10^7$ yr. Wide-field extractions and field-star decontamination increase the stellar statistics and enhance both CMDs and RDPs, which is essential for faint and bright star clusters.
astro-ph.GA:From our radio observations of the magnetic field strength and large-scale pattern of spiral galaxies of different Hubble types and star formation rates (SFR) we conclude that - though a high SFR in the disk increases the total magnetic field strength in the disk and the halo - the SFR does not change the global field configuration nor influence the global scale heights of the radio emission. The similar scale heights indicate that the total magnetic field regulates the galactic wind velocities. The galactic wind itself may be essential for an effective dynamo action.
astro-ph.GA:We follow numerically the nonlinear evolution of the Parker instability in the presence of phase transitions from a warm to a cold HI interstellar medium in two spatial dimensions. The nonlinear evolution of the system favors modes that allow the magnetic field lines to cross the galactic plane. Cold HI clouds form with typical masses ~= 10^5 M_sun, mean densities ~= 20 cm^-3, mean magnetic field strengths ~= 4.3 muG (rms field strengths ~= 6.4 muG), mass-to-flux ratios ~= 0.1 - 0.3 relative to critical, temperatures ~= 50 K, (two-dimensional) turbulent velocity dispersions ~= 1.6 km s^-1, and separations ~= 500 pc, in agreement with observations. The maximum density and magnetic field strength are ~= 10^3 cm^-3 and ~= 20 muG, respectively. Approximately 60% of all HI mass is in the warm neutral medium. The cold neutral medium is arranged into sheet-like structures both perpendicular and parallel to the galactic plane, but it is also found almost everywhere in the galactic plane, with the density being highest in valleys of the magnetic field lines. `Cloudlets' also form whose physical properties are in quantitative agreement with those observed for such objects by Heiles (1967). The nonlinear phase of the evolution takes ~< 30 Myr, so that, if the instability is triggered by a nonlinear perturbation such as a spiral density shock wave, interstellar clouds can form within a time suggested by observations.
astro-ph.GA:It has been shown recently that the dynamical V-band mass-to-light ratios of compact stellar systems with masses from 10^6 to 10^8 Solar masses are not consistent with the predictions from simple stellar population (SSP) models. Top-heavy stellar initial mass functions (IMFs) in these so-called ultra compact dwarf galaxies (UCDs) offer an attractive explanation for this finding, the stellar remnants and retained stellar envelopes providing the unseen mass. We therefore construct a model which quantifies by how much the IMFs of UCDs would have to deviate in the intermediate-mass and high-mass range from the canonical IMF in order to account for the enhanced M/L_V ratio of the UCDs. The deduced high-mass IMF in the UCDs depends on the age of the UCDs and the number of faint products of stellar evolution retained by them. Assuming that the IMF in the UCDs is a three-part power-law equal to the canonical IMF in the low-mass range and taking 20% as a plausible choice for the fraction of the remnants of high-mass stars retained by UCDs, the model suggests the exponent of the high-mass IMF to be approximately 1.6 if the UCDs are 13 Gyr old (i.e. almost as old as the Universe) or approximately 1.0 if the UCDs are 7 Gyr old, in contrast to 2.3 for the Salpeter-Massey IMF. If the IMF was as top-heavy as suggested here, the stability of the UCDs might have been threatened by heavy mass loss induced by the radiation and evolution of massive stars. The central densities of UCDs must have been in the range 10^6 to 10^7 Solar masses per cubic parsec when they formed with star formation rates of 10 to 100 Solar masses per year.
astro-ph.GA:H-alpha emission from neutral halo clouds probes the radiation and hydrodynamic conditions in the halo. Armed with such measurements, we can explore how radiation escapes from the Galactic plane and how infalling gas can survive a trip through the halo. The Wisconsin H-Alpha Mapper (WHAM) is one of the most sensitive instruments for detecting and mapping optical emission from the ISM. Here, we present recent results exploring the ionization of two infallling high-velocity complexes. First, we report on our progress mapping H-alpha emission covering the full extent of Complex A. Intensities are faint (<100 mR; EM <0.2 pc cm^-6 but correlate on the sky and in velocity with 21-cm emission. Second, we explore the ionized component of some Anti-Center Complex clouds studied by Peek et al. (2007) that show dynamic shaping from interaction with the Galactic halo.
astro-ph.GA:This article reviews observations and models of the diffuse ionized gas that permeates the disk and halo of our Galaxy and others. It was inspired by a series of invited talks presented during an afternoon scientific session of the 65th birthday celebration for Professor Carl Heiles held at Arecibo Observatory in August 2004. This review is in recognition of Carl's long standing interest in and advocacy for studies of the ionized as well as the neutral components of the interstellar medium.
astro-ph.GA:Three recent surveys of 21-cm line emission in the Galactic plane, combining single dish and interferometer observations to achieve resolution of 1 arcmin to 2 arcmin, 1 km/s, and good brightness sensitivity, have provided some 650 absorption spectra with corresponding emission spectra for study of the distribution of warm and cool phase H I in the interstellar medium. These emission-absorption spectrum pairs are used to study the temperature of the interstellar neutral hydrogen in the outer disk of the Milky Way, outside the solar circle, to a radius of 25 kpc.   The cool neutral medium is distributed in radius and height above the plane with very similar parameters to the warm neutral medium. In particular, the ratio of the emission to the absorption, which gives the mean spin temperature of the gas, stays nearly constant with radius to 25 kpc radius. This suggests that the mixture of cool and warm phases is a robust quantity, and that the changes in the interstellar environment do not force the H I into a regime where there is only one temperature allowed. The mixture of atomic gas phases in the outer disk is roughly 15% to 20% cool (40 K to 60 K), the rest warm, corresponding to mean spin temperature 250 to 400 K.   The Galactic warp appears clearly in the absorption data, and other features on the familiar longitude-velocity diagram have analogs in absorption with even higher contrast than for 21-cm emission. In the third and fourth Galactic quadrants the plane is quite flat, in absorption as in emission, in contrast to the strong warp in the first and second quadrants. The scale height of the cool gas is similar to that of the warm gas, and both increase with Galactic radius in the outer disk.
astro-ph.GA:We have examined the physical conditions in the narrow-line region (NLR) of the Seyfert 2 galaxy Markarian 3, using long-slit spectra obtained with the Hubble Space Telescope/Space Telescope Imaging Spectrograph and photoionization models. We find three components of photoionized gas in the NLR. Two of these components, characterized by emission lines such as [NeV] 3426 and [OIII] 5007, lie within the envelope of the bi-conical region described in our previous kinematic study. A component of lower ionization gas, in which lines such as [OII] 3727 arise, is found to lie outside the bi-cone. Each of these components is irradiated by a power-law continuum which is attenuated by intervening gas, presumably closer to the central source. The radiation incident upon the low ionization gas, external to the bi-cone, is much more heavily absorbed. These absorbers are similar to the intrinsic UV and X-ray absorbers detected in many Seyfert 1 galaxies, which suggests that the collimation of the ionizing radiation occurs in a circumnuclear wind, rather than a thick, molecular torus. We estimate the mass for the observed NLR emitting gas to be 2 million solar-masses. It is likely that Markarian 3 acquired this gas through an on-going interaction with the spiral galaxy UGC 3422.
astro-ph.GA:We present the results of the EROS2 search for the hidden galactic matter of the halo through the gravitational microlensing of stars in the Magellanic clouds. Microlensing was also searched for and found in the Milky-Way plane, where foreground faint stars are expected to lens background stars. A total of 67 million of stars were monitored over a period of about 7 years. Hundreds of microlensing candidates have been found in the galactic plane, but only one was found towards the subsample of bright --well measured-- Magellanic stars. This result implies that massive compact halo objects (machos) in the mass range $10^{-7}M_\odot<M<5M_{\odot}$ are ruled out as a major component of the Milky Way Halo.
astro-ph.GA:Near-infrared spectroscopic data for the five Seyfert galaxies with jet-gas interaction Mrk 348, Mrk 573, Mrk 1066, NGC 7212, and NGC 7465, taken with the LIRIS near-infrared camera/spectrometer at the William Herschel Telescope (WHT) are reported. The long-slit spectra reveal the characteristic strong emission lines of this type of objects. Many forbidden transitions and hydrogen recombination lines are employed here to study the excitation and ionization mechanisms that are dominating the narrow-line region emission of these objects, that is affected by the radio-jet interaction. Several absorption features are also detected in the H and K bands of these galaxies, allowing us to identify the spectral types that are producing them. We find that the continuum can be reproduced by a combination of late-type stellar templates plus a Blackbody component associated to host dust, mainly contributing to the K band emission. The detection of the permitted O I and Fe II lines and broad components of the hydrogen recombination lines in the spectra of Mrk 573 and NGC 7465 allows the reclassification of these two galaxies that are not canonical Type-2 Seyferts: Mrk 573 is confirmed to be an obscured Narrow-line Seyfert 1 and NGC 7465 is revealed for the first time as a Type-1 LINER through its near-infrared spectrum.
astro-ph.GA:Context: An unexpectedly complex polyatomic chemistry exists in diffuse clouds, allowing detection of species such as C2H, C3H2, H2CO and NH3 which have relative abundances that are strikingly similar to those inferred toward the dark cloud TMC-1   Aims: We probe the limits of complexity of diffuse cloud polyatomic chemistry.   Methods: We used the IRAM Plateau de Bure Interferometer to search for galactic absorption from low-lying J=2-1 rotational transitions of A- and E-CH3OH near 96.740 GHz and used the VLA to search for the J=8-7 transition of HC5N at 21.3 GHz.   Results: Neither CH3OH nor HC5N were detected at column densities well below those of all polyatomics known in diffuse clouds and somewhat below the levels expected from comparison with TMC-1. The HCN/HC5N ratio is at least 3-10 times higher in diffuse gas than toward TMC-1.   Conclusions: It is possible to go to the well once (or more) too often
astro-ph.GA:Recent observations of astrophysical jets emanating from various galactic nuclei strongly suggest that a double layered structure, or a spine-sheath structure, is likely to be their common feature. We propose that such a sheath jet structure can be formed magnetohydrodynamically within a valley of the magnetic pressures, which is formed between the peaks due to the poloidal and toroidal components, with the centrifugal force acting on the rotating sheath plasma is balanced by the hoop stress of the toroidal field. The poloidal field concentrated near the polar axis is maintained by a converging plasma flow toward the jet region, and the toroidal field is developed outside the jet cone owing to the poloidal current circulating through the jet. Under such situations, the set of magnetohydrodynamic (MHD) equations allows two main types of solutions, at least, in the region far from the footpoint. The first type solution describes the jets of marginally bound nature. This type is realized when the jet temperature decreases like viral one, and neither the pressure-gradient nor the MHD forces, which are both determined consistently, cannot completely overcome the gravity even at infinity. The second type is realized under an isothermal situation, and the gravity is cancelled exactly by the pressure-gradient force. Hence, the jets of this type are accelerated purely by the MHD force. It is suggested also that these two types correspond, respectively, to the jets from type I and II radio galaxies in the Fanaroff-Riley classification.
astro-ph.GA:We describe a new sample of 226 GPS (GHz-Peaked Spectrum) source candidates selected using simultaneous 1-22 GHz multi-frequency observations with the RATAN-600 radio telescope. Sixty objects in our sample are identified as GPS source candidates for the first time. The candidates were selected on the basis of their broad-band radio spectra only. We discuss the spectral and variability properties of selected objects of different optical classes.
astro-ph.GA:We describe Monte Carlo models for the dynamical evolution of the nearby globular cluster NGC 6397. The code includes treatments of two-body relaxation, most kinds of three- and four-body interactions involving primordial binaries and those formed dynamically, the Galactic tide, and the internal evolution of both single and binary stars. We arrive at a set of initial parameters for the cluster which, after 12Gyr of evolution, gives a model with a fairly satisfactory match to the surface brightness profile, the velocity dispersion profile, and the luminosity function in two fields. We describe in particular those aspects of the evolution which distinguish this cluster from M4, which has a roughly similar mass and Galactocentric distance, but a qualitatively different surface brightness profile. Within the limitations of our modelling, we conclude that the most plausible explanation for the difference is fluctuations: both clusters are post-collapse objects, but sometimes have resolvable cores and sometimes not.
astro-ph.GA:The importance of the radiative feedback from SMBHs at the centers of elliptical galaxies is not in doubt, given the well established relations among electromagnetic output, black hole mass and galaxy optical luminosity. In addition, feedback due to mechanical and thermal deposition of energy from jets and winds emitted by the accretion disk around the central SMBH is also expected to occur. In this paper we improve and extend the accretion and feedback physics explored in our previous papers to include also a physically motivated mechanical feedback. We study the evolution of an isolated elliptical galaxy with the aid of a high-resolution 1-D hydrodynamical code, where the cooling and heating functions include photoionization and Compton effects, and restricting to models which include only radiative or only mechanical feedback. We confirm that for Eddington ratios above 0.01 both the accretion and radiative output are forced by feedback effects to be in burst mode, so that strong intermittencies are expected at early times, while at low redshift the explored models are characterized by smooth, very sub-Eddington mass accretion rates punctuated by rare outbursts. However, the explored models always fail some observational tests. If we assume the high mechanical efficiency of 10^{-2.3}, we find that most of the gas is ejected from the galaxy, the resulting X-ray luminosity is far less than is typically observed and little SMBH growth occurs. But models with low enough mechanical efficiency to accomodate satisfactory SMBH growth tend to allow too strong cooling flows and leave galaxies at z=0 with E+A spectra more frequently than is observed. We conclude that both types of feedback are required. Models with combined feedback are explored in a forthcoming paper [abridged]
astro-ph.GA:The colour-magnitude diagrams of resolved stellar populations are the best tool to study the star formation histories of the host galactic regions. In this review the method to derive star formation histories by means of synthetic colour-magnitude diagrams is briefly outlined, and the results of its application to resolved galaxies of various morphological types are summarized. It is shown that all the galaxies studied so far were already forming stars at the lookback time reached by the observational data, independently of morphological type and metallicity. Early-type galaxies have formed stars predominantly, but in several cases not exclusively, at the earliest epochs. All the other galaxies appear to have experienced rather continuous star formation activities throughout their lifetimes, although with significant rate variations and, sometimes, short quiescent phases.
astro-ph.GA:We present an analysis of late-O/early-B-powered, parsec-sized bubbles and associated star-formation using 2MASS, GLIMPSE, MIPSGAL and MAGPIS surveys. Three bubbles were selected from the Churchwell et al. (2007) catalog. We confirm that the structure identified in Watson et al. (2008) holds in less energetic bubbles, i.e. a PDR, identified by 8 um emission due to PAHs surrounds hot dust, identified by 24 um emission and ionized gas, identified by 20 cm continuum. We estimate the dynamical age of two bubbles by comparing bubble sizes to numerical models of Hosokawa & Inutsuka (2006). We also identify and analyze candidate young stellar objects (YSOs) using SED fitting and identify sites of possible triggered star-formation. Lastly, we identify likely ionizing sources for two sources based on SED fitting.
astro-ph.GA:Methods: 12CO emission is imaged in position and position-velocity space analyzed statistically, and then compared with maps of total reddening and with models of the C+ - CO transition in H2-bearing diffuse clouds. Results: Around Zeta Oph, 12CO emission appears in two distinct intervals of reddening centered near EBV = 0.4 and 0.65 mag, of which < 0.2 mag is background material. Within either interval, the integrated 12CO intensity varies up to 6-12 K-km/s compared to 1.5 K-km/s toward Zeta Oph. Nearly 80% of the individual profiles have velocity dispersions < 0.6 km/s, which are subsonic at the kinetic temperature derived from H2 toward Zeta Oph, 55 K. Partly as a result, 12CO emission exposes the internal, turbulent, supersonic (1-3 km/s) gas flows with especial clarity in the cores of strong lines. The flows are manifested as resolved velocity gradients in narrow, subsonically-broadened line cores. Conclusions: The scatter between N(CO) and EBV in global, CO absorption line surveys toward bright stars is present in the gas seen around Zeta Oph, reflecting the extreme sensitivity of N(12CO) to ambient conditions. The two-component nature of the optical absorption toward Zeta Oph is coincidental and the star is occulted by a single body of gas with a complex internal structure, not by two distinct clouds. The very bright 12CO lines in diffuse gas arise at N(H2) ~ 10^21/cm^2 in regions of modest density n(H) ~ 200-500/cc and somewhat more complete C+-CO conversion. Given the variety of structure in the foreground gas, it is apparent that only large surveys of absorption sightlines can hope to capture the intrinsic behavior of diffuse gas.
astro-ph.GA:Aims: We show the existence of a small family of inner-galaxy dust lanes and dust lane standing shocks beyond the two major ones that were previously known to exist Methods: We analyze images of CO emission in the inner regions of the Galaxy Results: The peculiar kinematics of the major dust lane features are repeated in several other distinct instances at l > 0deg, in one case at a contrary location 100 pc above the galactic equator at l > 3degr at the upper extremity of Clump 2. Like the previously-known dust lanes, these new examples are alsoassociated with localized, exceptionally broad line profiles believed to be characteristic of the shredding of neutral gas at the standing dust lane shocks. Conclusions: There may be secondary dust lane and standing shocks in the Milky Way bulge. The vertical structure provides a temporal sequence for understanding the secular evolution of gas flow in the bar.
astro-ph.GA:Context: Over the past thirty years a wealth of observations of CO and other molecules in optical/uv absorption in diffuse clouds has accumulated for which no comparable CO emission line data exist. Aims: To acquire mm-wave J=1-0 CO emission line profiles toward a substantial sample of commonly-studied optical/uv absorption line targets and to compare with the properties of the absorbing gas, especially the predicted emission line strengths. Methods: Using the ARO 12m telescope we observed mm-wavelength J=1-0 CO emission with spectral resolution R ~ 3x10^6 and spatial resolution 1' toward a sample of 110 lines of sight previously studied in optical/uv absorption lines of CO, \HH, CH, etc. Results: Interstellar CO emission was detected along 65 of the 110 lines of sight surveyed and there is a general superabundance of CO emission given the distribution of galactic latitudes in the survey sample. Much of the emission is optically thick or very intense and must emanate from dark clouds or warm dense gas near HII regions. Conclusions: Judging from the statistical superabundance of CO emission, seen also in the total line of sight reddening, the OB star optical/uv absorption line targets must be physically associated with the large quantities of neutral gas whose CO emission was detected, in which case they are probably influencing the absorbing gas by heating and/or photoionizing it. This explains why CO/H2 and 12CO/13CO ratios differ somewhat between $uv$ and mm-wave absorption line studies. Because the lines of sight have been preselected to have AV < 1 mag, relatively little of the associated material actually occults the targets, making it difficult for CO emission line observations to isolate the foreground gas contribution.
astro-ph.GA:We have obtained deep multi-object optical spectra of 49 HII regions in the outer disk of the spiral galaxy M83 (=NGC 5236) with the FORS2 spectrograph at the Very Large Telescope. The targets span the range in galactocentric distance between 0.64 and 2.64 times the R25 isophotal radius (5.4-22.3 kpc), and 31 of them are located at R>R25, thus belonging to the extreme outer disk of the galaxy, populated by UV complexes revealed recently by the GALEX satellite. In order to derive the nebular chemical abundances, we apply several diagnostics of the oxygen abundance, including R23, [NII]/[OII] and the [OIII]4363 auroral line, which was detected in four HII regions. We find that, while inwards of the optical edge the O/H ratio follows the radial gradient known from previous investigations, the outer abundance trend flattens out to an approximately constant value. The latter varies, according to the adopted diagnostic, between 12+log(O/H)=8.2 and 12+log(O/H)=8.6 (i.e. from approximately 1/3 the solar oxygen abundance to nearly the solar value). An abrupt discontinuity in the radial oxygen abundance trend is also detected near the optical edge of the disk. These results are tentatively linked to the flat gas surface density in the outskirts of the galaxy, the relatively unevolved state of the extended disk of M83, and the redistribution of chemically enriched gas following a past galaxy encounter.
astro-ph.GA:Methods: The microscopic equations of H2-formation and protonation are integrated numerically over time in such a manner that the overall structures evolve self-consistently under benign conditions. Results: The equilibrium H2 formation timescale in an H I cloud with N(H) ~ 4x10^{20}/cm^2 is 1-3 x 10^7 yr, nearly independent of the assumed density or H2 formation rate constant on grains, etc. Attempts to speed up the evolution of the H2-fraction would require densities well beyond the range usually considered typical of diffuse gas. The calculations suggest that, under benign, quiescent conditions, formation of H2 is favored in larger regions having moderate density, consistent with the rather high mean kinetic temperatures measured in H2, 70-80 K. Formation of H3+ is essentially complete when H2-formation equilibrates but the final abundance of H3+ appears more nearly at the very last instant. Chemistry in a weakly-molecular gas has particular properties so that the abundance patterns change appreciably as gas becomes more fully molecular, either in model sequences or with time in a single model. One manifestation of this is that the predicted abundance of H3+ is much more weakly dependent on the cosmic-ray ionization rate when n(H2)/n(H) < 0.05. In general, high abundances of H3+ do not enhance the abundances of other species (e.g. HCO+) but late-time OH formation proceeds most vigourously in more diffuse regions having modest density, extinction and H2 fraction and somewhat higher fractional ionization, suggesting that atypically high OH/H2 abundance ratios might be found optically in diffuse clouds having modest extinction.
astro-ph.GA:The Parkes Galactic All-Sky Survey (GASS) is a survey of Galactic atomic hydrogen (HI) emission in the Southern sky covering declinations $\delta \leq 1^{\circ}$ using the Parkes Radio Telescope. The survey covers $2\pi$ steradians with an effective angular resolution of ~16', at a velocity resolution of 1.0 km/s, and with an rms brightness temperature noise of 57 mK. GASS is the most sensitive, highest angular resolution survey of Galactic HI emission ever made in the Southern sky. In this paper we outline the survey goals, describe the observations and data analysis, and present the first-stage data release. The data product is a single cube at full resolution, not corrected for stray radiation. Spectra from the survey and other data products are publicly available online.
astro-ph.GA:The magnetic structure in the Galactic disk, the Galactic center and the Galactic halo can be delineated more clearly than ever before. In the Galactic disk, the magnetic structure has been revealed by starlight polarization within 2 or 3 kpc of the Solar vicinity, by the distribution of the Zeeman splitting of OH masers in two or three nearby spiral arms, and by pulsar dispersion measures and rotation measures in nearly half of the disk. The polarized thermal dust emission of clouds at infrared, mm and submm wavelengths and the diffuse synchrotron emission are also related to the large-scale magnetic field in the disk. The rotation measures of extragalactic radio sources at low Galactic latitudes can be modeled by electron distributions and large-scale magnetic fields. The statistical properties of the magnetized interstellar medium at various scales have been studied using rotation measure data and polarization data. In the Galactic center, the non-thermal filaments indicate poloidal fields. There is no consensus on the field strength, maybe mG, maybe tens of uG. The polarized dust emission and much enhanced rotation measures of background radio sources are probably related to toroidal fields. In the Galactic halo, the antisymmetric RM sky reveals large-scale toroidal fields with reversed directions above and below the Galactic plane. Magnetic fields from all parts of our Galaxy are connected to form a global field structure. More observations are needed to explore the untouched regions and delineate how fields in different parts are connected.
astro-ph.GA:The source J 1128+5925 was found recently to show strong intraday variability at radio wavelengths and its radio variability may come from interstellar scintillation. In optical, the object was quiet in our 2007 monitoring session. Here we report the results of our new optical monitoring of this source in 2008. In addition to confirm our 2007 results, that the object did not display any clear variation on timescales from hour--day to month, we provide evidence that the object does not vary on timescale of one year, and it is probably intrinsically quiet in optical domain. Its very different behaviors in optical and radio regimes can be naturally explained if its strong radio variability comes from interstellar scintillation.
astro-ph.GA:The high redshift GPS quasar PKS 0858-279 exhibits the following properties which make the source unusual. Our RATAN-600 monitoring of 1-22 GHz spectrum has detected broad-band radio variability with high amplitude and relatively short time scale. In the same time, the milliarcsecond scale structure observed in a snapshot VLBA survey turned out to be very resolved which is not expected from the fast flux density variations. We performed 1.4-22 GHz VLBA observations of this quasar in 2005-2007. It has revealed a core-jet morphology. A high Doppler factor delta is suggested for the jet, its nature is discussed in this report on the basis of the multi-frequency VLBA and RATAN data collected. Synchrotron self-absorption was confirmed to be dominating at low frequencies, the magnetic field strength of the dominating jet feature is estimated of an order of 0.1*delta mG.
astro-ph.GA:We present photometric evolution models of galaxies, in which, in addition to the stellar component, the effects of an evolving dusty interstellar medium have been included with particular care. Starting from the work of Calura, Pipino & Matteucci (2008), in which chemical evolution models have been used to study the evolution of both the gas and dust components of the interstellar medium in the solar neighbourhood, elliptical and irregular galaxies, it has been possible to combine these models with a spectrophotometric stellar code that includes dust reprocessing (GRASIL) (Silva et al. 1998) to analyse the evolution of the spectral energy distributions (SED) of these galaxies. We test our models against observed SEDs both in the local universe and at high redshift and use them to predict how the percentage of reprocessed starlight evolves for each type of galaxy. The importance of following the dust evolution is investigated by comparing our results with those obtained by adopting simple assumptions to treat this component.
astro-ph.GA:Infrared photometry and later infrared spectroscopy provided powerful diagnostics to distinguish between the main emission mechanisms in galaxies: AGN and Starburst. After the pioneering work on infrared photometry with IRAS in the far-IR and the S.Pedro Martir and ESO ground-based work in the near-IR, ISO photometry extended up to 200um the coverage of the galaxies energy distributions. Then Spitzer collected accurate mid-infrared spectroscopy on different samples of galaxies. We will review the work done on the 12um galaxy sample since the times of IRAS photometry to the new Spitzer spectroscopy. The main results on the multifrequency data of 12um selected Seyfert galaxies are presented and discussed in the light of unification and evolution models. The spectroscopic work of Spitzer will soon be complemented at longer wavelengths by the Herschel spectrometers and in the future by SPICA at higher redshift.
astro-ph.GA:We investigate the sample of 213 GPS sources selected from simultaneous multi-frequency 1-22 GHz observations obtained with RATAN-600 radio telescope. We use publicly available data to characterize parsec-scale structure of the selected sources. Among them we found 121 core dominated sources, 76 Compact Symmetric Object (CSO) candidates (24 of them are highly probable), 16 sources have complex parsec-scale morphology. Most of GPS galaxies are characterized by CSO-type morphology and lower observed peak frequency (~1.8 GHz). Most of GPS quasars are characterized by "core-jet"-type morphology and higher observed peak frequency (~3.6 GHz). This is in good agreement with previous results. However, we found a number of sources for which the general relation CSO - galaxy, core-jet - quasar does not hold. These sources deserve detailed investigation. Assuming simple synchrotron model of a homogeneous cloud we estimate characteristic magnetic field in parsec-scale components of GPS sources to be B ~ 10 mG.
astro-ph.GA:Accretion disks in AGN should be subject to the same type of instability as in cataclysmic variables (CVs) or in low-mass X-ray binaries (LMXBs), which leads to dwarf nova and soft X-ray transient outbursts. It has been suggested that this thermal/viscous instability can account for the long term variability of AGNs. We test this assertion by presenting a systematic study of the application of the disk instability model (DIM) to AGNs. We are using the adaptative grid numerical code we have developed in the context of CVs, enabling us to fully resolve the radial structure of the disk. We show that, because in AGN disks the Mach numbers are very large, the heating and cooling fronts are so narrow that they cannot be resolved by the numerical codes that have been used until now. In addition, these fronts propagate on time scales much shorter than the viscous time. As a result, a sequence of heating and cooling fronts propagate back and forth in the disk, leading only to small variations of the accretion rate onto the black hole, with short quiescent states occurring for very low mass transfer rates only. Truncation of the inner part of the disk by e.g. an ADAF does not alter this result, but enables longer quiescent states. Finally we discuss the effects of irradiation by the central X-ray source, and show that, even for extremely high irradiation efficiencies, outbursts are not a natural outcome of the model.
astro-ph.GA:We outline a method for fitting binary-lens caustic-crossing microlensing events based on the alternative model parameterisation proposed and detailed in Cassan (2008). As an illustration of our methodology, we present an analysis of OGLE-2007-BLG-472, a double-peaked Galactic microlensing event with a source crossing the whole caustic structure in less than three days. In order to identify all possible models we conduct an extensive search of the parameter space, followed by a refinement of the parameters with a Markov Chain-Monte Carlo algorithm. We find a number of low-chi2 regions in the parameter space, which lead to several distinct competitive best models. We examine the parameters for each of them, and estimate their physical properties. We find that our fitting strategy locates several minima that are difficult to find with other modelling strategies and is therefore a more appropriate method to fit this type of events.
astro-ph.GA:We present new interferometric data obtained with MIDI (MID infrared Interferometric instrument) for the Seyfert II galaxy NGC 1068, with an extensive coverage of sixteen uv points. These observations resolve the nuclear mid-infrared emission from NGC 1068 in unprecedented detail with a maximum resolution of 7 mas. For the first time, sufficient uv points have been obtained, allowing us to generate an image of the source using maximum entropy image reconstruction. The features of the image are similar to those obtained by modelling. We find that the mid-infrared emission can be represented by two components, each with a Gaussian brightness distribution. The first, identified as the inner funnel of the obscuring torus, is hot (800K), 1.35 parsec long, and 0.45 parsec thick in FWHM at a PA=-42 degrees (from north to east). It has an absorption profile different than standard interstellar dust and with evidence for clumpiness. The second component is 3 by 4 pc in FWHM with T=300K, and we identify it with the cooler body of the torus. The compact component is tilted by 45 degrees with respect to the radio jet and has similar size and orientation to the observed water maser distribution. We show how the dust distribution relates to other observables within a few parsecs of the core of the galaxy such as the nuclear masers, the radio jet, and the ionization cone. We compare our findings to a similar study of the Circinus galaxy and other relevant studies. Our findings shed new light on the relation between the different parsec-scale components in NGC 1068 and the obscuring torus.
astro-ph.GA:Blue hook (BHk) stars are a rare class of horizontal branch stars that so far have been found in only very few Galactic globular clusters (GCs). The dominant mechanism for producing these objects is currently still unclear. In order to test if the presence of BHk populations in a given GC is linked to specific physical or structural cluster properties, we have constructed a parent sample of GCs for which existing data is sufficient to establish the presence or absence of BHk populations with confidence. We then compare the properties of those clusters in our parent sample that do contain a BHk population to those that do not. We find that there is only one compelling difference between BHk and non-BHk clusters: all known BHk clusters are unusually massive. However, we also find that the BHk clusters are consistent with being uniformly distributed within the cumulative mass distribution of the parent sample. Thus, while it is attractive to suggest there is is a lower mass cut-off for clusters capable of forming BHk stars, the data do not require this. Instead, the apparent preference for massive clusters could still be a purely statistical effect: intrinsically rare objects can only be found by searching a sufficiently large number of stars.
astro-ph.GA:The goal of this paper is to provide a numerically fast and stable description for the microlensing amplification of an extended source (either uniform or limb-darkened) that holds in any amplification regime. We show that our method of evaluating the amplification can be implemented into a light-curve fitting routine using the Levenberg-Marquardt algorithm. We compare the accuracy and computation times to previous methods that either work in the high-amplification regime only, or require special treatments due to the singularity of elliptic integrals.   In addition, we also provide the equations including finite lens effects in microlensing light curves. We apply our methods to the MACHO-1995-BLG-30 and the OGLE-2003-BLG-262 events and obtain results consistent to former studies. We derive an upper limit for the OGLE-2003-BLG-262 event lens size.   We conclude that our method allows to simultaneously search for point-source and finite-source microlensing events in future large area microlensing surveys in a fast manner.
astro-ph.GA:The EROS-2 project has been designed to search for microlensing events towards any dense stellar field. The densest parts of the Galactic spiral arms have been monitored to maximize the microlensing signal expected from the stars of the Galactic disk and bulge. 12.9 million stars have been monitored during 7 seasons towards 4 directions in the Galactic plane, away from the Galactic center. A total of 27 microlensing event candidates have been found. Estimates of the optical depths from the 22 best events are provided. A first order interpretation shows that simple Galactic models with a standard disk and an elongated bulge are in agreement with our observations. We find that the average microlensing optical depth towards the complete EROS-cataloged stars of the spiral arms is $\bar{\tau} =0.51\pm .13\times 10^{-6}$, a number that is stable when the selection criteria are moderately varied. As the EROS catalog is almost complete up to $I_C=18.5$, the optical depth estimated for the sub-sample of bright target stars with $I_C<18.5$ ($\bar{\tau}=0.39\pm >.11\times 10^{-6}$) is easier to interpret. The set of microlensing events that we have observed is consistent with a simple Galactic model. A more precise interpretation would require either a better knowledge of the distance distribution of the target stars, or a simulation based on a Galactic model. For this purpose, we define and discuss the concept of optical depth for a given catalog or for a limiting magnitude.
astro-ph.GA:The HII complex N44 in the Large Magellanic Cloud (LMC) provides an excellent site to perform a detailed study of star formation in a mild starburst, as it hosts three regions of star formation at different evolutionary stages and it is not as complicated and confusing as the 30 Doradus giant HII region. We have obtained Spitzer Space Telescope observations and complementary ground-based 4m uBVIJK observations of N44 to identify candidate massive young stellar objects (YSOs). We further classify the YSOs into Types I, II, and III, according to their spectral energy distributions (SEDs). In our sample of 60 YSO candidates, ~65% of them are resolved into multiple components or extended sources in high-resolution ground-based images. We have modeled the SEDs of 36 YSOs that appear single or dominant within a group. We find good fits for Types I and I/II YSOs,but Types II and II/III YSOs show deviations between their observed SEDs and models that do not include PAH emission. We have also found that some Type III YSOs have central holes in their disk components. YSO counterparts are found in four ultracompact HII regions and their stellar masses determined from SED model fits agree well with those estimated from the ionization requirements of the HII regions. The distribution of YSOs is compared with those of the underlying stellar population and interstellar gas conditions to illustrate a correlation between the current formation of O-type stars and previous formation of massive stars. Evidence of triggered star formation is also presented.
astro-ph.GA:This is the initial paper in a series presenting the first optical detections and subsequent follow-up spectroscopy of known Southern Galactic supernova remnants (SNRs) previously discovered in the radio. These new detections come from the AAO/UKST HAlpha survey of the Southern Galactic plane which has opened up fresh opportunities to study Galactic remnants. Here we present the first optical imaging and follow-up spectra of Galactic SNR G279.0+1.1 where a series of 14 small-scale fragmented groups of HAlpha filaments have been discovered in a ~2.3 deg. area centred on G279.0+1.1. Individually they are somewhat inconspicuous but collectively they are completely enclosed within the overall radio contours of this known SNR. Three of these filamentary groupings are particularly prominent and optical spectra have been obtained across two of them. Their morphological structure and spectral characteristics are typical of optically detected SNR filaments. Very strong [S II] emission relative to H has been detected with [S II]/HAlpha 0.7 and 1.1, confirming strong, shock heated emission. This is sufficient to classify these filaments in the likely SNR domain and therefore indicating a direct connection with the radio remnant. Other typical SNR emission lines such as [O II] at 3727A, HBeta, [O III] at 4959 and 5007A, HAlpha and [N II] at 6548 and 6584A were also detected, lending strong support to an SNR origin of these optical filaments. The value and insights that these optical data can provide for known remnants are discussed along with their relevance to the Galactic nitrogen abundance. A serendipitous discovery of an adjacent H II region is also briefly described.
astro-ph.GA:We demonstrate for the first time that gaseous halos of disk galaxies can play a vital role in recycling metal-rich gas ejected from the bulges and thus in promoting chemical evolution of disks. Our numerical simulations show that metal-rich stellar winds from bulges in disk galaxies can be accreted onto the thin disks owing to hydrodynamical interaction between the gaseous ejecta and the gaseous halos, if the mean densities of the halos (rho_ hg) are as high as 10^{-5} cm^{-3}. The total amount of gas that is ejected from a bulge through a stellar wind and then accreted onto the disk depends mainly on rho_ hg and the initial velocity of the stellar wind. About ~ 1% of gaseous ejecta from bulges in disk galaxies of scale length a_d can be accreted onto disks around R ~ 2.5 a_ d for a reasonable set of model parameters. We discuss these results in the context of the origin of the surprisingly high metallicities of the solar neighborhood disk stars in the Galaxy. We also discuss some implications of the present results in terms of chemical evolution of disk galaxies with possibly different rho_ hg in different galaxy environments.
astro-ph.GA:Using high-resolution data of the linearly polarized intensity and polarization angle at 3.6, 6.2, and 20 cm together with a 3-D model of the regular magnetic field, we study variations of the structure, strength, and energy density of the magnetic field in the Scd galaxy M33. The regular magnetic field consists of a horizontal component (represented by an axisymmetric mode from 1 to 3 kpc radius and a superposition of axisymmetric and bisymmetric modes from 3 to 5 kpc radius) and a vertical component. However, the inferred `vertical field' may be partly due to a galactic warp. We estimate the average total and regular magnetic field strengths as ~ 6.4 and 2.5 $\mu$G, respectively. Generation of interstellar magnetic fields by turbulent gas motion in M33 is indicated as the turbulent and magnetic energy densities are about equal.
astro-ph.GA:Black hole mass determination in active galaxies is a key issue in understanding various luminosity states. In the present paper we try to generalise the mass determination method based on the X-ray excess variance, successfully used for typical broad line Seyfert 1 galaxies (BLS1) to Narrow Line Seyfert 1 (NLS1) galaxies. NLS1 galaxies differ from BLS1 with respect to several properties. They are generally more variable in 2-10 keV energy band so the natural expectation is the need to use a different scaling coefficient between the mass and the variance in these two types of sources. However, we find that such a simple approach is not enough. Although for majority of the 21 NLS1 galaxies in our sample a single scaling coefficient (larger by a factor 20) provided us with a satisfactory method of mass determination, in a small subset of NLS1 galaxies this approach failed. Variability of those objects appeared to be at the intermediate level between NLS1 and BLS1 galaxies. These exceptional NLS1 galaxies have much harder soft X-ray spectra than majority of NLS1 galaxies. We thus postulate that the division of Seyfert 1 galaxies into BLS1 and NLS1 according to the widths of the Hbeta line is less generic than according to the soft X-ray slope.
astro-ph.GA:The Galactic Center lobe is a degree-tall shell seen in radio continuum images of the Galactic center (GC) region. If it is actually located in the GC region, formation models would require massive energy input (e.g., starburst or jet) to create it. At present, observations have not strongly constrained the location or physical conditions of the GC lobe. This paper describes the analysis of new and archival single-dish observations of radio recombination lines toward this enigmatic object. The observations find that the ionized gas has a morphology similar to the radio continuum emission, suggesting that they are associated. We study averages of several transitions from H106alpha to H191epsilon and find that the line ratios are most consistent with gas in local thermodynamic equilibrium. The radio recombination line widths are remarkably narrow, constraining the typical electron temperature to be less than about 4000 K. These observations also find evidence of pressure broadening in the higher electronic states, implying a gas density of n_e=910^{+310}_{-450} cm^{-3}. The electron temperature, gas pressure, and morphology are all consistent with the idea that the GC lobe is located in the GC region. If so, the ionized gas appears to form a shell surrounding the central 100 parsecs of the galaxy with a mass of roughly 10^5 Msun, similar to ionized outflows seen in dwarf starbursts.
astro-ph.GA:In February 1997, the Japanese radio astronomy satellite HALCA was launched to provide the space-bourne element for the VLBI Space Observatory Programme (VSOP) mission. A significant fraction of the mission time was to be dedicated to the VSOP Survey of bright compact Active Galactic Nuclei (AGN) at 5 GHz, which was lead by ISAS. The VSOP Survey Sources are an unbiased dataset of 294 targets, of which 82% were successfully observed. These are now undergoing statistical analysis to tease out the characteristics of typical AGN sources. We present here the summary of the imaging and conclusions we have reached.
astro-ph.GA:We test the reliability of infrared (IR) emission to trace star formation in individual star-forming sites of M33, and outline a new method for testing the distribution function of massive stars in newly formed clusters. We select IR sources from the Spitzer survey of M33 and show that the IR and Halpha luminosities are not correlated. Complementing the infrared photometry with GALEX-UV data, we estimate the source bolometric luminosities. For a given stellar IMF we simulate a theoretical curve for the expected bolometric-to-Halpha luminosity ratio, along which stellar clusters are born. We call this the cluster birthline in the Lbol--Lbol/LHal plane. The birthline is flat for Lbol>3x10^{39}erg/s because all clusters fully sample the IMF and it increases toward lower luminosities as the upper end of the IMF becomes incompletely sampled. The observations of M33 show that young isolated clusters lie close to the theoretical birthline for a wide range of Lbol. The luminosity is not proportional to Halpha emission for low mass clusters and aging moves clusters above the birthline. The best fit to the birthline is for a randomly sampled IMF, in which the mass of most massive star in a cluster is not strictly limited by the cluster's mass. We also find that the IR luminosity of young stellar clusters in M33 is not proportional to their bolometric luminosity. This irregularity could be the result of low and patchy dust abundance in M33.
astro-ph.GA:We present results of three-dimensional, fully nonlinear MHD simulations of a large-scale magnetic field evolution in a barred galaxy. The model does not take into consideration the dynamo process. We find that the obtained magnetic field configurations are highly similar to the observed maps of the polarized intensity of barred galaxies, because the modeled vectors form coherent structures along the bar and spiral arms. Due to the dynamical influence of the bar the gas forms spiral waves which go radially outward. Each spiral arm forms the magnetic arm which stays much longer in the disk, than the gaseous spiral structure. Additionally the modeled total energy of magnetic field grows due to strong compression and shear of non-axisymmetrical bar flows and differential rotation, respectively.
astro-ph.GA:The interstellar medium (ISM) is a key ingredient in galaxy formation and evolution as it provides the molecular gas reservoir which fuels star formation and supermassive black hole accretion. Yet the ISM is one of the least studied aspects of distant galaxies. Molecular and atomic transitions at (sub)millimetre wavelengths hold great promise in measuring macroscopic properties (e.g. masses, morphologies, star formation laws), as well as microscopic properties (e.g. gas densities, temperatures, cooling) of high-z galaxies. In this overview I summarize the growing number of high-z molecular line detections, highlighting some of the most intriguing results along the way. I end by discussing a few areas where future facilities (e.g. ALMA, EVLA, CCAT, LMT) will drastically improve on the current state of affairs.
astro-ph.GA:In this second of a series of papers on spatially resolved star formation, we investigate the impact of the density-morphology relation of galaxies on the spatial variation of star formation (SF) and its dependence on environment. We find that while a density-morphology relation is present for the sample, it cannot solely explain the observed suppression of SF in galaxies in high-density environments. We also find that early-type and late-type galaxies exhibit distinct radial star formation rate (SFR) distributions, with early-types having a SFR distribution that extends further relative to the galaxy scale length, compared to late-types at all densities. We find that a suppression of SF in the highest density environments is found in the highest star forming galaxies for both galaxy types. This suppression occurs in the innermost regions in late-types (r <= 0.125 Petrosian radii), and further out in radius in early-types (0.125< r <= 0.25 Petrosian radii). When the full sample is considered no clear suppression of SF is detected, indicating that the environmental trends are driven only by the highest SF galaxies. We demonstrate that the density-morphology relation alone cannot account for the suppression of SF in the highest density environments. This points to an environmentally-governed evolutionary mechanism that affects the SF in the innermost regions in both early and late-type galaxies. We suggest that this is a natural consequence of the "downsizing" of SF in galaxies.
astro-ph.GA:To date the onset of large-scale star formation in galaxies and its link to gravitational stability of the galactic disk have not been fully understood. The nearby face-on spiral galaxy M51 is an ideal target for studying this subject. This paper combines CO, dust, HI, and stellar maps of M51 and its companion galaxy to study the H2/HI transition, the gas-to-dust ratios, and the stability of the disk against gravitational collapse. We combine maps of the molecular gas using 12CO 2--1 map HERA/IRAM-30m data and HI VLA data to study the total gas surface density and the phase transition of atomic to molecular gas. The total gas surface density is compared to the dust surface density from 850 micron SCUBA data. Taking into account the velocity dispersions of the molecular and atomic gas, and the stellar surface densities derived from the 2MASS K-band survey, we derive the total Toomre Q parameter of the disk. The gas surface density in the spiral arms is approximately 2-3 higher compared to that of the interarm regions. The ratio of molecular to atomic surface density shows a nearly power-law dependence on the hydrostatic pressure P_hydro. The gas surface density distribution in M51 shows an underlying exponential distribution with a scale length of h_gas=7.6 kpc representing 55% of the total gas mass, comparable to the properties of the exponential dust disk. In contrast to the velocity widths observed in HI, the CO velocity dispersion shows enhanced line widths in the spiral arms compared to the interarm regions. The contribution of the stellar component in the Toomre Q-parameter analysis is significant and lowers the combined Q-parameter Q_tot by up to 70% towards the threshold for gravitational instability. The value of Q_tot varies from 1.5-3 in radial averages. A map of Q_tot shows values around 1 on the spiral arms.
astro-ph.GA:We present high resolution images of the 12CO(2-1) emission in the central 1' (1 kpc) of NGC 5128 (Centaurus A), observed using the SMA. We elucidate for the first time the distribution and kinematics of the molecular gas in this region with a resolution of 6'.0 x 2'.4 (100 pc x 40 pc). We spatially resolve the circumnuclear molecular gas in the inner 24'' x 12'' (400 pc x 200 pc), which is elongated along a position angle P.A. = 155 deg and perpendicular to the radio/X-ray jet. The SE and NW components of the circumnuclear gas are connected to molecular gas found at larger radii. This gas appears as two parallel filaments at P.A. = 120 deg, which are coextensive with the long sides of the 3 kiloparsec parallelogram shape of the previously observed dust continuum, as well as ionized and pure rotational H2 lines. Spatial and kinematical asymmetries are apparent in both the circumnuclear and outer gas, suggesting non-coplanar and/or non-circular motions. We extend to inner radii (r < 200 pc) previously studied warped disk models built to reproduce the central parallelogram-shaped structure. Adopting the warped disk model we would confirm a gap in emission between the radii r = 200 - 800 pc (12'' - 50''), as has been suggested previously. Although this model explains this prominent feature, however, our 12CO(2-1) observations show relevant deviations from this model. Namely, the physical connection between the circumnuclear gas and that at larger radii, brighter SE and NW sides on the parallelogram-shaped feature, and an outer curvature of its long sides. Overall it resembles more closely an S-shaped morphology, a trend that is also found in other molecular species. Hence, we explore qualitatively the possible contribution of a weak bi-symmetric potential which would naturally explain these peculiarities.
astro-ph.GA:The spatial distributions of the most recently discovered ultra faint dwarf satellites around the Milky Way and the Andromeda galaxy are compared to the previously reported discs-of-satellites (DoS) of their host galaxies. In our investigation we pay special attention to the selection bias introduced due to the limited sky coverage of SDSS. We find that the new Milky Way satellite galaxies follow closely the DoS defined by the more luminous dwarfs, thereby further emphasizing the statistical significance of this feature in the Galactic halo. We also notice a deficit of satellite galaxies with Galactocentric distances larger than 100 kpc that are away from the disc-of-satellites of the Milky Way. In the case of Andromeda, we obtain similar results, naturally complementing our previous finding and strengthening the notion that the discs-of-satellites are optical manifestations of a phase-space correlation of satellite galaxies.
astro-ph.GA:Observations of the Galactic Centre show evidence of disc-like structures of very young stars orbiting the central super-massive black hole within a distance of a few 0.1 pc. While it is widely accepted that about half of the stars form a relatively flat disc rotating clockwise on the sky, there is a substantial ongoing debate on whether there is a second, counter-clockwise disc of stars.   By means of N-body simulations using our bhint code, we show that two highly inclined stellar discs with the observed properties cannot be recognised as two flat circular discs after 5 Myr of mutual interaction. Instead, our calculations predict a significant warping of the two discs, which we show to be apparent among the structures observed in the Galactic Centre. While the high eccentricities of the observed counter-clockwise orbits suggest an eccentric origin of this system, we show the eccentricity distribution in the inner part of the more massive clockwise disc to be perfectly consistent with an initially circular disc in which stellar eccentricities increase due to both non-resonant and resonant relaxation.   We conclude that the relevant question to ask is therefore not whether there are two discs of young stars, but whether there were two such discs to begin with.
astro-ph.GA:The growth of supermassive black holes and their host galaxies are thought to be linked, but the precise nature of this symbiotic relationship is still poorly understood. Both observations and simulations of galaxy formation suggest that the energy input from active galactic nuclei (AGN), as the central supermassive black hole accretes material and grows, heats the interstellar material and suppresses star formation. In this Letter, we show that most host galaxies of moderate-luminosity supermassive black holes in the local universe have intermediate optical colors that imply the host galaxies are transitioning from star formation to quiescence, the first time this has been shown to be true for all AGN independent of obscuration. The intermediate colors suggest that star formation in the host galaxies ceased roughly 100 Myr ago. This result indicates that either the AGN are very long-lived, accreting for more than 1 Gyr beyond the end of star formation, or there is a ~100 Myr time delay between the shutdown of star formation and detectable black hole growth. The first explanation is unlikely given current estimates for AGN lifetimes, so low-lumiosity AGN must shut down star formation before substantial black hole accretion activity is detected. The scarcity of AGN host galaxies in the blue cloud reported here challenges scenarios where significant star formation and black hole growth are coeval. Lastly, these observations also strongly support the `Unified Model' of AGN as the host galaxy colors are independent of obscuration towards the central engine.
astro-ph.GA:We investigated the kinematic and excitation structure of the NGC 1068 narrow-line region (NLR). We obtained profiles of several emission lines, [OIII]$\lambda$5007, H$\beta$, [OI]$\lambda$6300 and [FeVII]$\lambda$6087 at high-velocity resolution (R ~ 7500 - 11000), and confirmed that they showed different profiles. These profiles are useful for understanding the NLR structure, as they cover a wide ionization potential range. By comparing the results with a photoionization model, we found that 1) blueshifted components at the center are very dense, 2) those in the northeast region have slightly lower densities than those in the center, and 3) ionization parameters of the blueshifted components increase with increasing velocity with respect to the systemic velocity. We investigated the NLR structure in NGC 1068 based on these results. We show that both the observed velocity dependence of the ionization parameter and the gradually increasing velocity field can be reproduced by varying the ionizing continuum attenuation, assuming a hollowed biconical geometry and varying the column densities of outflowing clouds.
astro-ph.GA:Microlensing observations towards M31 are a powerful tool for the study of the dark matter population in the form of MACHOs both in the Galaxy and the M31 halos, a still unresolved issue, as well as for the analysis of the characteristics of the M31 luminous populations. In this work we present the second year results of our pixel lensing campaign carried out towards M31 using the 152 cm Cassini telescope in Loiano. We have established an automatic pipeline for the detection and the characterisation of microlensing variations. We have carried out a complete simulation of the experiment and evaluated the expected signal, including an analysis of the efficiency of our pipeline. As a result, we select 1-2 candidate microlensing events (according to different selection criteria). This output is in agreement with the expected rate of M31 self-lensing events. However, the statistics are still too low to draw definitive conclusions on MACHO lensing.
astro-ph.GA:In this paper we present extinction properties of interstellar dust in a prominent dust lane galaxy NGC 4370 based on the optical broad band (BVRI) imaging observations taken from the Himalaya Chandra Telescope (HCT), Hanle and the near-IR (J,H,K$_s$) images taken from the 2MASS archive. NGC 4370 belongs to the Virgo cluster (VCC 0758) and form a non-interactive pair with NGC 4365 at 10$\arcmin$. NGC 4370 hosts a prominent dust lane running parallel to its optical major axis and is extended almost up to 1\arcmin. The extinction curve derived for NGC 4370 is found to run parallel to Galactic extinction curve, implying that the properties of dust in NGC 4370 are identical to those of the canonical grains in the Milky Way. The $R_V$ value is found to be equal to 2.85$\pm$0.05 and is consitent with the values reported for the dust lane galaxies. The total dust content of NGC 4370 estimated using optical extinction and IRAS flux densities are found to be equal to $4.4\times 10^4$ \msol and $2.0\times 10^5$ \msol, respectively. As regard to the origin of dust and ISM in this galaxy, the accumulated dust by this galaxy over its life-time is insufficient to account for the detected mass by optical means, which in turn imply that the ISM might have been acquired by the NGC 4370 through a merger like event. An attempt is also made to study the apparent spatial correspondence between the multiple phases of ISM, i.e., hot gas, warm gas and dust in this galaxy by obtaining optical emission maps from narrow band imaging and diffuse X-ray emission map obtained from the analysis of \emph{Chandra} archival data. This analysis implies a physical connection between the dust and warm gas in terms of their physical co-existence and common origin too.
astro-ph.GA:We present a homogeneous and 92 % complete dataset of optical nuclear spectra for the 113 3CR radio sources with redshifts < 0.3, obtained with the Telescopio Nazionale Galileo. For these sources we could obtain uniform and uninterrupted coverage of the key spectroscopic optical diagnostics. The observed sample, including powerful classical FR II radio-galaxies and FR I, together spanning four orders of magnitude in radio-luminosity, provides a broad representation of the spectroscopic properties of radio galaxies. In this first paper we present an atlas of the spectra obtained, provide measurements of the diagnostic emission line ratios, and identify active nuclei with broad line emission. These data will be used in follow-up papers to address the connection between the optical spectral characteristics and the multiwavelength properties of the sample.
astro-ph.GA:We present the first results of the expected variations of the molecular line emission arising from material recently affected by C-shocks (shock precursors). Our parametric model of the structure of C-shocks has been coupled with a radiative transfer code to calculate the molecular excitation and line profiles of shock tracers such as SiO, and of ion and neutral molecules such as H13CO+ and HN13C, as the shock propagates through the unperturbed medium. Our results show that the SiO emission arising from the early stage of the magnetic precursor typically has very narrow line profiles slightly shifted in velocity with respect to the ambient cloud. This narrow emission is generated in the region where the bulk of the ion fluid has already slipped to larger velocities in the precursor as observed toward the young L1448-mm outflow. This strongly suggests that the detection of narrow SiO emission and of an ion enhancement in young shocks, is produced by the magnetic precursor of C-shocks. In addition, our model shows that the different velocity components observed toward this outflow can be explained by the coexistence of different shocks at different evolutionary stages, within the same beam of the single-dish observations.
astro-ph.GA:We review the use of velocity centroids statistics to recover information of interstellar turbulence from observations. Velocity centroids have been used for a long time now to retrieve information about the scaling properties of the turbulent velocity field in the interstellar medium. We show that, while they are useful to study subsonic turbulence, they do not trace the statistics of velocity in supersonic turbulence, because they are highly influenced by fluctuations of density. We show also that for sub-Alfv\'enic turbulence (both supersonic and subsonic) two-point statistics (e.g. correlation functions or power-spectra) are anisotropic. This anisotropy can be used to determine the direction of the mean magnetic field projected in the plane of the sky.
astro-ph.GA:We present the results of a Suzaku monitoring campaign of the Seyfert 2 galaxy, NGC7582. The source is characterized by very rapid (on timescales even lower than a day) changes of the column density of an inner absorber, together with the presence of constant components arising as reprocessing from a Compton-thick material. The best fitting scenario implies important modifications to the zeroth order view of Unified Models. While the existence of a pc-scale torus is needed in order to produce a constant Compton reflection component and an iron K$\alpha$ emission line, in this Seyfert 2 galaxy this is not viewed along the line of sight. On the other hand, the absorption of the primary continuum is due to another material, much closer to the BH, roughly at the distance of the BLR, which can produce the observed rapid spectral variability. On top of that, the constant presence of a $10^{22}$ cm$^{-2}$ column density can be ascribed to the presence of a dust lane, extended on a galactic scale, as previously confirmed by Chandra. There is now mounting evidence that complexity in the obscuration of AGN may be the rule rather than the exception. We therefore propose to modify the Unification Model, adding to the torus the presence of two further absorbers/emitters. Their combination along the line of sight can reproduce all the observed phenomenology.
astro-ph.GA:Observations show that magnetic fields in the interstellar medium (ISM) often do not respond to increases in gas density as would be naively expected for a frozen-in field. This may suggest that the magnetic field in the diffuse gas becomes detached from dense clouds as they form. We have investigated this possibility using theoretical estimates, a simple magneto-hydrodynamic model of a flow without mass conservation and numerical simulations of a thermally unstable flow. Our results show that significant magnetic flux can be shed from dense clouds as they form in the diffuse ISM, leaving behind a magnetically dominated diffuse gas.
astro-ph.GA:Galactic winds in dwarf galaxies are driven by the energy released by supernova explosions and stellar winds following an intense episode of star formation, which create an over-pressured cavity of hot gas. Although the luminosity of the star formation episode and the mass of the galaxy play a key role in determining the occurrence of the galactic winds and the fate of the freshly produced metals, other parameters play an equally important role. In this contribution we address the following questions (i) What is the late evolution of superbubbles and what is the final fate of the superbubble cavities? (ii) How does the multi-phase nature of the ISM, in particular the coexistence of hot gas with embedded clouds, affect the development of galactic winds? (iii) What is the relation between the flattening of a galaxy and the development of bipolar galactic winds?
astro-ph.GA:Using deep J, H and Ks-band observations, we have studied the near-infrared (nIR) extinction of the Nuclear Bulge (NB) and we find significant, complex variations on small physical scales. We have applied a new variable nIR colour excess method, V-NICE, to measure the extinction; this method allows for variation in both the extinction law parameter alpha and the degree of absolute extinction on very small physical scales. We see significant variation in both these parameters on scales of 5 arcsec. In our observed fields, representing a random sample of sight lines to the NB, we measure alpha to be 2.64 +- 0.52, compared to the canonical "universal" value of 2. Our measured levels of A_Ks are similar to previously measured results (1 < A_Ks < 4.5); however, the steeper extinction law results in higher values for A_J (4.5 < A_J < 10) and A_H (1.5 < A_H < 6.5). Only when the extinction law is allowed to vary on the smallest scales can we recover self-consistent measures of the absolute extinction at each wavelength, allowing accurate reddening corrections for field star photometry in the NB. The steeper extinction law slope also suggests that previous conversions of nIR extinction to A_V may need to be reconsidered. Finally, we find that the measured values of extinction are significantly dependent on the filter transmission functions of the instrument used to obtain the data. This effect must be taken into account when combining or comparing data from different instruments.
astro-ph.GA:Although the continua of radio-loud Active Galactic Nuclei (AGN) are typically dominated by synchrotron radiation over virtually the entire spectrum, it is not clear whether the radio and higher-frequency emission originate in the same or different parts of the jet. Several different radio--optical correlations based on polarization data have been found recently, suggesting that the optical and radio polarization may be closely related, and that the corresponding emission regions may be cospatial (Gabuzda et. al2006, Jorstad et al. 2007, D'Arcangelo et al. 2007) Our joint analysis of optical and VLBA polarization data for a sample of about 40 AGNs shows that, after correction for the inferred VLBA core Faraday rotations, most BL Lac objects and some quasars have aligned VLBA-core and optical polarizations, although many quasars also show no obvious relationship between their VLBA-core and optical polarization angles. This may indicate that not all AGNs have cospatial regions of optical and radio emission in their jets. However, another possibility is that some of the 7mm-2cm VLBA cores have Faraday rotations of the order of several tens of thousand of rad/m^2, which were not properly fit by our three-frequency data due to n*pi ambiguities in the observed polarization angles, leading to incorrect subtraction of the effects of the core Faraday rotation, and so incorrect "zero-wavelength" radio polarization angles. The possibility of such high core Faraday rotations is supported by the results of the parsec-scale Faraday-rotation studies of Zavala & Taylor (2004) and Jorstad et al. (2007).
astro-ph.GA:We show a comparison of the rest-frame UV morphologies of a sample of 162 intermediate redshift (median redshift 1.02) galaxies with their rest-frame optical morphologies. We select our sample from the deepest near-UV image obtained with the Hubble Space Telescope (HST) using the WFPC2 (F300W) as part of the parallel observations of the Hubble Ultra Deep Field campaign overlapping with the HST/ACS GOODS dataset. We perform single component Sersic fits in both WFPC2/F300W (rest-frame UV) and ACS/F850LP (rest-frame optical) bands and deduce that the Sersic index $n$ is estimated to be smaller in the rest-frame UV compared to the rest-frame optical, leading to an overestimation of the number of merger candidates by ~40-100% compared to the rest-frame optical depending upon the cutoff in $n$ employed for identifying merger candidates. This effect seems to be dominated by galaxies with low values of n(F300W) <= 0.5 that have a value of n(F850LP) ~ 1.0. We argue that these objects are probably clumpy starforming galaxies or minor mergers, both of which are essentially contaminants, if one is interested in identifying major mergers.   In addition we also find evidence that the axis ratio b/a is lower, i.e. ellipticity (1-b/a) is higher in rest-frame UV compared to the rest-frame optical. Moreover, we find that in the rest-frame UV, the number of high ellipticity (e >= 0.8) objects are higher by a factor of ~2.8 compared to the rest-frame optical. This indicates that the reported dominance of elongated morphologies among high-z LBGs might just be a bias related to the use of rest-frame UV datasets in high-z studies.
astro-ph.GA:We present a new method to detect and quantify mass segregation in star clusters. It compares the minimum spanning tree (MST) of massive stars with that of random stars. If mass segregation is present, the MST length of the most massive stars will be shorter than that of random stars. This difference can be quantified (with an associated significance) to measure the degree of mass segregation. We test the method on simulated clusters in both 2D and 3D and show that the method works as expected.   We apply the method to the Orion Nebula Cluster (ONC) and show that the method is able to detect the mass segregation in the Trapezium with a `mass segregation ratio' \Lambda_{MSR}=8.0 \pm 3.5 (where \Lambda_{MSR}=1 is no mass segregation) down to 16 \Msun, and also that the ONC is mass segregated at a lower level (~2.0 \pm 0.5) down to 5 \Msun. Below 5 \Msun we find no evidence for any further mass segregation in the ONC.
astro-ph.GA:A study of the ionized and neutral gas kinematics near 23 WR stars in the Irr galaxy IC10 are provided. For most of the stars sings of the WR winds impact on the interstellar medium were detected. A rough estimate of the power of wind WR stars is about ~(0.01-0.84) 10^38 erg / sec.
astro-ph.GA:We discuss the results of the first model of the gas dynamics in the Milky Way in the presence of two bars: the large scale primary bar or boxy bulge and a secondary bar in the Galactic center region. We have obtained an accurate potential by modeling 2MASS star counts and we have used this potential to simulate the gas dynamics. As a first approximation we have used one single pattern speed \Omega_p. The models with Omega_p=30-40 \kmskpc and a primary bar orientation of 20-35 deg reproduce successfully many characteristics of the observed longitude-velocity diagrams as the terminal velocity curve or the spiral arm tangent points. The Galactic Molecular Ring is not an actual ring but the inner part of the spiral arms, within corotation. The model reproduces quantitatively the "3-kpc arm" and the recently found far-side counterpart, which are the lateral arms that contour the bar. In the Galactic center region, the model reproduces the 1-kpc HI ring and the Central Molecular Zone (CMZ), which is the gas response to the secondary bar. In order to reproduce the observed parallelogram shape of the CO longitude velocity diagram of the CMZ, the secondary bar should be oriented by and angle of 60-70 deg with respect to the Sun-GC line. The mass of the secondary bar amounts to (2-5.5)10^9 Msun, which is 10-25 % of the mass of the primary bar.
astro-ph.GA:We present the results of the one year long observational campaign of the type II-plateau SN 2005cs, which exploded in the nearby spiral galaxy M51 (the Whirlpool Galaxy). This extensive dataset makes SN 2005cs the best observed low-luminosity, 56Ni-poor type II-plateau event so far and one of the best core-collapse supernovae ever. The optical and near-infrared spectra show narrow P-Cygni lines characteristic of this SN family, which are indicative of a very low expansion velocity (about 1000 km/s) of the ejected material. The optical light curves cover both the plateau phase and the late-time radioactive tail, until about 380 days after core-collapse. Numerous unfiltered observations obtained by amateur astronomers give us the rare opportunity to monitor the fast rise to maximum light, lasting about 2 days. In addition to optical observations, we also present near-infrared light curves that (together with already published UV observations) allow us to construct for the first time a reliable bolometric light curve for an object of this class. Finally, comparing the observed data with those derived from a semi-analytic model, we infer for SN 2005cs a 56Ni mass of about 0.003 solar masses, a total ejected mass of 8-13 solar masses and an explosion energy of about 3 x 10^50 erg.
astro-ph.GA:We present a mid-infrared spectroscopic data cube of the central part of 30 Doradus, observed with Spitzer's IRS and MIPS/SED mode. Aromatic dust emission features and emission lines from molecular and atomic hydrogen are detected but not particularly strong. The dominant spectral features are emission lines from moderately ionized species of argon, neon, and sulphur, which are used to determine the physical conditions in the ionized gas. The ionized gas excitation shows strong variations on parsec scales, some of which can plausibly be associated with individual hot stars. We fit the ionic line strengths with photoionization and shock models, and find that photoionization dominates in the region. The ionization parameter U traces the rim of the central bubble, as well as highlighting isolated sources of ionization, and at least one quiescent clump. The hardness of the ionizing radiation field T_rad reveals several "hot spots" that are either the result of individual very hot stars or trace the propagation of the diffuse ionizing field through the surrounding neutral cloud. Consistent with other measurements of giant molecular hydrogen regions, log(U) ranges between -3 and -0.75, and T_rad between 30000 and 85000K.
astro-ph.GA:Cluster galaxies moving through the intracluster medium (ICM) are expected to lose some of their interstellar medium (ISM) through ISM-ICM interactions. We perform high resolution (40 pc) three-dimensional hydrodynamical simulations of a galaxy undergoing ram pressure stripping including radiative cooling in order to investigate stripping of a multiphase medium. The clumpy, multiphase ISM is self-consistently produced by the inclusion of radiative cooling, and spans six orders of magnitude in gas density. We find no large variations in the amount of gas lost whether or not cooling is involved, although the gas in the multiphase galaxy is stripped more quickly and to a smaller radius. We also see significant differences in the morphology of the stripped disks. This occurs because the multiphase medium naturally includes high density clouds set inside regions of lower density. We find that the lower density gas is stripped quickly from any radius of the galaxy, and the higher density gas can then be ablated. If high density clouds survive, through interaction with the ICM they lose enough angular momentum to drift towards the center of the galaxy where they are no longer stripped. Finally, we find that low ram pressure values compress gas into high density clouds that could lead to enhanced star formation, while high ram pressure leads to a smaller amount of high-density gas.
astro-ph.GA:(Abridged) The formation of massive spheroidal galaxies is studied on a visually classified sample of 910 galaxies extracted from the ACS/HST images of the GOODS North and South fields (0.4<z<.5). Three key observables are considered: comoving number density, internal colour distribution; and the Kormendy relation. The comoving number density of the most massive galaxies is found not to change significantly with redshift. One quarter of the whole sample of early-types are photometrically classified as blue galaxies. On a volume-limited subset out to z<0.7, the average stellar mass of the blue ellipticals is 5E9Msun compared to 4E10Msun for red ellipticals. On a volume-limited subsample of bright galaxies (Mv<-21) out to z=1.4 we find only 4% are blue early-types, in contrast with 26% for the full sample. The intrinsic colour distribution correlates overall bluer colours with **blue cores** (positive radial gradients of colour), suggesting an inside-out process of formation. The redshift evolution of the observed colour gradients is incompatible with a significant variaton in stellar age within each galaxy. The slope of the Kormendy relation in the subsample of massive galaxies does not change between z=0 and z=1.4.
astro-ph.GA:Young radio-loud active galactic nuclei form an important tool to investigate the evolution of extragalactic radio sources. To study the early phases of expanding radio sources, we have constructed CORALZ, a sample of 25 compact ($\theta<2"$) radio sources associated with nearby ($z<0.16$) galaxies. In this paper we determine the morphologies, linear sizes, and put first constraints on the lobe expansion speeds of the sources in the sample. We observed the radio sources from the CORALZ sample with MERLIN at 1.4 GHz or 1.6 GHz, the EVN at 1.6 GHz, and global VLBI at 1.6 GHz and/or 5.0 GHz. Radio maps, morphological classifications, and linear sizes are presented for all sources in the CORALZ sample. We have determined a first upper limit to the expansion velocity of one of the sources, which is remarkably low compared to the brighter GPS sources at higher redshifts, indicating a relation between radio luminosity and expansion speed, in agreement with analytical models. In addition we present further strong evidence that the spectral turnovers in GPS and CSS sources are caused by synchrotron self-absorption (SSA): the CORALZ sources are significantly offset from the well-known correlation between spectral peak frequency and angular size, but this correlation is recovered after correcting for the flux-density dependence, as predicted by SSA theory.
astro-ph.GA:Abridged: We use three-dimensional SPH simulations to investigate the collapse of low-mass prestellar cores and the formation and early evolution of protostellar discs. The initial conditions are slightly supercritical Bonnor-Ebert spheres in rigid rotation. The core mass and initial radius are held fixed at M_O=6.1 M_sun and R_O=17,000 AU, and the only parameter that we vary is the initial angular speed \Omega_O. Protostellar discs forming from cores with \Omega_O<1.35 10d-13 1/s have radii between 100 and 300 AU and are quite centrally concentrated; due to heating by gas infall onto the disc and accretion onto the central object, they are also quite warm, T>100 K, and therefore stable against gravitational fragmentation. In contrast, more rapidly rotating cores form discs which are less concentrated and cooler, and have radii between 400 and 1000 AU; as a consequence they are prone to gravitational fragmentation and the formation of multiple systems. We derive a criterion that predicts whether a rigidly rotating core having given M_O, R_O and \Omega_O will produce a protostellar disc which fragments whilst material is still infalling from the core envelope. We then apply this criterion to core samples for which M_O, R_O and \Omega_O have been estimated observationally. We conclude that the observed cores are stable against fragmentation at this stage, due to their low angular speeds and the heat delivered at the accretion shock where the infalling material hits the disc.
astro-ph.GA:We map the three dimensional extent of the Virgo Over-density by combining distance information from RR Lyrae variables and projected spatial information from SEKBO (Keller et al. 2008) and Sloan Digital Sky Survey (SDSS) DR6 photometry. The Virgo Over-density is seen to comprise two filaments 14.5 x 3 degrees and 10 x 3 degrees and a circular structure 3 degrees in diameter. Together the three features span 38 degrees of right ascension and declinations of +2 to -15 degrees. RR Lyrae variables place the two filamentary features at heliocentric distances of 20 and 17 kpc respectively, with projected dimensions of 5 x 1 kpc and 3 x 1 kpc.
astro-ph.GA:We draw a comparison between AGN and Galactic black hole binaries using a uniform description of spectral energy distribution of these two classes of accreting X-ray sources. We parametrize spectra of GBHs with an alpha_GBH parameter which we define as a slope of a nominal power law function between 3 and 20 keV. We show that this parameter can be treated as an equivalent of the X-ray loudness, alpha_OX, used to describe AGN spectra. We do not find linear correlation between the alpha_GBH and disc flux (similar to that between alpha_OX and optical/UV luminosity found in AGN). Instead, we show that alpha_GBH follows a well defined pattern during a GBH outburst. We find that alpha_GBH tend to cluster around 1, 1.5 and 2, which correspond to a hard, very high/intermediate and soft spectral state, respectively. We conclude that majority of the observed Type 1 radio quiet AGN are in a spectral state corresponding to a very high/intermediate state of GBHs. The same conclusion is valid for radio loud AGN. We also study variations of the spectral slopes (alpha_GBH and the X-ray photon index, Gamma) as a function of disc and Comptonization fluxes. We discuss these dependencies in the context of correlations of alpha_OX and Gamma with the optical/UV and X-ray 2 keV fluxes considered for AGN and quasars.
astro-ph.GA:We have decomposed the broad H-alpha, H-beta and H-gamma lines of 90 Active Galactic Nuclei (AGNs) into a superposition of a very broad and an intermediate Gaussian components (VBGC and IMGC) and discovered that the two Gaussian components evolve with FWHM of the whole emission lines. We suggest that the VBGC and the IMGC are produced in different emission regions, namely, Very Broad Line Region (VBLR) and Intermediate Line Region (IMLR). The details of the two components of H-alpha, H-beta and H-gamma lines indicate that the radius obtained from the emission line reverberation mapping normally corresponds to the radius of the VBLR, but the radius obtained from the infrared reverberation mapping corresponding to IMLR, i.e., the inner boundary of the dusty torus. The existence of the IMGC may affect the measurement of the black hole mass in AGNs. Therefore, the deviation of NLS1s from the M-sigma relation may be explained naturally in this way. The evolution of the two emission line regions may be related to the evolutionary stages of the broad line regions of AGNs from NLS1s to BLS1s. Other evidences for the existence of the IMLR are also presented.
astro-ph.GA:A significant fraction of high redshift starburst galaxies presents strong Ly alpha emission. Understanding the nature of these galaxies is important to assess the role they played in the early Universe and to shed light on the relation between the narrow band selected Lyalpha emitters and the Lyman break galaxies: are the Lyalpha emitters a subset of the general LBG population? or do they represent the youngest galaxies in their early phases of formation? We studied a sample of UV continuum selected galaxies from z~2.5 to z~6 (U, B, V and i-dropouts) from the GOODS-South survey, that have been observed spectroscopically. Using the GOODS-MUSIC catalog we investigated their physical properties, such as total masses, ages, SFRs, extinction etc as determined from a spectrophotometric fit to the multi-wavelength (U band to mid-IR) SEDs, and their dependence on the emission line characteristics. In particular we determined the nature of the LBGs with Lyalpha in emission and compared them to the properties of narrow band selected Lyalpha emitters. For U and B-dropouts we also compared the properties of LBGs with and without the Lyalpha emission line.
astro-ph.GA:IGR J16351-5806 has been associated with the Seyfert 2 galaxy ESO 137-G34, having been first reported as a high energy emitter in the third INTEGRAL/IBIS survey. Using a new diagnostic tool based on X-ray column density measurements vs softness ratios, Malizia et al. (2007) identified this source as a candidate Compton thick AGN. In the present work we have analysed combined XMM-Newton and INTEGRAL data of IGR J16351-5806 in order to study its broad band spectrum and investigate its Compton thick nature. The prominent K_alpha fluorescence line around 6.4 keV (EW > 1 keV) together with a flat 2-10 keV spectrum immediately point to a highly obscured source. The overall spectrum can be interpreted in terms of a transmission scenario where some of the high energy radiation is able to penetrate through the thick absorption but a good fit is also obtained using a pure reflection spectrum. An alternative possibility is that of a complex absorption, where two layers of absorbing matter each partially covering the central nucleus are present in IGR J16351-5806. All three scenarios are compatible from a statistical viewpoint and provide reasonable AGN spectral parameters; more importantly all point to a source with an absorbing column greater than 1.5 x 10^24 cm^-2, i.e. to a Compton thick AGN. Because of this heavy obscuration, some extra components which would otherwise be hidden are able to emerge at low energies and can be studied. By providing strong evidence for the Compton thick nature of IGR J16351-5806, we indirectly confirm the validity of the Malizia et al. diagnostic diagram.
astro-ph.GA:We carried out long-slit spectroscopic observations of the star forming knots along the polar ring of the dwarf galaxy IIZw71 in the spectral range 3500 - 10000 angstroms taken with the William erschel Telescope (WHT). The spectroscopic observations were complemented with available photometry of the galaxy in the narrow Halpha filter. We measured the rotation curve of the ring, from which we infer a ratio M/L_B = 3.9 inside the star forming ring. We measured the auroral [OIII] line in the two brightest knots, allowing us to measure oxygen, sulphur, nitrogen, argon and neon chemical abundances following the direct method. Different empirical calibrators were used to estimate the oxygen abundance in the two faintest knots. The metallicities obtained are very similar for all the knots, but lower than previously reported in the literature from integrated spectra. The N/O abundance, as derived from the N2O2 parameter, is remarkably constant over the ring, indicating that local polution processes are not conspicuous. Using synthetic stellar populations (SSPs) calculated with the code STARLIGHT, we studied the age distribution of the stellar populations in each knot, finding that in all of them there is a combination of a very young population with less than 10 Myr, responsible for the ionisation of the gas, with other populations older than 100 Myr, probably responsible for the chemical evolution of the knots. The small differences in metallicity and the age distributions among the different knots are indicative of a common chemical evolution, probably related to the process of interaction with the companion galaxy IIZw70.
astro-ph.GA:(Abridge) Bars are very common in the centre of the disc galaxies, and they drive the evolution of their structure. A volume-limited sample of 2106 disc galaxies extracted from the Sloan Digital Sky Survey Data Release 5 was studied to derive the bar fraction, length, and strength as a function of the morphology, size, local galaxy density, light concentration, and colour of the host galaxy. The bars were detected using the ellipse fitting method and Fourier analysis method. The ellipse fitting method was found to be more efficient in detecting bars in spiral galaxies. The fraction of barred galaxies turned out to be 45%. A bar was found in 29% of the lenticular galaxies, in 55% and 54% of the early- and late-type spirals, respectively. The bar length (normalised by the galaxy size) of late-type spirals is shorter than in early-type or lenticular ones. A correlation between the bar length and galaxy size was found with longer bars hosted by larger galaxies. The bars of the lenticular galaxies are weaker than those in spirals. Moreover, the unimodal distribution of the bar strength found for all the galaxy types argues against a quick transition between the barred and unbarred statues. There is no difference between the local galaxy density of barred and unbarred galaxies. Besides, neither the length nor strength of the bars are correlated with the local density of the galaxy neighbourhoods. In contrast, a statistical significant difference between the central light concentration and colour of barred and unbarred galaxies was found. Bars are mostly located in less concentrated and bluer galaxies. These results indicate that the properties of bars are strongly related to those of their host galaxies, but do not depend on the local environment.
astro-ph.GA:Using H I absorption spectra taken from the recent surveys of 21-cm line and continuum emission in the Galactic plane, the distribution of cool atomic clouds in the outer disk of the Milky Way is revealed. The warp of the midplane is clearly seen in absorption, as it is in emission, and the cool, neutral medium also shows flaring or increase in scale height with radius similar to that of the warm atomic hydrogen. The mixture of phases, as measured by the fraction of H I in the cool clouds relative to the total atomic hydrogen, stays nearly constant from the solar circle out to about 25 kpc radius. Assuming cool phase temperature ~50 K this indicates a mixing ratio of 15% to 20% cool H I, with the rest warm.
astro-ph.GA:The papers in this volume represent a broad spectrum of observational, theoretical, and computational astrophysics, sharing as a unifying core the Disk-Halo Interaction in the Milky Way and other spiral galaxies. This topic covers a wide range of Galactic and extra-galactic research, built on a foundation of numerous and diverse physical processes. This summary groups the papers according to six themes, with some historical background and finally a look to the future. The final message is that the astrophysical techniques discussed and reviewed at this conference will grow over the next decade to answer even more fundamental questions about galaxy evolution and the history of the universe.
astro-ph.GA:We present mid-IR observations of the Galactic Luminous Blue Variable (LBV) HR Car and its associated nebula carried out with the Spitzer Space Telescope using both IRAC and IRS, as part of a GTO program aimed to study stellar ejecta from evolved stars. Our observations reveal a rich mid-IR spectrum of the inner nebula showing both solid state and atomic gas signatures. Strong low-excitation atomic fine structure lines such as $ 26.0 \mu$m [\ion{Fe}{2}] and $ 34.8 \mu$m [\ion{Si}{2}], indicate, for the first time, the presence of a PDR in this object class. While the physics and chemistry of the low-excitation gas appears to be dominated by photodissociation, a possible contribution due to shocks can be inferred from the evidence of gas phase Fe abundance enhancement. The presence of amorphous silicates, inferred from the observed characteristic broad feature at $10 \mu$m located in the inner nebula, suggests that dust has formed during the LBV outburst. This is in contrast with the detection of crystalline dust in other probably more evolved Galactic LBVs, which is similar to the crystalline dust observed in red supergiants. This has been considered to be evidence of dust production during evolutionary phases prior to the outburst.
astro-ph.GA:We propose a methodology to perform a self-consistent analysis of the physical properties of the emitting gas of HII galaxies adequate to the data that can be obtained with the XXI century technology. This methodology requires the production and calibration of empirical relations between the different line temperatures that should superseed currently used ones based on very simple, and poorly tested, photo-ionization model sequences. Then, these observations are analysed applying a methodology designed to obtain accurate elemental abundances of oxygen, sulphur, nitrogen, neon, argon and iron in the ionsied gas. Four electron temperatures and one electron density are derived from the observed forbidden line ratios using the five-level atom approximation. For our best objects errors of 1% in T([OIII]), 3% in T([OII]) and 5% in T([SIII]) are achieved with a resulting accuracy between 5 and 9% in total oxygen abundances, O/H. These accuracies are expected to improve as better calibrations based on more precise measurements, both on electron temperatures and densities, are produced.
astro-ph.GA:We performed astrometric observations with the VLBA of WB89-437, an H2O maser source in the Outer spiral arm of the Galaxy. We measure an annual parallax of 0.167 +/- 0.006 mas, corresponding to a heliocentric distance of 6.0 +/- 0.2 kpc or a Galactocentric distance of 13.4 +/- 0.2 kpc. This value for the heliocentric distance is considerably smaller than the kinematic distance of 8.6 kpc. This confirms the presence of a faint Outer arm toward l = 135 degrees. We also measured the full space motion of the object and find a large peculiar motion of ~20 km/s toward the Galactic center. This peculiar motion explains the large error in the kinematic distance estimate. We also find that WB89-437 has the same rotation speed as the LSR, providing more evidence for a flat rotation curve and thus the presence of dark matter in the outer Galaxy.
astro-ph.GA:We revisit the mass ratio Rmol between molecular hydrogen (H2) and atomic hydrogen (HI) in different galaxies from a phenomenological and theoretical viewpoint. First, the local H2-mass function (MF) is estimated from the local CO-luminosity function (LF) of the FCRAO Extragalactic CO-Survey, adopting a variable CO-to-H2 conversion fitted to nearby observations. This implies an average H2-density Omega_H2=(6.9+-2.7) 10^5/h and Omega_H2/Omega_HI=0.26+-0.11 in the local Universe. Second, we investigate the correlations between Rmol and global galaxy properties in a sample of 245 local galaxies. Based on these correlations we introduce four phenomenological models for Rmol, which we apply to estimate H2-masses for each HI-galaxy in the HIPASS catalogue. The resulting H2-MFs (one for each model for Rmol) are compared to the reference H2-MF derived from the CO-LF, thus allowing us to determine the Bayesian evidence of each model and to identify a clear best model, in which, for spiral galaxies, Rmol negatively correlates with both galaxy Hubble type and total gas mass. Third, we derive a theoretical model for Rmol for regular galaxies based on an expression for their axially symmetric pressure profile dictating the degree of molecularization. This model is quantitatively similar to the best phenomenological one at redshift z=0, and hence represents a consistent generalization while providing a physical explanation for the dependence of Rmol on global galaxy properties. Applying the best phenomenological model for Rmol to the HIPASS sample, we derive the first integral cold gas-MF (HI+H2+helium) of the local Universe.
astro-ph.GA:Observations of high redshift galaxies have revealed a multitude of large clumpy rapidly star-forming galaxies. Their formation scenario and their link to present day spirals is still unknown. In this Letter we perform adaptive mesh refinement simulations of disk formation in a cosmological context that are unrivalled in terms of mass and spatial resolution. We find that the so called "chain-galaxies" and "clump-clusters" are a natural outcome of early epochs of enhanced gas accretion from cold dense streams as well as tidally and ram-pressured stripped material from minor mergers and satellites. Through interaction with the hot halo gas, this freshly accreted cold gas settles into a large disk-like system, not necessarily aligned to an older stellar component, that undergoes fragmentation and subsequent star formation, forming large clumps in the mass range 10^7-10^9 M_sun. Galaxy formation is a complex process at this important epoch when most of the central baryons are being acquired through a range of different mechanisms - we highlight that a rapid mass loading epoch is required to fuel the fragmentation taking place in the massive arms in the outskirts of extended disks, an accretion mode that occurs naturally in the hierarchical assembly process at early epochs.
astro-ph.GA:We report on the detection of a population of weak metal-line absorbers in the halo or nearby intergalactic environment of the Milky Way. Using high-resolution ultraviolet absorption-line spectra of bright QSOs obtained with the Space Telescope Imaging Spectrograph (STIS), along six sight lines we have observed unsaturated, narrow absorption in OI and SiII together with mildly saturated CII absorption at high radial velocities (|v_LSR|=100-320 km/s). The measured OI column densities are small, implying that these structures represent Lyman-Limit Systems and sub-Lyman-Limit System with HI column densities < 3x10^18 cm^-2, thus below the detection limits of current 21cm all-sky surveys of high-velocity clouds (HVCs). The absorbers apparently are not directly associated with any of the large high-column density HVC complexes, but rather represent isolated, partly neutral gas clumps embedded in a more tenuous, ionized gaseous medium situated in the halo or nearby intergalactic environment of the Galaxy. We speculate that this absorber population represents the local analog of weak MgII systems that are commonly observed in the circumgalactic environment of low- and high-redshift galaxies.
astro-ph.GA:I review the observational constraints on the star formation histories in the spheroids of M33 and M31, the other two spiral galaxies in the Local Group. M33 does not possess a traditional bulge; instead, it has a small nuclear region hosting stars with a wide range of ages. The star formation history of the M33 halo is poorly constrained, but composite spectra of its halo globular clusters imply a wide age spread of 5 - 7 years, while the presence of RR Lyrae stars in the halo implies at least some of the population is ancient. Although it is possible to obtain the detailed star formation history of the M33 halo via deep photometry, this has not been done to date. M31 hosts a traditional bulge that is apparently dominated by stars older than 10 Gyr. Deep photometry of the M31 halo demonstrates that it hosts both a population of ancient metal-poor stars and a significant population extending to younger ages and high metallicity, apparently due to its active merger history.
astro-ph.GA:The complete census of globular clusters formerly belonging to the Sgr dSph and now deposited into the Galactic halo is an important contribution to our comprehension of the evolution and disruption of this dwarf galaxy. We investigate in this study the possibility that the poorly known "old" globular AM 4 might be associated with the Sagittarius dwarf galaxy, and at the same time provide more solid estimate of its basic parameters. New high quality BVI photometry is presented, from which an improved Color Ma gnitude Diagram is constructed, and estimates of age and distance are then derived. The distance and Galactic position are finally investigated in details. AM~4 is found to be a low luminosity (M$_V$=-1.82) cluster undergoing strong tidal stress by the Milky Way and on the verge to be dissolved. Besides, and at odds with previous suggestions, we provide evidences that AM 4 is indeed young, with an age around 9 Gyrs (as Terzan~7), but somewhat more metal poor ([Fe/H=-0.97]). AM~4 is located at 33$_{-4}^{+3}$ kpc from the Sun, in a direction and at distance not totally incompatible with the Sgr dSph stream. Although we significantly improved our knowledge of AM 4, further studies are encouraged to obtain radial velocity and metallicity to d emonstrate more firmly (or deny) the association to Sgr
astro-ph.GA:In this paper, a consistent model of the multifrequency emission of the starburst galaxy M82, from radio to gamma-rays is presented and discussed. Predictions for observations with Fermi, MAGIC II/VERITAS and CTA telescopes are made. The model is also used to self-consistenty compute the (all flavors) emission of neutrinos resulting from this starburst galaxy, what can be used in considerations of the diffuse contributions of such objects.
astro-ph.GA:Ram pressure stripping of the multiphase ISM is studied in the perturbed Virgo cluster spiral galaxy NGC 4438. This galaxy underwent a tidal interaction ~100 Myr ago and is now strongly affected by ram pressure stripping. Deep VLA radio continuum observations at 6 and 20 cm are presented. We detect prominent extraplanar emission to the west of the galactic center, which extends twice as far as the other tracers of extraplanar material. The spectral index of the extraplanar emission does not steepen with increasing distance from the galaxy. This implies in situ re-acceleration of relativistic electrons. The comparison with multiwavelength observations shows that the magnetic field and the warm ionized interstellar medium traced by Halpha emission are closely linked. The kinematics of the northern extraplanar Halpha emission, which is ascribed to star formation, follow those of the extraplanar CO emission. In the western and southern extraplanar regions, the Halpha measured velocities are greater than those of the CO lines. We suggest that the ionized gas of this region is excited by ram pressure. The spatial and velocity offsets are consistent with a scenario where the diffuse ionized gas is more efficiently pushed by ram pressure stripping than the neutral gas. We suggest that the recently found radio-deficient regions compared to 24 mum emission are due to this difference in stripping efficiency.
astro-ph.GA:We present an analysis of the X-ray point source populations in 182 Chandra images of galaxy clusters at z>0.1 with exposure time >10 ksec, as well as 44 non-cluster fields. Analysis of the number and flux of these sources, using a detailed pipeline to predict the distribution of non-cluster sources in each field, reveals an excess of X-ray point sources associated with the galaxy clusters. A sample of 148 galaxy clusters at 0.1<z<0.9, with no other nearby clusters, show an excess of 230 cluster sources in total, an average of ~1.5 sources per cluster. The lack of optical data for these clusters limits the physical interpretation of this result, as we cannot calculate the fraction of cluster galaxies hosting X-ray sources. However, the fluxes of the excess sources indicate that over half of them are very likely to be AGN, and the radial distribution shows that they are quite evenly distributed over the central 1 Mpc of the cluster, with almost no sources found beyond this radius. We also use this pipeline to successfully reproduce the results of previous studies, particularly the higher density of sources in the central 0.5 Mpc of a few cluster fields, but show that these conclusions are not generally valid for this larger sample of clusters. We conclude that some of these differences may be due to the sample properties, such as the size and redshift of the clusters studied, or a lack of publications for cluster fields with no excess sources. This paper also presents the basic X-ray properties of the galaxy clusters, and in subsequent papers in this series the dependence of the AGN population on these cluster properties will be evaluated.   In addition the properties of over 9500 X-ray point sources in the fields of galaxy clusters are tabulated in a separate catalogue available online.
astro-ph.GA:We report spatially-resolved variations in the 3.4micron hydrocarbon absorption feature and the 3.3micron polycyclic aromatic hydrocarbon (PAH) emission band in the Circinus galaxy over the central few arcsec. The absorption is measured towards warm emitting dust associated with Coronal line regions to the east and west of the nucleus. There is an absorption optical depth tau(3.4um) ~0.1 in the core which decreases to the west and increases to the east. This is consistent with increased extinction out to ~40 pc east of the core, supported by the Coronal emission line intensities which are significantly lower to the east than the west. PAH emission is measured to be symmetrically distributed out to +/- 4 arcsec, outside the differential extinction region. The asymmetry in the 3.4micron absorption band reflects that seen in the 9.7micron silicate absorption band reported by Roche et al. (2006) and the ratio of the two absorption depths remains approximately constant across the central regions, with tau(3.4um) / tau(9.7um) ~ 0.06 +/-0.01. This indicates well-mixed hydrocarbon and silicate dust populations, with no evidence for significant changes near the nucleus.
astro-ph.GA:In a programme of observations of local luminous blue compact galaxies (BCGs), we are investigating kinematics by using tracers of both stars and ionized gas. Here we summarise our program and present new data on the local Lyman break galaxy analogue Haro 11. From spatially-resolved spectroscopy around the near-infrared Ca II triplet, we find that its stars and ionized gas have similar velocity fields. Our programme so far indicates however that emission line velocities can differ locally by a few tens of km/s from the Ca II values. Comparing our data to simple stellar population models, we assess which stellar population the Ca II triplet traces and its potential beyond the local universe.
astro-ph.GA:The study of PopI and PopII indicators in galaxies has a profound impact on our understanding of galaxy evolution. Their present (z=0) ratio suggests that the star formation history of galaxies was primarily dictated by their global mass. Since 1989 Luis Carrasco and I spent most of our sleepless nights gathering H_alpha and near infrared surface photometry of galaxies in the local Universe and focused most of our scientific career on these two indicators trying to convince the community that the mass was the key parameter to their evolution. We were unsuccessful, until in 2004 the Sloan team rediscovered this phenomenon and named it "downsizing"
astro-ph.GA:Gamma-ray emission from cocoons of young radio galaxies is predicted. Considering the process of adiabatic injection of the shock dissipation energy and mass of the relativistic jet into the cocoon, we find that the thermal electron temperature of the cocoon is typically predicted to be of the order of $\sim$ MeV, and is determined only by the bulk Lorentz factor of the jet. Together with the time-dependent dynamics of the cocoon expansion, we find that young cocoons can yield thermal Bremsstrahlung emissions at energies $\sim$MeV. Hotter cocoons (i.e., GeV) for younger sources are also discussed.
astro-ph.GA:Coordinates, magnitudes and spectra are presented for 39 cataclysmic variables found in Sloan Digital Sky Survey spectra that were primarily obtained in 2006. Of these, 12 were CVs identified prior to the SDSS spectra (GY Cnc, GO Com, ST LMi, NY Ser, MR Ser, QW Ser, EU UMa, IY UMa, HS1340+1524, RXJ1610.1+0352, Boo 1, Leo 5). Follow-up spectroscopic observations of seven systems (including one from year 2005 and another from year 2004) were obtained, resulting in estimates of the orbital periods for 3 objects. The new CVs include two candidates for high inclination, eclipsing systems, 4 new Polars and three systems whose spectra clearly reveal atmospheric absorption lines from the underlying white dwarf.
astro-ph.GA:Recent developments on the study of mixed morphology supernova remnants (MMSNRs) have revealed the presence of metal rich X-ray emitting plasma inside a fraction of these remnant, a feature not properly addressed by traditional models for these objects. Radial profiles of thermodynamical and chemical parameters are needed for a fruitful comparison of data and model of MMSNRs, but these are available only in a few cases. We analyze XMM-Newton data of two MMSNRs, namely IC443 and G166.0+4.3, previously known to have solar metal abundances, and we perform spatially resolved spectral analysis of the X-ray emission. We detected enhanced abundances of Ne, Mg and Si in the hard X-ray bright peak in the north of IC443, and of S in the outer regions of G166.0+4.3. The metal abundances are not distributed uniformly in both remnants. The evaporating clouds model and the radiative SNR model fail to reproduce consistently all the observational results. We suggest that further deep X-ray observations of MMSNRs may reveal more metal rich objects. More detailed models which include ISM-ejecta mixing are needed to explain the nature of this growing subclass of MMSNRs.
astro-ph.GA:Deep ACS slitless grism observations and identification of stellar sources are presented within the Great Observatories Origins Deep Survey (GOODS) North and South fields which were obtained in the Probing Evolution And Reionization Spectroscopically (PEARS) program. It is demonstrated that even low resolution spectra can be a very powerful means to identify stars in the field, especially low mass stars with stellar types M0 and later. The PEARS fields lay within the larger GOODS fields, and we used new, deeper images to further refine the selection of stars in the PEARS field, down to a magnitude of mz = 25 using a newly developed stellarity parameter. The total number of stars with reliable spectroscopic and morphological identification was 95 and 108 in the north and south fields respectively. The sample of spectroscopically identified stars allows constraints to be set on the thickness of the Galactic thin disk as well as contributions from a thick disk and a halo component. We derive a thin disk scale height, as traced by the population of M4 to M9 dwarfs along two independent lines of sight, of h_thin = 370 +60/-65 pc. When including the more massive M0 to M4 dwarf population, we derive h_thin = 300 +/- 70pc. In both cases, we observe that we must include a combination of thick and halo components in our models in order to account for the observed numbers of faint dwarfs. The required thick disk scale height is typically h_thick=1000 pc and the acceptable relative stellar densities of the thin disk to thick disk and the thin disk to halo components are in the range of 0.00025<f_halo<0.0005 and 0.05<f_thick<0.08 and are somewhat dependent on whether the more massive M0 to M4 dwarfs are included in our sample.
astro-ph.GA:The Large Area Telescope on the recently launched Fermi Gamma-ray Space Telescope (formerly GLAST), with its large field of view and effective area, combined with its excellent timing capabilities, is poised to revolutionize the field of gamma-ray astrophysics. The large improvement in sensitivity over EGRET is expected to result in the discovery of many new gamma-ray pulsars, which in turn should lead to fundamental advances in our understanding of pulsar physics and the role of neutron stars in the Galaxy. Almost immediately after launch, Fermi clearly detected all previously known gamma-ray pulsars and is producing high precision results on these. An extensive radio and X-ray timing campaign of known (primarily radio) pulsars is being carried out in order to facilitate the discovery of new gamma-ray pulsars. In addition, a highly efficient time-differencing technique is being used to conduct blind searches for radio-quiet pulsars, which has already resulted in new discoveries. I present some recent results from searches for pulsars carried out on Fermi data, both blind searches, and using contemporaneous timing of known radio pulsars.
astro-ph.GA:We observed the northern rim of the Cygnus Loop with the \textit{Suzaku} observatory in 5 pointings (P21-P25). From the spatially resolved analysis, all the spectra are well fitted by the single component of the non-equilibrium ionization plasma model. From the best-fit parameters, we found that the abundances of the heavy elements are significantly lower than the solar values except those at the outermost edge in P21 and P22. The origin of the depleted metal abundances is still unclear while such deficiencies have been reported from many other rim observations of the Loop. To explain these depletion at the rim regions, we considered the several possibilities. The effects of the resonance-line-scattering and the grain condensation lower the values of the abundances. However, these are not sufficient to account for the abundance depletion observed.   We found that the abundances at the outermost edge in P21 and P22 are higher than those at the other regions. From the morphological point of view, it is reasonable to consider that this abundance inhomogeneity is derived from the breakout or the thinness of the cavity wall of the Loop.
astro-ph.GA:We analyzed the metal distribution of the Cygnus Loop using 14 and 7 pointings observation data obtained by the \textit{Suzaku} and the \textit{XMM-Newton} observatories. The spectral analysis shows that all the spectra are well fitted by the two-$kT_e$ non-equilibrium ionization plasma model as shown by the earlier observations. From the best-fit parameters of the high-$kT_e$ component, we calculated the emission measures about various elements and showed the metal distribution of the ejecta component. We found that the distributions of Si and Fe are centered at the southwest of the geometric center toward the blow-out region. From the best-fit parameters, we also estimated the progenitor mass of the Cygnus Loop from our field of view and the metal rich region with a radius of 25 arcmin from the metal center. The result from the metal circle is similar to that from our entire FOV, which suggests the mixing of the metal. From the results, we estimated the mass of the progenitor star at 12-15\MO.
astro-ph.GA:Context. The origin, evolution, and ultimate fate of magnetic cataclysmic variables are poorly understood. It is largely the nature of the magnetic fields in these systems that leads to this poor understanding. Fundamental properties, such as the field strength and the axis alignment, are unknown in a majority of these systems. Aims. We undertake to put all the previous circular polarization measurements into context and systematically survey intermediate polars for signs of circular polarization, hence to get an indication of their true magnetic field strengths and try to understand the evolution of magnetic cataclysmic variables. Methods. We used the TurPol instrument at the Nordic Optical Telescope to obtain simultaneous UBVRI photo-polarimetric observations of a set of intermediate polars, during the epoch 2006 July 31 - August 2. Results. Of this set of eight systems two (1RXS J213344.1+510725 and 1RXS J173021.5-055933) were found to show significant levels of circular polarization, varying with spin phase. Five others (V2306 Cyg, AO Psc, DQ Her, FO Aqr, and V1223 Sgr) show some evidence for circular polarization and variation of this with spin phase, whilst AE Aqr shows little evidence for polarized emission. We also report the first simultaneous UBVRI photometry of the newly identified intermediate polar 1RXS J173021.5-055933. Conclusions. Circular polarization may be ubiquitous in intermediate polars, albeit at a low level of one or two percent or less. It is stronger at longer wavelengths in the visible spectrum. Our results lend further support to the possible link between the presence of soft X-ray components and the detectability of circular polarization in intermediate polars.
astro-ph.GA:White dwarf masses in cataclysmic variables are difficult to determine accurately, but are fundamental for understanding binary system parameters, as well as binary evolution. We investigate the X-ray spectral properties of a sample of Intermediate Polars detected above 15 keV to derive the masses of their accreting white dwarfs. We use data from the Swift/BAT instrument which during the first 2.5 yrs of operation has detected 22 known intermediate polars. The X-ray spectra of these sources are used to estimate the mass of the white dwarfs. We are able to produce a mass estimate for 22 out of 29 of the confirmed intermediate polars. Comparison with previous mass measurements shows good agreement. For GK Per, we were able to detect spectral changes due to the changes in the accretion rate. The Swift/BAT detector with its combination of sensitivity and all-sky coverage provides an ideal tool to determine accurate white dwarf masses in intermediate polars.
astro-ph.GA:Supersonic turbulence is a large reservoir of suprathermal energy in the interstellar medium. Its dissipation, because it is intermittent in space and time, can deeply modify the chemistry of the gas. We further explore a hybrid method to compute the chemical and thermal evolution of a magnetized dissipative structure, under the energetic constraints provided by the observed properties of turbulence in the cold neutral medium. For the first time, we model a random line of sight by taking into account the relative duration of the bursts with respect to the thermal and chemical relaxation timescales of the gas. The key parameter is the turbulent rate of strain "a" due to the ambient turbulence. With the gas density, it controls the size of the dissipative structures, therefore the strength of the burst. For a large range of rates of strain and densities, the models of turbulent dissipation regions (TDR) reproduce the CH+ column densities observed in the diffuse medium and their correlation with highly excited H2. They do so without producing an excess of CH. As a natural consequence, they reproduce the abundance ratios of HCO+/OH and HCO+/H2O, and their dynamic range of about one order of magnitude observed in diffuse gas. Large C2H and CO abundances, also related to those of HCO+, are another outcome of the TDR models that compare well with observed values. The abundances and column densities computed for CN, HCN and HNC are one order of magnitude above PDR model predictions, although still significantly smaller than observed values.
astro-ph.GA:The black hole at the Galactic Center, Sgr A*, is the prototype of a galactic nucleus at a very low level of activity. Its radio through submm-wave emission is known to come from a region close to the event horizon, however, the source of the emission is still under debate. A successful theory explaining the emission is based on a relativistic jet model scaled down from powerful quasars. We want to test the predictive power of this established jet model against newly available measurements of wavelength-dependent time lags and the size-wavelength structure in Sgr A*. Using all available closure amplitude VLBI data from different groups, we again derived the intrinsic wavelength-dependent size of Sgr A*. This allowed us to calculate the expected frequency-dependent time lags of radio flares, assuming a range of in- and outflow velocities. Moreover, we calculated the time lags expected in the previously published pressure-driven jet model. The predicted lags are then compared to radio monitoring observations at 22, 43, and 350 GHz. The combination of time lags and size measurements imply a mildly relativistic outflow with bulk outflow speeds of gamma*beta ~ 0.5-2. The newly measured time lags are reproduced well by the jet model without any major fine tuning. The results further strengthen the case for the cm-to-mm wave radio emission in Sgr A* as coming from a mildly relativistic jet-like outflow. The combination of radio time lag and VLBI closure amplitude measurements is a powerful new tool for assessing the flow speed and direction in Sgr A*. Future VLBI and time lag measurements over a range of wavelengths will reveal more information about Sgr A*, such as the existence of a jet nozzle, and measure the detailed velocity structure of a relativistic jet near its launching point for the first time.
astro-ph.GA:High-dynamic-range surface photometry in a companion paper makes possible accurate measurement of the stellar light deficits L_def and mass deficits M_def associated with the cores of elliptical galaxies. We show that L_def correlates with the velocity dispersion sigma of the host galaxy bulge averaged outside the central region that may be affected by a supermassive black hole (BH). We confirm that L_def correlates with BH mass MBH. Also, the fractional light deficit L_def/L correlates with MBH/M, the ratio of BH mass to the galaxy stellar mass. All three correlations have scatter similar to or smaller than the scatter in the well known correlation between MBH and sigma. The new correlations are remarkable in view of the dichotomy between ellipticals with cores and those with central extra light. Core light deficit correlates closely with MBH and sigma, but extra light does not. This supports the suggestion that extra light Es are made in wet mergers with starbursts whereas core Es are made in dry mergers. After dry mergers, cores are believed to be scoured by BH binaries that fling stars away as their orbits decay or by BHs that sink back to the center after recoiling from anisotropic gravitational radiation emitted when they merge. Direct evidence has been elusive. We interpret the new correlations as the "smoking gun" that connects cores with BHs. Together, the MBH - sigma and MBH - L_def correlations give us two independent ways to estimate BH masses in core ellipticals.
astro-ph.GA:We identify SDSS J153636.22+044127.0, a QSO discovered in the Sloan Digital Sky Survey, as a promising candidate for a binary black hole system. This QSO has two broad-line emission systems separated by 3500 km/sec. The redder system at z=0.3889 also has a typical set of narrow forbidden lines. The bluer system (z=0.3727) shows only broad Balmer lines and UV Fe II emission, making it highly unusual in its lack of narrow lines. A third system, which includes only unresolved absorption lines, is seen at a redshift, z=0.3878, intermediate between the two emission-line systems. While the observational signatures of binary nuclear black holes remain unclear, J1536+0441 is unique among all QSOs known in having two broad-line regions, indicative of two separate black holes presently accreting gas. The interpretation of this as a bound binary system of two black holes having masses of 10^8.9 and 10^7.3 solar masses, yields a separation of ~ 0.1 parsec and an orbital period of ~100 years. The separation implies that the two black holes are orbiting within a single narrow-line region, consistent with the characteristics of the spectrum. This object was identified as an extreme outlier of a Karhunen-Loeve Transform of 17,500 z < 0.7 QSO spectra from the SDSS. The probability of the spectrum resulting from a chance superposition of two QSOs with similar redshifts is estimated at 2X10^-7, leading to the expectation of 0.003 such objects in the sample studied; however, even in this case, the spectrum of the lower redshift QSO remains highly unusual.
astro-ph.GA:We use velocity and metallicity information from SDSS and SEGUE stellar spectroscopy to fit an orbit to the narrow $63^\circ$ stellar stream of Grillmair and Dionatos. The stars in the stream have a retrograde orbit with eccentricity $e = 0.33$ (perigalacticon of 14.4 kpc and apogalacticon of 28.7 kpc) and inclination approximately $i \sim 35^\circ$. In the region of the orbit which is detected, it has a distance of about 7 to 11 kpc from the Sun. Assuming a standard disk plus bulge and logarithmic halo potential for the Milky Way stars plus dark matter, the stream stars are moving with a large space velocity of approximately $276 \rm km s^{-1}$ at perigalacticon. Using this stream alone, we are unable to determine if the dark matter halo is oblate or prolate. The metallicity of the stream is [Fe/H] $= -2.1\pm0.1$. Observed proper motions for individual stream members above the main sequence turnoff are consistent with the derived orbit. None of the known globular clusters in the Milky Way have positions, radial velocities, and metallicities that are consistent with being the progenitor of the GD-1 stream.
astro-ph.GA:We study the polarization properties of relativistic reconfinement shocks with chaotic magnetic fields. Using our hydrodynamical model of their structure, we calculate synthetic polarization maps, longitudinal polarization profiles and discuss the spatially averaged polarization degree as a function of jet half-opening angle Theta_j, jet Lorentz factor Gamma_j and observer inclination angle to the jet axis theta_{obs}. We find, that for theta_{obs} <= Theta_j the wave electric vectors are parallel in the vicinity of the structure ends and perpendicular in between, while for theta_{obs} > Theta_j the polarization can only be perpendicular. The spatially averaged polarization degree does not exceed 30%. Parallel average polarization, with polarization degrees lower than 10%, have been found for theta_{obs} < Theta_j under the condition Gamma_j * Theta_j > 1. As earlier works predicted the parallel polarization from relativistic conical shocks, we explain our results by discussing conical shocks with divergent upstream flow.
astro-ph.GA:Two compact HI clouds which seem to belong to the Ophiuchus superbubble were studied at ~30" resolution using the Very Large Array (VLA) in C and D configurations together with the Green Bank Telescope (GBT) providing the short-spacing flux. Here we present preliminary results of the data analysis.
astro-ph.GA:We present Submillimeter Array observations toward the 10^{4.7} Lsun star-forming region G240.31+0.07, in the J=2-1 transition of 12CO and 13CO and at 1.3 mm continuum, as well as the 12CO and 13CO observations from the Caltech Submillimeter Observatory to recover the extended emission filtered out by the interferometer. Maps of the 12CO and 13CO emission show a bipolar, wide-angle, quasi-parabolic molecular outflow, roughly coincident with an IR nebula revealed by the Spitzer 3.6 and 4.5 micron emission. The outflow has ~98 Msun molecular gas, making it one of the most massive molecular outflows known, and resulting in a very high mass-loss rate of 4.1 by 10^{-3} Msun yr^{-1} over a dynamical timescale of 2.4 by 10^4 yr. The 1.3 mm continuum observations with a 4" by 3" beam reveal a flattened dusty envelope of ~150 Msun, which is further resolved with a 1.2" by 1" beam into three dense cores with a total mass of ~40 Msun. The central mm core, showing evidence of active star formation, approximately coincides with the geometric center of the bipolar outflow thus most likely harbors the powering source of the outflow. Overall our observations provide the best case to date of a well-defined wide-angle molecular outflow in a >10^4 Lsun star-forming region. The outflow is morphologically and kinematically similar to low-mass protostellar outflows but has two to three orders of magnitude greater mass, momentum, and energy, and is apparently driven by an underlying wide-angle wind, hence further supports that high-mass stars up to late-O types, even in a crowded clustering environment, can form as a scaled-up version of low-mass star formation.
astro-ph.GA:Thin accretion discs around massive compact objects can support slow pressure modes of oscillations in the linear regime that have azimuthal wavenumber $m=1$. We consider finite, flat discs composed of barotropic fluid for various surface density profiles and demonstrate--through WKB analysis and numerical solution of the eigenvalue problem--that these modes are stable and have spatial scales comparable to the size of the disc. We show that the eigenvalue equation can be mapped to a Schr\"odinger-like equation. Analysis of this equation shows that all eigenmodes have discrete spectra. We find that all the models we have considered support negative frequency eigenmodes; however, the positive eigenfrequency modes are only present in power law discs, albeit for physically uninteresting values of the power law index $\beta$ and barotropic index $\gamma$.
astro-ph.GA:We aim to study the structure, dynamics and physical conditions of Gomez's Hamburger (IRAS 18059-3211; GoHam). We confirm that GoHam essentially consists of a flaring disk in keplerian rotation around a young, probably pre-MS star. We present high resolution SMA maps of 12CO J=2-1, 13CO J=2-1, 12CO J=3-2, and C17O J=3-2, as well as data on 12CO J=6-5 and the continuum flux at these wavelengths. Spatial resolutions up to 1" are obtained. Except for the C17O data, the dynamical ranges are larger than 10. The maps are compared to a numerical model, which simulates the emission of a rotating disk with the expected general properties of such objects; a very satisfactory fitting of our maps is obtained. The meaning and reliability of our results are thoroughly discussed. Our observations allow measurement of the main properties of GoHam at scales between ~ 1" (~ 5 10^15 cm, for the assumed distance, 300 pc) and the total extent of the nebula, 14". We are able to measure the global structure of the gas-rich disk, which is found to be flaring, and its dynamics, which is clearly dominated by keplerian rotation, with a very small degree of turbulence. The combination of different lines, particularly showing different opacities, allows us to reasonably estimate the distributions of the gas temperature and density. We clearly find a significant and sharp increase in temperature at large distances from the equator, accompanied by a decrease in density of the same order. Finally, we identify and study a condensation in the southern part of the disk that has no counterparts in the rest of the nebula. This condensation is quite extended (about 5 10^15 cm), contains a significant amount of mass (roughly, ~ 6 10^-3 Mo), and seems to be associated with a detectable distortion of the global rotation kinematics.
astro-ph.GA:We present a study of the X-ray properties of a sample of six nearby late-type spiral galaxies based on XMM-Newton observations. Since our primary focus is on the linkage between X-ray emission and star formation in extended, extranuclear galactic disks, we have selected galaxies with near face-on aspect and sufficient angular extent so as to be readily amenable to investigation with the moderate spatial resolution afforded by XMM-Newton. After excluding regions in each galaxy dominated by bright point sources, we study both the morphology and spectral properties of the residual X-ray emission, comprised of both diffuse emission and the integrated signal of the fainter discrete source populations. The soft X-ray morphology generally traces the inner spiral arms and shows a strong correlation with the distribution of UV light, indicative of a close connection between the X-ray emission and recent star formation. The soft (0.3-2 keV) X-ray luminosity to star formation rate (SFR) ratio varies from 1-5 x 10^39 erg/s(/Msun/yr), with an indication that the lower range of this ratio relates to regions of lower SFR density. The X-ray spectra are well matched by a two-temperature thermal model with derived temperatures of typically ~0.2 keV and ~0.65 keV, in line with published results for other normal and star-forming galaxies. The hot component contributes a higher fraction of the soft luminosity in the galaxies with highest X-ray/SFR ratio, suggesting a link between plasma temperature and X-ray production efficiency. The physical properties of the gas present in the galactic disks are consistent with a clumpy thin-disk distribution, presumably composed of diffuse structures such as superbubbles together with the integrated emission of unresolved discrete sources including young supernova remnants.
astro-ph.GA:We present preliminary results from the highest available signal-to-noise rest-frame 2-8um spectra of z~2 ULIRGs. Our 10 targets are selected for their deep silicate absorption features based on previous shallower IRS spectra. The goal of this follow-up program is: 1) allow for a more accurate analysis of inner/hot dust continuum, 2) detecting the 3.3um and 6.2um PAH features, and 3) detecting molecular absorption features such as due to water ice and hydrocarbons (HACs). We find that the 3.4um HAC absorption feature is observed in four sources, while the 3.05um water ice feature is observed in three of the sources. The HAC detectability is higher and ice detectability lower than expected from local ULIRGs, but consistent with a more AGN-dominated sample such as this one. Where ice is detected, the ice-to-silicate ratio is somewhat lower than many local ULIRGs implying on average thinner ice mantles. One source shows the, to our knowledge, highest redshift reported detection of the 3.3um PAH feature (along with a previously detected 6.2um feature). The strength of the 3.3um feature is as expected for a starburst-dominated ULIRG.
astro-ph.GA:We compare the metallicities in high-redshift quasars to the star formation rates (SFR) in their host galaxies using measurements of broad emission lines and far-infrared (FIR) luminosities. The FIR emission indicates the level of ongoing massive starbursts in the galaxy, whereas the abundance of metals in the gas surrounding the quasar indicates the amount of star formation which occurred before the visible quasar phase began. The results of this study can be used to constrain the late stages of starburst-quasar evolution. We detect high metallicities throughout the sample, up to several times solar, confirming that star formation must have begun before the visible quasar phase. However, we do not detect a trend in metallicity versus current SFR.
astro-ph.GA:We present results of deep echelle spectrophotometry of the brightest knot of the HH202 in the Orion Nebula --HH202-S-- using the ultraviolet Visual Echelle Spectrograph (UVES). The high spectral resolution has permitted to separate the component associated with the ambient gas from that associated with the gas flow. We derive electron densities and temperatures for both components, as well as the chemical abundances of several ions and elements from collisionally excited lines, including the first determinations of Ca^{+} and Cr^{+} abundances in the Orion Nebula. We also calculate the He^{+}, C^{2+}, O^{+} and O^{2+} abundances from recombination lines. The difference between the O^{2+} abundances determined from collisionally excited and recombination lines --the so-called abundance discrepancy factor-- is 0.35 dex and 0.11 dex for the shock and nebular components, respectively. Assuming that the abundance discrepancy is produced by spatial variations in the electron temperature, we derive values of the temperature fluctuation parameter, t^2, of 0.050 and 0.016, for the shock and nebular components, respectively. Interestingly, we obtain almost coincident t^2 values for both components from the analysis of the intensity ratios of He I lines. We find significant departures from case B predictions in the Balmer and Paschen flux ratios of lines of high principal quantum number n. We analyze the ionization structure of HH202-S, finding enough evidence to conclude that the flow of HH202-S has compressed the ambient gas inside the nebula trapping the ionization front. We measure a strong increase of the total abundances of nickel and iron in the shock component, the abundance pattern and the results of photoionization models for both components are consistent with the partial destruction of dust after the passage of the shock wave in HH202-S.
astro-ph.GA:Although the stellar initial mass function (IMF) has only been directly determined in star clusters it has been manifoldly applied on galaxy-wide scales. But taking the clustered nature of star formation into account the galaxy-wide IMF is constructed by adding all IMFs of all young star clusters leading to an integrated galactic initial mass function (IGIMF). The IGIMF is top-light compared to the canonical IMF in star clusters and steepens with decreasing total star formation rate (SFR). This discrepancy is marginal for large disk galaxies but becomes significant for SMC-type galaxies and less massive ones. We here construct IGIMF-based relations between the total FUV and NUV luminosities of galaxies and the underlying SFR. We make the prediction that the Halpha luminosity of star forming dwarf galaxies decreases faster with decreasing SFR than the UV luminosity. This turn-down of the Halpha-UV flux ratio should be evident below total SFRs of 10^-2 M_sun/yr.
astro-ph.GA:Recent work has produced a wealth of data concerning the chemical evolution of the galactic bulge, both for stars and nebulae. Present theoretical models generally adopt a limited range of such constraints, frequently using a single chemical element (usually iron), which is not enough to describe it unambiguously. In this work, we take into account constraints involving as many chemical elements as possible, basically obtained from bulge nebulae and stars. Our main goal is to show that different scenarios can describe, at least partially, the abundance distribution and several distance-independent correlationss for these objects. Three classes of models were developed. The first is a one-zone, single-infall model, the second is a one-zone, double-infall model and the third is a multizone, double infall model. We show that a one-zone model with a single infall episode is able to reproduce some of the observational data, but the best results are achieved using a multizone, double infall model.
astro-ph.GA:We discuss whether the Gaussian is a reasonable approximation of the velocity distribution of stellar systems that are not spherically distributed. By using a non-Gaussian velocity distribution to describe the sources in the Large Magellanic Cloud (LMC), we reinvestigate the expected microlensing parameters of a lens population isotropically distributed either in the Milky Way halo or in the LMC (self lensing). We compare our estimates with the experimental results of the MACHO collaboration. An interesting result that emerges from our analysis is that, moving from the Gaussian to the non-Gaussian case, we do not observe any change in the form of the distribution curves describing the rate of microlensing events for lenses in the Galactic halo. The corresponding expected timescales and number of expected events also do not vary. Conversely, with respect to the self-lensing case, we observe a moderate increase in the rate and number of expected events. We conclude that the error in the estimate of the most likely value for the MACHO mass and the Galactic halo fraction in form of MACHOs, calculated with a Gaussian velocity distribution for the LMC sources, is not higher than 2%.
astro-ph.GA:In this paper we show results of numerical simulations for the turbulence in the interstellar medium. These results were obtained using a Riemann solver-free numerical scheme for high-Mach number hyperbolic equations. Here we especially concentrate on the physical properties of the ISM. That is, we do not present turbulence simulations trimmed to be applicable to the interstellar medium. The simulations are rather based on physical estimates for the relevant parameters of the interstellar gas.   Applying our code to simulate the turbulent plasma motion within a typical interstellar molecular cloud, we investigate the influence of different equations of state (isothermal and adiabatic) on the statistical properties of the resulting turbulent structures. We find slightly different density power spectra and dispersion maps, while both cases yield qualitatively similar dissipative structures, and exhibit a departure from the classical Kolmogorov case towards a scaling described by the She-Leveque model.   Solving the full energy equation with realistic heating/cooling terms appropriate for the diffuse interstellar gas, we are able to reproduce a realistic two-phase distribution of cold and warm plasma. When extracting maps of polarised intensity from our simulation data, we find encouraging similarity to actual observations. Finally, we compare the actual magnetic field strength of our simulations to its value inferred from the rotation measure. We find these to be systematically different by a factor of about 1.5, thus highlighting the often underestimated influence of varying line-of-sight particle densities on the magnetic field strength derived from observed rotation measures.
astro-ph.GA:Preliminary results are presented about a fully self-consistent N-body simulation of a sample of four massive globular clusters in close interaction within the central region of a galaxy. The N-body representation (with N=1.5x10^6 particles in total) of both the clusters and the galaxy allows to include in a natural and self-consistent way dynamical friction and tidal interactions. The results confirm the decay and merging of globulars as a viable scenario for the formation/accretion of compact nuclear clusters. Specifically: i) the frictional orbital decay is about 2 times faster than that predicted by the generalized Chandrasekhar formula; ii) the progenitor clusters merge in less than 20 galactic core-crossing times; iii) the NC configuration keeps quasi-stable at least within 70 galactic core-crossing times.
astro-ph.GA:We present a study of outflow and feedback in the well-known Seyfert 2 galaxy Markarian 573 using high angular resolution long-slit spectrophotometry obtained with the Hubble Space Telescope Imaging Spectrograph (STIS). Through analysis of the kinematics and ionization state of a biconical outflow region emanating from the nucleus, we find that the outflow does not significantly accelerate the surrounding host-galaxy interstellar gas and is too weak to be a strong ionization mechanism in the extended emission regions. Instead, the excitation of the extended regions is consistent with photoionization by the active nucleus. From energetics arguments we show that the nuclear outflow is slow and heavy and has a mechanical luminosity that is only ~1% of the estimated bolometric luminosity of the system. The energy in the outflow is able to mildly shape the gas in the extended regions but appears to be insufficient to unbind it, or even to plausibly disrupt star formation. These results are at odds with the picture of strong AGN feedback that has been invoked to explain certain aspects of galaxy evolution.
astro-ph.GA:N-body simulations show that "box-shaped bulges" of edge-on galaxies are not bulges at all: they are bars seen side-on. The two components that we readily see in edge-on Sb galaxies like NGC 4565 are a disk and a bar, but face-on SBb galaxies always show a disk, a bar, and a (pseudo)bulge. Where is the (pseudo)bulge in NGC 4565? We use archival Hubble Space Telescope K-band and Spitzer Space Telescope 3.6 um images to penetrate the dust in NGC 4565. We find a high surface brightness, central stellar component, distinct from the boxy bar and from the galaxy's disk. Its minor-axis profile has a Sersic index of 1.33+/-0.12, so it is a pseudobulge. The pseudobulge has the smallest scale height (~90 pc) of any component in the galaxy, in contrast to ~740 pc for the boxy bar plus thin disk. The disky pseudobulge is also much less luminous than the boxy bar, so the true (pseudo)bulge-to-total luminosity ratio of the galaxy is much less than previously thought. We infer that the pseudobulge-to-total luminosity ratios of edge-on galaxies with box-shaped bulges have generally been overestimated. Therefore more galaxies than we have recognized contain little or no evidence of a merger-built classical bulge. This challenges our picture of galaxy formation by hierarchical clustering, because it is difficult to grow big galaxies without also making a big classical bulge. Solving the puzzle of the "missing pseudobulge" in NGC 4565 further increases our confidence that we understand box-shaped bulges correctly as edge-on bars. This supports our developing picture of the formation of pseudobulges -- both edge-on bars and disky central components -- by secular evolution in isolated galaxies.
astro-ph.GA:[Abridged] We present Gemini-N GMOS-IFU observations of the central starburst clumps and inner wind of M82, together with WIYN DensePak IFU observations of the inner 2x0.9kpc of the disk. These cover the emission lines of H$\alpha$, [NII], [SII], and [SIII]. We were able to accurately decompose the emission line profiles into multiple narrow components (FWHM~30-130kms) superimposed on a broad (FWHM 150-350kms) feature. This paper is the first of a series examining the optical structure of M82's disk and inner wind; here we focus on the ionized gaseous and stellar dynamics and present maps of the relevant emission line properties.   Our observations show that ionized gas in the starburst core of M82 is dynamically complex. Localised line splitting of up to 100kms in the narrow component is associated with expanding shells of compressed, cool, photoionized gas. We have been able to associate some of this inner-wind gas with a distinct outflow channel characterised by its dynamics and gas density patterns, and we discuss the consequences of this discovery in terms of the developing wind outflow.   The broad optical emission line component is observed to become increasingly important moving outward along the outflow channel, and in general with increasing height above/below the plane. Following our recent work on the origins of this component, we associate it with turbulent gas in wind-clump interface layers and hence sites of mass loading, meaning that the turbulent mixing of cooler gas into the outflowing hot gas must become increasingly important with height, and provides powerful direct evidence for the existence of mass-loading over a large, spatially extended area.
astro-ph.GA:Adequate modelling of the multiphase interstellar medium requires optically thin radiative cooling, comprising an inherent thermal instability. The size of the occurring condensation and evaporation interfaces is determined by the so-called Field-length, which gives the dimension at which the instability is significantly damped by thermal conduction. Our aim is to study the relevance of conduction scale effects in the numerical modelling of a bistable medium and check the applicability of conventional and alternative adaptive mesh techniques. The low physical value of the thermal conduction within the ISM defines a multiscale problem, hence promoting the use of adaptive meshes. We here introduce a new refinement strategy that applies the Field condition by Koyama & Inutsuka as a refinement criterion. The described method is very similar to the Jeans criterion for gravitational instability by Truelove and efficiently allows to trace the unstable gas situated at the thermal interfaces. We present test computations that demonstrate the greater accuracy of the newly proposed refinement criterion in comparison to refinement based on the local density gradient. Apart from its usefulness as a refinement trigger, we do not find evidence in favour of the Field criterion as a prerequisite for numerical stability.
astro-ph.GA:Stellar feedback in galactic bulges plays an essential role in shaping the evolution of galaxies. To quantify this role and facilitate comparisons with X-ray observations, we conduct 3D hydrodynamical simulations with the adaptive mesh refinement code, FLASH, to investigate the physical properties of hot gas inside a galactic bulge, similar to that of our Galaxy or M31. We assume that the dynamical and thermal properties of the hot gas are dominated by mechanical energy input from SNe, primarily Type Ia, and mass injection from evolved stars as well as iron enrichment from SNe. We study the bulge-wide outflow as well as the SN heating on scales down to ~4 pc. An embedding scheme that is devised to plant individual SNR seeds, allows to examine, for the first time, the effect of sporadic SNe on the density, temperature, and iron ejecta distribution of the hot gas as well as the resultant X-ray morphology and spectrum. We find that the SNe produce a bulge wind with highly filamentary density structures and patchy ejecta. Compared with a 1D spherical wind model, the non-uniformity of simulated gas density, temperature, and metallicity substantially alters the spectral shape and increases the diffuse X-ray luminosity. The differential emission measure as a function of temperature of the simulated gas exhibits a log-normal distribution, with a peak value much lower than that of the corresponding 1D model. The bulk of the X-ray emission comes from the relatively low temperature and low abundance gas shells associated with SN blastwaves. SN ejecta are not well mixed with the ambient medium, at least in the bulge region. These results, at least partly, account for the apparent lack of evidence for iron enrichment in the soft X-ray-emitting gas in galactic bulges and intermediate-mass elliptical galaxies.[...]
astro-ph.GA:During a survey for stars with disks in the Taurus star-forming region using the Spitzer Space Telescope, we have discovered a pair of young brown dwarfs, FU Tau A and B, in the Barnard 215 dark cloud. They have a projected angular separation of 5.7", corresponding to 800 AU at the distance of Taurus. To assess the nature of these two objects, we have obtained spectra of them and have constructed their spectral energy distributions. Both sources are young (~1 Myr) according to their Halpha emission, gravity-sensitive spectral features, and mid-IR excess emission. The proper motion of FU Tau A provides additional evidence of its membership in Taurus. We measure spectral types of M7.25 and M9.25 for FU Tau A and B, respectively, which correspond to masses of ~0.05 and ~0.015 M\cdot according to the evolutionary models of Chabrier and Baraffe. FU Tau A is significantly overluminous relative to an isochrone passing through FU Tau B and relative to other members of Taurus near its spectral type, which may indicate that it is an unresolved binary. FU Tau A and B are likely to be components of a binary system based on the low probability (~3x10^-4) that Taurus would produce two unrelated brown dwarfs with a projected separation of a </- 6". Barnard 215 contains only one other young star and is in a remote area of Taurus, making FU Tau A and B the first spectroscopically-confirmed brown dwarfs discovered forming in isolation rather than in a stellar cluster or aggregate. Because they were born in isolation and comprise a weakly bound binary, dynamical interactions with stars could not have played a role in their formation, and thus are not essential for the birth of brown dwarfs. ERRATUM: The K-band magnitude for FU Tau B in Table 1 is incorrect and should be 13.33. The bolometric luminosity of FU Tau B in Table 3 and Figure 5 is incorrect because of that mistake and a separate arithmetic error. The correct value of the luminosity is 0.0039 Lsun. FU Tau A and B exhibited different isochronal ages in the original Hertzsprung-Russell diagram in Figure 5, which was unexpected for members of a binary system. This discrepancy is reduced in the corrected version of Figure 5 since both objects are now above the isochrone for 1 Myr. Given the large uncertainties in model isochrones at such young ages, the positions of FU Tau A and B in Figure 5 could be roughly consistent with coevality.
astro-ph.GA:Barium is a key element in constraining the evolution of the (not well understood) r-process in the first galactic stars and currently the Ba abundances in these very metal-poor stars were mostly measured under the Local Thermodynamical Equilibrium (LTE) assumption, which may lead in general to an underestimation of Ba. We present here determinations of the barium abundance taking into account the non-LTE (NLTE) effects in a sample of extremely metal-poor stars (EMP stars): 6 turnoff stars and 35 giants. The NLTE profiles of the three unblended Ba II lines (455.4, 585.3, 649.6nm) have been computed. The computations were made with a modified version of the MULTI code, applied to an atomic model of the Ba atom with 31 levels of Ba I, 101 levels of Ba II, and compared to the observations. The ratios of the NLTE abundances of barium relative to Fe are slightly shifted towards the solar ratio. In the plot of [Ba/Fe] versus [Fe/H], the slope of the regression line is slightly reduced as is the scatter. In the interval -3.3 <[Fe/H] < -2.6, [Ba/Fe] decreases with a slope of about 1.4 and a scatter close to 0.44. For [Fe/H] <-3.3 the number of stars is not sufficient to decide whether [Ba/Fe] keeps decreasing (and then CD-38:245 should be considered as a peculiar "barium-rich star") or if a plateau is reached as soon as [Ba/Fe] ~ -1. In both cases the scatter remains quite large, larger than what can be accounted for by the measurement and determination errors, suggesting the influence of a complex process of Ba production, and/or inefficient mixing in the early Galaxy.
astro-ph.GA:Optical studies of starbursts, AGN and their connections usually leave out galaxies whose emission lines are too weak to warrant reliable measurement and classification. Yet, weak line galaxies abound, and deserve a closer look. We show that these galaxies are either massive, metal rich star-forming systems, or, more often, LINERs. From our detailed stellar population analysis, we find that these LINERs have stopped forming stars long ago. Moreover, their ionizing radiation field is amazingly consistent with that expected from their old stellar populations alone. The black-hole in the centers of these massive, early-type galaxies is not active enough to overwhelm stellar ionization, and thus, despite their looks, they should not be called AGN.
astro-ph.GA:Galaxies are usually classified as star forming or active by using diagnostic diagrams, such as [N II]/Halpha vs. [O III]/Hbeta. Active galaxies are further classified into Seyfert or LINER-like sources. We claim that a non-negligible fraction of galaxies classified as LINERs in the Sloan Digital Sky Survey are in fact ionized by hot post-AGB stars and white dwarfs.
astro-ph.GA:The runaway star HD34078, initially selected to investigate small scale structure in a foreground diffuse cloud has been shown to be surrounded by highly excited H2. We first search for an association between the foreground cloud and HD34078. Second, we extend previous investigations of temporal absorption line variations (CH, CH+, H2) in order to better characterize them. We have mapped the CO(2-1) emission at 12 arcsec resolution around HD34078's position, using the 30 m IRAM antenna. The follow-up of CH and CH+ absorption lines has been extended over 5 more years. In parallel, CH absorption towards the reddened star Zeta Per have been monitored to check the homogeneity of our measurements. Three more FUSE spectra have been obtained to search for N(H2) variations. CO observations show a pronounced maximum near HD34078's position, clearly indicating that the star and diffuse cloud are associated. The optical spectra confirm the reality of strong, rapid and correlated CH and CH+ fluctuations. On the other hand, N(H2, J=0) has varied by less than 5 % over 4 years. We also discard N(CH) variations towards Zeta Per at scales less than 20 AU. Observational constraints from this work and from 24 micron dust emission appear to be consistent with H2 excitation but inconsistent with steady-state bow shock models and rather suggest that the shell of compressed gas surrounding HD34078, is seen at an early stage of the interaction. The CH and CH+ time variations as well as their large abundances are likely due to chemical structure in the shocked gas layer located at the stellar wind/ambient cloud interface. Finally, the lack of variations for both N(H2, J=0) towards HD34078 and N(CH) towards Zeta Per suggests that quiescent molecular gas is not subject to pronounced small-scale structure.
astro-ph.GA:Cool subdwarfs of types K and M are the fainter counterparts of cool main sequence dwarfs that dominate the Galactic population. In this paper we present the results of an optical speckle survey of 62 confirmed cool subdwarf systems within 60 pc. We have resolved two new companions and confirmed two previously known companions with separations 0\farcs13 to 3\farcs29. After including previously known wide companions and all known spectroscopic binaries, we determine the multiplicity rate of cool subdwarfs to be 26$\pm$6%, which is somewhat lower than comparable main sequence stars, which have a multiplicity rate of 37$\pm$5%. We find that only 3% of the cool subdwarfs surveyed have companions within 10 AU, 3% have companions between 10 and 100 AU, and 14% have companions beyond 100 AU. The other 6% of cool subdwarfs are spectroscopic binaries. This is very different from K/M dwarfs that have most companions (13%) at separations closer than 10 AU. However, because a search for close binaries among a large sample of nearby cool subdwarfs remains elusive, it is not yet settled whether or not the multiplicity rates are significantly different. Nonetheless, several different observational results and theories pointing to a possible dearth of subdwarf multiples are discussed.
astro-ph.GA:There is a large observational scatter toward low velocities in the stellar mass Tully-Fisher relation if disturbed and compact objects are included. However, this scatter can be eliminated if one replaces rotation velocity with $\rm S_{\rm 0.5}$, a quantity that includes a velocity dispersion term added in quadrature with the rotation velocity. In this work we use a large suite of hydrodynamic N-body galaxy merger simulations to explore a possible mechanism for creating the observed relations. Using mock observations of the simulations, we test for the presence of observational effects and explore the relationship between $\rm S_{\rm 0.5}$ and intrinsic properties of the galaxies. We find that galaxy mergers can explain the scatter in the TF as well as the tight $\rm S_{\rm 0.5}$-stellar mass relation. Furthermore, $\rm S_{\rm 0.5}$ is correlated with the total central mass of a galaxy, including contributions due to dark matter.
astro-ph.GA:We propose a new chemical evolution model aimed at explaining the chemical properties of globular clusters (GC) stars. Our model depends upon the existence of (i) a peculiar pre-enrichment phase in the GC's parent galaxy associated with very low-metallicity Type II supernovae (SNeII), and (ii) localized inhomogeneous enrichment from a single Type Ia supernova (SNeIa) and intermediate-mass (4 7Msun) asymptotic giant branch (AGB) field stars. GC formation is then assumed to take place within this chemically-peculiar region. Thus, in our model the first low-mass GC stars to form are those with peculiar abundances (i.e., O-depleted and Na-enhanced) while ``normal'' stars (i.e., O-rich and Na depleted) are formed in a second stage when self-pollution from SNeII occurs and the peculiar pollution from the previous phase is dispersed. In this study, we focus on three different GCs: NGC6752, NGC6205 (M13) and NGC2808. We demonstrate that, within this framework, a model can be constructed which is consistent with (i) the elemental abundance anti-correlations, (ii) isotopic abundance patterns, and (iii) the extreme [O/Fe] values observed in NGC2808 and M13, without violating the global constraints of approximately unimodal [Fe/H] and C+N+O.
astro-ph.GA:We present high resolution (R = 75,000-100,000) mid-infrared spectra of the high-mass embedded young star IRS 1 in the NGC 7538 star-forming region. Absorption lines from many rotational states of C2H2, 13C12CH2, CH3, CH4, NH3, HCN, HNCO, and CS are seen. The gas temperature, column density, covering factor, line width, and Doppler shift for each molecule are derived. All molecules were fit with two velocity components between -54 and -63 km/s. We find high column densities (~ 10e16 cm^2) for all the observed molecules compared to values previously reported and present new results for CH3 and HNCO. Several physical and chemical models are considered. The favored model involves a nearly edge-on disk around a massive star. Radiation from dust in the inner disk passes through the disk atmosphere, where large molecular column densities can produce the observed absorption line spectrum.
astro-ph.GA:We present accurate trigonometric parallaxes for 20 new members of the 25 pc white dwarf sample as part of the DENSE project (Discovery and Evalution of Nearby Stellar Embers, http://www.DenseProject.com). Previously, there were a total of 112 white dwarf systems with trigonometric parallaxes placing them within 25 pc and of these, 99 have trigonometric parallaxes known to better than 10%. Thus, the 20 new members presented in this work represent a 20% increase in the number of white dwarfs accurately known to be within 25 pc. In addition, we present updated parallaxes for seven known white dwarfs within 10 pc that have been observed as part of the ASPENS initiative (Astrometric Search for Planets Encircling Nearby Stars) to monitor nearby southern red and white dwarfs for astrometric perturbations from unseen companions. Including a few white dwarf companions and white dwarfs beyond 25 pc, we present a total of 33 trigonometric parallaxes. We perform atmospheric modeling for white dwarfs to determine physical parameters (i.e., effective temperature, log g, mass, and white dwarf age). Finally, a new ZZ Ceti pulsating white dwarf was identified and revised constraints are placed on two mixed H/He atmosphere cool white dwarfs that display continuum absorption in the near-infrared.
astro-ph.GA:Polarisation measurements of pulsars and of their pulsar wind nebulae (PWNe) are uniquely able to provide deep insights into the highly magnetised relativistic environment of young, rotation-powered isolated neutron stars (INSs). Besides the radio band, optical observations are primarily suited to providing such insights. The first INS for which optical polarisation observations were performed is the Crab pulsar which is also the brightest one (V=16.5). For this reason, the Crab pulsar is also the only INS for which repeated, phase-resolved polarisation measurements have been performed through the years. Moreover, it is the only case, together with the much fainter and distant PSR B0540-69 in the Large Magellanic Cloud (LMC), of an optical pulsar embedded in an optical PWN. Thus, the Crab is a perfect test case to study the optical polarisation properties of pulsars and of their PWNe. In this paper, we review the polarisation properties of the Crab pulsar and of its PWN in the optical and ultraviolet domains, we summarise the state of the art of the polarisation observations of other INSs, and we outline perspectives for INS polarisation studies with present and future generations of optical telescopes
astro-ph.GA:We investigate whether the formation mechanism of boxy and peanut-shaped (B/PS) bulges could depend on the gas content of the galaxy. We have performed N-body simulations with and without a gaseous component. In the second case star formation/feedback recipes have also been implemented to create new stellar populations. As in many previous studies, in our N-body collisionless simulation, the B/PS is due to the classical break in the z mirror symmetry lasting roughly 200 Myr. When a gaseous component and star formation recipes are added to the simulation, the bulge-growing mechanism is quite different. The young stellar population that is born in the thin gaseous disc rapidly populates vertical resonant orbits triggered by the combined effects of the linear horizontal and vertical ILRs. This leads to a B/PS bulge mainly made of stellar material younger than the surrounding population. The non-linear analysis of the orbital structure shows that the main orbit family responsible for the B/PS is not the same in the two cases. The 2:2:1 orbits prevail in the collisionless simulation whereas additional asymmetrical families contribute to the B/PS if a dissipative component is present and can form new stars. We found that 2:3:1 and 2:5:1 orbits trap a significant fraction of the mass. A flat ringed discy stellar component also appears simultaneously with the thickening of the young population. It is due to the star formation in a nuclear gaseous disc located in the central kpc, inside the ILR, and accumulated there by the torques exerted by the large-scale bar. Remarkably, it remains flat throughout the simulation although it develops a nuclear bar, leading to a double-barred galaxy. We predict that two populations of B/PS bulges could exist and even coexist in the same galaxy.
astro-ph.GA:The interstellar medium (ISM) is subject, on one hand, to heating and cooling processes that tend to segregate it into distinct phases due to thermal instability (TI), and on the other, to turbulence-driving mechanisms that tend to produce strong nonlinear fluctuations in all the thermodynamic variables. In this regime, large-scale turbulent compressions in the stable warm neutral medium (WNM) dominate the clump-formation process rather than the linear developent of TI. Cold clumps formed by this mechanism are often bounded by sharp density and temperature discontinuities, which however are not contact discontinuities as in the classical 2-phase model, but rather "phase transition fronts", across which there is net mass and momentum flux from the WNM into the clumps. The clumps grow mainly by accretion through their boundaries, are in both thermal and ram pressure balance with their surroundings, and are internally turbulent as well, thus also having significant density fluctuations inside. The temperature and density of the cold and warm gas around the phase transition fronts fluctuate with time and location due to fluctuations in the turbulent pressure. Moreover, shock-compressed diffuse unstable gas can remain in the unstable regime for up to a few Myr before it undergoes a phase transition to the cold phase. These processes populate the classically forbidden density and temperature ranges. Since gas at all temperatures appears to be present in bi- or tri-stable turbulence, we conclude that the word "phase" applies only locally, surrounding phase transition sites in the gas. Globally, the word "phase" must relax its meaning to simply denote a certain temperature or density range.
astro-ph.GA:Active galactic nuclei (AGN) in low surface brightness galaxies (LSBGs) have received little attention in previous studies. In this paper, we present detailed spectral analysis of 194 LSBGs from the Impey et al. (1996) APM LSBG sample which have been observed spectroscopically by the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). Our elaborate spectral analysis enables us to carry out, for the first time, reliable spectral classification of nuclear activities in LSBGs based on the standard emission line diagnostic diagrams in a rigorous way. Star-forming galaxies are common, as found in about 52% LSBGs. We find, contrary to some of the previous claims, that the fraction of galaxies containing an AGN is significantly lower than that found in nearby normal galaxies of high surface brightness. This is qualitatively in line with the finding of Impey et al. (2001). This result holds true even within each morphological type from Sa to Sc. LSBGs having larger central stellar velocity dispersions, or larger physical sizes, tend to have a higher chance to harbor an AGN. For three AGNs with broad emission lines, the black hole masses estimated from the emission lines are broadly consistent with the well known M-$\sigma_\ast$ relation established for normal galaxies and AGNs.
astro-ph.GA:We take advantage of the very simple morphology of RCW 120 -- a perfect bubble -- to understand the mechanisms triggering star formation around an HII region and to establish what kind of stars are formed there. We present 870 microns observations of RCW 120, obtained with the APEX-LABOCA camera. These show the distribution of cold dust, and thus of neutral material. We use Spitzer-MIPS observations at 24 and 70 microns to detect the young stellar objects (YSOs) present in this region and to estimate their evolutionary stages.   A layer of dense neutral material surrounds the HII region, having been swept up during the region's expansion. This layer has a mass greater than 2000 solar masses and is fragmented, with massive fragments elongated along the ionization front (IF). We measured the 24 microns flux of 138 sources. Of these, 39 are Class I or flat-spectrum YSOs observed in the direction of the collected layer. We show that several triggering mechanisms are acting simultaneously in the swept-up shell, where they form a second generation of stars. No massive YSOs are detected. However, a massive, compact 870 microns core lies adjacent to the IF. A 70 microns source with no 24 microns counterpart is detected at the same position. This source is a likely candidate for a Class 0 YSO. Also at 24 microns, we detect a chain of about ten regularly spaced Class I or flat spectrum sources, parallel to the IF, in the direction of the most massive fragment. We suggest that the formation of these YSOs is the result of Jeans gravitational instabilities in the collected layer. Finally, the 870 microns emission, the 24 microns emission, and the Halpha emission show the existence of an extended and partially ionized photodissociation region around RCW 120.
astro-ph.GA:We examine the UV and X-ray properties of 256 radio-quiet SDSS quasars (QSOs) observed in X-rays with Chandra and/or XMM-Newton in order to study the relationship between QSOs with broad CIV absorption lines (BALs; width >2000 km/s) and those with CIV mini-BALs (here defined to have widths of 1000--2000 km/s). Our sample includes 42 BAL and 48 mini-BAL QSOs. The relative X-ray brightness and hard spectral slopes of the mini-BAL population are, on average, intermediate between those of BAL and non-BAL QSOs, as might be expected if narrower and broader absorption line outflows are physically related. However, a significant population of mini-BALs has outflow velocities higher than would be expected for BAL QSOs of the same relative X-ray brightness. Consistenly strong X-ray absorption is apparently not required to accelerate at least some mini-BALs to high outflow velocities. Assuming the mini-BAL features are correctly attributed to intrinsic CIV absorption, we suggest that their observed properties may be explained if mini-BALs are "seeds" which can be accelerated to form BALs when sufficient X-ray shielding is present.   We also examine several QSOs with broad CIV absorption that have been recently reported to be unusually X-ray bright. Such cases are frequently mini-BAL QSOs, which as a population are generally brighter in X-rays than BAL QSOs. Pointed XMM-Newton observations also suggest that these sources (or unresolved neighbors) may have been previously observed in a high flux state.
astro-ph.GA:The slopes of interstellar reddening lines in the 2MASS J-H versus H-Ks diagrams for 26 areas in the inner Galaxy (from Vulpecula to Centaurus) are determined. For this aim we use the red-clump giants located inside and behind spiral arms, or behind dense dust clouds of the Local arm. In most of the investigated directions the ratio E(J-H)/E(H-K_s) is found to be between 1.9 and 2.0, taking the stars with the visual extinction less than 12 mag. The stars with larger extinction deviate down from the reddening lines corresponding to less reddened stars. Probably, this is related to the curvature of reddening lines due to the band-width effect. However, some of the deviating stars may be heavily reddened oxygen- and carbon-rich AGB stars (giants of the latest M subclasses or N-type carbon stars), and pre-main-sequence objects (YSOs).
astro-ph.GA:The band-width effect on interstellar reddening lines in the J-H vs. H-K_s diagram of the 2MASS survey is investigated using synthetic color indices and color excesses based on the Kurucz model atmospheres. At large interstellar reddenings (E(H-K_s) larger than 1.0) reddening lines deviate considerably from a straight line. The lines can be approximated by an equation: E(J-H) = r E(H-K_s) + s E(H-K_s)^2, where the slope coefficient, r, and the curvature coefficient, s, depend slightly on the intrinsic energy distribution of the source. The curvature of the reddening lines is confirmed by the J-H vs. H-K_s diagrams plotted by Straizys and Laugalys (2008) from 2MASS observations.
astro-ph.GA:Recent observations of the white dwarf (WD) populations in the Galactic globular cluster NGC 6397 suggest that WDs receive a kick of a few km/s shortly before they are born. Using our Monte Carlo cluster evolution code, which includes accurate treatments of all relevant physical processes operating in globular clusters, we study the effects of the kicks on their host cluster and on the WD population itself. We find that in clusters whose velocity dispersion is comparable to the kick speed, WD kicks are a significant energy source for the cluster, prolonging the initial cluster core contraction phase significantly so that at late times the cluster core to half-mass radius ratio is a factor of up to ~ 10 larger than in the no-kick case. WD kicks thus represent a possible resolution of the large discrepancy between observed and theoretically predicted values of this key structural parameter. Our modeling also reproduces the observed trend for younger WDs to be more extended in their radial distribution in the cluster than older WDs.
astro-ph.GA:The unified model of active galactic nuclei (AGN) predicts silicate emission features at 10 and 18 microns in type 1 AGN, and such features have now been observed in objects ranging from distant QSOs to nearby LINERs. More surprising, however, is the detection of silicate emission in a few type 2 AGN. By combining Gemini and Spitzer mid-infrared imaging and spectroscopy of NGC 2110, the closest known Seyfert 2 galaxy with silicate emission features, we can constrain the location of the silicate emitting region to within 32 pc of the nucleus. This is the strongest constraint yet on the size of the silicate emitting region in a Seyfert galaxy of any type. While this result is consistent with a narrow line region origin for the emission, comparison with clumpy torus models demonstrates that emission from an edge-on torus can also explain the silicate emission features and 2-20 micron spectral energy distribution of this object. In many of the best-fitting models the torus has only a small number of clouds along the line of sight, and does not extend far above the equatorial plane. Extended silicate-emitting regions may well be present in AGN, but this work establishes that emission from the torus itself is also a viable option for the origin of silicate emission features in active galaxies of both type 1 and type 2.
astro-ph.GA:Based on the kernel estimator and wavelet technique, we have identified 22 moving group candidates in the solar neighborhood from a sample which includes around 14,000 dwarfs and 6000 giants. Six of them were previously known as the Hercules stream, the Sirus-UMa stream, the Hyades stream, the Caster group, the Pleiades stream, and the IC 2391; five of them have also been reported by other authors. 11 moving group candidates, not previously reported in the literature, showprominent structures in dwarf or giant samples.Acatalog of moving group candidates in the solar neighborhood is presented in this work.
astro-ph.GA:The role played by protostellar feedback in clustered star formation is still a matter of debate. In particular, protostellar outflows have been proposed as a source of turbulence in cluster-forming clumps, which may provide support against global collapse for several free-fall times.   Here, we seek to test the above hypothesis in the case of the well-documented NGC 2264-C protocluster, byquantifying the amount of turbulence and support injected in the surrounding medium by protostellar outflows.   Using the HERA heterodyne array on the IRAM 30m telescope, we carried out an extensive mapping of NGC 2264-C in the three molecular line transitions 12CO(2-1), 13CO(2-1), and C18O(2-1). We found widespread high-velocity 12CO emission, testifying to the presence of eleven outflow lobes, closely linked to the compact millimeter continuum sources previously detected in the protocluster.   We carried out a detailed analysis of the dynamical parameters of these outflows, including a quantitative evaluation of the overall momentum flux injected in the cluster-forming clump. These dynamical parameters were compared to the gravitational and turbulent properties of the clump.   We show that the population of protostellar outflows identified in NGC 2264-C are likely to contribute a significant fraction of the observed turbulence but cannot efficiently support the protocluster against global collapse. Gravity appears to largely dominate the dynamics of the NGC 2264-C clump at the present time. It is however possible that an increase in the star formation rate during the further evolution of the protocluster will trigger sufficient outflows to finally halt the contraction of the cloud.
astro-ph.GA:OH(1720 MHz) masers are excellent signposts of interaction between supernova remnants(SNRs) and molecular clouds. Using the GBT and VLA we have surveyed 75 SNRs and six candidates for maser emission. Four new interacting SNRs are detected with OH masers: G5.4-1.2, G5.7-0.0, G8.7-0.1 and G9.7-0.0. The newly detected interacting SNRs G5.7-0.0 and G8.7-0.1 have TeV gamma-ray counterparts which may indicate a local cosmic ray enhancement. It has been noted that maser-emitting SNRs are preferentially distributed in the Molecular Ring and Nuclear Disk. We use the present and existing surveys to demonstrate that masers are strongly confined to within 50 degrees Galactic longitude at a rate of 15 percent of the total SNR population. All new detections are within 10 degrees Galactic longitude emphasizing this trend. Additionally, a substantial number of SNR masers have peak fluxes at or below the detection threshold of existing surveys. This calls into question whether maser surveys of Galactic SNRs can be considered complete and how many maser-emitting remnants remain to be detected in the Galaxy.
astro-ph.GA:Photon-dominated regions (PDRs) are expected to show a layered structure in molecular abundances and emerging line emission, which is sensitive to the physical structure of the region as well as the UV radiation illuminating it. We aim to study this layering in the Orion Bar, a prototypical nearby PDR with a favorable edge-on geometry. We present new maps of 2 by 2 arcminute fields at 14-23 arcsecond resolution toward the Orion Bar in the SO 8_8-9_9, H2CO 5_(1,5)-4_(1,4), 13CO 3-2, C2H 4_(9/2)-3_(7/2) and 4_(7/2)-3_(5/2), C18O 2-1 and HCN 3-2 transitions. The data reveal a clear chemical stratification pattern. The C2H emission peaks close to the ionization front, followed by H2CO and SO, while C18O, HCN and 13CO peak deeper into the cloud. A simple PDR model reproduces the observed stratification, although the SO emission is predicted to peak much deeper into the cloud than observed while H2CO is predicted to peak closer to the ionization front than observed. In addition, the predicted SO abundance is higher than observed while the H2CO abundance is lower than observed. The discrepancies between the models and observations indicate that more sophisticated models, including production of H2CO through grain surface chemistry, are needed to quantitatively match the observations of this region.
astro-ph.GA:We measure the Tully-Fisher relations of 14 lenticular galaxies (S0s) and 14 spirals. We use two measures of rotational velocity. One is derived directly from observed spatially-resolved stellar kinematics and the other from the circular velocities of mass models that include a dark halo and whose parameters are constrained by detailed kinematic modelling. Contrary to the naive expectations of theories of S0 formation, we find no significant difference between the Tully-Fisher relations of the two samples when plotted as functions of both brightness and stellar mass.
astro-ph.GA:We analyze the conditions for detection of CO(1-0) emission in the Large Magellanic Cloud (LMC), using the recently completed second NANTEN CO survey. In particular, we investigate correlations between CO integrated intensity and HI integrated intensity, peak brightness temperature, and line width at a resolution of 2.6' (~40 pc). We find that significant HI column density and peak brightness temperature are necessary but not sufficient conditions for CO detection, with many regions of strong HI emission not associated with molecular clouds. The large scatter in CO intensities for a given HI intensity persists even when averaging on scales of >200 pc, indicating that the scatter is not solely due to local conversion of HI into H_2 near GMCs. We focus on two possibilities to account for this scatter: either there exist spatial variations in the I(CO) to N(H_2) conversion factor, or a significant fraction of the atomic gas is not involved in molecular cloud formation. A weak tendency for CO emission to be suppressed for large HI linewidths supports the second hypothesis, insofar as large linewidths may be indicative of warm HI, and calls into question the likelihood of forming molecular clouds from colliding HI flows. We also find that the ratio of molecular to atomic gas shows no significant correlation (or anti-correlation) with the stellar surface density, though a correlation with midplane hydrostatic pressure P_h is found when the data are binned in P_h. The latter correlation largely reflects the increasing likelihood of CO detection at high HI column density.
astro-ph.GA:Recently, controversy has erupted over whether gas-rich spiral-spiral mergers are capable of forming {\it m$^{*}$} ellipticals. Measurements of $\sigma$$_{\circ}$ from the 2.29$\micron$ CO band-head for local LIRG/ULIRGs, suggest they are not. IR-bright mergers are often cited as the best candidates for forming massive ellipticals, so the recent observations have raised doubts about both the Toomre Merger Hypothesis and the fundamental assumptions of $\Lambda$-CDM galaxy formation models. However, kinematics obtained with the Calcium II Triplet at 8500 {\AA} suggest mergers are forming {\it m} $\ge$ {\it m$^{*}$} ellipticals. In this work, we show that kinematics derived from the CO stellar absorption band-head leads to a significant underestimation of the masses of LIRGs/ULIRGs. This is primarily due to the presence of a young population affecting CO band-head measurements.
astro-ph.GA:We present results of high resolution hydrodynamical simulations of the formation and evolution of dwarf galaxies. Our simulations start from cosmological initial conditions at high redshift. They include metal-dependent cooling, star formation, feedback from type II and type Ia supernovae and UV background radiation, with physical recipes identical to those applied in a previous study of Milky Way type galaxies. We find that a combination of feedback and the cosmic UV background results in the formation of galaxies with properties similar to the Local Group dwarf spheroidals, and that their effect is strongly moderated by the depth of the gravitational potential. Taking this into account, our models naturally reproduce the observed luminosities and metallicities. The final objects have halo masses between 2.3x10^8 and 1.1x10^9 solar masses, mean velocity dispersions between 6.5 and 9.7 kms-1, stellar masses ranging from 5x10^5 to 1.2x10^7 solar masses, median metallicities between [Fe/H] = -1.8 and -1.1, and half-light radii of the order of 200 to 300 pc, all comparable with Local Group dwarf spheroidals. Our simulations also indicate that the dwarf spheroidal galaxies observed today lie near a halo mass threshold around 10^9 solar masses, in agreement with stellar kinematic data, where supernova feedback not only suffices to completely expel the interstellar medium and leave the residual gas-free, but where the combination of feedback, UV radiation and self-shielding establishes a dichotomy of age distributions similar to that observed in the Milky Way and M31 satellites.
astro-ph.GA:The SEGUE survey obtained 240,000 moderate resolution (R = 1800) spectra from 3900 - 9000 Angstroms of fainter Milky Way stars (14.0 < g < 20.3) of a wide variety of spectral types, both main sequence and evolved objects, with the goal of studying the kinematics and populations of our Galaxy and its halo. The spectra are clustered in 212 regions spaced over three-quarters of the sky. Radial velocity accuracies for stars are 4 km/s at g < 18, degrading to 15 km/s at g = 20. For stars with S/N > 10 per resolution element, stellar atmospheric parameters are estimated, including metallicity, surface gravity, and effective temperature. SEGUE obtained 3500 square degrees of additional ugriz imaging (primarily at low Galactic latitudes) providing precise multi-color photometry (g,r,i = 2%), (u,z = 3%) and astrometry (0.1 arcsec) for spectroscopic target selection. The stellar spectra, imaging data, and derived parameter catalogs for this survey are publicly available as part of SDSS Data Release 7 (DR7).
astro-ph.GA:We present results from X-ray analysis of a Galactic middle-aged supernova remnant (SNR) G156.2+5.7 which is bright and largely extended in X-ray wavelengths, showing a clear circular shape (radius about 50'). Using the Suzaku satellite, we observed this SNR in three pointings; partially covering the northwestern rim, the eastern rim, and the central portion of this SNR. In the northwestern rim and the central portion, we confirm that the X-ray spectra consist of soft and hard-tail emission, while in the eastern rim we find no significant hard-tail emission. The soft emission is well fitted by non-equilibrium ionization (NEI) model. In the central portion, a two-component (the interstellar medium and the metal-rich ejecta) NEI model fits the soft emission better than a one-component NEI model from a statistical point of view. The relative abundances in the ejecta component suggest that G156.2+5.7 is a remnant from a core-collapse SN explosion whose progenitor mass is less than 15 M_solar. The origin of the hard-tail emission is highly likely non-thermal synchrotron emission from relativistic electrons. In the northwestern rim, the relativistic electrons seem to be accelerated by a forward shock with a slow velocity of about 500 km/sec.
astro-ph.GA:We investigate the mean velocity dispersion and the velocity dispersion profile of stellar systems in MOND, using the N-body code N-MODY, which is a particle-mesh based code with a numerical MOND potential solver developed by Ciotti, Londrillo and Nipoti (2006). We have calculated mean velocity dispersions for stellar systems following Plummer density distributions with masses in the range of $10^4 M_\odot$ to $10^9 M_\odot$ and which are either isolated or immersed in an external field. Our integrations reproduce previous analytic estimates for stellar velocities in systems in the deep MOND regime ($a_i, a_e \ll a_0$), where the motion of stars is either dominated by internal accelerations ($a_i \gg a_e$) or constant external accelerations ($a_e \gg a_i$). In addition, we derive for the first time analytic formulae for the line-of-sight velocity dispersion in the intermediate regime ($a_i \sim a_e \sim a_0$). This allows for a much improved comparison of MOND with observed velocity dispersions of stellar systems. We finally derive the velocity dispersion of the globular cluster Pal 14 as one of the outer Milky Way halo globular clusters that have recently been proposed as a differentiator between Newtonian and MONDian dynamics.
astro-ph.GA:Historical optical data are combined with more recent optical, extreme ultraviolet, and X-ray data to update the spin ephemeris of the cataclysmic variable EX Hya.
astro-ph.GA:(Abridged) We perform dissipationless N-body simulations to elucidate the dynamical response of thin disks to bombardment by cold dark matter (CDM) substructure. Our method combines (1) cosmological simulations of the formation of Milky Way (MW)-sized CDM halos to derive the properties of substructure and (2) controlled numerical experiments of consecutive subhalo impacts onto an initially-thin, fully-formed MW type disk galaxy. The present study is the first to account for the evolution of satellite populations over cosmic time in such an investigation of disk structure. We find that accretions of massive subhalos onto the central regions of host halos, where the galactic disks reside, since z~1 should be common. One host halo accretion history is used to initialize the controlled simulations of satellite-disk encounters. We show that these accretion events severely perturb the thin galactic disk and produce a wealth of distinctive dynamical signatures on its structure and kinematics. These include (1) considerable thickening and heating at all radii, with the disk thickness and velocity ellipsoid nearly doubling at the solar radius; (2) prominent flaring associated with an increase in disk thickness greater than a factor of 4 in the disk outskirts; (3) surface density excesses at large radii, beyond ~5 disk scale lengths, resembling those of observed antitruncated disks; (4) lopsidedness at levels similar to those measured in observational samples of disk galaxies; and (5) substantial tilting. The interaction with the most massive subhalo drives the disk response while subsequent bombardment is much less efficient at disturbing the disk. We conclude that substructure-disk encounters of the kind expected in the LCDM paradigm play a significant role in setting the structure of disk galaxies and driving galaxy evolution.
astro-ph.GA:We present a study of active stellar forming regions in the environs of the HII region Sh2-205. The analysis is based on data obtained from point source catalogues and images extracted from 2MASS, MSX, and IRAS surveys. Complementary data are taken from CO survey. The identification of primary candidates to stellar formation activity is made following colour criteria and the correlation with molecular gas emission.   A number of stellar formation tracer candidates are projected on two substructures of the HII region: SH148.83-0.67 and SH149.25-0.00. However, the lack of molecular gas related to these structures casts doubts on the nature of the sources. Additional infrared sources may be associated with the HI shell centered at (l,b) = (149\degr 0\arcmin, -1\degr 30\arcmin).   The most striking active area was found in connection to the HII region LBN 148.11-0.45, where stellar formation candidates are projected onto molecular gas. The analytical model to the "collect and collapse" process shows that stellar formation activity could have been triggered by the expansion of this HII region.
astro-ph.GA:We report on a timing analysis performed on a 62-ks long XMM-Newton observation of the accreting millisecond pulsar SAX J1808.4-3658 during the latest X-ray outburst that started on September 21, 2008. By connecting the time of arrivals of the pulses observed during the XMM observation, we derived the best-fit orbital solution and a best-fit value of the spin period for the 2008 outburst. Comparing this new set of orbital parameters and, in particular, the value of the time of ascending-node passage with the orbital parameters derived for the previous four X-ray outbursts of SAX J1808.4-3658 observed by the PCA on board RXTE, we find an updated value of the orbital period derivative, which turns out to be $\dot P_{\rm orb} = (3.89 \pm 0.15) \times 10^{-12}$ s/s. This new value of the orbital period derivative agrees with the previously reported value, demonstrating that the orbital period derivative in this source has remained stable over the past ten years. Although this timespan is not sufficient yet for confirming the secular evolution of the system, we again propose an explanation of this behavior in terms of a highly non-conservative mass transfer in this system, where the accreted mass (as derived from the X-ray luminosity during outbursts) accounts for a mere 1% of the mass lost by the companion.
astro-ph.GA:We present a study of the intrinsic UV absorption and emission lines in an historically low-state spectrum of the Seyfert 1 galaxy NGC 5548, which we obtained in 2004 February at high spatial and spectral resolution with the Space Telescope Imaging Spectrograph (STIS) on the Hubble Space Telescope. We isolate a component of emission with a width of 680 km/s (FWHM) that arises from an "intermediate line region" (ILR), similar to the one we discovered in NGC 4151, at a distance of ~1 pc from the central continuum source. From a detailed analysis of the five intrinsic absorption components in NGC 5548 and their behavior over a span of 8 years, we present evidence that most of the UV absorbers only partially cover the ILR and do not cover an extended region of UV continuum emission, most likely from hot stars in the circumnuclear region. We also find that four of the UV absorbers are at much greater distances (>70 pc) than the ILR, and none have sufficient N V or C IV column densities to be the ILR in absorption. At least a portion of the UV absorption component 3, at a radial velocity of -530 km/s, is likely responsible for most of the X-ray absorption, at a distance < 7 pc from the central source. The fact that we see the ILR in absorption in NGC 4151 and not in NGC 5548 suggests that the ILR is located at a relatively large polar angle (~45 degrees) with respect to the narrow-line region outflow axis.
astro-ph.GA:We study the velocity distribution of Milky Way disk stars in a kiloparsec-sized region around the Sun, based on ~ 2 million M-type stars from DR7 of SDSS, which have newly re-calibrated absolute proper motions from combining SDSS positions with the USNO-B catalogue. We estimate photometric distances to all stars, accurate to ~ 20 %, and combine them with the proper motions to derive tangential velocities for this kinematically unbiased sample of stars. Based on a statistical de-projection method we then derive the vertical profiles (to heights of Z = 800 pc above the disk plane) for the first and second moments of the three dimensional stellar velocity distribution. We find that <W> = -7 +/- 1 km/s and <U> = -9 +/- 1 km/s, independent of height above the mid-plane, reflecting the Sun's motion with respect to the local standard of rest. In contrast, <V> changes distinctly from -20 +/- 2 km/s in the mid-plane to <V> = -32 km/s at Z = 800 pc, reflecting an asymmetric drift of the stellar mean velocity that increases with height. All three components of the M-star velocity dispersion show a strong linear rise away from the mid-plane, most notably \sigma_{ZZ}, which grows from 18 km/s (Z = 0) to 40 km/s (at Z = 800 pc). We determine the orientation of the velocity ellipsoid, and find a significant vertex deviation of 20 to 25 degrees, which decreases only slightly to heights of Z = 800 pc. Away from the mid-plane, our sample exhibits a remarkably large tilt of the velocity ellipsoid towards the Galactic plane, which reaches 20 deg. at Z = 800 pc and which is not easily explained. Finally, we determine the ratio \sigma^2_{\phi\phi}/\sigma^2_{RR} near the mid-plane, which in the epicyclic approximation implies an almost perfectly flat rotation curve at the Solar radius.
