cs.AI:Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem. In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty. The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.
cs.AI:Market price systems constitute a well-understood class of mechanisms that under certain conditions provide effective decentralization of decision making with minimal communication overhead. In a market-oriented programming approach to distributed problem solving, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy. WALRAS provides basic constructs for defining computational market structures, and protocols for deriving their corresponding price equilibria. In a particular realization of this approach for a form of multicommodity flow problem, we see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation, and that the behavior of the system can be meaningfully analyzed in economic terms.
cs.AI:We describe an extensive study of search in GSAT, an approximation procedure for propositional satisfiability. GSAT performs greedy hill-climbing on the number of satisfied clauses in a truth assignment. Our experiments provide a more complete picture of GSAT's search than previous accounts. We describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search. We demonstrate that when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate. Our results allow us to make detailed numerical conjectures about the length of the hill-climbing phase, the average gradient of this phase, and to conjecture that both the average score and average branching rate decay exponentially during plateau search. We end by showing how these results can be used to direct future theoretical analysis. This work provides a case study of how computer experiments can be used to improve understanding of the theoretical properties of algorithms.
cs.AI:As real logic programmers normally use cut (!), an effective learning procedure for logic programs should be able to deal with it. Because the cut predicate has only a procedural meaning, clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems. On the other hand, searching a space of possible programs (instead of a space of independent clauses) is unfeasible. An alternative solution is to generate first a candidate base program which covers the positive examples, and then make it consistent by inserting cut where appropriate. The problem of learning programs with cut has not been investigated before and this seems to be a natural and reasonable approach. We generalize this scheme and investigate the difficulties that arise. Some of the major shortcomings are actually caused, in general, by the need for intensional evaluation. As a conclusion, the analysis of this paper suggests, on precise and technical grounds, that learning cut is difficult, and current induction techniques should probably be restricted to purely declarative logic languages.
cs.AI:To support the goal of allowing users to record and retrieve information, this paper describes an interactive note-taking system for pen-based computers with two distinctive features. First, it actively predicts what the user is going to write. Second, it automatically constructs a custom, button-box user interface on request. The system is an example of a learning-apprentice software- agent. A machine learning component characterizes the syntax and semantics of the user's information. A performance system uses this learned information to generate completion strings and construct a user interface. Description of Online Appendix: People like to record information. Doing this on paper is initially efficient, but lacks flexibility. Recording information on a computer is less efficient but more powerful. In our new note taking softwre, the user records information directly on a computer. Behind the interface, an agent acts for the user. To help, it provides defaults and constructs a custom user interface. The demonstration is a QuickTime movie of the note taking agent in action. The file is a binhexed self-extracting archive. Macintosh utilities for binhex are available from mac.archive.umich.edu. QuickTime is available from ftp.apple.com in the dts/mac/sys.soft/quicktime.
cs.AI:Terminological knowledge representation systems (TKRSs) are tools for designing and using knowledge bases that make use of terminological languages (or concept languages). We analyze from a theoretical point of view a TKRS whose capabilities go beyond the ones of presently available TKRSs. The new features studied, often required in practical applications, can be summarized in three main points. First, we consider a highly expressive terminological language, called ALCNR, including general complements of concepts, number restrictions and role conjunction. Second, we allow to express inclusion statements between general concepts, and terminological cycles as a particular case. Third, we prove the decidability of a number of desirable TKRS-deduction services (like satisfiability, subsumption and instance checking) through a sound, complete and terminating calculus for reasoning in ALCNR-knowledge bases. Our calculus extends the general technique of constraint systems. As a byproduct of the proof, we get also the result that inclusion statements in ALCNR can be simulated by terminological cycles, if descriptive semantics is adopted.
cs.AI:A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments. We introduce the notion of teleo-reactive (T-R) programs whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based. In addition to continuous feedback, T-R programs support parameter binding and recursion. A primary difference between T-R programs and many other circuit-based systems is that the circuitry of T-R programs is more compact; it is constructed at run time and thus does not have to anticipate all the contingencies that might arise over all possible runs. In addition, T-R programs are intuitive and easy to write and are written in a form that is compatible with automatic planning and learning methods. We briefly describe some experimental applications of T-R programs in the control of simulated and actual mobile robots.
cs.AI:Learning the past tense of English verbs - a seemingly minor aspect of language acquisition - has generated heated debates since 1986, and has become a landmark task for testing the adequacy of cognitive modeling. Several artificial neural networks (ANNs) have been implemented, and a challenge for better symbolic models has been posed. In this paper, we present a general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree learning algorithm ID3. We conduct extensive head-to-head comparisons on the generalization ability between ANN models and the SPA under different representations. We conclude that the SPA generalizes the past tense of unseen verbs better than ANN models by a wide margin, and we offer insights as to why this should be the case. We also discuss a new default strategy for decision-tree learning algorithms.
cs.AI:The ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data. We describe a new version of our SUBDUE substructure discovery system based on the minimum description length principle. The SUBDUE system discovers substructures that compress the original data and represent structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of SUBDUE produce a hierarchical description of the structural regularities in the data. SUBDUE uses a computationally-bounded inexact graph match that identifies similar, but not identical, instances of a substructure and finds an approximate measure of closeness of two substructures when under computational constraints. In addition to the minimum description length principle, other background knowledge can be used by SUBDUE to guide the search towards more appropriate substructures. Experiments in a variety of domains demonstrate SUBDUE's ability to find substructures capable of compressing the original data and to discover structural concepts important to the domain. Description of Online Appendix: This is a compressed tar file containing the SUBDUE discovery system, written in C. The program accepts as input databases represented in graph form, and will output discovered substructures with their corresponding value.
cs.AI:The theory revision problem is the problem of how best to go about revising a deficient domain theory using information contained in examples that expose inaccuracies. In this paper we present our approach to the theory revision problem for propositional domain theories. The approach described here, called PTR, uses probabilities associated with domain theory elements to numerically track the ``flow'' of proof through the theory. This allows us to measure the precise role of a clause or literal in allowing or preventing a (desired or undesired) derivation for a given example. This information is used to efficiently locate and repair flawed elements of the theory. PTR is proved to converge to a theory which correctly classifies all examples, and shown experimentally to be fast and accurate even for deep theories.
cs.AI:We report on a series of experiments in which all decision trees consistent with the training data are constructed. These experiments were run to gain an understanding of the properties of the set of consistent decision trees and the factors that affect the accuracy of individual trees. In particular, we investigated the relationship between the size of a decision tree consistent with some training data and the accuracy of the tree on test data. The experiments were performed on a massively parallel Maspar computer. The results of the experiments on several artificial and two real world problems indicate that, for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.
cs.AI:This paper analyzes the correctness of the subsumption algorithm used in CLASSIC, a description logic-based knowledge representation system that is being used in practical applications. In order to deal efficiently with individuals in CLASSIC descriptions, the developers have had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics. We provide a variant semantics for descriptions with respect to which the current implementation is complete, and which can be independently motivated. The soundness and completeness of the polynomial-time subsumption algorithm is established using description graphs, which are an abstracted version of the implementation structures used in CLASSIC, and are of independent interest.
cs.AI:In this paper we describe how to modify GSAT so that it can be applied to non-clausal formulas. The idea is to use a particular ``score'' function which gives the number of clauses of the CNF conversion of a formula which are false under a given truth assignment. Its value is computed in linear time, without constructing the CNF conversion itself. The proposed methodology applies to most of the variants of GSAT proposed so far.
cs.AI:Given a knowledge base KB containing first-order and statistical facts, we consider a principled method, called the random-worlds method, for computing a degree of belief that some formula Phi holds given KB. If we are reasoning about a world or system consisting of N individuals, then we can consider all possible worlds, or first-order models, with domain {1,...,N} that satisfy KB, and compute the fraction of them in which Phi is true. We define the degree of belief to be the asymptotic value of this fraction as N grows large. We show that when the vocabulary underlying Phi and KB uses constants and unary predicates only, we can naturally associate an entropy with each world. As N grows larger, there are many more worlds with higher entropy. Therefore, we can use a maximum-entropy computation to compute the degree of belief. This result is in a similar spirit to previous work in physics and artificial intelligence, but is far more general. Of equal interest to the result itself are the limitations on its scope. Most importantly, the restriction to unary predicates seems necessary. Although the random-worlds method makes sense in general, the connection to maximum entropy seems to disappear in the non-unary case. These observations suggest unexpected limitations to the applicability of maximum-entropy methods.
cs.AI:Information extraction is the task of automatically picking up information of interest from an unconstrained text. Information of interest is usually extracted in two steps. First, sentence level processing locates relevant pieces of information scattered throughout the text; second, discourse processing merges coreferential information to generate the output. In the first step, pieces of information are locally identified without recognizing any relationships among them. A key word search or simple pattern search can achieve this purpose. The second step requires deeper knowledge in order to understand relationships among separately identified pieces of information. Previous information extraction systems focused on the first step, partly because they were not required to link up each piece of information with other pieces. To link the extracted pieces of information and map them onto a structured output format, complex discourse processing is essential. This paper reports on a Japanese information extraction system that merges information using a pattern matcher and discourse processor. Evaluation results show a high level of system performance which approaches human performance.
cs.AI:This article describes a new system for induction of oblique decision trees. This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree. Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes. We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to construct oblique trees that are smaller and more accurate than their axis-parallel counterparts. We also examine the benefits of randomization for the construction of oblique decision trees.
cs.AI:This paper introduces a framework for Planning while Learning where an agent is given a goal to achieve in an environment whose behavior is only partially known to the agent. We discuss the tractability of various plan-design processes. We show that for a large natural class of Planning while Learning systems, a plan can be presented and verified in a reasonable time. However, coming up algorithmically with a plan, even for simple classes of systems is apparently intractable. We emphasize the role of off-line plan-design processes, and show that, in most natural cases, the verification (projection) part can be carried out in an efficient algorithmic manner.
cs.AI:The vast amounts of on-line text now available have led to renewed interest in information extraction (IE) systems that analyze unrestricted text, producing a structured representation of selected information from the text. This paper presents a novel approach that uses machine learning to acquire knowledge for some of the higher level IE processing. Wrap-Up is a trainable IE discourse component that makes intersentential inferences and identifies logical relations among information extracted from the text. Previous corpus-based approaches were limited to lower level processing such as part-of-speech tagging, lexical disambiguation, and dictionary construction. Wrap-Up is fully trainable, and not only automatically decides what classifiers are needed, but even derives the feature set for each classifier automatically. Performance equals that of a partially trainable discourse module requiring manual customization for each domain.
cs.AI:This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, and the manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximization algorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. The main original contributions here are the decomposition techniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms.
cs.AI:For many years, the intuitions underlying partial-order planning were largely taken for granted. Only in the past few years has there been renewed interest in the fundamental principles underlying this paradigm. In this paper, we present a rigorous comparative analysis of partial-order and total-order planning by focusing on two specific planners that can be directly compared. We show that there are some subtle assumptions that underly the wide-spread intuitions regarding the supposed efficiency of partial-order planning. For instance, the superiority of partial-order planning can depend critically upon the search strategy and the structure of the search space. Understanding the underlying assumptions is crucial for constructing efficient planners.
cs.AI:Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k &gt 2 values (i.e., k ``classes''). The definition is acquired by studying collections of training examples of the form [x_i, f (x_i)]. Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that---like the other methods---the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.
cs.AI:The paradigms of transformational planning, case-based planning, and plan debugging all involve a process known as plan adaptation - modifying or repairing an old plan so it solves a new problem. In this paper we provide a domain-independent algorithm for plan adaptation, demonstrate that it is sound, complete, and systematic, and compare it to other adaptation algorithms in the literature. Our approach is based on a view of planning as searching a graph of partial plans. Generative planning starts at the graph's root and moves from node to node using plan-refinement operators. In planning by adaptation, a library plan - an arbitrary node in the plan graph - is the starting point for the search, and the plan-adaptation algorithm can apply both the same refinement operators available to a generative planner and can also retract constraints and steps from the plan. Our algorithm's completeness ensures that the adaptation algorithm will eventually search the entire graph and its systematicity ensures that it will do so without redundantly searching any parts of the graph.
cs.AI:Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor lambda. Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learning. This paper examines the issues of the efficient and general implementation of TD(lambda) for arbitrary lambda, for use with reinforcement learning algorithms optimizing the discounted sum of rewards. The traditional approach, based on eligibility traces, is argued to suffer from both inefficiency and lack of generality. The TTD (Truncated Temporal Differences) procedure is proposed as an alternative, that indeed only approximates TD(lambda), but requires very little computation per action and can be used with arbitrary function representation methods. The idea from which it is derived is fairly simple and not new, but probably unexplored so far. Encouraging experimental results are presented, suggesting that using lambda &gt 0 with the TTD procedure allows one to obtain a significant learning speedup at essentially the same cost as usual TD(0) learning.
cs.AI:This paper introduces ICET, a new algorithm for cost-sensitive classification. ICET uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm. The fitness function of the genetic algorithm is the average cost of classification when using the decision tree, including both the costs of tests (features, measurements) and the costs of classification errors. ICET is compared here with three other algorithms for cost-sensitive classification - EG2, CS-ID3, and IDX - and also with C4.5, which classifies without regard to cost. The five algorithms are evaluated empirically on five real-world medical datasets. Three sets of experiments are performed. The first set examines the baseline performance of the five algorithms on the five datasets and establishes that ICET performs significantly better than its competitors. The second set tests the robustness of ICET under a variety of conditions and shows that ICET maintains its advantage. The third set looks at ICET's search in bias space and discovers a way to improve the search.
cs.AI:Theory revision integrates inductive learning and background knowledge by combining training examples with a coarse domain theory to produce a more accurate theory. There are two challenges that theory revision and other theory-guided systems face. First, a representation language appropriate for the initial theory may be inappropriate for an improved theory. While the original representation may concisely express the initial theory, a more accurate theory forced to use that same representation may be bulky, cumbersome, and difficult to reach. Second, a theory structure suitable for a coarse domain theory may be insufficient for a fine-tuned theory. Systems that produce only small, local changes to a theory have limited value for accomplishing complex structural alterations that may be required. Consequently, advanced theory-guided learning systems require flexible representation and flexible structure. An analysis of various theory revision systems and theory-guided learning systems reveals specific strengths and weaknesses in terms of these two desired properties. Designed to capture the underlying qualities of each system, a new system uses theory-guided constructive induction. Experiments in three domains show improvement over previous theory-guided systems. This leads to a study of the behavior, limitations, and potential of theory-guided constructive induction.
cs.AI:Many studies have been carried out in order to increase the search efficiency of constraint satisfaction problems; among them, some make use of structural properties of the constraint network; others take into account semantic properties of the constraints, generally assuming that all the constraints possess the given property. In this paper, we propose a new decomposition method benefiting from both semantic properties of functional constraints (not bijective constraints) and structural properties of the network; furthermore, not all the constraints need to be functional. We show that under some conditions, the existence of solutions can be guaranteed. We first characterize a particular subset of the variables, which we name a root set. We then introduce pivot consistency, a new local consistency which is a weak form of path consistency and can be achieved in O(n^2d^2) complexity (instead of O(n^3d^3) for path consistency), and we present associated properties; in particular, we show that any consistent instantiation of the root set can be linearly extended to a solution, which leads to the presentation of the aforementioned new method for solving by decomposing functional CSPs.
cs.AI:We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system, without use of either central coordination or explicit communication. We first define a precise framework in which to study adaptive load balancing, important features of which are its stochastic nature and the purely local information available to individual agents. Given this framework, we show illuminating results on the interplay between basic adaptive behavior parameters and their effect on system efficiency. We then investigate the properties of adaptive load balancing in heterogeneous populations, and address the issue of exploration vs. exploitation in that context. Finally, we show that naive use of communication may not improve, and might even harm system efficiency.
cs.AI:Since its inception, artificial intelligence has relied upon a theoretical foundation centered around perfect rationality as the desired property of intelligent systems. We argue, as others have done, that this foundation is inadequate because it imposes fundamentally unsatisfiable requirements. As a result, there has arisen a wide gap between theory and practice in AI, hindering progress in the field. We propose instead a property called bounded optimality. Roughly speaking, an agent is bounded-optimal if its program is a solution to the constrained optimization problem presented by its architecture and the task environment. We show how to construct agents with this property for a simple class of machine architectures in a broad class of real-time environments. We illustrate these results using a simple model of an automated mail sorting facility. We also define a weaker property, asymptotic bounded optimality (ABO), that generalizes the notion of optimality in classical complexity theory. We then construct universal ABO programs, i.e., programs that are ABO no matter what real-time constraints are applied. Universal ABO programs can be used as building blocks for more complex systems. We conclude with a discussion of the prospects for bounded optimality as a theoretical basis for AI, and relate it to similar trends in philosophy, economics, and game theory.
cs.AI:We present algorithms that learn certain classes of function-free recursive logic programs in polynomial time from equivalence queries. In particular, we show that a single k-ary recursive constant-depth determinate clause is learnable. Two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause are also learnable, if an additional ``basecase'' oracle is assumed. These results immediately imply the pac-learnability of these classes. Although these classes of learnable recursive programs are very constrained, it is shown in a companion paper that they are maximally general, in that generalizing either class in any natural way leads to a computationally difficult learning problem. Thus, taken together with its companion paper, this paper establishes a boundary of efficient learnability for recursive logic programs.
cs.AI:In a companion paper it was shown that the class of constant-depth determinate k-ary recursive clauses is efficiently learnable. In this paper we present negative results showing that any natural generalization of this class is hard to learn in Valiant's model of pac-learnability. In particular, we show that the following program classes are cryptographically hard to learn: programs with an unbounded number of constant-depth linear recursive clauses; programs with one constant-depth determinate clause containing an unbounded number of recursive calls; and programs with one linear recursive clause of constant locality. These results immediately imply the non-learnability of any more general class of programs. We also show that learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause is as hard as learning boolean DNF. Together with positive results from the companion paper, these negative results establish a boundary of efficient learnability for recursive function-free clauses.
cs.AI:There has been evidence that least-commitment planners can efficiently handle planning problems that involve difficult goal interactions. This evidence has led to the common belief that delayed-commitment is the "best" possible planning strategy. However, we recently found evidence that eager-commitment planners can handle a variety of planning problems more efficiently, in particular those with difficult operator choices. Resigned to the futility of trying to find a universally successful planning strategy, we devised a planner that can be used to study which domains and problems are best for which planning strategies. In this article we introduce this new planning algorithm, FLECS, which uses a FLExible Commitment Strategy with respect to plan-step orderings. It is able to use any strategy from delayed-commitment to eager-commitment. The combination of delayed and eager operator-ordering commitments allows FLECS to take advantage of the benefits of explicitly using a simulated execution state and reasoning about planning constraints. FLECS can vary its commitment strategy across different problems and domains, and also during the course of a single planning problem. FLECS represents a novel contribution to planning in that it explicitly provides the choice of which commitment strategy to use while planning. FLECS provides a framework to investigate the mapping from planning domains and problems to efficient planning strategies.
cs.AI:This paper presents a method for inducing logic programs from examples that learns a new class of concepts called first-order decision lists, defined as ordered lists of clauses each ending in a cut. The method, called FOIDL, is based on FOIL (Quinlan, 1990) but employs intensional background knowledge and avoids the need for explicit negative examples. It is particularly useful for problems that involve rules with specific exceptions, such as learning the past-tense of English verbs, a task widely studied in the context of the symbolic/connectionist debate. FOIDL is able to learn concise, accurate programs for this problem from significantly fewer examples than previous methods (both connectionist and symbolic).
cs.AI:ion is one of the most promising approaches to improve the performance of problem solvers. In several domains abstraction by dropping sentences of a domain description -- as used in most hierarchical planners -- has proven useful. In this paper we present examples which illustrate significant drawbacks of abstraction by dropping sentences. To overcome these drawbacks, we propose a more general view of abstraction involving the change of representation language. We have developed a new abstraction methodology and a related sound and complete learning algorithm that allows the complete change of representation language of planning cases from concrete to abstract. However, to achieve a powerful change of the representation language, the abstract language itself as well as rules which describe admissible ways of abstracting states must be provided in the domain model. This new abstraction approach is the core of Paris (Plan Abstraction and Refinement in an Integrated System), a system in which abstract planning cases are automatically learned from given concrete cases. An empirical study in the domain of process planning in mechanical engineering shows significant advantages of the proposed reasoning from abstract cases over classical hierarchical planning.
cs.AI:Identifying inaccurate data has long been regarded as a significant and difficult problem in AI. In this paper, we present a new method for identifying inaccurate data on the basis of qualitative correlations among related data. First, we introduce the definitions of related data and qualitative correlations among related data. Then we put forward a new concept called support coefficient function (SCF). SCF can be used to extract, represent, and calculate qualitative correlations among related data within a dataset. We propose an approach to determining dynamic shift intervals of inaccurate data, and an approach to calculating possibility of identifying inaccurate data, respectively. Both of the approaches are based on SCF. Finally we present an algorithm for identifying inaccurate data by using qualitative correlations among related data as confirmatory or disconfirmatory evidence. We have developed a practical system for interpreting infrared spectra by applying the method, and have fully tested the system against several hundred real spectra. The experimental results show that the method is significantly better than the conventional methods used in many similar systems.
cs.AI:Learning and reasoning are both aspects of what is considered to be intelligence. Their studies within AI have been separated historically, learning being the topic of machine learning and neural networks, and reasoning falling under classical (or symbolic) AI. However, learning and reasoning are in many ways interdependent. This paper discusses the nature of some of these interdependencies and proposes a general framework called FLARE, that combines inductive learning using prior knowledge together with reasoning in a propositional setting. Several examples that test the framework are presented, including classical induction, many important reasoning protocols and two simple expert systems.
cs.AI:This paper studies the problem of ergodicity of transition probability matrices in Markovian models, such as hidden Markov models (HMMs), and how it makes very difficult the task of learning to represent long-term context for sequential data. This phenomenon hurts the forward propagation of long-term context information, as well as learning a hidden state representation to represent long-term context, which depends on propagating credit information backwards in time. Using results from Markov chain theory, we show that this problem of diffusion of context and credit is reduced when the transition probabilities approach 0 or 1, i.e., the transition probability matrices are sparse and the model essentially deterministic. The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm.
cs.AI:Symmetric networks designed for energy minimization such as Boltzman machines and Hopfield nets are frequently investigated for use in optimization, constraint satisfaction and approximation of NP-hard problems. Nevertheless, finding a global solution (i.e., a global minimum for the energy function) is not guaranteed and even a local solution may take an exponential number of steps. We propose an improvement to the standard local activation function used for such networks. The improved algorithm guarantees that a global minimum is found in linear time for tree-like subnetworks. The algorithm, called activate, is uniform and does not assume that the network is tree-like. It can identify tree-like subnetworks even in cyclic topologies (arbitrary networks) and avoid local minima along these trees. For acyclic networks, the algorithm is guaranteed to converge to a global minimum from any initial state of the system (self-stabilization) and remains correct under various types of schedulers. On the negative side, we show that in the presence of cycles, no uniform algorithm exists that guarantees optimality even under a sequential asynchronous scheduler. An asynchronous scheduler can activate only one unit at a time while a synchronous scheduler can activate any number of units in a single time step. In addition, no uniform algorithm exists to optimize even acyclic networks when the scheduler is synchronous. Finally, we show how the algorithm can be improved using the cycle-cutset scheme. The general algorithm, called activate-with-cutset, improves over activate and has some performance guarantees that are related to the size of the network's cycle-cutset.
cs.AI:Functionality-based recognition systems recognize objects at the category level by reasoning about how well the objects support the expected function. Such systems naturally associate a ``measure of goodness'' or ``membership value'' with a recognized object. This measure of goodness is the result of combining individual measures, or membership values, from potentially many primitive evaluations of different properties of the object's shape. A membership function is used to compute the membership value when evaluating a primitive of a particular physical property of an object. In previous versions of a recognition system known as Gruff, the membership function for each of the primitive evaluations was hand-crafted by the system designer. In this paper, we provide a learning component for the Gruff system, called Omlet, that automatically learns membership functions given a set of example objects labeled with their desired category measure. The learning algorithm is generally applicable to any problem in which low-level membership values are combined through an and-or tree structure to give a final overall membership value.
cs.AI:This paper presents an approach to learning from situated, interactive tutorial instruction within an ongoing agent. Tutorial instruction is a flexible (and thus powerful) paradigm for teaching tasks because it allows an instructor to communicate whatever types of knowledge an agent might need in whatever situations might arise. To support this flexibility, however, the agent must be able to learn multiple kinds of knowledge from a broad range of instructional interactions. Our approach, called situated explanation, achieves such learning through a combination of analytic and inductive techniques. It combines a form of explanation-based learning that is situated for each instruction with a full suite of contextually guided responses to incomplete explanations. The approach is implemented in an agent called Instructo-Soar that learns hierarchies of new tasks and other domain knowledge from interactive natural language instructions. Instructo-Soar meets three key requirements of flexible instructability that distinguish it from previous systems: (1) it can take known or unknown commands at any instruction point; (2) it can handle instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions); and (3) it can learn, from instructions, each class of knowledge it uses to perform tasks.
cs.AI:OPUS is a branch and bound search algorithm that enables efficient admissible search through spaces for which the order of search operator application is not significant. The algorithm's search efficiency is demonstrated with respect to very large machine learning search spaces. The use of admissible search is of potential value to the machine learning community as it means that the exact learning biases to be employed for complex learning tasks can be precisely specified and manipulated. OPUS also has potential for application in other areas of artificial intelligence, notably, truth maintenance.
cs.AI:The main aim of this work is the development of a vision-based road detection system fast enough to cope with the difficult real-time constraints imposed by moving vehicle applications. The hardware platform, a special-purpose massively parallel system, has been chosen to minimize system production and operational costs. This paper presents a novel approach to expectation-driven low-level image segmentation, which can be mapped naturally onto mesh-connected massively parallel SIMD architectures capable of handling hierarchical data structures. The input image is assumed to contain a distorted version of a given template; a multiresolution stretching process is used to reshape the original template in accordance with the acquired image content, minimizing a potential function. The distorted template is the process output.
cs.AI:In the area of inductive learning, generalization is a main operation, and the usual definition of induction is based on logical implication. Recently there has been a rising interest in clausal representation of knowledge in machine learning. Almost all inductive learning systems that perform generalization of clauses use the relation theta-subsumption instead of implication. The main reason is that there is a well-known and simple technique to compute least general generalizations under theta-subsumption, but not under implication. However generalization under theta-subsumption is inappropriate for learning recursive clauses, which is a crucial problem since recursion is the basic program structure of logic programs. We note that implication between clauses is undecidable, and we therefore introduce a stronger form of implication, called T-implication, which is decidable between clauses. We show that for every finite set of clauses there exists a least general generalization under T-implication. We describe a technique to reduce generalizations under implication of a clause to generalizations under theta-subsumption of what we call an expansion of the original clause. Moreover we show that for every non-tautological clause there exists a T-complete expansion, which means that every generalization under T-implication of the clause is reduced to a generalization under theta-subsumption of the expansion.
cs.AI:We present a definition of cause and effect in terms of decision-theoretic primitives and thereby provide a principled foundation for causal reasoning. Our definition departs from the traditional view of causation in that causal assertions may vary with the set of decisions available. We argue that this approach provides added clarity to the notion of cause. Also in this paper, we examine the encoding of causal relationships in directed acyclic graphs. We describe a special class of influence diagrams, those in canonical form, and show its relationship to Pearl's representation of cause and effect. Finally, we show how canonical form facilitates counterfactual reasoning.
cs.AI:Characteristic models are an alternative, model based, representation for Horn expressions. It has been shown that these two representations are incomparable and each has its advantages over the other. It is therefore natural to ask what is the cost of translating, back and forth, between these representations. Interestingly, the same translation questions arise in database theory, where it has applications to the design of relational databases. This paper studies the computational complexity of these problems. Our main result is that the two translation problems are equivalent under polynomial reductions, and that they are equivalent to the corresponding decision problem. Namely, translating is equivalent to deciding whether a given set of models is the set of characteristic models for a given Horn expression. We also relate these problems to the hypergraph transversal problem, a well known problem which is related to other applications in AI and for which no polynomial time algorithm is known. It is shown that in general our translation problems are at least as hard as the hypergraph transversal problem, and in a special case they are equivalent to it.
cs.AI:This article describes an application of three well-known statistical methods in the field of game-tree search: using a large number of classified Othello positions, feature weights for evaluation functions with a game-phase-independent meaning are estimated by means of logistic regression, Fisher's linear discriminant, and the quadratic discriminant function for normally distributed features. Thereafter, the playing strengths are compared by means of tournaments between the resulting versions of a world-class Othello program. In this application, logistic regression - which is used here for the first time in the context of game playing - leads to better results than the other approaches.
cs.AI:We describe a machine learning method for predicting the value of a real-valued function, given the values of multiple input variables. The method induces solutions from samples in the form of ordered disjunctive normal form (DNF) decision rules. A central objective of the method and representation is the induction of compact, easily interpretable solutions. This rule-based decision model can be extended to search efficiently for similar cases prior to approximating function values. Experimental results on real-world data demonstrate that the new techniques are competitive with existing machine learning and statistical methods and can sometimes yield superior regression performance.
cs.AI:Many applications -- from planning and scheduling to problems in molecular biology -- rely heavily on a temporal reasoning component. In this paper, we discuss the design and empirical analysis of algorithms for a temporal reasoning system based on Allen's influential interval-based framework for representing temporal information. At the core of the system are algorithms for determining whether the temporal information is consistent, and, if so, finding one or more scenarios that are consistent with the temporal information. Two important algorithms for these tasks are a path consistency algorithm and a backtracking algorithm. For the path consistency algorithm, we develop techniques that can result in up to a ten-fold speedup over an already highly optimized implementation. For the backtracking algorithm, we develop variable and value ordering heuristics that are shown empirically to dramatically improve the performance of the algorithm. As well, we show that a previously suggested reformulation of the backtracking search problem can reduce the time and space requirements of the backtracking search. Taken together, the techniques we develop allow a temporal reasoning component to solve problems that are of practical size.
cs.AI:The paper describes an extension of well-founded semantics for logic programs with two types of negation. In this extension information about preferences between rules can be expressed in the logical language and derived dynamically. This is achieved by using a reserved predicate symbol and a naming technique. Conflicts among rules are resolved whenever possible on the basis of derived preference information. The well-founded conclusions of prioritized logic programs can be computed in polynomial time. A legal reasoning example illustrates the usefulness of the approach.
cs.AI:Traditional databases commonly support efficient query and update procedures that operate in time which is sublinear in the size of the database. Our goal in this paper is to take a first step toward dynamic reasoning in probabilistic databases with comparable efficiency. We propose a dynamic data structure that supports efficient algorithms for updating and querying singly connected Bayesian networks. In the conventional algorithm, new evidence is absorbed in O(1) time and queries are processed in time O(N), where N is the size of the network. We propose an algorithm which, after a preprocessing phase, allows us to answer queries in time O(log N) at the expense of O(log N) time per evidence absorption. The usefulness of sub-linear processing time manifests itself in applications requiring (near) real-time response over large probabilistic databases. We briefly discuss a potential application of dynamic probabilistic reasoning in computational biology.
cs.AI:We introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average. This is done by exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices. This quantum algorithm is much more likely to find solutions than the simple direct use of quantum parallelism. Furthermore, empirical evaluation on small problems shows this quantum algorithm displays the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods. Specifically, difficult problem instances are concentrated near the abrupt change from underconstrained to overconstrained problems.
cs.AI:We develop a mean field theory for sigmoid belief networks based on ideas from statistical mechanics. Our mean field theory provides a tractable approximation to the true probability distribution in these networks; it also yields a lower bound on the likelihood of evidence. We demonstrate the utility of this framework on a benchmark problem in statistical pattern recognition---the classification of handwritten digits.
cs.AI:A reported weakness of C4.5 in domains with continuous attributes is addressed by modifying the formation and evaluation of tests on continuous attributes. An MDL-inspired penalty is applied to such tests, eliminating some of them from consideration and altering the relative desirability of all tests. Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies. Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.
cs.AI:For many types of machine learning algorithms, one can compute the statistically `optimal' way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.
cs.AI:Inductive theorem provers often diverge. This paper describes a simple critic, a computer program which monitors the construction of inductive proofs attempting to identify diverging proof attempts. Divergence is recognized by means of a ``difference matching'' procedure. The critic then proposes lemmas and generalizations which ``ripple'' these differences away so that the proof can go through without divergence. The critic enables the theorem prover Spike to prove many theorems completely automatically from the definitions alone.
cs.AI:Termination of logic programs with negated body atoms (here called general logic programs) is an important topic. One reason is that many computational mechanisms used to process negated atoms, like Clark's negation as failure and Chan's constructive negation, are based on termination conditions. This paper introduces a methodology for proving termination of general logic programs w.r.t. the Prolog selection rule. The idea is to distinguish parts of the program depending on whether or not their termination depends on the selection rule. To this end, the notions of low-, weakly up-, and up-acceptable program are introduced. We use these notions to develop a methodology for proving termination of general logic programs, and show how interesting problems in non-monotonic reasoning can be formalized and implemented by means of terminating general logic programs.
cs.AI:Clustering is often used for discovering structure in data. Clustering systems differ in the objective function used to evaluate clustering quality and the control strategy used to search the space of clusterings. Ideally, the search strategy should consistently construct clusterings of high quality, but be computationally inexpensive as well. In general, we cannot have it both ways, but we can partition the search so that a system inexpensively constructs a `tentative' clustering for initial examination, followed by iterative optimization, which continues to search in background for improved clusterings. Given this motivation, we evaluate an inexpensive strategy for creating initial clusterings, coupled with several control strategies for iterative optimization, each of which repeatedly modifies an initial clustering in search of a better one. One of these methods appears novel as an iterative optimization strategy in clustering contexts. Once a clustering has been constructed it is judged by analysts -- often according to task-specific criteria. Several authors have abstracted these criteria and posited a generic performance task akin to pattern completion, where the error rate over completed patterns is used to `externally' judge clustering utility. Given this performance task, we adapt resampling-based pruning strategies used by supervised learning systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis. Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and simplicity dimensions.
cs.AI:This paper presents new experimental evidence against the utility of Occam's razor. A~systematic procedure is presented for post-processing decision trees produced by C4.5. This procedure was derived by rejecting Occam's razor and instead attending to the assumption that similar objects are likely to belong to the same class. It increases a decision tree's complexity without altering the performance of that tree on the training data from which it is inferred. The resulting more complex decision trees are demonstrated to have, on average, for a variety of common learning tasks, higher predictive accuracy than the less complex original decision trees. This result raises considerable doubt about the utility of Occam's razor as it is commonly applied in modern machine learning.
cs.AI:The main operations in Inductive Logic Programming (ILP) are generalization and specialization, which only make sense in a generality order. In ILP, the three most important generality orders are subsumption, implication and implication relative to background knowledge. The two languages used most often are languages of clauses and languages of only Horn clauses. This gives a total of six different ordered languages. In this paper, we give a systematic treatment of the existence or non-existence of least generalizations and greatest specializations of finite sets of clauses in each of these six ordered sets. We survey results already obtained by others and also contribute some answers of our own. Our main new results are, firstly, the existence of a computable least generalization under implication of every finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses). Secondly, we show that such a least generalization need not exist under relative implication, not even if both the set that is to be generalized and the background knowledge are function-free. Thirdly, we give a complete discussion of existence and non-existence of greatest specializations in each of the six ordered languages.
cs.AI:This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.
cs.AI:Although most scheduling problems are NP-hard, domain specific techniques perform well in practice but are quite expensive to construct. In adaptive problem-solving solving, domain specific knowledge is acquired automatically for a general problem solver with a flexible control architecture. In this approach, a learning system explores a space of possible heuristic methods for one well-suited to the eccentricities of the given domain and problem distribution. In this article, we discuss an application of the approach to scheduling satellite communications. Using problem distributions based on actual mission requirements, our approach identifies strategies that not only decrease the amount of CPU time required to produce schedules, but also increase the percentage of problems that are solvable within computational resource limitations.
cs.AI:Speedup learning seeks to improve the computational efficiency of problem solving with experience. In this paper, we develop a formal framework for learning efficient problem solving from random problems and their solutions. We apply this framework to two different representations of learned knowledge, namely control rules and macro-operators, and prove theorems that identify sufficient conditions for learning in each representation. Our proofs are constructive in that they are accompanied with learning algorithms. Our framework captures both empirical and explanation-based speedup learning in a unified fashion. We illustrate our framework with implementations in two domains: symbolic integration and Eight Puzzle. This work integrates many strands of experimental and theoretical work in machine learning, including empirical learning of control rules, macro-operator learning, Explanation-Based Learning (EBL), and Probably Approximately Correct (PAC) Learning.
cs.AI:A fundamental assumption made by classical AI planners is that there is no uncertainty in the world: the planner has full knowledge of the conditions under which the plan will be executed and the outcome of every action is fully predictable. These planners cannot therefore construct contingency plans, i.e., plans in which different actions are performed in different circumstances. In this paper we discuss some issues that arise in the representation and construction of contingency plans and describe Cassandra, a partial-order contingency planner. Cassandra uses explicit decision-steps that enable the agent executing the plan to decide which plan branch to follow. The decision-steps in a plan result in subgoals to acquire knowledge, which are planned for in the same way as any other subgoals. Cassandra thus distinguishes the process of gathering information from the process of making decisions. The explicit representation of decisions in Cassandra allows a coherent approach to the problems of contingent planning, and provides a solid base for extensions such as the use of different decision-making procedures.
cs.AI:An important problem in geometric reasoning is to find the configuration of a collection of geometric bodies so as to satisfy a set of given constraints. Recently, it has been suggested that this problem can be solved efficiently by symbolically reasoning about geometry. This approach, called degrees of freedom analysis, employs a set of specialized routines called plan fragments that specify how to change the configuration of a set of bodies to satisfy a new constraint while preserving existing constraints. A potential drawback, which limits the scalability of this approach, is concerned with the difficulty of writing plan fragments. In this paper we address this limitation by showing how these plan fragments can be automatically synthesized using first principles about geometric bodies, actions, and topology.
cs.AI:Motivated by the control theoretic distinction between controllable and uncontrollable events, we distinguish between two types of agents within a multi-agent system: controllable agents, which are directly controlled by the system's designer, and uncontrollable agents, which are not under the designer's direct control. We refer to such systems as partially controlled multi-agent systems, and we investigate how one might influence the behavior of the uncontrolled agents through appropriate design of the controlled agents. In particular, we wish to understand which problems are naturally described in these terms, what methods can be applied to influence the uncontrollable agents, the effectiveness of such methods, and whether similar methods work across different domains. Using a game-theoretic framework, this paper studies the design of partially controlled multi-agent systems in two contexts: in one context, the uncontrollable agents are expected utility maximizers, while in the other they are reinforcement learners. We suggest different techniques for controlling agents' behavior in each domain, assess their success, and examine their relationship.
cs.AI:Visual thinking plays an important role in scientific reasoning. Based on the research in automating diverse reasoning tasks about dynamical systems, nonlinear controllers, kinematic mechanisms, and fluid motion, we have identified a style of visual thinking, imagistic reasoning. Imagistic reasoning organizes computations around image-like, analogue representations so that perceptual and symbolic operations can be brought to bear to infer structure and behavior. Programs incorporating imagistic reasoning have been shown to perform at an expert level in domains that defy current analytic or numerical methods. We have developed a computational paradigm, spatial aggregation, to unify the description of a class of imagistic problem solvers. A program written in this paradigm has the following properties. It takes a continuous field and optional objective functions as input, and produces high-level descriptions of structure, behavior, or control actions. It computes a multi-layer of intermediate representations, called spatial aggregates, by forming equivalence classes and adjacency relations. It employs a small set of generic operators such as aggregation, classification, and localization to perform bidirectional mapping between the information-rich field and successively more abstract spatial aggregates. It uses a data structure, the neighborhood graph, as a common interface to modularize computations. To illustrate our theory, we describe the computational structure of three implemented problem solvers -- KAM, MAPS, and HIPAIR --- in terms of the spatial aggregation generic operators by mixing and matching a library of commonly used routines.
cs.AI:Finding the stable models of a knowledge base is a significant computational problem in artificial intelligence. This task is at the computational heart of truth maintenance systems, autoepistemic logic, and default logic. Unfortunately, it is NP-hard. In this paper we present a hierarchy of classes of knowledge bases, Omega_1,Omega_2,..., with the following properties: first, Omega_1 is the class of all stratified knowledge bases; second, if a knowledge base Pi is in Omega_k, then Pi has at most k stable models, and all of them may be found in time O(lnk), where l is the length of the knowledge base and n the number of atoms in Pi; third, for an arbitrary knowledge base Pi, we can find the minimum k such that Pi belongs to Omega_k in time polynomial in the size of Pi; and, last, where K is the class of all knowledge bases, it is the case that union{i=1 to infty} Omega_i = K, that is, every knowledge base belongs to some class in the hierarchy.
cs.AI:We propose some domain-independent techniques for bringing well-founded partial-order planners closer to practicality. The first two techniques are aimed at improving search control while keeping overhead costs low. One is based on a simple adjustment to the default A* heuristic used by UCPOP to select plans for refinement. The other is based on preferring ``zero commitment'' (forced) plan refinements whenever possible, and using LIFO prioritization otherwise. A more radical technique is the use of operator parameter domains to prune search. These domains are initially computed from the definitions of the operators and the initial and goal conditions, using a polynomial-time algorithm that propagates sets of constants through the operator graph, starting in the initial conditions. During planning, parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats. In experiments based on modifications of UCPOP, our improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version. Crucially, the hardest problems gave the greatest improvements. The pruning technique based on parameter domains often gave speedups by an order of magnitude or more for difficult problems, both with the default UCPOP search strategy and with our improved strategy. The Lisp code for our techniques and for the test problems is provided in on-line appendices.
cs.AI:Cue phrases may be used in a discourse sense to explicitly signal discourse structure, but also in a sentential sense to convey semantic rather than structural information. Correctly classifying cue phrases as discourse or sentential is critical in natural language processing systems that exploit discourse structure, e.g., for performing tasks such as anaphora resolution and plan recognition. This paper explores the use of machine learning for classifying cue phrases as discourse or sentential. Two machine learning programs (Cgrendel and C4.5) are used to induce classification models from sets of pre-classified cue phrases and their features in text and speech. Machine learning is shown to be an effective technique for not only automating the generation of classification models, but also for improving upon previous results. When compared to manually derived classification models already in the literature, the learned models often perform with higher accuracy and contain new linguistic insights into the data. In addition, the ability to automatically construct classification models makes it easier to comparatively analyze the utility of alternative feature representations of the data. Finally, the ease of retraining makes the learning approach more scalable and flexible than manual methods.
cs.AI:This paper lays part of the groundwork for a domain theory of negotiation, that is, a way of classifying interactions so that it is clear, given a domain, which negotiation mechanisms and strategies are appropriate. We define State Oriented Domains, a general category of interaction. Necessary and sufficient conditions for cooperation are outlined. We use the notion of worth in an altered definition of utility, thus enabling agreements in a wider class of joint-goal reachable situations. An approach is offered for conflict resolution, and it is shown that even in a conflict situation, partial cooperative steps can be taken by interacting agents (that is, agents in fundamental conflict might still agree to cooperate up to a certain point). A Unified Negotiation Protocol (UNP) is developed that can be used in all types of encounters. It is shown that in certain borderline cooperative situations, a partial cooperative agreement (i.e., one that does not achieve all agents' goals) might be preferred by all agents, even though there exists a rational agreement that would achieve all their goals. Finally, we analyze cases where agents have incomplete information on the goals and worth of other agents. First we consider the case where agents' goals are private information, and we analyze what goal declaration strategies the agents might adopt to increase their utility. Then, we consider the situation where the agents' goals (and therefore stand-alone costs) are common knowledge, but the worth they attach to their goals is private information. We introduce two mechanisms, one 'strict', the other 'tolerant', and analyze their affects on the stability and efficiency of negotiation outcomes.
cs.AI:First-order learning involves finding a clause-form definition of a relation from examples of the relation and relevant background information. In this paper, a particular first-order learning system is modified to customize it for finding definitions of functional relations. This restriction leads to faster learning times and, in some cases, to definitions that have higher predictive accuracy. Other first-order learning systems might benefit from similar specialization.
cs.AI:This paper describes an extension to the constraint satisfaction problem (CSP) called MUSE CSP (MUltiply SEgmented Constraint Satisfaction Problem). This extension is especially useful for those problems which segment into multiple sets of partially shared variables. Such problems arise naturally in signal processing applications including computer vision, speech processing, and handwriting recognition. For these applications, it is often difficult to segment the data in only one way given the low-level information utilized by the segmentation algorithms. MUSE CSP can be used to compactly represent several similar instances of the constraint satisfaction problem. If multiple instances of a CSP have some common variables which have the same domains and constraints, then they can be combined into a single instance of a MUSE CSP, reducing the work required to apply the constraints. We introduce the concepts of MUSE node consistency, MUSE arc consistency, and MUSE path consistency. We then demonstrate how MUSE CSP can be used to compactly represent lexically ambiguous sentences and the multiple sentence hypotheses that are often generated by speech recognition algorithms so that grammar constraints can be used to provide parses for all syntactically correct sentences. Algorithms for MUSE arc and path consistency are provided. Finally, we discuss how to create a MUSE CSP from a set of CSPs which are labeled to indicate when the same variable is shared by more than a single CSP.
cs.AI:A new method is proposed for exploiting causal independencies in exact Bayesian network inference. A Bayesian network can be viewed as representing a factorization of a joint probability into the multiplication of a set of conditional probabilities. We present a notion of causal independence that enables one to further factorize the conditional probabilities into a combination of even smaller factors and consequently obtain a finer-grain factorization of the joint probability. The new formulation of causal independence lets us specify the conditional probability of a variable given its parents in terms of an associative and commutative operator, such as ``or'', ``sum'' or ``max'', on the contribution of each parent. We start with a simple algorithm VE for Bayesian network inference that, given evidence and a query variable, uses the factorization to find the posterior distribution of the query. We show how this algorithm can be extended to exploit causal independence. Empirical studies, based on the CPCS networks for medical diagnosis, show that this method is more efficient than previous methods and allows for inference in larger networks than previous algorithms.
cs.AI:Efficiently entering information into a computer is key to enjoying the benefits of computing. This paper describes three intelligent user interfaces: handwriting recognition, adaptive menus, and predictive fillin. In the context of adding a personUs name and address to an electronic organizer, tests show handwriting recognition is slower than typing on an on-screen, soft keyboard, while adaptive menus and predictive fillin can be twice as fast. This paper also presents strategies for applying these three interfaces to other information collection domains.
cs.AI:Decomposable dependency models possess a number of interesting and useful properties. This paper presents new characterizations of decomposable models in terms of independence relationships, which are obtained by adding a single axiom to the well-known set characterizing dependency models that are isomorphic to undirected graphs. We also briefly discuss a potential application of our results to the problem of learning graphical models from data.
cs.AI:Instance-based learning techniques typically handle continuous and linear input values well, but often do not handle nominal input attributes appropriately. The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values. This paper proposes three new heterogeneous distance functions, called the Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric (IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions are designed to handle applications with nominal attributes, continuous attributes, or both. In experiments on 48 applications the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.
cs.AI:Previous approaches of analyzing spontaneously spoken language often have been based on encoding syntactic and semantic knowledge manually and symbolically. While there has been some progress using statistical or connectionist language models, many current spoken- language systems still use a relatively brittle, hand-coded symbolic grammar or symbolic semantic component. In contrast, we describe a so-called screening approach for learning robust processing of spontaneously spoken language. A screening approach is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic, semantic and dialog levels. Rather than using a deeply structured symbolic analysis, we use a flat connectionist analysis. This screening approach aims at supporting speech and language processing by using (1) data-driven learning and (2) robustness of connectionist networks. In order to test this approach, we have developed the SCREEN system which is based on this new robust, learned and flat analysis. In this paper, we focus on a detailed description of SCREEN's architecture, the flat syntactic and semantic analysis, the interaction with a speech recognizer, and a detailed evaluation analysis of the robustness under the influence of noisy or incomplete input. The main result of this paper is that flat representations allow more robust processing of spontaneous spoken language than deeply structured representations. In particular, we show how the fault-tolerance and learning capability of connectionist networks can support a flat analysis for providing more robust spoken-language processing within an overall hybrid symbolic/connectionist framework.
cs.AI:Most modern formalisms used in Databases and Artificial Intelligence for describing an application domain are based on the notions of class (or concept) and relationship among classes. One interesting feature of such formalisms is the possibility of defining a class, i.e., providing a set of properties that precisely characterize the instances of the class. Many recent articles point out that there are several ways of assigning a meaning to a class definition containing some sort of recursion. In this paper, we argue that, instead of choosing a single style of semantics, we achieve better results by adopting a formalism that allows for different semantics to coexist. We demonstrate the feasibility of our argument, by presenting a knowledge representation formalism, the description logic muALCQ, with the above characteristics. In addition to the constructs for conjunction, disjunction, negation, quantifiers, and qualified number restrictions, muALCQ includes special fixpoint constructs to express (suitably interpreted) recursive definitions. These constructs enable the usual frame-based descriptions to be combined with definitions of recursive data structures such as directed acyclic graphs, lists, streams, etc. We establish several properties of muALCQ, including the decidability and the computational complexity of reasoning, by formulating a correspondence with a particular modal logic of programs called the modal mu-calculus.
cs.AI:We argue that the analysis of agent/environment interactions should be extended to include the conventions and invariants maintained by agents throughout their activity. We refer to this thicker notion of environment as a lifeworld and present a partial set of formal tools for describing structures of lifeworlds and the ways in which they computationally simplify activity. As one specific example, we apply the tools to the analysis of the Toast system and show how versions of the system with very different control structures in fact implement a common control structure together with different conventions for encoding task state in the positions or states of objects in the environment.
cs.AI:We describe a new paradigm for implementing inference in belief networks, which consists of two steps: (1) compiling a belief network into an arithmetic expression called a Query DAG (Q-DAG); and (2) answering queries using a simple evaluation algorithm. Each node of a Q-DAG represents a numeric operation, a number, or a symbol for evidence. Each leaf node of a Q-DAG represents the answer to a network query, that is, the probability of some event of interest. It appears that Q-DAGs can be generated using any of the standard algorithms for exact inference in belief networks (we show how they can be generated using clustering and conditioning algorithms). The time and space complexity of a Q-DAG generation algorithm is no worse than the time complexity of the inference algorithm on which it is based. The complexity of a Q-DAG evaluation algorithm is linear in the size of the Q-DAG, and such inference amounts to a standard evaluation of the arithmetic expression it represents. The intended value of Q-DAGs is in reducing the software and hardware resources required to utilize belief networks in on-line, real-world applications. The proposed framework also facilitates the development of on-line inference on different software and hardware platforms due to the simplicity of the Q-DAG evaluation algorithm. Interestingly enough, Q-DAGs were found to serve other purposes: simple techniques for reducing Q-DAGs tend to subsume relatively complex optimization techniques for belief-network inference, such as network-pruning and computation-caching.
cs.AI:An algorithm that learns from a set of examples should ideally be able to exploit the available resources of (a) abundant computing power and (b) domain-specific knowledge to improve its ability to generalize. Connectionist theory-refinement systems, which use background knowledge to select a neural network's topology and initial weights, have proven to be effective at exploiting domain-specific knowledge; however, most do not exploit available computing power. This weakness occurs because they lack the ability to refine the topology of the neural networks they produce, thereby limiting generalization, especially when given impoverished domain theories. We present the REGENT algorithm which uses (a) domain-specific knowledge to help create an initial population of knowledge-based neural networks and (b) genetic operators of crossover and mutation (specifically designed for knowledge-based networks) to continually search for better network topologies. Experiments on three real-world domains indicate that our new algorithm is able to significantly increase generalization compared to a standard connectionist theory-refinement system, as well as our previous algorithm for growing knowledge-based networks.
cs.AI:Several recent studies have compared the relative efficiency of alternative flaw selection strategies for partial-order causal link (POCL) planning. We review this literature, and present new experimental results that generalize the earlier work and explain some of the discrepancies in it. In particular, we describe the Least-Cost Flaw Repair (LCFR) strategy developed and analyzed by Joslin and Pollack (1994), and compare it with other strategies, including Gerevini and Schubert's (1996) ZLIFO strategy. LCFR and ZLIFO make very different, and apparently conflicting claims about the most effective way to reduce search-space size in POCL planning. We resolve this conflict, arguing that much of the benefit that Gerevini and Schubert ascribe to the LIFO component of their ZLIFO strategy is better attributed to other causes. We show that for many problems, a strategy that combines least-cost flaw selection with the delay of separable threats will be effective in reducing search-space size, and will do so without excessive computational overhead. Although such a strategy thus provides a good default, we also show that certain domain characteristics may reduce its effectiveness.
cs.AI:We investigate the computational properties of the spatial algebra RCC-5 which is a restricted version of the RCC framework for spatial reasoning. The satisfiability problem for RCC-5 is known to be NP-complete but not much is known about its approximately four billion subclasses. We provide a complete classification of satisfiability for all these subclasses into polynomial and NP-complete respectively. In the process, we identify all maximal tractable subalgebras which are four in total.
cs.AI:The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning. We test the generality of this explanation by examining one of its predictions: if the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost. Instead, we find the easy-hard-easy pattern in median search cost even when the number of solutions is held constant, for some search methods. This generalizes previous observations of this pattern and shows that the existing theory does not explain the full range of the peak in search cost. In these cases the pattern appears to be due to changes in the size of the minimal unsolvable subproblems, rather than changing numbers of solutions.
cs.AI:This paper combines two important directions of research in temporal resoning: that of finding maximal tractable subclasses of Allen's interval algebra, and that of reasoning with metric temporal information. Eight new maximal tractable subclasses of Allen's interval algebra are presented, some of them subsuming previously reported tractable algebras. The algebras allow for metric temporal constraints on interval starting or ending points, using the recent framework of Horn DLRs. Two of the algebras can express the notion of sequentiality between intervals, being the first such algebras admitting both qualitative and metric time.
cs.AI:Starting with a likelihood or preference order on worlds, we extend it to a likelihood ordering on sets of worlds in a natural way, and examine the resulting logic. Lewis earlier considered such a notion of relative likelihood in the context of studying counterfactuals, but he assumed a total preference order on worlds. Complications arise when examining partial orders that are not present for total orders. There are subtleties involving the exact approach to lifting the order on worlds to an order on sets of worlds. In addition, the axiomatization of the logic of relative likelihood in the case of partial orders gives insight into the connection between relative likelihood and default reasoning.
cs.AI:Many AI researchers are today striving to build agent teams for complex, dynamic multi-agent domains, with intended applications in arenas such as education, training, entertainment, information integration, and collective robotics. Unfortunately, uncertainties in these complex, dynamic domains obstruct coherent teamwork. In particular, team members often encounter differing, incomplete, and possibly inconsistent views of their environment. Furthermore, team members can unexpectedly fail in fulfilling responsibilities or discover unexpected opportunities. Highly flexible coordination and communication is key in addressing such uncertainties. Simply fitting individual agents with precomputed coordination plans will not do, for their inflexibility can cause severe failures in teamwork, and their domain-specificity hinders reusability. Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork. Agents exploit such models to autonomously reason about coordination and communication, providing requisite flexibility. Furthermore, the models enable reuse across domains, both saving implementation effort and enforcing consistency. This article presents one general, implemented model of teamwork, called STEAM. The basic building block of teamwork in STEAM is joint intentions (Cohen & Levesque, 1991b); teamwork in STEAM is based on agents' building up a (partial) hierarchy of joint intentions (this hierarchy is seen to parallel Grosz & Kraus's partial SharedPlans, 1996). Furthermore, in STEAM, team members monitor the team's and individual members' performance, reorganizing the team as necessary. Finally, decision-theoretic communication selectivity in STEAM ensures reduction in communication overheads of teamwork, with appropriate sensitivity to the environmental conditions. This article describes STEAM's application in three different complex domains, and presents detailed empirical results.
cs.AI:SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively. The result is a hierarchical representation of the original sequence, which offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the size of the grammar, and produce structure as a by-product. SEQUITUR breaks new ground by operating incrementally. Moreover, the method's simple structure permits a proof that it operates in space and time that is linear in the size of the input. Our implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences.
cs.AI:Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improvements it provides are dependent on adequate judgements as to problem similarity. In particular, although CBP may substantially reduce planning effort overall, it is subject to a mis-retrieval problem. The success of CBP depends on these retrieval errors being relatively rare. This paper describes the design and implementation of a replay framework for the case-based planner DERSNLP+EBL. DERSNLP+EBL extends current CBP methodology by incorporating explanation-based learning techniques that allow it to explain and learn from the retrieval failures it encounters. These techniques are used to refine judgements about case similarity in response to feedback when a wrong decision has been made. The same failure analysis is used in building the case library, through the addition of repairing cases. Large problems are split and stored as single goal subproblems. Multi-goal problems are stored only when these smaller cases fail to be merged into a full solution. An empirical evaluation of this approach demonstrates the advantage of learning from experienced retrieval failure.
cs.AI:Partially observable Markov decision processes (POMDPs) are a natural model for planning problems where effects of actions are nondeterministic and the state of the world is not completely observable. It is difficult to solve POMDPs exactly. This paper proposes a new approximation scheme. The basic idea is to transform a POMDP into another one where additional information is provided by an oracle. The oracle informs the planning agent that the current state of the world is in a certain region. The transformed POMDP is consequently said to be region observable. It is easier to solve than the original POMDP. We propose to solve the transformed POMDP and use its optimal policy to construct an approximate policy for the original POMDP. By controlling the amount of additional information that the oracle provides, it is possible to find a proper tradeoff between computational time and approximation quality. In terms of algorithmic contributions, we study in details how to exploit region observability in solving the transformed POMDP. To facilitate the study, we also propose a new exact algorithm for general POMDPs. The algorithm is conceptually simple and yet is significantly more efficient than all previous exact algorithms.
cs.AI:The model of a non-Bayesian agent who faces a repeated game with incomplete information against Nature is an appropriate tool for modeling general agent-environment interactions. In such a model the environment state (controlled by Nature) may change arbitrarily, and the feedback/reward function is initially unknown. The agent is not Bayesian, that is he does not form a prior probability neither on the state selection strategy of Nature, nor on his reward function. A policy for the agent is a function which assigns an action to every history of observations and actions. Two basic feedback structures are considered. In one of them -- the perfect monitoring case -- the agent is able to observe the previous environment state as part of his feedback, while in the other -- the imperfect monitoring case -- all that is available to the agent is the reward obtained. Both of these settings refer to partially observable processes, where the current environment state is unknown. Our main result refers to the competitive ratio criterion in the perfect monitoring case. We prove the existence of an efficient stochastic policy that ensures that the competitive ratio is obtained at almost all stages with an arbitrarily high probability, where efficiency is measured in terms of rate of convergence. It is further shown that such an optimal policy does not exist in the imperfect monitoring case. Moreover, it is proved that in the perfect monitoring case there does not exist a deterministic policy that satisfies our long run optimality criterion. In addition, we discuss the maxmin criterion and prove that a deterministic efficient optimal strategy does exist in the imperfect monitoring case under this criterion. Finally we show that our approach to long-run optimality can be viewed as qualitative, which distinguishes it from previous work in this area.
cs.AI:Local search algorithms for combinatorial search problems frequently encounter a sequence of states in which it is impossible to improve the value of the objective function; moves through these regions, called plateau moves, dominate the time spent in local search. We analyze and characterize plateaus for three different classes of randomly generated Boolean Satisfiability problems. We identify several interesting features of plateaus that impact the performance of local search algorithms. We show that local minima tend to be small but occasionally may be very large. We also show that local minima can be escaped without unsatisfying a large number of clauses, but that systematically searching for an escape route may be computationally expensive if the local minimum is large. We show that plateaus with exits, called benches, tend to be much larger than minima, and that some benches have very few exit states which local search can use to escape. We show that the solutions (i.e., global minima) of randomly generated problem instances form clusters, which behave similarly to local minima. We revisit several enhancements of local search algorithms and explain their performance in light of our results. Finally we discuss strategies for creating the next generation of local search algorithms.
cs.AI:The assessment of bidirectional heuristic search has been incorrect since it was first published more than a quarter of a century ago. For quite a long time, this search strategy did not achieve the expected results, and there was a major misunderstanding about the reasons behind it. Although there is still wide-spread belief that bidirectional heuristic search is afflicted by the problem of search frontiers passing each other, we demonstrate that this conjecture is wrong. Based on this finding, we present both a new generic approach to bidirectional heuristic search and a new approach to dynamically improving heuristic values that is feasible in bidirectional search only. These approaches are put into perspective with both the traditional and more recently proposed approaches in order to facilitate a better overall understanding. Empirical results of experiments with our new approaches show that bidirectional heuristic search can be performed very efficiently and also with limited memory. These results suggest that bidirectional heuristic search appears to be better for solving certain difficult problems than corresponding unidirectional search. This provides some evidence for the usefulness of a search strategy that was long neglected. In summary, we show that bidirectional heuristic search is viable and consequently propose that it be reconsidered.
cs.AI:Approximating a general formula from above and below by Horn formulas (its Horn envelope and Horn core, respectively) was proposed by Selman and Kautz (1991, 1996) as a form of ``knowledge compilation,'' supporting rapid approximate reasoning; on the negative side, this scheme is static in that it supports no updates, and has certain complexity drawbacks pointed out by Kavvadias, Papadimitriou and Sideri (1993). On the other hand, the many frameworks and schemes proposed in the literature for theory update and revision are plagued by serious complexity-theoretic impediments, even in the Horn case, as was pointed out by Eiter and Gottlob (1992), and is further demonstrated in the present paper. More fundamentally, these schemes are not inductive, in that they may lose in a single update any positive properties of the represented sets of formulas (small size, Horn structure, etc.). In this paper we propose a new scheme, incremental recompilation, which combines Horn approximation and model-based updates; this scheme is inductive and very efficient, free of the problems facing its constituents. A set of formulas is represented by an upper and lower Horn approximation. To update, we replace the upper Horn formula by the Horn envelope of its minimum-change update, and similarly the lower one by the Horn core of its update; the key fact which enables this scheme is that Horn envelopes and cores are easy to compute when the underlying formula is the result of a minimum-change update of a Horn formula by a clause. We conjecture that efficient algorithms are possible for more complex updates.
cs.AI:An important characteristic of many logics for Artificial Intelligence is their nonmonotonicity. This means that adding a formula to the premises can invalidate some of the consequences. There may, however, exist formulae that can always be safely added to the premises without destroying any of the consequences: we say they respect monotonicity. Also, there may be formulae that, when they are a consequence, can not be invalidated when adding any formula to the premises: we call them conservative. We study these two classes of formulae for preferential logics, and show that they are closely linked to the formulae whose truth-value is preserved along the (preferential) ordering. We will consider some preferential logics for illustration, and prove syntactic characterization results for them. The results in this paper may improve the efficiency of theorem provers for preferential logics.
cs.AI:Existing plan synthesis approaches in artificial intelligence fall into two categories -- domain independent and domain dependent. The domain independent approaches are applicable across a variety of domains, but may not be very efficient in any one given domain. The domain dependent approaches need to be (re)designed for each domain separately, but can be very efficient in the domain for which they are designed. One enticing alternative to these approaches is to automatically synthesize domain independent planners given the knowledge about the domain and the theory of planning. In this paper, we investigate the feasibility of using existing automated software synthesis tools to support such synthesis. Specifically, we describe an architecture called CLAY in which the Kestrel Interactive Development System (KIDS) is used to derive a domain-customized planner through a semi-automatic combination of a declarative theory of planning, and the declarative control knowledge specific to a given domain, to semi-automatically combine them to derive domain-customized planners. We discuss what it means to write a declarative theory of planning and control knowledge for KIDS, and illustrate our approach by generating a class of domain-specific planners using state space refinements. Our experiments show that the synthesized planners can outperform classical refinement planners (implemented as instantiations of UCP, Kambhampati & Srivastava, 1995), using the same control knowledge. We will contrast the costs and benefits of the synthesis approach with conventional methods for customizing domain independent planners.
cs.AI:This paper introduces new algorithms and data structures for quick counting for machine learning datasets. We focus on the counting task of constructing contingency tables, but our approach is also applicable to counting the number of records in a dataset that match conjunctive queries. Subject to certain assumptions, the costs of these operations can be shown to be independent of the number of records in the dataset and loglinear in the number of non-zero entries in the contingency table. We provide a very sparse data structure, the ADtree, to minimize memory use. We provide analytical worst-case bounds for this structure for several models of data distribution. We empirically demonstrate that tractably-sized data structures can be produced for large real-world datasets by (a) using a sparse tree structure that never allocates memory for counts of zero, (b) never allocating memory for counts that can be deduced from other counts, and (c) not bothering to expand the tree fully near its leaves. We show how the ADtree can be used to accelerate Bayes net structure finding algorithms, rule learning algorithms, and feature selection algorithms, and we provide a number of empirical results comparing ADtree methods against traditional direct counting approaches. We also discuss the possible uses of ADtrees in other machine learning methods, and discuss the merits of ADtrees in comparison with alternative representations such as kd-trees, R-trees and Frequent Sets.
cs.AI:In this paper we consider the problem of `theory patching', in which we are given a domain theory, some of whose components are indicated to be possibly flawed, and a set of labeled training examples for the domain concept. The theory patching problem is to revise only the indicated components of the theory, such that the resulting theory correctly classifies all the training examples. Theory patching is thus a type of theory revision in which revisions are made to individual components of the theory. Our concern in this paper is to determine for which classes of logical domain theories the theory patching problem is tractable. We consider both propositional and first-order domain theories, and show that the theory patching problem is equivalent to that of determining what information contained in a theory is `stable' regardless of what revisions might be performed to the theory. We show that determining stability is tractable if the input theory satisfies two conditions: that revisions to each theory component have monotonic effects on the classification of examples, and that theory components act independently in the classification of examples in the theory. We also show how the concepts introduced can be used to determine the soundness and completeness of particular theory patching algorithms.
cs.AI:In this paper we re-investigate windowing for rule learning algorithms. We show that, contrary to previous results for decision tree learning, windowing can in fact achieve significant run-time gains in noise-free domains and explain the different behavior of rule learning algorithms by the fact that they learn each rule independently. The main contribution of this paper is integrative windowing, a new type of algorithm that further exploits this property by integrating good rules into the final theory right after they have been discovered. Thus it avoids re-learning these rules in subsequent iterations of the windowing process. Experimental evidence in a variety of noise-free domains shows that integrative windowing can in fact achieve substantial run-time gains. Furthermore, we discuss the problem of noise in windowing and present an algorithm that is able to achieve run-time gains in a set of experiments in a simple domain with artificial noise.
cs.AI:This paper presents a comprehensive approach for model-based diagnosis which includes proposals for characterizing and computing preferred diagnoses, assuming that the system description is augmented with a system structure (a directed graph explicating the interconnections between system components). Specifically, we first introduce the notion of a consequence, which is a syntactically unconstrained propositional sentence that characterizes all consistency-based diagnoses and show that standard characterizations of diagnoses, such as minimal conflicts, correspond to syntactic variations on a consequence. Second, we propose a new syntactic variation on the consequence known as negation normal form (NNF) and discuss its merits compared to standard variations. Third, we introduce a basic algorithm for computing consequences in NNF given a structured system description. We show that if the system structure does not contain cycles, then there is always a linear-size consequence in NNF which can be computed in linear time. For arbitrary system structures, we show a precise connection between the complexity of computing consequences and the topology of the underlying system structure. Finally, we present an algorithm that enumerates the preferred diagnoses characterized by a consequence. The algorithm is shown to take linear time in the size of the consequence if the preference criterion satisfies some general conditions.
cs.AI:One of the most common mechanisms used for speeding up problem solvers is macro-learning. Macros are sequences of basic operators acquired during problem solving. Macros are used by the problem solver as if they were basic operators. The major problem that macro-learning presents is the vast number of macros that are available for acquisition. Macros increase the branching factor of the search space and can severely degrade problem-solving efficiency. To make macro learning useful, a program must be selective in acquiring and utilizing macros. This paper describes a general method for selective acquisition of macros. Solvable training problems are generated in increasing order of difficulty. The only macros acquired are those that take the problem solver out of a local minimum to a better state. The utility of the method is demonstrated in several domains, including the domain of NxN sliding-tile puzzles. After learning on small puzzles, the system is able to efficiently solve puzzles of any size.
cs.AI:We examine the computational complexity of testing and finding small plans in probabilistic planning domains with both flat and propositional representations. The complexity of plan evaluation and existence varies with the plan type sought; we examine totally ordered plans, acyclic plans, and looping plans, and partially ordered plans under three natural definitions of plan value. We show that problems of interest are complete for a variety of complexity classes: PL, P, NP, co-NP, PP, NP^PP, co-NP^PP, and PSPACE. In the process of proving that certain planning problems are complete for NP^PP, we introduce a new basic NP^PP-complete problem, E-MAJSAT, which generalizes the standard Boolean satisfiability problem to computations involving probabilistic quantities; our results suggest that the development of good heuristics for E-MAJSAT could be important for the creation of efficient algorithms for a wide variety of problems.
cs.AI:In this paper we describe SYNERGY, which is a highly parallelizable, linear planning system that is based on the genetic programming paradigm. Rather than reasoning about the world it is planning for, SYNERGY uses artificial selection, recombination and fitness measure to generate linear plans that solve conjunctive goals. We ran SYNERGY on several domains (e.g., the briefcase problem and a few variants of the robot navigation problem), and the experimental results show that our planner is capable of handling problem instances that are one to two orders of magnitude larger than the ones solved by UCPOP. In order to facilitate the search reduction and to enhance the expressive power of SYNERGY, we also propose two major extensions to our planning system: a formalism for using hierarchical planning operators, and a framework for planning in dynamic environments.
cs.AI:We show that several constraint propagation algorithms (also called (local) consistency, consistency enforcing, Waltz, filtering or narrowing algorithms) are instances of algorithms that deal with chaotic iteration. To this end we propose a simple abstract framework that allows us to classify and compare these algorithms and to establish in a uniform way their basic properties.
cs.AI:This paper examines the phenomenon of daydreaming: spontaneously recalling or imagining personal or vicarious experiences in the past or future. The following important roles of daydreaming in human cognition are postulated: plan preparation and rehearsal, learning from failures and successes, support for processes of creativity, emotion regulation, and motivation.   A computational theory of daydreaming and its implementation as the program DAYDREAMER are presented. DAYDREAMER consists of 1) a scenario generator based on relaxed planning, 2) a dynamic episodic memory of experiences used by the scenario generator, 3) a collection of personal goals and control goals which guide the scenario generator, 4) an emotion component in which daydreams initiate, and are initiated by, emotional states arising from goal outcomes, and 5) domain knowledge of interpersonal relations and common everyday occurrences.   The role of emotions and control goals in daydreaming is discussed. Four control goals commonly used in guiding daydreaming are presented: rationalization, failure/success reversal, revenge, and preparation. The role of episodic memory in daydreaming is considered, including how daydreamed information is incorporated into memory and later used. An initial version of DAYDREAMER which produces several daydreams (in English) is currently running.
cs.AI:Real world combinatorial optimization problems such as scheduling are typically too complex to solve with exact methods. Additionally, the problems often have to observe vaguely specified constraints of different importance, the available data may be uncertain, and compromises between antagonistic criteria may be necessary. We present a combination of approximate reasoning based constraints and iterative optimization based heuristics that help to model and solve such problems in a framework of C++ software libraries called StarFLIP++. While initially developed to schedule continuous caster units in steel plants, we present in this paper results from reusing the library components in a shift scheduling system for the workforce of an industrial production plant.
cs.AI:The study of belief change has been an active area in philosophy and AI. In recent years two special cases of belief change, belief revision and belief update, have been studied in detail. In a companion paper (Friedman & Halpern, 1997), we introduce a new framework to model belief change. This framework combines temporal and epistemic modalities with a notion of plausibility, allowing us to examine the change of beliefs over time. In this paper, we show how belief revision and belief update can be captured in our framework. This allows us to compare the assumptions made by each method, and to better understand the principles underlying them. In particular, it shows that Katsuno and Mendelzon's notion of belief update (Katsuno & Mendelzon, 1991a) depends on several strong assumptions that may limit its applicability in artificial intelligence. Finally, our analysis allow us to identify a notion of minimal change that underlies a broad range of belief change operations including revision and update.
cs.AI:How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations," which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations," which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations," grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z").
cs.AI:In tree search problem the best-first search algorithm needs too much of space . To remove such drawbacks of these algorithms the IDA* was developed which is both space and time cost efficient. But again IDA* can give an optimal solution for real valued problems like Flow shop scheduling, Travelling Salesman and 0/1 Knapsack due to their real valued cost estimates. Thus further modifications are done on it and the Iterative Deepening Branch and Bound Search Algorithms is developed which meets the requirements. We have tried using this algorithm for the Flow Shop Scheduling Problem and have found that it is quite effective.
cs.AI:Agents are small programs that autonomously take actions based on changes in their environment or ``state.'' Over the last few years, there have been an increasing number of efforts to build agents that can interact and/or collaborate with other agents. In one of these efforts, Eiter, Subrahmanian amd Pick (AIJ, 108(1-2), pages 179-255) have shown how agents may be built on top of legacy code. However, their framework assumes that agent states are completely determined, and there is no uncertainty in an agent's state. Thus, their framework allows an agent developer to specify how his agents will react when the agent is 100% sure about what is true/false in the world state. In this paper, we propose the concept of a \emph{probabilistic agent program} and show how, given an arbitrary program written in any imperative language, we may build a declarative ``probabilistic'' agent program on top of it which supports decision making in the presence of uncertainty. We provide two alternative semantics for probabilistic agent programs. We show that the second semantics, though more epistemically appealing, is more complex to compute. We provide sound and complete algorithms to compute the semantics of \emph{positive} agent programs.
cs.AI:The assumptions needed to prove Cox's Theorem are discussed and examined. Various sets of assumptions under which a Cox-style theorem can be proved are provided, although all are rather strong and, arguably, not natural.
cs.AI:We revisit the issue of connections between two leading formalisms in nonmonotonic reasoning: autoepistemic logic and default logic. For each logic we develop a comprehensive semantic framework based on the notion of a belief pair. The set of all belief pairs together with the so called knowledge ordering forms a complete lattice. For each logic, we introduce several semantics by means of fixpoints of operators on the lattice of belief pairs. Our results elucidate an underlying isomorphism of the respective semantic constructions. In particular, we show that the interpretation of defaults as modal formulas proposed by Konolige allows us to represent all semantics for default logic in terms of the corresponding semantics for autoepistemic logic. Thus, our results conclusively establish that default logic can indeed be viewed as a fragment of autoepistemic logic. However, as we also demonstrate, the semantics of Moore and Reiter are given by different operators and occupy different locations in their corresponding families of semantics. This result explains the source of the longstanding difficulty to formally relate these two semantics. In the paper, we also discuss approximating skeptical reasoning with autoepistemic and default logics and establish constructive principles behind such approximations.
cs.AI:Randomized algorithms for deciding satisfiability were shown to be effective in solving problems with thousands of variables. However, these algorithms are not complete. That is, they provide no guarantee that a satisfying assignment, if one exists, will be found. Thus, when studying randomized algorithms, there are two important characteristics that need to be considered: the running time and, even more importantly, the accuracy --- a measure of likelihood that a satisfying assignment will be found, provided one exists. In fact, we argue that without a reference to the accuracy, the notion of the running time for randomized algorithms is not well-defined. In this paper, we introduce a formal notion of accuracy. We use it to define a concept of the running time. We use both notions to study the random walk strategy GSAT algorithm. We investigate the dependence of accuracy on properties of input formulas such as clause-to-variable ratio and the number of satisfying assignments. We demonstrate that the running time of GSAT grows exponentially in the number of variables of the input formula for randomly generated 3-CNF formulas and for the formulas encoding 3- and 4-colorability of graphs.
cs.AI:Two different types of agency are discussed based on dynamically coherent and incoherent couplings with an environment respectively. I propose that until a private syntax (syntactic autonomy) is discovered by dynamically coherent agents, there are no significant or interesting types of closure or autonomy. When syntactic autonomy is established, then, because of a process of description-based selected self-organization, open-ended evolution is enabled. At this stage, agents depend, in addition to dynamics, on localized, symbolic memory, thus adding a level of dynamical incoherence to their interaction with the environment. Furthermore, it is the appearance of syntactic autonomy which enables much more interesting types of closures amongst agents which share the same syntax. To investigate how we can study the emergence of syntax from dynamical systems, experiments with cellular automata leading to emergent computation to solve non-trivial tasks are discussed. RNA editing is also mentioned as a process that may have been used to obtain a primordial biological code necessary open-ended evolution.
cs.AI:This paper presents a method of computing a revision of a function-free normal logic program. If an added rule is inconsistent with a program, that is, if it leads to a situation such that no stable model exists for a new program, then deletion and addition of rules are performed to avoid inconsistency. We specify a revision by translating a normal logic program into an abductive logic program with abducibles to represent deletion and addition of rules. To compute such deletion and addition, we propose an adaptation of our top-down abductive proof procedure to compute a relevant abducibles to an added rule. We compute a minimally revised program, by choosing a minimal set of abducibles among all the sets of abducibles computed by a top-down proof procedure.
cs.AI:This is a system description for the OSCAR defeasible reasoner.
cs.AI:Diagnostic reasoning has been characterized logically as consistency-based reasoning or abductive reasoning. Previous analyses in the literature have shown, on the one hand, that choosing the (in general more restrictive) abductive definition may be appropriate or not, depending on the content of the knowledge base [Console&Torasso91], and, on the other hand, that, depending on the choice of the definition the same knowledge should be expressed in different form [Poole94].   Since in Model-Based Diagnosis a major problem is finding the right way of abstracting the behavior of the system to be modeled, this paper discusses the relation between modeling, and in particular abstraction in the model, and the notion of diagnosis.
cs.AI:ACLP is a system which combines abductive reasoning and constraint solving by integrating the frameworks of Abductive Logic Programming (ALP) and Constraint Logic Programming (CLP). It forms a general high-level knowledge representation environment for abductive problems in Artificial Intelligence and other areas. In ACLP, the task of abduction is supported and enhanced by its non-trivial integration with constraint solving facilitating its application to complex problems. The ACLP system is currently implemented on top of the CLP language of ECLiPSe as a meta-interpreter exploiting its underlying constraint solver for finite domains. It has been applied to the problems of planning and scheduling in order to test its computational effectiveness compared with the direct use of the (lower level) constraint solving framework of CLP on which it is built. These experiments provide evidence that the abductive framework of ACLP does not compromise significantly the computational efficiency of the solutions. Other experiments show the natural ability of ACLP to accommodate easily and in a robust way new or changing requirements of the original problem.
cs.AI:We present a method for relevance sensitive non-monotonic inference from belief sequences which incorporates insights pertaining to prioritized inference and relevance sensitive, inconsistency tolerant belief revision.   Our model uses a finite, logically open sequence of propositional formulas as a representation for beliefs and defines a notion of inference from maxiconsistent subsets of formulas guided by two orderings: a temporal sequencing and an ordering based on relevance relations between the conclusion and formulas in the sequence. The relevance relations are ternary (using context as a parameter) as opposed to standard binary axiomatizations. The inference operation thus defined easily handles iterated revision by maintaining a revision history, blocks the derivation of inconsistent answers from a possibly inconsistent sequence and maintains the distinction between explicit and implicit beliefs. In doing so, it provides a finitely presented formalism and a plausible model of reasoning for automated agents.
cs.AI:We propose a combination of probabilistic reasoning from conditional constraints with approaches to default reasoning from conditional knowledge bases. In detail, we generalize the notions of Pearl's entailment in system Z, Lehmann's lexicographic entailment, and Geffner's conditional entailment to conditional constraints. We give some examples that show that the new notions of z-, lexicographic, and conditional entailment have similar properties like their classical counterparts. Moreover, we show that the new notions of z-, lexicographic, and conditional entailment are proper generalizations of both their classical counterparts and the classical notion of logical entailment for conditional constraints.
cs.AI:This paper describes a system, called PLP, for compiling ordered logic programs into standard logic programs under the answer set semantics. In an ordered logic program, rules are named by unique terms, and preferences among rules are given by a set of dedicated atoms. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed theory correspond with the preferred answer sets of the original theory. Since the result of the translation is an extended logic program, existing logic programming systems can be used as underlying reasoning engine. In particular, PLP is conceived as a front-end to the logic programming systems dlv and smodels.
cs.AI:The SLDNFA-system results from the LP+ project at the K.U.Leuven, which investigates logics and proof procedures for these logics for declarative knowledge representation. Within this project inductive definition logic (ID-logic) is used as representation logic. Different solvers are being developed for this logic and one of these is SLDNFA. A prototype of the system is available and used for investigating how to solve efficiently problems represented in ID-logic.
cs.AI:We describe an approach for compiling preferences into logic programs under the answer set semantics. An ordered logic program is an extended logic program in which rules are named by unique terms, and in which preferences among rules are given by a set of dedicated atoms. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed theory correspond with the preferred answer sets of the original theory. Our approach allows both the specification of static orderings (as found in most previous work), in which preferences are external to a logic program, as well as orderings on sets of rules. In large part then, we are interested in describing a general methodology for uniformly incorporating preference information in a logic program. Since the result of our translation is an extended logic program, we can make use of existing implementations, such as dlv and smodels. To this end, we have developed a compiler, available on the web, as a front-end for these programming systems.
cs.AI:This paper proposes two kinds of fuzzy abductive inference in the framework of fuzzy rule base. The abductive inference processes described here depend on the semantic of the rule. We distinguish two classes of interpretation of a fuzzy rule, certainty generation rules and possible generation rules. In this paper we present the architecture of abductive inference in the first class of interpretation. We give two kinds of problem that we can resolve by using the proposed models of inference.
cs.AI:The goal of the LP+ project at the K.U.Leuven is to design an expressive logic, suitable for declarative knowledge representation, and to develop intelligent systems based on Logic Programming technology for solving computational problems using the declarative specifications. The ID-logic is an integration of typed classical logic and a definition logic. Different abductive solvers for this language are being developed. This paper is a report of the integration of high order aggregates into ID-logic and the consequences on the solver SLDNFA.
cs.AI:We propose a new approach to belief revision that provides a way to change knowledge bases with a minimum of effort. We call this way of revising belief states optimal belief revision. Our revision method gives special attention to the fact that most belief revision processes are directed to a specific informational objective. This approach to belief change is founded on notions such as optimal context and accessibility. For the sentential model of belief states we provide both a formal description of contexts as sub-theories determined by three parameters and a method to construct contexts. Next, we introduce an accessibility ordering for belief sets, which we then use for selecting the best (optimal) contexts with respect to the processing effort involved in the revision. Then, for finitely axiomatizable knowledge bases, we characterize a finite accessibility ranking from which the accessibility ordering for the entire base is generated and show how to determine the ranking of an arbitrary sentence in the language. Finally, we define the adjustment of the accessibility ranking of a revised base of a belief set.
cs.AI:High-level robot controllers in realistic domains typically deal with processes which operate concurrently, change the world continuously, and where the execution of actions is event-driven as in ``charge the batteries as soon as the voltage level is low''. While non-logic-based robot control languages are well suited to express such scenarios, they fare poorly when it comes to projecting, in a conspicuous way, how the world evolves when actions are executed. On the other hand, a logic-based control language like \congolog, based on the situation calculus, is well-suited for the latter. However, it has problems expressing event-driven behavior. In this paper, we show how these problems can be overcome by first extending the situation calculus to support continuous change and event-driven behavior and then presenting \ccgolog, a variant of \congolog which is based on the extended situation calculus. One benefit of \ccgolog is that it narrows the gap in expressiveness compared to non-logic-based control languages while preserving a semantically well-founded projection mechanism.
cs.AI:The Smodels system implements the stable model semantics for normal logic programs. It handles a subclass of programs which contain no function symbols and are domain-restricted but supports extensions including built-in functions as well as cardinality and weight constraints. On top of this core engine more involved systems can be built. As an example, we have implemented total and partial stable model computation for disjunctive logic programs. An interesting application method is based on answer set programming, i.e., encoding an application problem as a set of rules so that its solutions are captured by the stable models of the rules. Smodels has been applied to a number of areas including planning, model checking, reachability analysis, product configuration, dynamic constraint satisfaction, and feature interaction.
cs.AI:E-RES is a system that implements the Language E, a logic for reasoning about narratives of action occurrences and observations. E's semantics is model-theoretic, but this implementation is based on a sound and complete reformulation of E in terms of argumentation, and uses general computational techniques of argumentation frameworks. The system derives sceptical non-monotonic consequences of a given reformulated theory which exactly correspond to consequences entailed by E's model-theory. The computation relies on a complimentary ability of the system to derive credulous non-monotonic consequences together with a set of supporting assumptions which is sufficient for the (credulous) conclusion to hold. E-RES allows theories to contain general action laws, statements about action occurrences, observations and statements of ramifications (or universal laws). It is able to derive consequences both forward and backward in time. This paper gives a short overview of the theoretical basis of E-RES and illustrates its use on a variety of examples. Currently, E-RES is being extended so that the system can be used for planning.
cs.AI:In this paper, we outline the prototype of an automated inference tool, called QUIP, which provides a uniform implementation for several nonmonotonic reasoning formalisms. The theoretical basis of QUIP is derived from well-known results about the computational complexity of nonmonotonic logics and exploits a representation of the different reasoning tasks in terms of quantified boolean formulae.
cs.AI:Over the past decade a considerable amount of research has been done to expand logic programming languages to handle incomplete information. One such language is the language of epistemic specifications. As is usual with logic programming languages, the problem of answering queries is intractable in the general case. For extended disjunctive logic programs, an idea that has proven useful in simplifying the investigation of answer sets is the use of splitting sets. In this paper we will present an extended definition of splitting sets that will be applicable to epistemic specifications. Furthermore, an extension of the splitting set theorem will be presented. Also, a characterization of stratified epistemic specifications will be given in terms of splitting sets. This characterization leads us to an algorithmic method of computing world views of a subclass of epistemic logic programs.
cs.AI:The US Data Encryption Standard, DES for short, is put forward as an interesting benchmark problem for nonmonotonic reasoning systems because (i) it provides a set of test cases of industrial relevance which shares features of randomly generated problems and real-world problems, (ii) the representation of DES using normal logic programs with the stable model semantics is simple and easy to understand, and (iii) this subclass of logic programs can be seen as an interesting special case for many other formalizations of nonmonotonic reasoning. In this paper we present two encodings of DES as logic programs: a direct one out of the standard specifications and an optimized one extending the work of Massacci and Marraro. The computational properties of the encodings are studied by using them for DES key search with the Smodels system as the implementation of the stable model semantics. Results indicate that the encodings and Smodels are quite competitive: they outperform state-of-the-art SAT-checkers working with an optimized encoding of DES into SAT and are comparable with a SAT-checker that is customized and tuned for the optimized SAT encoding.
cs.AI:We generalize a theorem by Francois Fages that describes the relationship between the completion semantics and the answer set semantics for logic programs with negation as failure. The study of this relationship is important in connection with the emergence of answer set programming. Whenever the two semantics are equivalent, answer sets can be computed by a satisfiability solver, and the use of answer set solvers such as smodels and dlv is unnecessary. A logic programming representation of the blocks world due to Ilkka Niemelae is discussed as an example.
cs.AI:We introduced decomposable negation normal form (DNNF) recently as a tractable form of propositional theories, and provided a number of powerful logical operations that can be performed on it in polynomial time. We also presented an algorithm for compiling any conjunctive normal form (CNF) into DNNF and provided a structure-based guarantee on its space and time complexity. We present in this paper a linear-time algorithm for converting an ordered binary decision diagram (OBDD) representation of a propositional theory into an equivalent DNNF, showing that DNNFs scale as well as OBDDs. We also identify a subclass of DNNF which we call deterministic DNNF, d-DNNF, and show that the previous complexity guarantees on compiling DNNF continue to hold for this stricter subclass, which has stronger properties. In particular, we present a new operation on d-DNNF which allows us to count its models under the assertion, retraction and flipping of every literal by traversing the d-DNNF twice. That is, after such traversal, we can test in constant-time: the entailment of any literal by the d-DNNF, and the consistency of the d-DNNF under the retraction or flipping of any literal. We demonstrate the significance of these new operations by showing how they allow us to implement linear-time, complete truth maintenance systems and linear-time, complete belief revision systems for two important classes of propositional theories.
cs.AI:The paper reports on first preliminary results and insights gained in a project aiming at implementing the fluent calculus using methods and techniques based on binary decision diagrams. After reporting on an initial experiment showing promising results we discuss our findings concerning various techniques and heuristics used to speed up the reasoning process.
cs.AI:Planning is a natural domain of application for frameworks of reasoning about actions and change. In this paper we study how one such framework, the Language E, can form the basis for planning under (possibly) incomplete information. We define two types of plans: weak and safe plans, and propose a planner, called the E-Planner, which is often able to extend an initial weak plan into a safe plan even though the (explicit) information available is incomplete, e.g. for cases where the initial state is not completely known. The E-Planner is based upon a reformulation of the Language E in argumentation terms and a natural proof theory resulting from the reformulation. It uses an extension of this proof theory by means of abduction for the generation of plans and adopts argumentation-based techniques for extending weak plans into safe plans. We provide representative examples illustrating the behaviour of the E-Planner, in particular for cases where the status of fluents is incompletely known.
cs.AI:In an earlier work, we have presented operations of belief change which only affect the relevant part of a belief base. In this paper, we propose the application of the same strategy to the problem of model-based diangosis. We first isolate the subset of the system description which is relevant for a given observation and then solve the diagnosis problem for this subset.
cs.AI:We present a general, consistency-based framework for belief change. Informally, in revising K by A, we begin with A and incorporate as much of K as consistently possible. Formally, a knowledge base K and sentence A are expressed, via renaming propositions in K, in separate languages. Using a maximization process, we assume the languages are the same insofar as consistently possible. Lastly, we express the resultant knowledge base in a single language. There may be more than one way in which A can be so extended by K: in choice revision, one such ``extension'' represents the revised state; alternately revision consists of the intersection of all such extensions.   The most general formulation of our approach is flexible enough to express other approaches to revision and update, the merging of knowledge bases, and the incorporation of static and dynamic integrity constraints. Our framework differs from work based on ordinal conditional functions, notably with respect to iterated revision. We argue that the approach is well-suited for implementation: the choice revision operator gives better complexity results than general revision; the approach can be expressed in terms of a finite knowledge base; and the scope of a revision can be restricted to just those propositions mentioned in the sentence for revision A.
cs.AI:SATEN is an object-oriented web-based extraction and belief revision engine. It runs on any computer via a Java 1.1 enabled browser such as Netscape 4. SATEN performs belief revision based on the AGM approach. The extraction and belief revision reasoning engines operate on a user specified ranking of information. One of the features of SATEN is that it can be used to integrate mutually inconsistent commensuate rankings into a consistent ranking.
cs.AI:Answer-set programming (ASP) has emerged recently as a viable programming paradigm. We describe here an ASP system, DATALOG with constraints or DC, based on non-monotonic logic. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules. The semantics is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax, use and implementation of DC and provide experimental results.
cs.AI:Answer-set programming (ASP) has emerged recently as a viable programming paradigm well attuned to search problems in AI, constraint satisfaction and combinatorics. Propositional logic is, arguably, the simplest ASP system with an intuitive semantics supporting direct modeling of problem constraints. However, for some applications, especially those requiring that transitive closure be computed, it requires additional variables and results in large theories. Consequently, it may not be a practical computational tool for such problems. On the other hand, ASP systems based on nonmonotonic logics, such as stable logic programming, can handle transitive closure computation efficiently and, in general, yield very concise theories as problem representations. Their semantics is, however, more complex. Searching for the middle ground, in this paper we introduce a new nonmonotonic logic, DATALOG with constraints or DC. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules. The semantics is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax and semantics of DC, and study its properties. We discuss an implementation of DC and present results of experimental study of the effectiveness of DC, comparing it with CSAT, a satisfiability checker and SMODELS implementation of stable logic programming. Our results show that DC is competitive with the other two approaches, in case of many search problems, often yielding much more efficient solutions.
cs.AI:We study here the well-known propagation rules for Boolean constraints. First we propose a simple notion of completeness for sets of such rules and establish a completeness result. Then we show an equivalence in an appropriate sense between Boolean constraint propagation and unit propagation, a form of resolution for propositional logic.   Subsequently we characterize one set of such rules by means of the notion of hyper-arc consistency introduced in (Mohr and Masini 1988). Also, we clarify the status of a similar, though different, set of rules introduced in (Simonis 1989a) and more fully in (Codognet and Diaz 1996).
cs.AI:A general notion of algebraic conditional plausibility measures is defined. Probability measures, ranking functions, possibility measures, and (under the appropriate definitions) sets of probability measures can all be viewed as defining algebraic conditional plausibility measures. It is shown that algebraic conditional plausibility measures can be represented using Bayesian networks.
cs.AI:In this paper we present a rule based formalism for filtering variables domains of constraints. This formalism is well adapted for solving dynamic CSP. We take diagnosis as an instance problem to illustrate the use of these rules. A diagnosis problem is seen like finding all the minimal sets of constraints to be relaxed in the constraint network that models the device to be diagnosed
cs.AI:Despite the effort of many researchers in the area of multi-agent systems (MAS) for designing and programming agents, a few years ago the research community began to take into account that common features among different MAS exists. Based on these common features, several tools have tackled the problem of agent development on specific application domains or specific types of agents. As a consequence, their scope is restricted to a subset of the huge application domain of MAS. In this paper we propose a generic infrastructure for programming agents whose name is Brainstorm/J. The infrastructure has been implemented as an object oriented framework. As a consequence, our approach supports a broader scope of MAS applications than previous efforts, being flexible and reusable.
cs.AI:In fuzzy propositional logic, to a proposition a partial truth in [0,1] is assigned. It is well known that under certain circumstances, fuzzy logic collapses to classical logic. In this paper, we will show that under dual conditions, fuzzy logic collapses to four-valued (relevance) logic, where propositions have truth-value true, false, unknown, or contradiction. As a consequence, fuzzy entailment may be considered as ``in between'' four-valued (relevance) entailment and classical entailment.
cs.AI:We propose a new definition of actual cause, using structural equations to model counterfactuals. We show that the definition yields a plausible and elegant account of causation that handles well examples which have caused problems for other definitions and resolves major difficulties in the traditional account.
cs.AI:Many logic programming based approaches can be used to describe and solve combinatorial search problems. On the one hand there is constraint logic programming which computes a solution as an answer substitution to a query containing the variables of the constraint satisfaction problem. On the other hand there are systems based on stable model semantics, abductive systems, and first order logic model generators which compute solutions as models of some theory. This paper compares these different approaches from the point of view of knowledge representation (how declarative are the programs) and from the point of view of performance (how good are they at solving typical problems).
cs.AI:In this paper, we introduce a new machine learning theory based on multi-channel parallel adaptation for rule discovery. This theory is distinguished from the familiar parallel-distributed adaptation theory of neural networks in terms of channel-based convergence to the target rules. We show how to realize this theory in a learning system named CFRule. CFRule is a parallel weight-based model, but it departs from traditional neural computing in that its internal knowledge is comprehensible. Furthermore, when the model converges upon training, each channel converges to a target rule. The model adaptation rule is derived by multi-level parallel weight optimization based on gradient descent. Since, however, gradient descent only guarantees local optimization, a multi-channel regression-based optimization strategy is developed to effectively deal with this problem. Formally, we prove that the CFRule model can explicitly and precisely encode any given rule set. Also, we prove a property related to asynchronous parallel convergence, which is a critical element of the multi-channel parallel adaptation theory for rule learning. Thanks to the quantizability nature of the CFRule model, rules can be extracted completely and soundly via a threshold-based mechanism. Finally, the practical application of the theory is demonstrated in DNA promoter recognition and hepatitis prognosis prediction.
cs.AI:We present an approach for modelling the structure and coarse content of legal documents with a view to providing automated support for the drafting of contracts and contract database retrieval. The approach is designed to be applicable where contract drafting is based on model-form contracts or on existing examples of a similar type. The main features of the approach are: (1) the representation addresses the structure and the interrelationships between the constituent parts of contracts, but not the text of the document itself; (2) the representation of documents is separated from the mechanisms that manipulate it; and (3) the drafting process is subject to a collection of explicitly stated constraints that govern the structure of the documents. We describe the representation of document instances and of 'generic documents', which are data structures used to drive the creation of new document instances, and we show extracts from a sample session to illustrate the features of a prototype system implemented in MacProlog.
cs.AI:One influential approach to assessing the "goodness" of arguments is offered by the Pragma-Dialectical school (p-d) (Eemeren & Grootendorst 1992). This can be compared with Rhetorical Structure Theory (RST) (Mann & Thompson 1988), an approach that originates in discourse analysis. In p-d terms an argument is good if it avoids committing a fallacy, whereas in RST terms an argument is good if it is coherent. RST has been criticised (Snoeck Henkemans 1997) for providing only a partially functional account of argument, and similar criticisms have been raised in the Natural Language Generation (NLG) community-particularly by Moore & Pollack (1992)- with regards to its account of intentionality in text in general. Mann and Thompson themselves note that although RST can be successfully applied to a wide range of texts from diverse domains, it fails to characterise some types of text, most notably legal contracts. There is ongoing research in the Artificial Intelligence and Law community exploring the potential for providing electronic support to contract negotiators, focusing on long-term, complex engineering agreements (see for example Daskalopulu & Sergot 1997). This paper provides a brief introduction to RST and illustrates its shortcomings with respect to contractual text. An alternative approach for modelling argument structure is presented which not only caters for contractual text, but also overcomes the aforementioned limitations of RST.
cs.AI:Information Integration is a young and exciting field with enormous research and commercial significance in the new world of the Information Society. It stands at the crossroad of Databases and Artificial Intelligence requiring novel techniques that bring together different methods from these fields. Information from disparate heterogeneous sources often with no a-priori common schema needs to be synthesized in a flexible, transparent and intelligent way in order to respond to the demands of a query thus enabling a more informed decision by the user or application program. The field although relatively young has already found many practical applications particularly for integrating information over the World Wide Web. This paper gives a brief introduction of the field highlighting some of the main current and future research issues and application areas. It attempts to evaluate the current and potential role of Computational Logic in this and suggests some of the problems where logic-based techniques could be used.
cs.AI:Constraint propagation is a general algorithmic approach for pruning the search space of a CSP. In a uniform way, K. R. Apt has defined a computation as an iteration of reduction functions over a domain. He has also demonstrated the need for integrating static properties of reduction functions (commutativity and semi-commutativity) to design specialized algorithms such as AC3 and DAC. We introduce here a set of operators for modeling compositions of reduction functions. Two of the major goals are to tackle parallel computations, and dynamic behaviours (such as slow convergence).
cs.AI:We consider an approach to update nonmonotonic knowledge bases represented as extended logic programs under answer set semantics. New information is incorporated into the current knowledge base subject to a causal rejection principle enforcing that, in case of conflicts, more recent rules are preferred and older rules are overridden. Such a rejection principle is also exploited in other approaches to update logic programs, e.g., in dynamic logic programming by Alferes et al. We give a thorough analysis of properties of our approach, to get a better understanding of the causal rejection principle. We review postulates for update and revision operators from the area of theory change and nonmonotonic reasoning, and some new properties are considered as well. We then consider refinements of our semantics which incorporate a notion of minimality of change. As well, we investigate the relationship to other approaches, showing that our approach is semantically equivalent to inheritance programs by Buccafurri et al. and that it coincides with certain classes of dynamic logic programs, for which we provide characterizations in terms of graph conditions. Therefore, most of our results about properties of causal rejection principle apply to these approaches as well. Finally, we deal with computational complexity of our approach, and outline how the update semantics and its refinements can be implemented on top of existing logic programming engines.
cs.AI:We introduce a learning method called ``gradient-based reinforcement planning'' (GREP). Unlike traditional DP methods that improve their policy backwards in time, GREP is a gradient-based method that plans ahead and improves its policy before it actually acts in the environment. We derive formulas for the exact policy gradient that maximizes the expected future reward and confirm our ideas with numerical experiments.
cs.AI:Much work in computer science has adopted competitive analysis as a tool for decision making under uncertainty. In this work we extend competitive analysis to the context of multi-agent systems. Unlike classical competitive analysis where the behavior of an agent's environment is taken to be arbitrary, we consider the case where an agent's environment consists of other agents. These agents will usually obey some (minimal) rationality constraints. This leads to the definition of rational competitive analysis. We introduce the concept of rational competitive analysis, and initiate the study of competitive analysis for multi-agent systems. We also discuss the application of rational competitive analysis to the context of bidding games, as well as to the classical one-way trading problem.
cs.AI:This article aims at clarifying the language and practice of scientific experiment, mainly by hooking observability on calculability.
cs.AI:Many systems that exhibit nonmonotonic behavior have been described and studied already in the literature. The general notion of nonmonotonic reasoning, though, has almost always been described only negatively, by the property it does not enjoy, i.e. monotonicity. We study here general patterns of nonmonotonic reasoning and try to isolate properties that could help us map the field of nonmonotonic reasoning by reference to positive properties. We concentrate on a number of families of nonmonotonic consequence relations, defined in the style of Gentzen. Both proof-theoretic and semantic points of view are developed in parallel. The former point of view was pioneered by D. Gabbay, while the latter has been advocated by Y. Shoham in. Five such families are defined and characterized by representation theorems, relating the two points of view. One of the families of interest, that of preferential relations, turns out to have been studied by E. Adams. The "preferential" models proposed here are a much stronger tool than Adams' probabilistic semantics. The basic language used in this paper is that of propositional logic. The extension of our results to first order predicate calculi and the study of the computational complexity of the decision problems described in this paper will be treated in another paper.
cs.AI:This paper presents a logical approach to nonmonotonic reasoning based on the notion of a nonmonotonic consequence relation. A conditional knowledge base, consisting of a set of conditional assertions of the type "if ... then ...", represents the explicit defeasible knowledge an agent has about the way the world generally behaves. We look for a plausible definition of the set of all conditional assertions entailed by a conditional knowledge base. In a previous paper, S. Kraus and the authors defined and studied "preferential" consequence relations. They noticed that not all preferential relations could be considered as reasonable inference procedures. This paper studies a more restricted class of consequence relations, "rational" relations. It is argued that any reasonable nonmonotonic inference procedure should define a rational relation. It is shown that the rational relations are exactly those that may be represented by a "ranked" preferential model, or by a (non-standard) probabilistic model. The rational closure of a conditional knowledge base is defined and shown to provide an attractive answer to the question of the title. Global properties of this closure operation are proved: it is a cumulative operation. It is also computationally tractable. This paper assumes the underlying language is propositional.
cs.AI:It is shown that Darwiche and Pearl's postulates imply an interesting property, not noticed by the authors.
cs.AI:A vast and interesting family of natural semantics for belief revision is defined. Suppose one is given a distance d between any two models. One may then define the revision of a theory K by a formula a as the theory defined by the set of all those models of a that are closest, by d, to the set of models of K. This family is characterized by a set of rationality postulates that extends the AGM postulates. The new postulates describe properties of iterated revisions.
cs.AI:We give a semantics to iterated update by a preference relation on possible developments. An iterated update is a sequence of formulas, giving (incomplete) information about successive states of the world. A development is a sequence of models, describing a possible trajectory through time. We assume a principle of inertia and prefer those developments, which are compatible with the information, and avoid unnecessary changes. The logical properties of the updates defined in this way are considered, and a representation result is proved.
cs.AI:A. Tarski proposed the study of infinitary consequence operations as the central topic of mathematical logic. He considered monotonicity to be a property of all such operations. In this paper, we weaken the monotonicity requirement and consider more general operations, inference operations. These operations describe the nonmonotonic logics both humans and machines seem to be using when infering defeasible information from incomplete knowledge. We single out a number of interesting families of inference operations. This study of infinitary inference operations is inspired by the results of Kraus, Lehmann and Magidor on finitary nonmonotonic operations, but this paper is self-contained.
cs.AI:The Expansion property considered by researchers in Social Choice is shown to correspond to a logical property of nonmonotonic consequence relations that is the {\em pure}, i.e., not involving connectives, version of a previously known weak rationality condition. The assumption that the union of two definable sets of models is definable is needed for the soundness part of the result.
cs.AI:The lexicographic closure of any given finite set D of normal defaults is defined. A conditional assertion "if a then b" is in this lexicographic closure if, given the defaults D and the fact a, one would conclude b. The lexicographic closure is essentially a rational extension of D, and of its rational closure, defined in a previous paper. It provides a logic of normal defaults that is different from the one proposed by R. Reiter and that is rich enough not to require the consideration of non-normal defaults. A large number of examples are provided to show that the lexicographic closure corresponds to the basic intuitions behind Reiter's logic of defaults.
cs.AI:We provide a characterization of those nonmonotonic inference operations C for which C(X) may be described as the set of all logical consequences of X together with some set of additional assumptions S(X) that depends anti-monotonically on X (i.e., X is a subset of Y implies that S(Y) is a subset of S(X)). The operations represented are exactly characterized in terms of properties most of which have been studied in Freund-Lehmann(cs.AI/0202031). Similar characterizations of right-absorbing and cumulative operations are also provided. For cumulative operations, our results fit in closely with those of Freund. We then discuss extending finitary operations to infinitary operations in a canonical way and discuss co-compactness properties. Our results provide a satisfactory notion of pseudo-compactness, generalizing to deductive nonmonotonic operations the notion of compactness for monotonic operations. They also provide an alternative, more elegant and more general, proof of the existence of an infinitary deductive extension for any finitary deductive operation (Theorem 7.9 of Freund-Lehmann).
cs.AI:Stereotypical reasoning assumes that the situation at hand is one of a kind and that it enjoys the properties generally associated with that kind of situation. It is one of the most basic forms of nonmonotonic reasoning. A formal model for stereotypical reasoning is proposed and the logical properties of this form of reasoning are studied. Stereotypical reasoning is shown to be cumulative under weak assumptions.
cs.AI:We introduce a methodology and framework for expressing general preference information in logic programming under the answer set semantics. An ordered logic program is an extended logic program in which rules are named by unique terms, and in which preferences among rules are given by a set of atoms of form s < t where s and t are names. An ordered logic program is transformed into a second, regular, extended logic program wherein the preferences are respected, in that the answer sets obtained in the transformed program correspond with the preferred answer sets of the original program. Our approach allows the specification of dynamic orderings, in which preferences can appear arbitrarily within a program. Static orderings (in which preferences are external to a logic program) are a trivial restriction of the general dynamic case. First, we develop a specific approach to reasoning with preferences, wherein the preference ordering specifies the order in which rules are to be applied. We then demonstrate the wide range of applicability of our framework by showing how other approaches, among them that of Brewka and Eiter, can be captured within our framework. Since the result of each of these transformations is an extended logic program, we can make use of existing implementations, such as dlv and smodels. To this end, we have developed a publicly available compiler as a front-end for these programming systems.
cs.AI:Prioritized default reasoning has illustrated its rich expressiveness and flexibility in knowledge representation and reasoning. However, many important aspects of prioritized default reasoning have yet to be thoroughly explored. In this paper, we investigate two properties of prioritized logic programs in the context of answer set semantics. Specifically, we reveal a close relationship between mutual defeasibility and uniqueness of the answer set for a prioritized logic program. We then explore how the splitting technique for extended logic programs can be extended to prioritized logic programs. We prove splitting theorems that can be used to simplify the evaluation of a prioritized logic program under certain conditions.
cs.AI:The (extended) AGM postulates for belief revision seem to deal with the revision of a given theory K by an arbitrary formula, but not to constrain the revisions of two different theories by the same formula. A new postulate is proposed and compared with other similar postulates that have been proposed in the literature. The AGM revisions that satisfy this new postulate stand in one-to-one correspondence with the rational, consistency-preserving relations. This correspondence is described explicitly. Two viewpoints on iterative revisions are distinguished and discussed.
cs.AI:We study fixpoints of operators on lattices. To this end we introduce the notion of an approximation of an operator. We order approximations by means of a precision ordering. We show that each lattice operator O has a unique most precise or ultimate approximation. We demonstrate that fixpoints of this ultimate approximation provide useful insights into fixpoints of the operator O.   We apply our theory to logic programming and introduce the ultimate Kripke-Kleene, well-founded and stable semantics. We show that the ultimate Kripke-Kleene and well-founded semantics are more precise then their standard counterparts We argue that ultimate semantics for logic programming have attractive epistemological properties and that, while in general they are computationally more complex than the standard semantics, for many classes of theories, their complexity is no worse.
cs.AI:Representing defeasibility is an important issue in common sense reasoning. In reasoning about action and change, this issue becomes more difficult because domain and action related defeasible information may conflict with general inertia rules. Furthermore, different types of defeasible information may also interfere with each other during the reasoning. In this paper, we develop a prioritized logic programming approach to handle defeasibilities in reasoning about action. In particular, we propose three action languages {\cal AT}^{0}, {\cal AT}^{1} and {\cal AT}^{2} which handle three types of defeasibilities in action domains named defeasible constraints, defeasible observations and actions with defeasible and abnormal effects respectively. Each language with a higher superscript can be viewed as an extension of the language with a lower superscript. These action languages inherit the simple syntax of {\cal A} language but their semantics is developed in terms of transition systems where transition functions are defined based on prioritized logic programs. By illustrating various examples, we show that our approach eventually provides a powerful mechanism to handle various defeasibilities in temporal prediction and postdiction. We also investigate semantic properties of these three action languages and characterize classes of action domains that present more desirable solutions in reasoning about action within the underlying action languages.
cs.AI:An anticipatory system for guiding plot development in interactive narratives is described. The executable model is a finite automaton that provides the implemented system with a look-ahead. The identification of undesirable future states in the model is used to guide the player, in a transparent manner. In this way, too radical twists of the plot can be avoided. Since the player participates in the development of the plot, such guidance can have many forms, depending on the environment of the player, on the behavior of the other players, and on the means of player interaction. We present a design method for interactive narratives which produces designs suitable for the implementation of anticipatory mechanisms. Use of the method is illustrated by application to our interactive computer game Kaktus.
cs.AI:Open logic programs and open entailment have been recently proposed as an abstract framework for the verification of incomplete specifications based upon normal logic programs and the stable model semantics. There are obvious analogies between open predicates and abducible predicates. However, despite superficial similarities, there are features of open programs that have no immediate counterpart in the framework of abduction and viceversa. Similarly, open programs cannot be immediately simulated with answer set programming (ASP). In this paper we start a thorough investigation of the relationships between open inference, abduction and ASP. We shall prove that open programs generalize the other two frameworks. The generalized framework suggests interesting extensions of abduction under the generalized stable model semantics. In some cases, we will be able to reduce open inference to abduction and ASP, thereby estimating its computational complexity. At the same time, the aforementioned reduction opens the way to new applications of abduction and ASP.
cs.AI:In this paper we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set semantics (AnsProlog*). AnsProlog* is designed to plan without control knowledge. We show how temporal, procedural and HTN-based control knowledge can be incorporated into AnsProlog* by the modular addition of a small number of domain-dependent rules, without the need to modify the planner. We formally prove the correctness of our planner, both in the absence and presence of the control knowledge. Finally, we perform some initial experimentation that demonstrates the potential reduction in planning time that can be achieved when procedural domain knowledge is used to solve planning problems with large plan length.
cs.AI:Dung's abstract framework for argumentation enables a study of the interactions between arguments based solely on an ``attack'' binary relation on the set of arguments. Various ways to solve conflicts between contradictory pieces of information have been proposed in the context of argumentation, nonmonotonic reasoning or logic programming, and can be captured by appropriate semantics within Dung's framework. A common feature of these semantics is that one can always maximize in some sense the set of acceptable arguments. We propose in this paper to extend Dung's framework in order to allow for the representation of what we call ``restricted'' arguments: these arguments should only be used if absolutely necessary, that is, in order to support other arguments that would otherwise be defeated. We modify Dung's preferred semantics accordingly: a set of arguments becomes acceptable only if it contains a minimum of restricted arguments, for a maximum of unrestricted arguments.
cs.AI:We address a general representation problem for belief change, and describe two interrelated representations for iterative non-prioritized change: a logical representation in terms of persistent epistemic states, and a constructive representation in terms of flocks of bases.
cs.AI:An extension of an abstract argumentation framework, called collective argumentation, is introduced in which the attack relation is defined directly among sets of arguments. The extension turns out to be suitable, in particular, for representing semantics of disjunctive logic programs. Two special kinds of collective argumentation are considered in which the opponents can share their arguments.
cs.AI:Logic programs with ordered disjunction (LPODs) combine ideas underlying Qualitative Choice Logic (Brewka et al. KR 2002) and answer set programming. Logic programming under answer set semantics is extended with a new connective called ordered disjunction. The new connective allows us to represent alternative, ranked options for problem solutions in the heads of rules: A \times B intuitively means: if possible A, but if A is not possible then at least B. The semantics of logic programs with ordered disjunction is based on a preference relation on answer sets. LPODs are useful for applications in design and configuration and can serve as a basis for qualitative decision making.
cs.AI:In this paper, we investigate the extent to which knowledge compilation can be used to improve inference from propositional weighted bases. We present a general notion of compilation of a weighted base that is parametrized by any equivalence--preserving compilation function. Both negative and positive results are presented. On the one hand, complexity results are identified, showing that the inference problem from a compiled weighted base is as difficult as in the general case, when the prime implicates, Horn cover or renamable Horn cover classes are targeted. On the other hand, we show that the inference problem becomes tractable whenever DNNF-compilations are used and clausal queries are considered. Moreover, we show that the set of all preferred models of a DNNF-compilation of a weighted base can be computed in time polynomial in the output size. Finally, we sketch how our results can be used in model-based diagnosis in order to compute the most probable diagnoses of a system.
cs.AI:This paper studies the problem of modeling complex domains of actions and change within high-level action description languages. We investigate two main issues of concern: (a) can we represent complex domains that capture together different problems such as ramifications, non-determinism and concurrency of actions, at a high-level, close to the given natural ontology of the problem domain and (b) what features of such a representation can affect, and how, its computational behaviour. The paper describes the main problems faced in this representation task and presents the results of an empirical study, carried out through a series of controlled experiments, to analyze the computational performance of reasoning in these representations. The experiments compare different representations obtained, for example, by changing the basic ontology of the domain or by varying the degree of use of indirect effect laws through domain constraints. This study has helped to expose the main sources of computational difficulty in the reasoning and suggest some methodological guidelines for representing complex domains. Although our work has been carried out within one particular high-level description language, we believe that the results, especially those that relate to the problems of representation, are independent of the specific modeling language.
cs.AI:This paper introduces the notion of value-based argumentation frameworks, an extension of the standard argumentation frameworks proposed by Dung, which are able toshow how rational decision is possible in cases where arguments derive their force from the social values their acceptance would promote.
cs.AI:We analyze the problem of defining well-founded semantics for ordered logic programs within a general framework based on alternating fixpoint theory. We start by showing that generalizations of existing answer set approaches to preference are too weak in the setting of well-founded semantics. We then specify some informal yet intuitive criteria and propose a semantical framework for preference handling that is more suitable for defining well-founded semantics for ordered logic programs. The suitability of the new approach is convinced by the fact that many attractive properties are satisfied by our semantics. In particular, our semantics is still correct with respect to various existing answer sets semantics while it successfully overcomes the weakness of their generalization to well-founded semantics. Finally, we indicate how an existing preferred well-founded semantics can be captured within our semantical framework.
cs.AI:In this paper we present a transformation of finite propositional default theories into so-called propositional argumentation systems. This transformation allows to characterize all notions of Reiter's default logic in the framework of argumentation systems. As a consequence, computing extensions, or determining wether a given formula belongs to one extension or all extensions can be answered without leaving the field of classical propositional logic. The transformation proposed is linear in the number of defaults.
cs.AI:In the present paper, the existence and multiplicity problems of extensions are addressed. The focus is on extension of the stable type. The main result of the paper is an elegant characterization of the existence and multiplicity of extensions in terms of the notion of dialectical justification, a close cousin of the notion of admissibility. The characterization is given in the context of the particular logic for dialectical argumentation DEFLOG. The results are of direct relevance for several well-established models of defeasible reasoning (like default logic, logic programming and argumentation frameworks), since elsewhere dialectical argumentation has been shown to have close formal connections with these models.
cs.AI:Recently, it has been shown that probabilistic entailment under coherence is weaker than model-theoretic probabilistic entailment. Moreover, probabilistic entailment under coherence is a generalization of default entailment in System P. In this paper, we continue this line of research by presenting probabilistic generalizations of more sophisticated notions of classical default entailment that lie between model-theoretic probabilistic entailment and probabilistic entailment under coherence. That is, the new formalisms properly generalize their counterparts in classical default reasoning, they are weaker than model-theoretic probabilistic entailment, and they are stronger than probabilistic entailment under coherence. The new formalisms are useful especially for handling probabilistic inconsistencies related to conditioning on zero events. They can also be applied for probabilistic belief revision. More generally, in the same spirit as a similar previous paper, this paper sheds light on exciting new formalisms for probabilistic reasoning beyond the well-known standard ones.
cs.AI:We seek to find normative criteria of adequacy for nonmonotonic logic similar to the criterion of validity for deductive logic. Rather than stipulating that the conclusion of an inference be true in all models in which the premises are true, we require that the conclusion of a nonmonotonic inference be true in ``almost all'' models of a certain sort in which the premises are true. This ``certain sort'' specification picks out the models that are relevant to the inference, taking into account factors such as specificity and vagueness, and previous inferences. The frequencies characterizing the relevant models reflect known frequencies in our actual world. The criteria of adequacy for a default inference can be extended by thresholding to criteria of adequacy for an extension. We show that this avoids the implausibilities that might otherwise result from the chaining of default inferences. The model proportions, when construed in terms of frequencies, provide a verifiable grounding of default rules, and can become the basis for generating default rules from statistics.
cs.AI:About ten years ago, various notions of preferential entailment have been introduced. The main reference is a paper by Kraus, Lehmann and Magidor (KLM), one of the main competitor being a more general version defined by Makinson (MAK). These two versions have already been compared, but it is time to revisit these comparisons. Here are our three main results: (1) These two notions are equivalent, provided that we restrict our attention, as done in KLM, to the cases where the entailment respects logical equivalence (on the left and on the right). (2) A serious simplification of the description of the fundamental cases in which MAK is equivalent to KLM, including a natural passage in both ways. (3) The two previous results are given for preferential entailments more general than considered in some of the original texts, but they apply also to the original definitions and, for this particular case also, the models can be simplified.
cs.AI:This work analyses main features that should be present in knowledge representation. It suggests a model for representation and a way to implement this model in software. Representation takes care of both low-level sensor information and high-level concepts.
cs.AI:We propose new definitions of (causal) explanation, using structural equations to model counterfactuals. The definition is based on the notion of actual cause, as defined and motivated in a companion paper. Essentially, an explanation is a fact that is not known for certain but, if found to be true, would constitute an actual cause of the fact to be explained, regardless of the agent's initial uncertainty. We show that the definition handles well a number of problematic examples from the literature.
cs.AI:Recently, several approaches to updating knowledge bases modeled as extended logic programs have been introduced, ranging from basic methods to incorporate (sequences of) sets of rules into a logic program, to more elaborate methods which use an update policy for specifying how updates must be incorporated. In this paper, we introduce a framework for reasoning about evolving knowledge bases, which are represented as extended logic programs and maintained by an update policy. We first describe a formal model which captures various update approaches, and we define a logical language for expressing properties of evolving knowledge bases. We then investigate semantical and computational properties of our framework, where we focus on properties of knowledge states with respect to the canonical reasoning task of whether a given formula holds on a given evolving knowledge base. In particular, we present finitary characterizations of the evolution for certain classes of framework instances, which can be exploited for obtaining decidability results. In more detail, we characterize the complexity of reasoning for some meaningful classes of evolving knowledge bases, ranging from polynomial to double exponential space complexity.
cs.AI:In this thesis I present a virtual laboratory which implements five different models for controlling animats: a rule-based system, a behaviour-based system, a concept-based system, a neural network, and a Braitenberg architecture. Through different experiments, I compare the performance of the models and conclude that there is no "best" model, since different models are better for different things in different contexts.   The models I chose, although quite simple, represent different approaches for studying cognition. Using the results as an empirical philosophical aid,   I note that there is no "best" approach for studying cognition, since different approaches have all advantages and disadvantages, because they study different aspects of cognition from different contexts. This has implications for current debates on "proper" approaches for cognition: all approaches are a bit proper, but none will be "proper enough". I draw remarks on the notion of cognition abstracting from all the approaches used to study it, and propose a simple classification for different types of cognition.
cs.AI:This paper deals with the revision of partially ordered beliefs. It proposes a semantic representation of epistemic states by partial pre-orders on interpretations and a syntactic representation by partially ordered belief bases. Two revision operations, the revision stemming from the history of observations and the possibilistic revision, defined when the epistemic state is represented by a total pre-order, are generalized, at a semantic level, to the case of a partial pre-order on interpretations, and at a syntactic level, to the case of a partially ordered belief base. The equivalence between the two representations is shown for the two revision operations.
cs.AI:This is the first in a series of connected papers discussing the problem of a dynamically reconfigurable universal learning neurocomputer that could serve as a computational model for the whole human brain. The whole series is entitled "The Brain Zero Project. My Brain as a Dynamically Reconfigurable Universal Learning Neurocomputer." (For more information visit the website www.brain0.com.) This introductory paper is concerned with general methodology. Its main goal is to explain why it is critically important for both neural modeling and cognitive modeling to pay much attention to the basic requirements of the whole brain as a complex computing system. The author argues that it can be easier to develop an adequate computational model for the whole "unprogrammed" (untrained) human brain than to find adequate formal representations of some nontrivial parts of brain's performance. (In the same way as, for example, it is easier to describe the behavior of a complex analytical function than the behavior of its real and/or imaginary part.) The "curse of dimensionality" that plagues purely phenomenological ("brainless") cognitive theories is a natural penalty for an attempt to represent insufficiently large parts of brain's performance in a state space of insufficiently high dimensionality. A "partial" modeler encounters "Catch 22." An attempt to simplify a cognitive problem by artificially reducing its dimensionality makes the problem more difficult.
cs.AI:As a part of our effort for studying the evolution and development of cognition, we present results derived from synthetic experimentations in a virtual laboratory where animats develop koncepts adaptively and ground their meaning through action. We introduce the term "koncept" to avoid confusions and ambiguity derived from the wide use of the word "concept". We present the models which our animats use for abstracting koncepts from perceptions, plastically adapt koncepts, and associate koncepts with actions. On a more philosophical vein, we suggest that knowledge is a property of a cognitive system, not an element, and therefore observer-dependent.
cs.AI:This paper presents a model for dynamic adjustment of the motivation degree, using a reinforcement learning approach, in an action selection mechanism previously developed by the authors. The learning takes place in the modification of a parameter of the model of combination of internal and external stimuli. Experiments that show the claimed properties are presented, using a VR simulation developed for such purposes. The importance of adaptation by learning in action selection is also discussed.
cs.AI:This article analyses the properties of the Internal Behaviour network, an action selection mechanism previously proposed by the authors, with the aid of a simulation developed for such ends. A brief review of the Internal Behaviour network is followed by the explanation of the implementation of the simulation. Then, experiments are presented and discussed analysing the properties of the action selection in the proposed model.
cs.AI:This paper proposes a model for combination of external and internal stimuli for the action selection in an autonomous agent, based in an action selection mechanism previously proposed by the authors. This combination model includes additive and multiplicative elements, which allows to incorporate new properties, which enhance the action selection. A given parameter a, which is part of the proposed model, allows to regulate the degree of dependence of the observed external behaviour from the internal states of the entity.
cs.AI:Reinforcement learning (RL) involves sequential decision making in uncertain environments. The aim of the decision-making agent is to maximize the benefit of acting in its environment over an extended period of time. Finding an optimal policy in RL may be very slow. To speed up learning, one often used solution is the integration of planning, for example, Sutton's Dyna algorithm, or various other methods using macro-actions.   Here we suggest to separate plannable, i.e., close to deterministic parts of the world, and focus planning efforts in this domain. A novel reinforcement learning method called plannable RL (pRL) is proposed here. pRL builds a simple model, which is used to search for macro actions. The simplicity of the model makes planning computationally inexpensive. It is shown that pRL finds an optimal policy, and that plannable macro actions found by pRL are near-optimal. In turn, it is unnecessary to try large numbers of macro actions, which enables fast learning. The utility of pRL is demonstrated by computer simulations.
cs.AI:Optimization of decision problems in stochastic environments is usually concerned with maximizing the probability of achieving the goal and minimizing the expected episode length. For interacting agents in time-critical applications, learning of the possibility of scheduling of subtasks (events) or the full task is an additional relevant issue. Besides, there exist highly stochastic problems where the actual trajectories show great variety from episode to episode, but completing the task takes almost the same amount of time. The identification of sub-problems of this nature may promote e.g., planning, scheduling and segmenting Markov decision processes. In this work, formulae for the average duration as well as the standard deviation of the duration of events are derived. The emerging Bellman-type equation is a simple extension of Sobel's work (1982). Methods of dynamic programming as well as methods of reinforcement learning can be applied for our extension. Computer demonstration on a toy problem serve to highlight the principle.
cs.AI:Much work has been done on extending the well-founded semantics to general disjunctive logic programs and various approaches have been proposed. However, these semantics are different from each other and no consensus is reached about which semantics is the most intended. In this paper we look at disjunctive well-founded reasoning from different angles. We show that there is an intuitive form of the well-founded reasoning in disjunctive logic programming which can be characterized by slightly modifying some exisitng approaches to defining disjunctive well-founded semantics, including program transformations, argumentation, unfounded sets (and resolution-like procedure). We also provide a bottom-up procedure for this semantics. The significance of our work is not only in clarifying the relationship among different approaches, but also shed some light on what is an intended well-founded semantics for disjunctive logic programs.
cs.AI:We provide a semantic framework for preference handling in answer set programming. To this end, we introduce preference preserving consequence operators. The resulting fixpoint characterizations provide us with a uniform semantic framework for characterizing preference handling in existing approaches. Although our approach is extensible to other semantics by means of an alternating fixpoint theory, we focus here on the elaboration of preferences under answer set semantics. Alternatively, we show how these approaches can be characterized by the concept of order preservation. These uniform semantic characterizations provide us with new insights about interrelationships and moreover about ways of implementation.
cs.AI:The work reported here introduces Defeasible Logic Programming (DeLP), a formalism that combines results of Logic Programming and Defeasible Argumentation. DeLP provides the possibility of representing information in the form of weak rules in a declarative manner, and a defeasible argumentation inference mechanism for warranting the entailed conclusions.   In DeLP an argumentation formalism will be used for deciding between contradictory goals. Queries will be supported by arguments that could be defeated by other arguments. A query q will succeed when there is an argument A for q that is warranted, ie, the argument A that supports q is found undefeated by a warrant procedure that implements a dialectical analysis.   The defeasible argumentation basis of DeLP allows to build applications that deal with incomplete and contradictory information in dynamic domains. Thus, the resulting approach is suitable for representing agent's knowledge and for providing an argumentation based reasoning mechanism to agents.
cs.AI:Cooperative constraint solving is an area of constraint programming that studies the interaction between constraint solvers with the aim of discovering the interaction patterns that amplify the positive qualities of individual solvers. Automatisation and formalisation of such studies is an important issue of cooperative constraint solving.   In this paper we present a constraint-based analysis of composite solvers that integrates reasoning about the individual solvers and the processed data. The idea is to approximate this reasoning by resolution of set constraints on the finite sets representing the predicates that express all the necessary properties. We illustrate application of our analysis to two important cooperation patterns: deterministic choice and loop.
cs.AI:There is a growing interest in using Kalman-filter models for brain modelling. In turn, it is of considerable importance to represent Kalman-filter in connectionist forms with local Hebbian learning rules. To our best knowledge, Kalman-filter has not been given such local representation. It seems that the main obstacle is the dynamic adaptation of the Kalman-gain. Here, a connectionist representation is presented, which is derived by means of the recursive prediction error method. We show that this method gives rise to attractive local learning rules and can adapt the Kalman-gain.
cs.AI:We discuss philosophical issues concerning the notion of cognition basing ourselves in experimental results in cognitive sciences, especially in computer simulations of cognitive systems. There have been debates on the "proper" approach for studying cognition, but we have realized that all approaches can be in theory equivalent. Different approaches model different properties of cognitive systems from different perspectives, so we can only learn from all of them. We also integrate ideas from several perspectives for enhancing the notion of cognition, such that it can contain other definitions of cognition as special cases. This allows us to propose a simple classification of different types of cognition.
cs.AI:The paper studies an implementation methodology for partial and disjunctive stable models where partiality and disjunctions are unfolded from a logic program so that an implementation of stable models for normal (disjunction-free) programs can be used as the core inference engine. The unfolding is done in two separate steps. Firstly, it is shown that partial stable models can be captured by total stable models using a simple linear and modular program transformation. Hence, reasoning tasks concerning partial stable models can be solved using an implementation of total stable models. Disjunctive partial stable models have been lacking implementations which now become available as the translation handles also the disjunctive case. Secondly, it is shown how total stable models of disjunctive programs can be determined by computing stable models for normal programs. Hence, an implementation of stable models of normal programs can be used as a core engine for implementing disjunctive programs. The feasibility of the approach is demonstrated by constructing a system for computing stable models of disjunctive programs using the smodels system as the core engine. The performance of the resulting system is compared to that of dlv which is a state-of-the-art special purpose system for disjunctive programs.
cs.AI:When tracking a large number of targets, it is often computationally expensive to represent the full joint distribution over target states. In cases where the targets move independently, each target can instead be tracked with a separate filter. However, this leads to a model-data association problem. Another approach to solve the problem with computational complexity is to track only the first moment of the joint distribution, the probability hypothesis density (PHD). The integral of this distribution over any area S is the expected number of targets within S. Since no record of object identity is kept, the model-data association problem is avoided.   The contribution of this paper is a particle filter implementation of the PHD filter mentioned above. This PHD particle filter is applied to tracking of multiple vehicles in terrain, a non-linear tracking problem. Experiments show that the filter can track a changing number of vehicles robustly, achieving near-real-time performance.
cs.AI:Search in cyclic AND/OR graphs was traditionally known to be an unsolved problem. In the recent past several important studies have been reported in this domain. In this paper, we have taken a fresh look at the problem. First, a new and comprehensive theoretical framework for cyclic AND/OR graphs has been presented, which was found missing in the recent literature. Based on this framework, two best-first search algorithms, S1 and S2, have been developed. S1 does uninformed search and is a simple modification of the Bottom-up algorithm by Martelli and Montanari. S2 performs a heuristically guided search and replicates the modification in Bottom-up's successors, namely HS and AO*. Both S1 and S2 solve the problem of searching AND/OR graphs in presence of cycles. We then present a detailed analysis for the correctness and complexity results of S1 and S2, using the proposed framework. We have observed through experiments that S1 and S2 output correct results in all cases.
cs.AI:Thomas M. Strat has developed a decision-theoretic apparatus for Dempster-Shafer theory (Decision analysis using belief functions, Intern. J. Approx. Reason. 4(5/6), 391-417, 1990). In this apparatus, expected utility intervals are constructed for different choices. The choice with the highest expected utility is preferable to others. However, to find the preferred choice when the expected utility interval of one choice is included in that of another, it is necessary to interpolate a discerning point in the intervals. This is done by the parameter rho, defined as the probability that the ambiguity about the utility of every nonsingleton focal element will turn out as favorable as possible. If there are several different decision makers, we might sometimes be more interested in having the highest expected utility among the decision makers rather than only trying to maximize our own expected utility regardless of choices made by other decision makers. The preference of each choice is then determined by the probability of yielding the highest expected utility. This probability is equal to the maximal interval length of rho under which an alternative is preferred. We must here take into account not only the choices already made by other decision makers but also the rational choices we can assume to be made by later decision makers. In Strats apparatus, an assumption, unwarranted by the evidence at hand, has to be made about the value of rho. We demonstrate that no such assumption is necessary. It is sufficient to assume a uniform probability distribution for rho to be able to discern the most preferable choice. We discuss when this approach is justifiable.
cs.AI:Currently, there is renewed interest in the problem, raised by Shafer in 1985, of updating probabilities when observations are incomplete. This is a fundamental problem in general, and of particular interest for Bayesian networks. Recently, Grunwald and Halpern have shown that commonly used updating strategies fail in this case, except under very special assumptions. In this paper we propose a new method for updating probabilities with incomplete observations. Our approach is deliberately conservative: we make no assumptions about the so-called incompleteness mechanism that associates complete with incomplete observations. We model our ignorance about this mechanism by a vacuous lower prevision, a tool from the theory of imprecise probabilities, and we use only coherence arguments to turn prior into posterior probabilities. In general, this new approach to updating produces lower and upper posterior probabilities and expectations, as well as partially determinate decisions. This is a logical consequence of the existing ignorance about the incompleteness mechanism. We apply the new approach to the problem of classification of new evidence in probabilistic expert systems, where it leads to a new, so-called conservative updating rule. In the special case of Bayesian networks constructed using expert knowledge, we provide an exact algorithm for classification based on our updating rule, which has linear-time complexity for a class of networks wider than polytrees. This result is then extended to the more general framework of credal networks, where computations are often much harder than with Bayesian nets. Using an example, we show that our rule appears to provide a solid basis for reliable updating with incomplete observations, when no strong assumptions about the incompleteness mechanism are justified.
cs.AI:As examples such as the Monty Hall puzzle show, applying conditioning to update a probability distribution on a ``naive space'', which does not take into account the protocol used, can often lead to counterintuitive results. Here we examine why. A criterion known as CAR (``coarsening at random'') in the statistical literature characterizes when ``naive'' conditioning in a naive space works. We show that the CAR condition holds rather infrequently, and we provide a procedural characterization of it, by giving a randomized algorithm that generates all and only distributions for which CAR holds. This substantially extends previous characterizations of CAR. We also consider more generalized notions of update such as Jeffrey conditioning and minimizing relative entropy (MRE). We give a generalization of the CAR condition that characterizes when Jeffrey conditioning leads to appropriate answers, and show that there exist some very simple settings in which MRE essentially never gives the right results. This generalizes and interconnects previous results obtained in the literature on CAR and MRE.
cs.AI:Configuring consists in simulating the realization of a complex product from a catalog of component parts, using known relations between types, and picking values for object attributes. This highly combinatorial problem in the field of constraint programming has been addressed with a variety of approaches since the foundation system R1(McDermott82). An inherent difficulty in solving configuration problems is the existence of many isomorphisms among interpretations. We describe a formalism independent approach to improve the detection of isomorphisms by configurators, which does not require to adapt the problem model. To achieve this, we exploit the properties of a characteristic subset of configuration problems, called the structural sub-problem, which canonical solutions can be produced or tested at a limited cost. In this paper we present an algorithm for testing the canonicity of configurations, that can be added as a symmetry breaking constraint to any configurator. The cost and efficiency of this canonicity test are given.
cs.AI:This article introduces the idea that probabilistic reasoning (PR) may be understood as "information compression by multiple alignment, unification and search" (ICMAUS). In this context, multiple alignment has a meaning which is similar to but distinct from its meaning in bio-informatics, while unification means a simple merging of matching patterns, a meaning which is related to but simpler than the meaning of that term in logic.   A software model, SP61, has been developed for the discovery and formation of 'good' multiple alignments, evaluated in terms of information compression. The model is described in outline.   Using examples from the SP61 model, this article describes in outline how the ICMAUS framework can model various kinds of PR including: PR in best-match pattern recognition and information retrieval; one-step 'deductive' and 'abductive' PR; inheritance of attributes in a class hierarchy; chains of reasoning (probabilistic decision networks and decision trees, and PR with 'rules'); geometric analogy problems; nonmonotonic reasoning and reasoning with default values; modelling the function of a Bayesian network.
cs.AI:This article presents an overview of the idea that "information compression by multiple alignment, unification and search" (ICMAUS) may serve as a unifying principle in computing (including mathematics and logic) and in such aspects of human cognition as the analysis and production of natural language, fuzzy pattern recognition and best-match information retrieval, concept hierarchies with inheritance of attributes, probabilistic reasoning, and unsupervised inductive learning. The ICMAUS concepts are described together with an outline of the SP61 software model in which the ICMAUS concepts are currently realised. A range of examples is presented, illustrated with output from the SP61 model.
cs.AI:We propose a calculus integrating two calculi well-known in Qualitative Spatial Reasoning (QSR): Frank's projection-based cardinal direction calculus, and a coarser version of Freksa's relative orientation calculus. An original constraint propagation procedure is presented, which implements the interaction between the two integrated calculi. The importance of taking into account the interaction is shown with a real example providing an inconsistent knowledge base, whose inconsistency (a) cannot be detected by reasoning separately about each of the two components of the knowledge, just because, taken separately, each is consistent, but (b) is detected by the proposed algorithm, thanks to the interaction knowledge propagated from each of the two compnents to the other.
cs.AI:We define a ternary Relation Algebra (RA) of relative position relations on two-dimensional directed lines (d-lines for short). A d-line has two degrees of freedom (DFs): a rotational DF (RDF), and a translational DF (TDF). The representation of the RDF of a d-line will be handled by an RA of 2D orientations, CYC_t, known in the literature. A second algebra, TA_t, which will handle the TDF of a d-line, will be defined. The two algebras, CYC_t and TA_t, will constitute, respectively, the translational and the rotational components of the RA, PA_t, of relative position relations on d-lines: the PA_t atoms will consist of those pairs <t,r> of a TA_t atom and a CYC_t atom that are compatible. We present in detail the RA PA_t, with its converse table, its rotation table and its composition tables. We show that a (polynomial) constraint propagation algorithm, known in the literature, is complete for a subset of PA_t relations including almost all of the atomic relations. We will discuss the application scope of the RA, which includes incidence geometry, GIS (Geographic Information Systems), shape representation, localisation in (multi-)robot navigation, and the representation of motion prepositions in NLP (Natural Language Processing). We then compare the RA to existing ones, such as an algebra for reasoning about rectangles parallel to the axes of an (orthogonal) coordinate system, a ``spatial Odyssey'' of Allen's interval algebra, and an algebra for reasoning about 2D segments.
cs.AI:An intelligent agent will often be uncertain about various properties of its environment, and when acting in that environment it will frequently need to quantify its uncertainty. For example, if the agent wishes to employ the expected-utility paradigm of decision theory to guide its actions, it will need to assign degrees of belief (subjective probabilities) to various assertions. Of course, these degrees of belief should not be arbitrary, but rather should be based on the information available to the agent. This paper describes one approach for inducing degrees of belief from very rich knowledge bases, that can include information about particular individuals, statistical correlations, physical laws, and default rules. We call our approach the random-worlds method. The method is based on the principle of indifference: it treats all of the worlds the agent considers possible as being equally likely. It is able to integrate qualitative default reasoning with quantitative probabilistic reasoning by providing a language in which both types of information can be easily expressed. Our results show that a number of desiderata that arise in direct inference (reasoning from statistical information to conclusions about individuals) and default reasoning follow directly {from} the semantics of random worlds. For example, random worlds captures important patterns of reasoning such as specificity, inheritance, indifference to irrelevant information, and default assumptions of independence. Furthermore, the expressive power of the language used and the intuitive semantics of random worlds allow the method to deal with problems that are beyond the scope of many other non-deductive reasoning systems.
cs.AI:This paper describes an approach to the representation and processing of ontologies in the Semantic Web, based on the ICMAUS theory of computation and AI. This approach has strengths that complement those of languages based on the Resource Description Framework (RDF) such as RDF Schema and DAML+OIL. The main benefits of the ICMAUS approach are simplicity and comprehensibility in the representation of ontologies, an ability to cope with errors and uncertainties in knowledge, and a versatile reasoning system with capabilities in the kinds of probabilistic reasoning that seem to be required in the Semantic Web.
cs.AI:Interactions are patterns between several attributes in data that cannot be inferred from any subset of these attributes. While mutual information is a well-established approach to evaluating the interactions between two attributes, we surveyed its generalizations as to quantify interactions between several attributes. We have chosen McGill's interaction information, which has been independently rediscovered a number of times under various names in various disciplines, because of its many intuitively appealing properties. We apply interaction information to visually present the most important interactions of the data. Visualization of interactions has provided insight into the structure of data on a number of domains, identifying redundant attributes and opportunities for constructing new features, discovering unexpected regularities in data, and have helped during construction of predictive models; we illustrate the methods on numerous examples. A machine learning method that disregards interactions may get caught in two traps: myopia is caused by learning algorithms assuming independence in spite of interactions, whereas fragmentation arises from assuming an interaction in spite of independence.
cs.AI:In this paper we develop an evidential force aggregation method intended for classification of evidential intelligence into recognized force structures. We assume that the intelligence has already been partitioned into clusters and use the classification method individually in each cluster. The classification is based on a measure of fitness between template and fused intelligence that makes it possible to handle intelligence reports with multiple nonspecific and uncertain propositions. With this measure we can aggregate on a level-by-level basis, starting from general intelligence to achieve a complete force structure with recognized units on all hierarchical levels.
cs.AI:Article discusses the application of Kullback-Leibler divergence to the recognition of speech signals and suggests three algorithms implementing this divergence criterion: correlation algorithm, spectral algorithm and filter algorithm. Discussion covers an approach to the problem of speech variability and is illustrated with the results of experimental modeling of speech signals. The article gives a number of recommendations on the choice of appropriate model parameters and provides a comparison to some other methods of speech recognition.
cs.AI:Richard Cox [1] set the axiomatic foundations of probable inference and the algebra of propositions. He showed that consistency within these axioms requires certain rules for updating belief. In this paper we use the analogy between probability and utility introduced in [2] to propose an axiomatic foundation for utility inference and the algebra of preferences. We show that consistency within these axioms requires certain rules for updating preference. We discuss a class of utility functions that stems from the axioms of utility inference and show that this class is the basic building block for any general multiattribute utility function. We use this class of utility functions together with the algebra of preferences to construct utility functions represented by logical operations on the attributes.
cs.AI:Recent literature in the last Maximum Entropy workshop introduced an analogy between cumulative probability distributions and normalized utility functions. Based on this analogy, a utility density function can de defined as the derivative of a normalized utility function. A utility density function is non-negative and integrates to unity. These two properties form the basis of a correspondence between utility and probability. A natural application of this analogy is a maximum entropy principle to assign maximum entropy utility values. Maximum entropy utility interprets many of the common utility functions based on the preference information needed for their assignment, and helps assign utility values based on partial preference information. This paper reviews maximum entropy utility and introduces further results that stem from the duality between probability and utility.
cs.AI:Abduction, first proposed in the setting of classical logics, has been studied with growing interest in the logic programming area during the last years.   In this paper we study abduction with penalization in the logic programming framework. This form of abductive reasoning, which has not been previously analyzed in logic programming, turns out to represent several relevant problems, including optimization problems, very naturally. We define a formal model for abduction with penalization over logic programs, which extends the abductive framework proposed by Kakas and Mancarella. We address knowledge representation issues, encoding a number of problems in our abductive framework. In particular, we consider some relevant problems, taken from different domains, ranging from optimization theory to diagnosis and planning; their encodings turn out to be simple and elegant in our formalism. We thoroughly analyze the computational complexity of the main problems arising in the context of abduction with penalization from logic programs. Finally, we implement a system supporting the proposed abductive framework on top of the DLV engine. To this end, we design a translation from abduction problems with penalties into logic programs with weak constraints. We prove that this approach is sound and complete.
cs.AI:We study local-search satisfiability solvers for propositional logic extended with cardinality atoms, that is, expressions that provide explicit ways to model constraints on cardinalities of sets. Adding cardinality atoms to the language of propositional logic facilitates modeling search problems and often results in concise encodings. We propose two ``native'' local-search solvers for theories in the extended language. We also describe techniques to reduce the problem to standard propositional satisfiability and allow us to use off-the-shelf SAT solvers. We study these methods experimentally. Our general finding is that native solvers designed specifically for the extended language perform better than indirect methods relying on SAT solvers.
cs.AI:We describe WSAT(cc), a local-search solver for computing models of theories in the language of propositional logic extended by cardinality atoms. WSAT(cc) is a processing back-end for the logic PS+, a recently proposed formalism for answer-set programming.
cs.AI:This paper presents duality between probability distributions and utility functions.
cs.AI:Disjunctive Logic Programming (\DLP) is an advanced formalism for Knowledge Representation and Reasoning (KRR). \DLP is very expressive in a precise mathematical sense: it allows to express every property of finite structures that is decidable in the complexity class $\SigmaP{2}$ ($\NP^{\NP}$). Importantly, the \DLP encodings are often simple and natural.   In this paper, we single out some limitations of \DLP for KRR, which cannot naturally express problems where the size of the disjunction is not known ``a priori'' (like N-Coloring), but it is part of the input. To overcome these limitations, we further enhance the knowledge modelling abilities of \DLP, by extending this language by {\em Parametric Connectives (OR and AND)}. These connectives allow us to represent compactly the disjunction/conjunction of a set of atoms having a given property. We formally define the semantics of the new language, named $DLP^{\bigvee,\bigwedge}$ and we show the usefulness of the new constructs on relevant knowledge-based problems. We address implementation issues and discuss related works.
cs.AI:The research field of Agent-Oriented Software Engineering (AOSE) aims to find abstractions, languages, methodologies and toolkits for modeling, verifying, validating and prototyping complex applications conceptualized as Multiagent Systems (MASs). A very lively research sub-field studies how formal methods can be used for AOSE. This paper presents a detailed survey of six logic-based executable agent specification languages that have been chosen for their potential to be integrated in our ARPEGGIO project, an open framework for specifying and prototyping a MAS. The six languages are ConGoLog, Agent-0, the IMPACT agent programming language, DyLog, Concurrent METATEM and Ehhf. For each executable language, the logic foundations are described and an example of use is shown. A comparison of the six languages and a survey of similar approaches complete the paper, together with considerations of the advantages of using logic-based languages in MAS modeling and prototyping.
cs.AI:We propose a generalization of expected utility that we call generalized EU (GEU), where a decision maker's beliefs are represented by plausibility measures, and the decision maker's tastes are represented by general (i.e.,not necessarily real-valued) utility functions. We show that every agent, ``rational'' or not, can be modeled as a GEU maximizer. We then show that we can customize GEU by selectively imposing just the constraints we want. In particular, we show how each of Savage's postulates corresponds to constraints on GEU.
cs.AI:Many different rules for decision making have been introduced in the literature. We show that a notion of generalized expected utility proposed in Part I of this paper is a universal decision rule, in the sense that it can represent essentially all other decision rules.
cs.AI:This paper describes a novel approach to grammar induction that has been developed within a framework designed to integrate learning with other aspects of computing, AI, mathematics and logic. This framework, called "information compression by multiple alignment, unification and search" (ICMAUS), is founded on principles of Minimum Length Encoding pioneered by Solomonoff and others. Most of the paper describes SP70, a computer model of the ICMAUS framework that incorporates processes for unsupervised learning of grammars. An example is presented to show how the model can infer a plausible grammar from appropriate input. Limitations of the current model and how they may be overcome are briefly discussed.
cs.AI:We consider the integration of existing cone-shaped and projection-based calculi of cardinal direction relations, well-known in QSR. The more general, integrating language we consider is based on convex constraints of the qualitative form $r(x,y)$, $r$ being a cone-shaped or projection-based cardinal direction atomic relation, or of the quantitative form $(\alpha ,\beta)(x,y)$, with $\alpha ,\beta\in [0,2\pi)$ and $(\beta -\alpha)\in [0,\pi ]$: the meaning of the quantitative constraint, in particular, is that point $x$ belongs to the (convex) cone-shaped area rooted at $y$, and bounded by angles $\alpha$ and $\beta$. The general form of a constraint is a disjunction of the form $[r_1\vee...\vee r_{n_1}\vee (\alpha_1,\beta_1)\vee...\vee (\alpha _{n_2},\beta_{n_2})](x,y)$, with $r_i(x,y)$, $i=1... n_1$, and $(\alpha _i,\beta_i)(x,y)$, $i=1... n_2$, being convex constraints as described above: the meaning of such a general constraint is that, for some $i=1... n_1$, $r_i(x,y)$ holds, or, for some $i=1... n_2$, $(\alpha_i,\beta_i)(x,y)$ holds. A conjunction of such general constraints is a $\tcsp$-like CSP, which we will refer to as an $\scsp$ (Spatial Constraint Satisfaction Problem). An effective solution search algorithm for an $\scsp$ will be described, which uses (1) constraint propagation, based on a composition operation to be defined, as the filtering method during the search, and (2) the Simplex algorithm, guaranteeing completeness, at the leaves of the search tree. The approach is particularly suited for large-scale high-level vision, such as, e.g., satellite-like surveillance of a geographic area.
cs.AI:Object oriented constraint programs (OOCPs) emerge as a leading evolution of constraint programming and artificial intelligence, first applied to a range of industrial applications called configuration problems. The rich variety of technical approaches to solving configuration problems (CLP(FD), CC(FD), DCSP, Terminological systems, constraint programs with set variables ...) is a source of difficulty. No universally accepted formal language exists for communicating about OOCPs, which makes the comparison of systems difficult. We present here a Z based specification of OOCPs which avoids the falltrap of hidden object semantics. The object system is part of the specification, and captures all of the most advanced notions from the object oriented modeling standard UML. The paper illustrates these issues and the conciseness and precision of Z by the specification of a working OOCP that solves an historical AI problem : parsing a context free grammar. Being written in Z, an OOCP specification also supports formal proofs. The whole builds the foundation of an adaptative and evolving framework for communicating about constrained object models and programs.
cs.AI:In this paper we suggest an architecture for a software agent which operates a physical device and is capable of making observations and of testing and repairing the device's components. We present simplified definitions of the notions of symptom, candidate diagnosis, and diagnosis which are based on the theory of action language ${\cal AL}$. The definitions allow one to give a simple account of the agent's behavior in which many of the agent's tasks are reduced to computing stable models of logic programs.
cs.AI:We compare two recent extensions of the answer set (stable model) semantics of logic programs. One of them, due to Lifschitz, Tang and Turner, allows the bodies and heads of rules to contain nested expressions. The other, due to Niemela and Simons, uses weight constraints. We show that there is a simple, modular translation from the language of weight constraints into the language of nested expressions that preserves the program's answer sets. Nested expressions can be eliminated from the result of this translation in favor of additional atoms. The translation makes it possible to compute answer sets for some programs with weight constraints using satisfiability solvers, and to prove the strong equivalence of programs with weight constraints using the logic of here-and there.
cs.AI:(We apologize for pidgin LaTeX) Schlipf \cite{sch91} proved that Stable Logic Programming (SLP) solves all $\mathit{NP}$ decision problems. We extend Schlipf's result to prove that SLP solves all search problems in the class $\mathit{NP}$. Moreover, we do this in a uniform way as defined in \cite{mt99}. Specifically, we show that there is a single $\mathrm{DATALOG}^{\neg}$ program $P_{\mathit{Trg}}$ such that given any Turing machine $M$, any polynomial $p$ with non-negative integer coefficients and any input $\sigma$ of size $n$ over a fixed alphabet $\Sigma$, there is an extensional database $\mathit{edb}_{M,p,\sigma}$ such that there is a one-to-one correspondence between the stable models of $\mathit{edb}_{M,p,\sigma} \cup P_{\mathit{Trg}}$ and the accepting computations of the machine $M$ that reach the final state in at most $p(n)$ steps. Moreover, $\mathit{edb}_{M,p,\sigma}$ can be computed in polynomial time from $p$, $\sigma$ and the description of $M$ and the decoding of such accepting computations from its corresponding stable model of $\mathit{edb}_{M,p,\sigma} \cup P_{\mathit{Trg}}$ can be computed in linear time. A similar statement holds for Default Logic with respect to $\Sigma_2^\mathrm{P}$-search problems\footnote{The proof of this result involves additional technical complications and will be a subject of another publication.}.
cs.AI:This book develops the conjecture that all kinds of information processing in computers and in brains may usefully be understood as "information compression by multiple alignment, unification and search". This "SP theory", which has been under development since 1987, provides a unified view of such things as the workings of a universal Turing machine, the nature of 'knowledge', the interpretation and production of natural language, pattern recognition and best-match information retrieval, several kinds of probabilistic reasoning, planning and problem solving, unsupervised learning, and a range of concepts in mathematics and logic. The theory also provides a basis for the design of an 'SP' computer with several potential advantages compared with traditional digital computers.
cs.AI:In rule-based systems, goal-oriented computations correspond naturally to the possible ways that an observation may be explained. In some applications, we need to compute explanations for a series of observations with the same domain. The question whether previously computed answers can be recycled arises. A yes answer could result in substantial savings of repeated computations. For systems based on classic logic, the answer is YES. For nonmonotonic systems however, one tends to believe that the answer should be NO, since recycling is a form of adding information. In this paper, we show that computed answers can always be recycled, in a nontrivial way, for the class of rewrite procedures that we proposed earlier for logic programs with negation. We present some experimental results on an encoding of the logistics domain.
cs.AI:Recent advances in programming languages study and design have established a standard way of grounding computational systems representation in category theory. These formal results led to a better understanding of issues of control and side-effects in functional and imperative languages. This framework can be successfully applied to the investigation of the performance of Artificial Intelligence (AI) inference and cognitive systems. In this paper, we delineate a categorical formalisation of memory as a control structure driving performance in inference systems. Abstracting away control mechanisms from three widely used representations of memory in cognitive systems (scripts, production rules and clusters) we explain how categorical triples capture the interaction between learning and problem-solving.
cs.AI:The field of machine learning (ML) is concerned with the question of how to construct algorithms that automatically improve with experience. In recent years many successful ML applications have been developed, such as datamining programs, information-filtering systems, etc. Although ML algorithms allow the detection and extraction of interesting patterns of data for several kinds of problems, most of these algorithms are based on quantitative reasoning, as they rely on training data in order to infer so-called target functions.   In the last years defeasible argumentation has proven to be a sound setting to formalize common-sense qualitative reasoning. This approach can be combined with other inference techniques, such as those provided by machine learning theory.   In this paper we outline different alternatives for combining defeasible argumentation and machine learning techniques. We suggest how different aspects of a generic argument-based framework can be integrated with other ML-based approaches.
cs.AI:Stable model semantics has become a very popular approach for the management of negation in logic programming. This approach relies mainly on the closed world assumption to complete the available knowledge and its formulation has its basis in the so-called Gelfond-Lifschitz transformation.   The primary goal of this work is to present an alternative and epistemic-based characterization of stable model semantics, to the Gelfond-Lifschitz transformation. In particular, we show that stable model semantics can be defined entirely as an extension of the Kripke-Kleene semantics. Indeed, we show that the closed world assumption can be seen as an additional source of `falsehood' to be added cumulatively to the Kripke-Kleene semantics. Our approach is purely algebraic and can abstract from the particular formalism of choice as it is based on monotone operators (under the knowledge order) over bilattices only.
cs.AI:We address the problem of the development of representations and their relationship to the environment. We study a software agent which develops in a network a representation of its simple environment which captures and integrates the relationships between agent and environment through a closure mechanism. The inclusion of a variable behavior modifier allows better representation development. This can be confirmed with an internal description of the closure mechanism, and with an external description of the properties of the representation network.
cs.AI:This document describes syntax, semantics and implementation guidelines in order to enrich the DLV system with the possibility to make external C function calls. This feature is realized by the introduction of parametric external predicates, whose extension is not specified through a logic program but implicitly computed through external code.
cs.AI:This document describes the functions as they are treated in the DLV system. We give first the language, then specify the main implementation issues.
cs.AI:We introduce Ak, an extension of the action description language A (Gelfond and Lifschitz, 1993) to handle actions which affect knowledge. We use sensing actions to increase an agent's knowledge of the world and non-deterministic actions to remove knowledge. We include complex plans involving conditionals and loops in our query language for hypothetical reasoning. We also present a translation of Ak domain descriptions into epistemic logic programs.
cs.AI:In this paper, we examine the performance of four fuzzy rule generation methods on Wisconsin breast cancer data. The first method generates fuzzy if then rules using the mean and the standard deviation of attribute values. The second approach generates fuzzy if then rules using the histogram of attributes values. The third procedure generates fuzzy if then rules with certainty of each attribute into homogeneous fuzzy sets. In the fourth approach, only overlapping areas are partitioned. The first two approaches generate a single fuzzy if then rule for each class by specifying the membership function of each antecedent fuzzy set using the information about attribute values of training patterns. The other two approaches are based on fuzzy grids with homogeneous fuzzy partitions of each attribute. The performance of each approach is evaluated on breast cancer data sets. Simulation results show that the Modified grid approach has a high classification rate of 99.73 %.
cs.AI:The integration of different learning and adaptation techniques to overcome individual limitations and to achieve synergetic effects through the hybridization or fusion of these techniques has, in recent years, contributed to a large number of new intelligent system designs. Computational intelligence is an innovative framework for constructing intelligent hybrid architectures involving Neural Networks (NN), Fuzzy Inference Systems (FIS), Probabilistic Reasoning (PR) and derivative free optimization techniques such as Evolutionary Computation (EC). Most of these hybridization approaches, however, follow an ad hoc design methodology, justified by success in certain application domains. Due to the lack of a common framework it often remains difficult to compare the various hybrid systems conceptually and to evaluate their performance comparatively. This chapter introduces the different generic architectures for integrating intelligent systems. The designing aspects and perspectives of different hybrid archirectures like NN-FIS, EC-FIS, EC-NN, FIS-PR and NN-FIS-EC systems are presented. Some conclusions are also provided towards the end.
cs.AI:Neuro-fuzzy systems have attracted growing interest of researchers in various scientific and engineering areas due to the increasing need of intelligent systems. This paper evaluates the use of two popular soft computing techniques and conventional statistical approach based on Box--Jenkins autoregressive integrated moving average (ARIMA) model to predict electricity demand in the State of Victoria, Australia. The soft computing methods considered are an evolving fuzzy neural network (EFuNN) and an artificial neural network (ANN) trained using scaled conjugate gradient algorithm (CGA) and backpropagation (BP) algorithm. The forecast accuracy is compared with the forecasts used by Victorian Power Exchange (VPX) and the actual energy demand. To evaluate, we considered load demand patterns for 10 consecutive months taken every 30 min for training the different prediction models. Test results show that the neuro-fuzzy system performed better than neural networks, ARIMA model and the VPX forecasts.
cs.AI:Fusion of Artificial Neural Networks (ANN) and Fuzzy Inference Systems (FIS) have attracted the growing interest of researchers in various scientific and engineering areas due to the growing need of adaptive intelligent systems to solve the real world problems. ANN learns from scratch by adjusting the interconnections between layers. FIS is a popular computing framework based on the concept of fuzzy set theory, fuzzy if-then rules, and fuzzy reasoning. The advantages of a combination of ANN and FIS are obvious. There are several approaches to integrate ANN and FIS and very often it depends on the application. We broadly classify the integration of ANN and FIS into three categories namely concurrent model, cooperative model and fully fused model. This paper starts with a discussion of the features of each model and generalize the advantages and deficiencies of each model. We further focus the review on the different types of fused neuro-fuzzy systems and citing the advantages and disadvantages of each model.
cs.AI:Long-term rainfall prediction is a challenging task especially in the modern world where we are facing the major environmental problem of global warming. In general, climate and rainfall are highly non-linear phenomena in nature exhibiting what is known as the butterfly effect. While some regions of the world are noticing a systematic decrease in annual rainfall, others notice increases in flooding and severe storms. The global nature of this phenomenon is very complicated and requires sophisticated computer modeling and simulation to predict accurately. In this paper, we report a performance analysis for Multivariate Adaptive Regression Splines (MARS)and artificial neural networks for one month ahead prediction of rainfall. To evaluate the prediction efficiency, we made use of 87 years of rainfall data in Kerala state, the southern part of the Indian peninsula situated at latitude -longitude pairs (8o29'N - 76o57' E). We used an artificial neural network trained using the scaled conjugate gradient algorithm. The neural network and MARS were trained with 40 years of rainfall data. For performance evaluation, network predicted outputs were compared with the actual rainfall data. Simulation results reveal that MARS is a good forecasting tool and performed better than the considered neural network.
cs.AI:Classification of texture pattern is one of the most important problems in pattern recognition. In this paper, we present a classification method based on the Discrete Cosine Transform (DCT) coefficients of texture image. As DCT works on gray level image, the color scheme of each image is transformed into gray levels. For classifying the images using DCT we used two popular soft computing techniques namely neurocomputing and neuro-fuzzy computing. We used a feedforward neural network trained using the backpropagation learning and an evolving fuzzy neural network to classify the textures. The soft computing models were trained using 80% of the texture data and remaining was used for testing and validation purposes. A performance comparison was made among the soft computing models for the texture classification problem. We also analyzed the effects of prolonged training of neural networks. It is observed that the proposed neuro-fuzzy model performed better than neural network.
cs.AI:Sorting by reversals is an important problem in inferring the evolutionary relationship between two genomes. The problem of sorting unsigned permutation has been proven to be NP-hard. The best guaranteed error bounded is the 3/2- approximation algorithm. However, the problem of sorting signed permutation can be solved easily. Fast algorithms have been developed both for finding the sorting sequence and finding the reversal distance of signed permutation. In this paper, we present a way to view the problem of sorting unsigned permutation as signed permutation. And the problem can then be seen as searching an optimal signed permutation in all n2 corresponding signed permutations. We use genetic algorithm to conduct the search. Our experimental result shows that the proposed method outperform the 3/2-approximation algorithm.
cs.AI:Past few years have witnessed a growing recognition of intelligent techniques for the construction of efficient and reliable intrusion detection systems. Due to increasing incidents of cyber attacks, building effective intrusion detection systems (IDS) are essential for protecting information systems security, and yet it remains an elusive goal and a great challenge. In this paper, we report a performance analysis between Multivariate Adaptive Regression Splines (MARS), neural networks and support vector machines. The MARS procedure builds flexible regression models by fitting separate splines to distinct intervals of the predictor variables. A brief comparison of different neural network learning algorithms is also given.
cs.AI:The aim of our research was to apply well-known data mining techniques (such as linear neural networks, multi-layered perceptrons, probabilistic neural networks, classification and regression trees, support vector machines and finally a hybrid decision tree neural network approach) to the problem of predicting the quality of service in call centers; based on the performance data actually collected in a call center of a large insurance company. Our aim was two-fold. First, to compare the performance of models built using the above-mentioned techniques and, second, to analyze the characteristics of the input sensitivity in order to better understand the relationship between the perform-ance evaluation process and the actual performance and in this way help improve the performance of call centers. In this paper we summarize our findings.
cs.AI:The use of intelligent systems for stock market predictions has been widely established. In this paper, we investigate how the seemingly chaotic behavior of stock markets could be well represented using several connectionist paradigms and soft computing techniques. To demonstrate the different techniques, we considered Nasdaq-100 index of Nasdaq Stock MarketS and the S&P CNX NIFTY stock index. We analyzed 7 year's Nasdaq 100 main index values and 4 year's NIFTY index values. This paper investigates the development of a reliable and efficient technique to model the seemingly chaotic behavior of stock markets. We considered an artificial neural network trained using Levenberg-Marquardt algorithm, Support Vector Machine (SVM), Takagi-Sugeno neuro-fuzzy model and a Difference Boosting Neural Network (DBNN). This paper briefly explains how the different connectionist paradigms could be formulated using different learning methods and then investigates whether they can provide the required level of performance, which are sufficiently good and robust so as to provide a reliable forecast model for stock market indices. Experiment results reveal that all the connectionist paradigms considered could represent the stock indices behavior very accurately.
cs.AI:The purpose of this paper is to point to the usefulness of applying a linear mathematical formulation of fuzzy multiple criteria objective decision methods in organising business activities. In this respect fuzzy parameters of linear programming are modelled by preference-based membership functions. This paper begins with an introduction and some related research followed by some fundamentals of fuzzy set theory and technical concepts of fuzzy multiple objective decision models. Further a real case study of a manufacturing plant and the implementation of the proposed technique is presented. Empirical results clearly show the superiority of the fuzzy technique in optimising individual objective functions when compared to non-fuzzy approach. Furthermore, for the problem considered, the optimal solution helps to infer that by incorporating fuzziness in a linear programming model either in constraints, or both in objective functions and constraints, provides a similar (or even better) level of satisfaction for obtained results compared to non-fuzzy linear programming.
cs.AI:In this paper, we present MLEANN (Meta-Learning Evolutionary Artificial Neural Network), an automatic computational framework for the adaptive optimization of artificial neural networks wherein the neural network architecture, activation function, connection weights; learning algorithm and its parameters are adapted according to the problem. We explored the performance of MLEANN and conventionally designed artificial neural networks for function approximation problems. To evaluate the comparative performance, we used three different well-known chaotic time series. We also present the state of the art popular neural network learning algorithms and some experimentation results related to convergence speed and generalization performance. We explored the performance of backpropagation algorithm; conjugate gradient algorithm, quasi-Newton algorithm and Levenberg-Marquardt algorithm for the three chaotic time series. Performances of the different learning algorithms were evaluated when the activation functions and architecture were changed. We further present the theoretical background, algorithm, design strategy and further demonstrate how effective and inevitable is the proposed MLEANN framework to design a neural network, which is smaller, faster and with a better generalization performance.
cs.AI:The phylogenetic tree construction is to infer the evolutionary relationship between species from the experimental data. However, the experimental data are often imperfect and conflicting each others. Therefore, it is important to extract the motif from the imperfect data. The largest compatible subset problem is that, given a set of experimental data, we want to discard the minimum such that the remaining is compatible. The largest compatible subset problem can be viewed as the vertex cover problem in the graph theory that has been proven to be NP-hard. In this paper, we propose a hybrid Evolutionary Computing (EC) method for this problem. The proposed method combines the EC approach and the algorithmic approach for special structured graphs. As a result, the complexity of the problem is dramatically reduced. Experiments were performed on randomly generated graphs with different edge densities. The vertex covers produced by the proposed method were then compared to the vertex covers produced by a 2-approximation algorithm. The experimental results showed that the proposed method consistently outperformed a classical 2- approximation algorithm. Furthermore, a significant improvement was found when the graph density was small.
cs.AI:Decision-making is a process of choosing among alternative courses of action for solving complicated problems where multi-criteria objectives are involved. The past few years have witnessed a growing recognition of Soft Computing technologies that underlie the conception, design and utilization of intelligent systems. Several works have been done where engineers and scientists have applied intelligent techniques and heuristics to obtain optimal decisions from imprecise information. In this paper, we present a concurrent fuzzy-neural network approach combining unsupervised and supervised learning techniques to develop the Tactical Air Combat Decision Support System (TACDSS). Experiment results clearly demonstrate the efficiency of the proposed technique.
cs.AI:In a universe with a single currency, there would be no foreign exchange market, no foreign exchange rates, and no foreign exchange. Over the past twenty-five years, the way the market has performed those tasks has changed enormously. The need for intelligent monitoring systems has become a necessity to keep track of the complex forex market. The vast currency market is a foreign concept to the average individual. However, once it is broken down into simple terms, the average individual can begin to understand the foreign exchange market and use it as a financial instrument for future investing. In this paper, we attempt to compare the performance of hybrid soft computing and hard computing techniques to predict the average monthly forex rates one month ahead. The soft computing models considered are a neural network trained by the scaled conjugate gradient algorithm and a neuro-fuzzy model implementing a Takagi-Sugeno fuzzy inference system. We also considered Multivariate Adaptive Regression Splines (MARS), Classification and Regression Trees (CART) and a hybrid CART-MARS technique. We considered the exchange rates of Australian dollar with respect to US dollar, Singapore dollar, New Zealand dollar, Japanese yen and United Kingdom pounds. The models were trained using 70% of the data and remaining was used for testing and validation purposes. It is observed that the proposed hybrid models could predict the forex rates more accurately than all the techniques when applied individually. Empirical results also reveal that the hybrid hard computing approach also improved some of our previous work using a neuro-fuzzy approach.
cs.AI:The rapid e-commerce growth has made both business community and customers face a new situation. Due to intense competition on one hand and the customer's option to choose from several alternatives business community has realized the necessity of intelligent marketing strategies and relationship management. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, personalization, network traffic flow analysis and so on. In this paper, we present the important concepts of Web usage mining and its various practical applications. We further present a novel approach 'intelligent-miner' (i-Miner) to optimize the concurrent architecture of a fuzzy clustering algorithm (to discover web data clusters) and a fuzzy inference system to analyze the Web site visitor trends. A hybrid evolutionary fuzzy clustering algorithm is proposed in this paper to optimally segregate similar user interests. The clustered data is then used to analyze the trends using a Takagi-Sugeno fuzzy inference system learned using a combination of evolutionary algorithm and neural network learning. Proposed approach is compared with self-organizing maps (to discover patterns) and several function approximation techniques like neural networks, linear genetic programming and Takagi-Sugeno fuzzy inference system (to analyze the clusters). The results are graphically illustrated and the practical significance is discussed in detail. Empirical results clearly show that the proposed Web usage-mining framework is efficient.
cs.AI:Normally a decision support system is build to solve problem where multi-criteria decisions are involved. The knowledge base is the vital part of the decision support containing the information or data that is used in decision-making process. This is the field where engineers and scientists have applied several intelligent techniques and heuristics to obtain optimal decisions from imprecise information. In this paper, we present a hybrid neuro-genetic learning approach for the adaptation a Mamdani fuzzy inference system for the Tactical Air Combat Decision Support System (TACDSS). Some simulation results demonstrating the difference of the learning techniques and are also provided.
cs.AI:Several adaptation techniques have been investigated to optimize fuzzy inference systems. Neural network learning algorithms have been used to determine the parameters of fuzzy inference system. Such models are often called as integrated neuro-fuzzy models. In an integrated neuro-fuzzy model there is no guarantee that the neural network learning algorithm converges and the tuning of fuzzy inference system will be successful. Success of evolutionary search procedures for optimization of fuzzy inference system is well proven and established in many application areas. In this paper, we will explore how the optimization of fuzzy inference systems could be further improved using a meta-heuristic approach combining neural network learning and evolutionary computation. The proposed technique could be considered as a methodology to integrate neural networks, fuzzy inference systems and evolutionary search procedures. We present the theoretical frameworks and some experimental results to demonstrate the efficiency of the proposed technique.
cs.AI:Evolutionary artificial neural networks (EANNs) refer to a special class of artificial neural networks (ANNs) in which evolution is another fundamental form of adaptation in addition to learning. Evolutionary algorithms are used to adapt the connection weights, network architecture and learning algorithms according to the problem environment. Even though evolutionary algorithms are well known as efficient global search algorithms, very often they miss the best local solutions in the complex solution space. In this paper, we propose a hybrid meta-heuristic learning approach combining evolutionary learning and local search methods (using 1st and 2nd order error information) to improve the learning and faster convergence obtained using a direct evolutionary approach. The proposed technique is tested on three different chaotic time series and the test results are compared with some popular neuro-fuzzy systems and a recently developed cutting angle method of global optimization. Empirical results reveal that the proposed technique is efficient in spite of the computational complexity.
cs.AI:The academic literature suggests that the extent of exporting by multinational corporation subsidiaries (MCS) depends on their product manufactured, resources, tax protection, customers and markets, involvement strategy, financial independence and suppliers' relationship with a multinational corporation (MNC). The aim of this paper is to model the complex export pattern behaviour using a Takagi-Sugeno fuzzy inference system in order to determine the actual volume of MCS export output (sales exported). The proposed fuzzy inference system is optimised by using neural network learning and evolutionary computation. Empirical results clearly show that the proposed approach could model the export behaviour reasonable well compared to a direct neural network approach.
cs.AI:The costs of fatalities and injuries due to traffic accident have a great impact on society. This paper presents our research to model the severity of injury resulting from traffic accidents using artificial neural networks and decision trees. We have applied them to an actual data set obtained from the National Automotive Sampling System (NASS) General Estimates System (GES). Experiment results reveal that in all the cases the decision tree outperforms the neural network. Our research analysis also shows that the three most important factors in fatal injury are: driver's seat belt usage, light condition of the roadway, and driver's alcohol usage.
cs.AI:This paper presents a comparative study of six soft computing models namely multilayer perceptron networks, Elman recurrent neural network, radial basis function network, Hopfield model, fuzzy inference system and hybrid fuzzy neural network for the hourly electricity demand forecast of Czech Republic. The soft computing models were trained and tested using the actual hourly load data for seven years. A comparison of the proposed techniques is presented for predicting 2 day ahead demands for electricity. Simulation results indicate that hybrid fuzzy neural network and radial basis function networks are the best candidates for the analysis and forecasting of electricity demand.
cs.AI:Decision-making is a process of choosing among alternative courses of action for solving complicated problems where multi-criteria objectives are involved. The past few years have witnessed a growing recognition of Soft Computing (SC) technologies that underlie the conception, design and utilization of intelligent systems. In this paper, we present different SC paradigms involving an artificial neural network trained using the scaled conjugate gradient algorithm, two different fuzzy inference methods optimised using neural network learning/evolutionary algorithms and regression trees for developing intelligent decision support systems. We demonstrate the efficiency of the different algorithms by developing a decision support system for a Tactical Air Combat Environment (TACE). Some empirical comparisons between the different algorithms are also provided.
cs.AI:In this paper, we present a state-based regression function for planning domains where an agent does not have complete information and may have sensing actions. We consider binary domains and employ the 0-approximation [Son & Baral 2001] to define the regression function. In binary domains, the use of 0-approximation means using 3-valued states. Although planning using this approach is incomplete with respect to the full semantics, we adopt it to have a lower complexity. We prove the soundness and completeness of our regression formulation with respect to the definition of progression. More specifically, we show that (i) a plan obtained through regression for a planning problem is indeed a progression solution of that planning problem, and that (ii) for each plan found through progression, using regression one obtains that plan or an equivalent one. We then develop a conditional planner that utilizes our regression function. We prove the soundness and completeness of our planning algorithm and present experimental results with respect to several well known planning problems in the literature.
cs.AI:Defeasible logic is a rule-based nonmonotonic logic, with both strict and defeasible rules, and a priority relation on rules. We show that inference in the propositional form of the logic can be performed in linear time. This contrasts markedly with most other propositional nonmonotonic logics, in which inference is intractable.
cs.AI:Defeasible argumentation has experienced a considerable growth in AI in the last decade. Theoretical results have been combined with development of practical applications in AI & Law, Case-Based Reasoning and various knowledge-based systems. However, the dialectical process associated with inference is computationally expensive. This paper focuses on speeding up this inference process by pruning the involved search space. Our approach is twofold. On one hand, we identify distinguished literals for computing defeat. On the other hand, we restrict ourselves to a subset of all possible conflicting arguments by introducing dialectical constraints.
cs.AI:Main purposes of the paper are followings: 1) To show examples of the calculations in domain of QFT via ``derivative rules'' of an expert system; 2) To consider advantages and disadvantage that technology of the calculations; 3) To reflect about how one would develop new physical theories, what knowledge would be useful in their investigations and how this problem can be connected with designing an expert system.
cs.AI:We will try to tackle both the theoretical and practical aspects of a very important problem in chess programming as stated in the title of this article - the issue of draw detection by move repetition. The standard approach that has so far been employed in most chess programs is based on utilising positional matrices in original and compressed format as well as on the implementation of the so-called bitboard format.   The new approach that we will be trying to introduce is based on using variant strings generated by the search algorithm (searcher) during the tree expansion in decision making. We hope to prove that this approach is more efficient than the standard treatment of the issue, especially in positions with few pieces (endgames). To illustrate what we have in mind a machine language routine that implements our theoretical assumptions is attached. The routine is part of the Axon chess program, developed by the authors. Axon, in its current incarnation, plays chess at master strength (ca. 2400-2450 Elo, based on both Axon vs computer programs and Axon vs human masters in over 3000 games altogether).
cs.AI:Learning to respond to voice-text input involves the subject's ability in understanding the phonetic and text based contents and his/her ability to communicate based on his/her experience. The neuro-cognitive facility of the subject has to support two important domains in order to make the learning process complete. In many cases, though the understanding is complete, the response is partial. This is one valid reason why we need to support the information from the subject with scalable techniques such as Natural Language Processing (NLP) for abstraction of the contents from the output. This paper explores the feasibility of using NLP modules interlaced with Neural Networks to perform the required task in autogenic training related to medical applications.
cs.AI:Generalized evolutionary algorithm based on Tsallis canonical distribution is proposed. The algorithm uses Tsallis generalized canonical distribution to weigh the configurations for `selection' instead of Gibbs-Boltzmann distribution. Our simulation results show that for an appropriate choice of non-extensive index that is offered by Tsallis statistics, evolutionary algorithms based on this generalization outperform algorithms based on Gibbs-Boltzmann distribution.
cs.AI:In this paper we present and evaluate a search strategy called Decomposition Based Search (DBS) which is based on two steps: subproblem generation and subproblem solution. The generation of subproblems is done through value ranking and domain splitting. Subdomains are explored so as to generate, according to the heuristic chosen, promising subproblems first.   We show that two well known search strategies, Limited Discrepancy Search (LDS) and Iterative Broadening (IB), can be seen as special cases of DBS. First we present a tuning of DBS that visits the same search nodes as IB, but avoids restarts. Then we compare both theoretically and computationally DBS and LDS using the same heuristic. We prove that DBS has a higher probability of being successful than LDS on a comparable number of nodes, under realistic assumptions. Experiments on a constraint satisfaction problem and an optimization problem show that DBS is indeed very effective if compared to LDS.
cs.AI:Solution techniques for Constraint Satisfaction and Optimisation Problems often make use of backtrack search methods, exploiting variable and value ordering heuristics. In this paper, we propose and analyse a very simple method to apply in case the value ordering heuristic produces ties: postponing the branching decision. To this end, we group together values in a tie, branch on this sub-domain, and defer the decision among them to lower levels of the search tree. We show theoretically and experimentally that this simple modification can dramatically improve the efficiency of the search strategy. Although in practise similar methods may have been applied already, to our knowledge, no empirical or theoretical study has been proposed in the literature to identify when and to what extent this strategy should be used.
cs.AI:In this paper, we propose an effective search procedure that interleaves two steps: subproblem generation and subproblem solution. We mainly focus on the first part. It consists of a variable domain value ranking based on reduced costs. Exploiting the ranking, we generate, in a Limited Discrepancy Search tree, the most promising subproblems first. An interesting result is that reduced costs provide a very precise ranking that allows to almost always find the optimal solution in the first generated subproblem, even if its dimension is significantly smaller than that of the original problem. Concerning the proof of optimality, we exploit a way to increase the lower bound for subproblems at higher discrepancies. We show experimental results on the TSP and its time constrained variant to show the effectiveness of the proposed approach, but the technique could be generalized for other problems.
cs.AI:One proposes a first alternative rule of combination to WAO (Weighted Average Operator) proposed recently by Josang, Daniel and Vannoorenberghe, called Proportional Conflict Redistribution rule (denoted PCR1). PCR1 and WAO are particular cases of WO (the Weighted Operator) because the conflicting mass is redistributed with respect to some weighting factors. In this first PCR rule, the proportionalization is done for each non-empty set with respect to the non-zero sum of its corresponding mass matrix - instead of its mass column average as in WAO, but the results are the same as Ph. Smets has pointed out. Also, we extend WAO (which herein gives no solution) for the degenerate case when all column sums of all non-empty sets are zero, and then the conflicting mass is transferred to the non-empty disjunctive form of all non-empty sets together; but if this disjunctive form happens to be empty, then one considers an open world (i.e. the frame of discernment might contain new hypotheses) and thus all conflicting mass is transferred to the empty set. In addition to WAO, we propose a general formula for PCR1 (WAO for non-degenerate cases).
cs.AI:In this paper one proposes a simple algorithm of combining the fusion rules, those rules which first use the conjunctive rule and then the transfer of conflicting mass to the non-empty sets, in such a way that they gain the property of associativity and fulfill the Markovian requirement for dynamic fusion. Also, a new rule, SDL-improved, is presented.
cs.AI:FLUX is a programming method for the design of agents that reason logically about their actions and sensor information in the presence of incomplete knowledge. The core of FLUX is a system of Constraint Handling Rules, which enables agents to maintain an internal model of their environment by which they control their own behavior. The general action representation formalism of the fluent calculus provides the formal semantics for the constraint solver. FLUX exhibits excellent computational behavior due to both a carefully restricted expressiveness and the inference paradigm of progression.
cs.AI:Boltzmann selection is an important selection mechanism in evolutionary algorithms as it has theoretical properties which help in theoretical analysis. However, Boltzmann selection is not used in practice because a good annealing schedule for the `inverse temperature' parameter is lacking. In this paper we propose a Cauchy annealing schedule for Boltzmann selection scheme based on a hypothesis that selection-strength should increase as evolutionary process goes on and distance between two selection strengths should decrease for the process to converge. To formalize these aspects, we develop formalism for selection mechanisms using fitness distributions and give an appropriate measure for selection-strength. In this paper, we prove an important result, by which we derive an annealing schedule called Cauchy annealing schedule. We demonstrate the novelty of proposed annealing schedule using simulations in the framework of genetic algorithms.
cs.AI:In this paper we propose five versions of a Proportional Conflict Redistribution rule (PCR) for information fusion together with several examples. From PCR1 to PCR2, PCR3, PCR4, PCR5 one increases the complexity of the rules and also the exactitude of the redistribution of conflicting masses. PCR1 restricted from the hyper-power set to the power set and without degenerate cases gives the same result as the Weighted Average Operator (WAO) proposed recently by J{\o}sang, Daniel and Vannoorenberghe but does not satisfy the neutrality property of vacuous belief assignment. That's why improved PCR rules are proposed in this paper. PCR4 is an improvement of minC and Dempster's rules. The PCR rules redistribute the conflicting mass, after the conjunctive rule has been applied, proportionally with some functions depending on the masses assigned to their corresponding columns in the mass matrix. There are infinitely many ways these functions (weighting factors) can be chosen depending on the complexity one wants to deal with in specific applications and fusion systems. Any fusion combination rule is at some degree ad-hoc.
cs.AI:This paper presents in detail the generalized pignistic transformation (GPT) succinctly developed in the Dezert-Smarandache Theory (DSmT) framework as a tool for decision process. The GPT allows to provide a subjective probability measure from any generalized basic belief assignment given by any corpus of evidence. We mainly focus our presentation on the 3D case and provide the complete result obtained by the GPT and its validation drawn from the probability theory.
cs.AI:Since no fusion theory neither rule fully satisfy all needed applications, the author proposes a Unification of Fusion Theories and a combination of fusion rules in solving problems/applications. For each particular application, one selects the most appropriate model, rule(s), and algorithm of implementation. We are working in the unification of the fusion theories and rules, which looks like a cooking recipe, better we'd say like a logical chart for a computer programmer, but we don't see another method to comprise/unify all things. The unification scenario presented herein, which is now in an incipient form, should periodically be updated incorporating new discoveries from the fusion and engineering research.
cs.AI:Normal forms for logic programs under stable/answer set semantics are introduced. We argue that these forms can simplify the study of program properties, mainly consistency. The first normal form, called the {\em kernel} of the program, is useful for studying existence and number of answer sets. A kernel program is composed of the atoms which are undefined in the Well-founded semantics, which are those that directly affect the existence of answer sets. The body of rules is composed of negative literals only. Thus, the kernel form tends to be significantly more compact than other formulations. Also, it is possible to check consistency of kernel programs in terms of colorings of the Extended Dependency Graph program representation which we previously developed. The second normal form is called {\em 3-kernel.} A 3-kernel program is composed of the atoms which are undefined in the Well-founded semantics. Rules in 3-kernel programs have at most two conditions, and each rule either belongs to a cycle, or defines a connection between cycles. 3-kernel programs may have positive conditions. The 3-kernel normal form is very useful for the static analysis of program consistency, i.e., the syntactic characterization of existence of answer sets. This result can be obtained thanks to a novel graph-like representation of programs, called Cycle Graph which presented in the companion article \cite{Cos04b}.
cs.AI:This paper may look like a glossary of the fusion rules and we also introduce new ones presenting their formulas and examples: Conjunctive, Disjunctive, Exclusive Disjunctive, Mixed Conjunctive-Disjunctive rules, Conditional rule, Dempster's, Yager's, Smets' TBM rule, Dubois-Prade's, Dezert-Smarandache classical and hybrid rules, Murphy's average rule, Inagaki-Lefevre-Colot-Vannoorenberghe Unified Combination rules [and, as particular cases: Iganaki's parameterized rule, Weighting Average Operator, minC (M. Daniel), and newly Proportional Conflict Redistribution rules (Smarandache-Dezert) among which PCR5 is the most exact way of redistribution of the conflicting mass to non-empty sets following the path of the conjunctive rule], Zhang's Center Combination rule, Convolutive x-Averaging, Consensus Operator (Josang), Cautious Rule (Smets), ?-junctions rules (Smets), etc. and three new T-norm & T-conorm rules adjusted from fuzzy and neutrosophic sets to information fusion (Tchamova-Smarandache). Introducing the degree of union and degree of inclusion with respect to the cardinal of sets not with the fuzzy set point of view, besides that of intersection, many fusion rules can be improved. There are corner cases where each rule might have difficulties working or may not get an expected result.
cs.AI:There are many examples in the literature that suggest that indistinguishability is intransitive, despite the fact that the indistinguishability relation is typically taken to be an equivalence relation (and thus transitive). It is shown that if the uncertainty perception and the question of when an agent reports that two things are indistinguishable are both carefully modeled, the problems disappear, and indistinguishability can indeed be taken to be an equivalence relation. Moreover, this model also suggests a logic of vagueness that seems to solve many of the problems related to vagueness discussed in the philosophical literature. In particular, it is shown here how the logic can handle the sorites paradox.
cs.AI:A careful analysis of conditioning in the Sleeping Beauty problem is done, using the formal model for reasoning about knowledge and probability developed by Halpern and Tuttle. While the Sleeping Beauty problem has been viewed as revealing problems with conditioning in the presence of imperfect recall, the analysis done here reveals that the problems are not so much due to imperfect recall as to asynchrony. The implications of this analysis for van Fraassen's Reflection Principle and Savage's Sure-Thing Principle are considered.
cs.AI:The paper is an attempt to generalize a methodology, which is similar to the bounded-input bounded-output method currently widely used for the system stability studies. The presented earlier methodology allows decomposition of input space into bounded subspaces and defining for each subspace its bounding surface. It also defines a corresponding predefined control, which maps any point of a bounded input into a desired bounded output subspace. This methodology was improved by providing a mechanism for the fast defining a bounded surface. This paper presents enhanced bounded-input bounded-predefined-control bounded-output approach, which provides adaptability feature to the control and allows transferring of a controlled system along a suboptimal trajectory.
cs.AI:The number of probability distributions required to populate a conditional probability table (CPT) in a Bayesian network, grows exponentially with the number of parent-nodes associated with that table. If the table is to be populated through knowledge elicited from a domain expert then the sheer magnitude of the task forms a considerable cognitive barrier. In this paper we devise an algorithm to populate the CPT while easing the extent of knowledge acquisition. The input to the algorithm consists of a set of weights that quantify the relative strengths of the influences of the parent-nodes on the child-node, and a set of probability distributions the number of which grows only linearly with the number of associated parent-nodes. These are elicited from the domain expert. The set of probabilities are obtained by taking into consideration the heuristics that experts use while arriving at probabilistic estimations. The algorithm is used to populate the CPT by computing appropriate weighted sums of the elicited distributions. We invoke the methods of information geometry to demonstrate how these weighted sums capture the expert's judgemental strategy.
cs.AI:Consider the problem of tracking a set of moving targets. Apart from the tracking result, it is often important to know where the tracking fails, either to steer sensors to that part of the state-space, or to inform a human operator about the status and quality of the obtained information. An intuitive quality measure is the correlation between two tracking results based on uncorrelated observations. In the case of Bayesian trackers such a correlation measure could be the Kullback-Leibler difference.   We focus on a scenario with a large number of military units moving in some terrain. The units are observed by several types of sensors and "meta-sensors" with force aggregation capabilities. The sensors register units of different size. Two separate multi-target probability hypothesis density (PHD) particle filters are used to track some type of units (e.g., companies) and their sub-units (e.g., platoons), respectively, based on observations of units of those sizes. Each observation is used in one filter only.   Although the state-space may well be the same in both filters, the posterior PHD distributions are not directly comparable -- one unit might correspond to three or four spatially distributed sub-units. Therefore, we introduce a mapping function between distributions for different unit size, based on doctrine knowledge of unit configuration.   The mapped distributions can now be compared -- locally or globally -- using some measure, which gives the correlation between two PHD distributions in a bounded volume of the state-space. To locate areas where the tracking fails, a discretized quality map of the state-space can be generated by applying the measure locally to different parts of the space.
cs.AI:We describe the recently introduced extremal optimization algorithm and apply it to target detection and association problems arising in pre-processing for multi-target tracking.   Here we consider the problem of pre-processing for multiple target tracking when the number of sensor reports received is very large and arrives in large bursts. In this case, it is sometimes necessary to pre-process reports before sending them to tracking modules in the fusion system. The pre-processing step associates reports to known tracks (or initializes new tracks for reports on objects that have not been seen before). It could also be used as a pre-process step before clustering, e.g., in order to test how many clusters to use.   The pre-processing is done by solving an approximate version of the original problem. In this approximation, not all pair-wise conflicts are calculated. The approximation relies on knowing how many such pair-wise conflicts that are necessary to compute. To determine this, results on phase-transitions occurring when coloring (or clustering) large random instances of a particular graph ensemble are used.
cs.AI:The management and combination of uncertain, imprecise, fuzzy and even paradoxical or high conflicting sources of information has always been, and still remains today, of primal importance for the development of reliable modern information systems involving artificial reasoning. In this chapter, we present a survey of our recent theory of plausible and paradoxical reasoning, known as Dezert-Smarandache Theory (DSmT) in the literature, developed for dealing with imprecise, uncertain and paradoxical sources of information. We focus our presentation here rather on the foundations of DSmT, and on the two important new rules of combination, than on browsing specific applications of DSmT available in literature. Several simple examples are given throughout the presentation to show the efficiency and the generality of this new approach. The last part of this chapter concerns the presentation of the neutrosophic logic, the neutro-fuzzy inference and its connection with DSmT. Fuzzy logic and neutrosophic logic are useful tools in decision making after fusioning the information using the DSm hybrid rule of combination of masses.
cs.AI:In this paper, we propose a new method based on Hidden Markov Models to interpret temporal sequences of sensor data from mobile robots to automatically detect features. Hidden Markov Models have been used for a long time in pattern recognition, especially in speech recognition. Their main advantages over other methods (such as neural networks) are their ability to model noisy temporal signals of variable length. We show in this paper that this approach is well suited for interpretation of temporal sequences of mobile-robot sensor data. We present two distinct experiments and results: the first one in an indoor environment where a mobile robot learns to detect features like open doors or T-intersections, the second one in an outdoor environment where a different mobile robot has to identify situations like climbing a hill or crossing a rock.
cs.AI:In this paper, we present a rich semantic network based on a differential analysis. We then detail implemented measures that take into account common and differential features between words. In a last section, we describe some industrial applications.
cs.AI:Answer set programming (ASP) with disjunction offers a powerful tool for declaratively representing and solving hard problems. Many NP-complete problems can be encoded in the answer set semantics of logic programs in a very concise and intuitive way, where the encoding reflects the typical "guess and check" nature of NP problems: The property is encoded in a way such that polynomial size certificates for it correspond to stable models of a program. However, the problem-solving capacity of full disjunctive logic programs (DLPs) is beyond NP, and captures a class of problems at the second level of the polynomial hierarchy. While these problems also have a clear "guess and check" structure, finding an encoding in a DLP reflecting this structure may sometimes be a non-obvious task, in particular if the "check" itself is a coNP-complete problem; usually, such problems are solved by interleaving separate guess and check programs, where the check is expressed by inconsistency of the check program. In this paper, we present general transformations of head-cycle free (extended) disjunctive logic programs into stratified and positive (extended) disjunctive logic programs based on meta-interpretation techniques. The answer sets of the original and the transformed program are in simple correspondence, and, moreover, inconsistency of the original program is indicated by a designated answer set of the transformed program. Our transformations facilitate the integration of separate "guess" and "check" programs, which are often easy to obtain, automatically into a single disjunctive logic program. Our results complement recent results on meta-interpretation in ASP, and extend methods and techniques for a declarative "guess and check" problem solving paradigm through ASP.
cs.AI:This paper presents an approach to enhance search engines with information about word senses available in WordNet. The approach exploits information about the conceptual relations within the lexical-semantic net. In the wrapper for search engines presented, WordNet information is used to specify user's request or to classify the results of a publicly available web search engine, like google, yahoo, etc.
cs.AI:This paper reports about experiments with GermaNet as a resource within domain specific document analysis. The main question to be answered is: How is the coverage of GermaNet in a specific domain? We report about results of a field test of GermaNet for analyses of autopsy protocols and present a sketch about the integration of GermaNet inside XDOC. Our remarks will contribute to a GermaNet user's wish list.
cs.AI:The aim of the project presented in this paper is to design a system for an NLG architecture, which supports the documentation process of eBusiness models. A major task is to enrich the formal description of an eBusiness model with additional information needed in an NLG task.
cs.AI:Lexical semantic resources, like WordNet, are often used in real applications of natural language document processing. For example, we integrated GermaNet in our document suite XDOC of processing of German forensic autopsy protocols. In addition to the hypernymy and synonymy relation, we want to adapt GermaNet's verb frames for our analysis. In this paper we outline an approach for the domain related enrichment of GermaNet verb frames by corpus based syntactic and co-occurred data analyses of real documents.
cs.AI:Real applications of natural language document processing are very often confronted with domain specific lexical gaps during the analysis of documents of a new domain. This paper describes an approach for the derivation of domain specific concepts for the extension of an existing ontology. As resources we need an initial ontology and a partially processed corpus of a domain. We exploit the specific characteristic of the sublanguage in the corpus. Our approach is based on syntactical structures (noun phrases) and compound analyses to extract information required for the extension of GermaNet's lexical resources.
cs.AI:We suggest to employ techniques from Natural Language Processing (NLP) and Knowledge Representation (KR) to transform existing documents into documents amenable for the Semantic Web. Semantic Web documents have at least part of their semantics and pragmatics marked up explicitly in both a machine processable as well as human readable manner. XML and its related standards (XSLT, RDF, Topic Maps etc.) are the unifying platform for the tools and methodologies developed for different application scenarios.
cs.AI:This text introduces the twin deadlocks of strong artificial life. Conceptualization of life is a deadlock both because of the existence of a continuum between the inert and the living, and because we only know one instance of life. Computationalism is a second deadlock since it remains a matter of faith. Nevertheless, artificial life realizations quickly progress and recent constructions embed an always growing set of the intuitive properties of life. This growing gap between theory and realizations should sooner or later crystallize in some kind of paradigm shift and then give clues to break the twin deadlocks.
cs.AI:In this chapter we describe new neural-network techniques developed for visual mining clinical electroencephalograms (EEGs), the weak electrical potentials invoked by brain activity. These techniques exploit fruitful ideas of Group Method of Data Handling (GMDH). Section 2 briefly describes the standard neural-network techniques which are able to learn well-suited classification modes from data presented by relevant features. Section 3 introduces an evolving cascade neural network technique which adds new input nodes as well as new neurons to the network while the training error decreases. This algorithm is applied to recognize artifacts in the clinical EEGs. Section 4 presents the GMDH-type polynomial networks learnt from data. We applied this technique to distinguish the EEGs recorded from an Alzheimer and a healthy patient as well as recognize EEG artifacts. Section 5 describes the new neural-network technique developed to induce multi-class concepts from data. We used this technique for inducing a 16-class concept from the large-scale clinical EEG data. Finally we discuss perspectives of applying the neural-network techniques to clinical EEGs.
cs.AI:Bayesian averaging over classification models allows the uncertainty of classification outcomes to be evaluated, which is of crucial importance for making reliable decisions in applications such as financial in which risks have to be estimated. The uncertainty of classification is determined by a trade-off between the amount of data available for training, the diversity of a classifier ensemble and the required performance. The interpretability of classification models can also give useful information for experts responsible for making reliable classifications. For this reason Decision Trees (DTs) seem to be attractive classification models. The required diversity of the DT ensemble can be achieved by using the Bayesian model averaging all possible DTs. In practice, the Bayesian approach can be implemented on the base of a Markov Chain Monte Carlo (MCMC) technique of random sampling from the posterior distribution. For sampling large DTs, the MCMC method is extended by Reversible Jump technique which allows inducing DTs under given priors. For the case when the prior information on the DT size is unavailable, the sweeping technique defining the prior implicitly reveals a better performance. Within this Chapter we explore the classification uncertainty of the Bayesian MCMC techniques on some datasets from the StatLog Repository and real financial data. The classification uncertainty is compared within an Uncertainty Envelope technique dealing with the class posterior distribution and a given confidence probability. This technique provides realistic estimates of the classification uncertainty which can be easily interpreted in statistical terms with the aim of risk evaluation.
cs.AI:Multiple Classifier Systems (MCSs) allow evaluation of the uncertainty of classification outcomes that is of crucial importance for safety critical applications. The uncertainty of classification is determined by a trade-off between the amount of data available for training, the classifier diversity and the required performance. The interpretability of MCSs can also give useful information for experts responsible for making reliable classifications. For this reason Decision Trees (DTs) seem to be attractive classification models for experts. The required diversity of MCSs exploiting such classification models can be achieved by using two techniques, the Bayesian model averaging and the randomised DT ensemble. Both techniques have revealed promising results when applied to real-world problems. In this paper we experimentally compare the classification uncertainty of the Bayesian model averaging with a restarting strategy and the randomised DT ensemble on a synthetic dataset and some domain problems commonly used in the machine learning community. To make the Bayesian DT averaging feasible, we use a Markov Chain Monte Carlo technique. The classification uncertainty is evaluated within an Uncertainty Envelope technique dealing with the class posterior distribution and a given confidence probability. Exploring a full posterior distribution, this technique produces realistic estimates which can be easily interpreted in statistical terms. In our experiments we found out that the Bayesian DTs are superior to the randomised DT ensembles within the Uncertainty Envelope technique.
cs.AI:Artificial intelligence (AI) research has evolved over the last few decades and knowledge acquisition research is at the core of AI research. PKAW-04 is one of three international knowledge acquisition workshops held in the Pacific-Rim, Canada and Europe over the last two decades. PKAW-04 has a strong emphasis on incremental knowledge acquisition, machine learning, neural nets and active mining.   The proceedings contain 19 papers that were selected by the program committee among 24 submitted papers. All papers were peer reviewed by at least two reviewers. The papers in these proceedings cover the methods and tools as well as the applications related to develop expert systems or knowledge based systems.
cs.AI:In the frame of designing a knowledge discovery system, we have developed stochastic models based on high-order hidden Markov models. These models are capable to map sequences of data into a Markov chain in which the transitions between the states depend on the \texttt{n} previous states according to the order of the model. We study the process of achieving information extraction fromspatial and temporal data by means of an unsupervised classification. We use therefore a French national database related to the land use of a region, named Teruti, which describes the land use both in the spatial and temporal domain. Land-use categories (wheat, corn, forest, ...) are logged every year on each site regularly spaced in the region. They constitute a temporal sequence of images in which we look for spatial and temporal dependencies. The temporal segmentation of the data is done by means of a second-order Hidden Markov Model (\hmmd) that appears to have very good capabilities to locate stationary segments, as shown in our previous work in speech recognition. Thespatial classification is performed by defining a fractal scanning ofthe images with the help of a Hilbert-Peano curve that introduces atotal order on the sites, preserving the relation ofneighborhood between the sites. We show that the \hmmd performs aclassification that is meaningful for the agronomists.Spatial and temporal classification may be achieved simultaneously by means of a 2 levels \hmmd that measures the \aposteriori probability to map a temporal sequence of images onto a set of hidden classes.
cs.AI:Our ongoing work aims at defining an ontology-centered approach for building expertise models for the CommonKADS methodology. This approach (which we have named "OntoKADS") is founded on a core problem-solving ontology which distinguishes between two conceptualization levels: at an object level, a set of concepts enable us to define classes of problem-solving situations, and at a meta level, a set of meta-concepts represent modeling primitives. In this article, our presentation of OntoKADS will focus on the core ontology and, in particular, on roles - the primitive situated at the interface between domain knowledge and reasoning, and whose ontological status is still much debated. We first propose a coherent, global, ontological framework which enables us to account for this primitive. We then show how this novel characterization of the primitive allows definition of new rules for the construction of expertise models.
cs.AI:Automatic or assisted workflow composition is a field of intense research for applications to the world wide web or to business process modeling. Workflow composition is traditionally addressed in various ways, generally via theorem proving techniques. Recent research observed that building a composite workflow bears strong relationships with finite model search, and that some workflow languages can be defined as constrained object metamodels . This lead to consider the viability of applying configuration techniques to this problem, which was proven feasible. Constrained based configuration expects a constrained object model as input. The purpose of this document is to formally specify the constrained object model involved in ongoing experiments and research using the Z specification language.
cs.AI:To the reduct problems of decision system, the paper proposes the notion of dynamic core according to the dynamic reduct model. It describes various formal definitions of dynamic core, and discusses some properties about dynamic core. All of these show that dynamic core possesses the essential characters of the feature core.
cs.AI:Correlated time series are time series that, by virtue of the underlying process to which they refer, are expected to influence each other strongly. We introduce a novel approach to handle such time series, one that models their interaction as a two-dimensional cellular automaton and therefore allows them to be treated as a single entity. We apply our approach to the problems of filling gaps and predicting values in rainfall time series. Computational results show that the new approach compares favorably to Kalman smoothing and filtering.
cs.AI:ATNoSFERES is a Pittsburgh style Learning Classifier System (LCS) in which the rules are represented as edges of an Augmented Transition Network. Genotypes are strings of tokens of a stack-based language, whose execution builds the labeled graph. The original ATNoSFERES, using a bitstring to represent the language tokens, has been favorably compared in previous work to several Michigan style LCSs architectures in the context of Non Markov problems. Several modifications of ATNoSFERES are proposed here: the most important one conceptually being a representational change: each token is now represented by an integer, hence the genotype is a string of integers; several other modifications of the underlying grammar language are also proposed. The resulting ATNoSFERES-II is validated on several standard animat Non Markov problems, on which it outperforms all previously published results in the LCS literature. The reasons for these improvement are carefully analyzed, and some assumptions are proposed on the underlying mechanisms in order to explain these good results.
cs.AI:We present a declarative language, PP, for the high-level specification of preferences between possible solutions (or trajectories) of a planning problem. This novel language allows users to elegantly express non-trivial, multi-dimensional preferences and priorities over such preferences. The semantics of PP allows the identification of most preferred trajectories for a given goal. We also provide an answer set programming implementation of planning problems with PP preferences.
cs.AI:Clustering is a widely used technique in data mining applications for discovering patterns in underlying data. Most traditional clustering algorithms are limited to handling datasets that contain either numeric or categorical attributes. However, datasets with mixed types of attributes are common in real life data mining applications. In this paper, we propose a novel divide-and-conquer technique to solve this problem. First, the original mixed dataset is divided into two sub-datasets: the pure categorical dataset and the pure numeric dataset. Next, existing well established clustering algorithms designed for different types of datasets are employed to produce corresponding clusters. Last, the clustering results on the categorical and numeric dataset are combined as a categorical dataset, on which the categorical data clustering algorithm is used to get the final clusters. Our contribution in this paper is to provide an algorithm framework for the mixed attributes clustering problem, in which existing clustering algorithms can be easily integrated, the capabilities of different kinds of clustering algorithms and characteristics of different types of datasets could be fully exploited. Comparisons with other clustering algorithms on real life datasets illustrate the superiority of our approach.
cs.AI:Clustering categorical data is an integral part of data mining and has attracted much attention recently. In this paper, we present k-histogram, a new efficient algorithm for clustering categorical data. The k-histogram algorithm extends the k-means algorithm to categorical domain by replacing the means of clusters with histograms, and dynamically updates histograms in the clustering process. Experimental results on real datasets show that k-histogram algorithm can produce better clustering results than k-modes algorithm, the one related with our work most closely.
cs.AI:This report describes a new version of the OntoSpec methodology for ontology building. Defined by the LaRIA Knowledge Engineering Team (University of Picardie Jules Verne, Amiens, France), OntoSpec aims at helping builders to model ontological knowledge (upstream of formal representation). The methodology relies on a set of rigorously-defined modelling primitives and principles. Its application leads to the elaboration of a semi-informal ontology, which is independent of knowledge representation languages. We recently enriched the OntoSpec methodology by endowing it with a new resource, the DOLCE top-level ontology defined at the LOA (IST-CNR, Trento, Italy). The goal of this integration is to provide modellers with additional help in structuring application ontologies, while maintaining independence vis-\`{a}-vis formal representation languages. In this report, we first provide an overview of the OntoSpec methodology's general principles and then describe the DOLCE re-engineering process. A complete version of DOLCE-OS (i.e. a specification of DOLCE in the semi-informal OntoSpec language) is presented in an appendix.
cs.AI:In this paper we present a new approach for marker less human motion capture from conventional camera feeds. The aim of our study is to recover 3D positions of key points of the body that can serve for gait analysis. Our approach is based on foreground segmentation, an articulated body model and particle filters. In order to be generic and simple no restrictive dynamic modelling was used. A new modified particle filtering algorithm was introduced. It is used efficiently to search the model configuration space. This new algorithm which we call Interval Particle Filtering reorganizes the configurations search space in an optimal deterministic way and proved to be efficient in tracking natural human movement. Results for human motion capture from a single camera are presented and compared to results obtained from a marker based system. The system proved to be able to track motion successfully even in partial occlusions.
cs.AI:The aim of our study is to detect balance disorders and a tendency towards the falls in the elderly, knowing gait parameters. In this paper we present a new tool for gait analysis based on markerless human motion capture, from camera feeds. The system introduced here, recovers the 3D positions of several key points of the human body while walking. Foreground segmentation, an articulated body model and particle filtering are basic elements of our approach. No dynamic model is used thus this system can be described as generic and simple to implement. A modified particle filtering algorithm, which we call Interval Particle Filtering, is used to reorganise and search through the model's configurations search space in a deterministic optimal way. This algorithm was able to perform human movement tracking with success. Results from the treatment of a single cam feeds are shown and compared to results obtained using a marker based human motion capture system.
cs.AI:An agent often has a number of hypotheses, and must choose among them based on observations, or outcomes of experiments. Each of these observations can be viewed as providing evidence for or against various hypotheses. All the attempts to formalize this intuition up to now have assumed that associated with each hypothesis h there is a likelihood function \mu_h, which is a probability measure that intuitively describes how likely each observation is, conditional on h being the correct hypothesis. We consider an extension of this framework where there is uncertainty as to which of a number of likelihood functions is appropriate, and discuss how one formal approach to defining evidence, which views evidence as a function from priors to posteriors, can be generalized to accommodate this uncertainty.
cs.AI:Being able to analyze and interpret signal coming from electroencephalogram (EEG) recording can be of high interest for many applications including medical diagnosis and Brain-Computer Interfaces. Indeed, human experts are today able to extract from this signal many hints related to physiological as well as cognitive states of the recorded subject and it would be very interesting to perform such task automatically but today no completely automatic system exists. In previous studies, we have compared human expertise and automatic processing tools, including artificial neural networks (ANN), to better understand the competences of each and determine which are the difficult aspects to integrate in a fully automatic system. In this paper, we bring more elements to that study in reporting the main results of a practical experiment which was carried out in an hospital for sleep pathology study. An EEG recording was studied and labeled by a human expert and an ANN. We describe here the characteristics of the experiment, both human and neuronal procedure of analysis, compare their performances and point out the main limitations which arise from this study.
cs.AI:Train timetabling is a difficult and very tightly constrained combinatorial problem that deals with the construction of train schedules. We focus on the particular problem of local reconstruction of the schedule following a small perturbation, seeking minimisation of the total accumulated delay by adapting times of departure and arrival for each train and allocation of resources (tracks, routing nodes, etc.). We describe a permutation-based evolutionary algorithm that relies on a semi-greedy heuristic to gradually reconstruct the schedule by inserting trains one after the other following the permutation. This algorithm can be hybridised with ILOG commercial MIP programming tool CPLEX in a coarse-grained manner: the evolutionary part is used to quickly obtain a good but suboptimal solution and this intermediate solution is refined using CPLEX. Experimental results are presented on a large real-world case involving more than one million variables and 2 million constraints. Results are surprisingly good as the evolutionary algorithm, alone or hybridised, produces excellent solutions much faster than CPLEX alone.
cs.AI:Evolutionary computing (EC) is an exciting development in Computer Science. It amounts to building, applying and studying algorithms based on the Darwinian principles of natural selection. In this paper we briefly introduce the main concepts behind evolutionary computing. We present the main components all evolutionary algorithms (EA), sketch the differences between different types of EAs and survey application areas ranging from optimization, modeling and simulation to entertainment.
cs.AI:This article is taken out.
cs.AI:A fuzzy controller is usually designed by formulating the knowledge of a human expert into a set of linguistic variables and fuzzy rules. Among the most successful methods to automate the fuzzy controllers development process are evolutionary algorithms. In this work, we propose the Recurrent Fuzzy Voronoi (RFV) model, a representation for recurrent fuzzy systems. It is an extension of the FV model proposed by Kavka and Schoenauer that extends the application domain to include temporal problems. The FV model is a representation for fuzzy controllers based on Voronoi diagrams that can represent fuzzy systems with synergistic rules, fulfilling the $\epsilon$-completeness property and providing a simple way to introduce a priory knowledge. In the proposed representation, the temporal relations are embedded by including internal units that provide feedback by connecting outputs to inputs. These internal units act as memory elements. In the RFV model, the semantic of the internal units can be specified together with the a priori rules. The geometric interpretation of the rules allows the use of geometric variational operators during the evolution. The representation and the algorithms are validated in two problems in the area of system identification and evolutionary robotics.
cs.AI:When solving numerical constraints such as nonlinear equations and inequalities, solvers often exploit pruning techniques, which remove redundant value combinations from the domains of variables, at pruning steps. To find the complete solution set, most of these solvers alternate the pruning steps with branching steps, which split each problem into subproblems. This forms the so-called branch-and-prune framework, well known among the approaches for solving numerical constraints. The basic branch-and-prune search strategy that uses domain bisections in place of the branching steps is called the bisection search. In general, the bisection search works well in case (i) the solutions are isolated, but it can be improved further in case (ii) there are continuums of solutions (this often occurs when inequalities are involved). In this paper, we propose a new branch-and-prune search strategy along with several variants, which not only allow yielding better branching decisions in the latter case, but also work as well as the bisection search does in the former case. These new search algorithms enable us to employ various pruning techniques in the construction of inner and outer approximations of the solution set. Our experiments show that these algorithms speed up the solving process often by one order of magnitude or more when solving problems with continuums of solutions, while keeping the same performance as the bisection search when the solutions are isolated.
cs.AI:IS success is a complex concept, and its evaluation is complicated, unstructured and not readily quantifiable. Numerous scientific publications address the issue of success in the IS field as well as in other fields. But, little efforts have been done for processing indeterminacy and uncertainty in success research. This paper shows a formal method for mapping success using Neutrosophic Success Map. This is an emerging tool for processing indeterminacy and uncertainty in success research. EIS success have been analyzed using this tool.
cs.AI:In this paper, a mathematical schema theory is developed. This theory has three roots: brain theory schemas, grid automata, and block-shemas. In Section 2 of this paper, elements of the theory of grid automata necessary for the mathematical schema theory are presented. In Section 3, elements of brain theory necessary for the mathematical schema theory are presented. In Section 4, other types of schemas are considered. In Section 5, the mathematical schema theory is developed. The achieved level of schema representation allows one to model by mathematical tools virtually any type of schemas considered before, including schemas in neurophisiology, psychology, computer science, Internet technology, databases, logic, and mathematics.
cs.AI:Data-based classification is fundamental to most branches of science. While recent years have brought enormous progress in various areas of statistical computing and clustering, some general challenges in clustering remain: model selection, robustness, and scalability to large datasets. We consider the important problem of deciding on the optimal number of clusters, given an arbitrary definition of space and clusteriness. We show how to construct a cluster information criterion that allows objective model selection. Differing from other approaches, our truecluster method does not require specific assumptions about underlying distributions, dissimilarity definitions or cluster models. Truecluster puts arbitrary clustering algorithms into a generic unified (sampling-based) statistical framework. It is scalable to big datasets and provides robust cluster assignments and case-wise diagnostics. Truecluster will make clustering more objective, allows for automation, and will save time and costs. Free R software is available.
cs.AI:An original approach, termed Divide-and-Evolve is proposed to hybridize Evolutionary Algorithms (EAs) with Operational Research (OR) methods in the domain of Temporal Planning Problems (TPPs). Whereas standard Memetic Algorithms use local search methods to improve the evolutionary solutions, and thus fail when the local method stops working on the complete problem, the Divide-and-Evolve approach splits the problem at hand into several, hopefully easier, sub-problems, and can thus solve globally problems that are intractable when directly fed into deterministic OR algorithms. But the most prominent advantage of the Divide-and-Evolve approach is that it immediately opens up an avenue for multi-objective optimization, even though the OR method that is used is single-objective. Proof of concept approach on the standard (single-objective) Zeno transportation benchmark is given, and a small original multi-objective benchmark is proposed in the same Zeno framework to assess the multi-objective capabilities of the proposed methodology, a breakthrough in Temporal Planning.
cs.AI:This article considers evidence from physical and biological sciences to show machines are deficient compared to biological systems at incorporating intelligence. Machines fall short on two counts: firstly, unlike brains, machines do not self-organize in a recursive manner; secondly, machines are based on classical logic, whereas Nature's intelligence may depend on quantum mechanics.
cs.AI:Constraint Programming (CP) has proved an effective paradigm to model and solve difficult combinatorial satisfaction and optimisation problems from disparate domains. Many such problems arising from the commercial world are permeated by data uncertainty. Existing CP approaches that accommodate uncertainty are less suited to uncertainty arising due to incomplete and erroneous data, because they do not build reliable models and solutions guaranteed to address the user's genuine problem as she perceives it. Other fields such as reliable computation offer combinations of models and associated methods to handle these types of uncertain data, but lack an expressive framework characterising the resolution methodology independently of the model.   We present a unifying framework that extends the CP formalism in both model and solutions, to tackle ill-defined combinatorial problems with incomplete or erroneous data. The certainty closure framework brings together modelling and solving methodologies from different fields into the CP paradigm to provide reliable and efficient approches for uncertain constraint problems. We demonstrate the applicability of the framework on a case study in network diagnosis. We define resolution forms that give generic templates, and their associated operational semantics, to derive practical solution methods for reliable solutions.
cs.AI:The application of Genetic Programming to the discovery of empirical laws is often impaired by the huge size of the search space, and consequently by the computer resources needed. In many cases, the extreme demand for memory and CPU is due to the massive growth of non-coding segments, the introns. The paper presents a new program evolution framework which combines distribution-based evolution in the PBIL spirit, with grammar-based genetic programming; the information is stored as a probability distribution on the gra mmar rules, rather than in a population. Experiments on a real-world like problem show that this approach gives a practical solution to the problem of intron growth.
cs.AI:This paper deals with the problem of classifying signals. The new method for building so called local classifiers and local features is presented. The method is a combination of the lifting scheme and the support vector machines. Its main aim is to produce effective and yet comprehensible classifiers that would help in understanding processes hidden behind classified signals. To illustrate the method we present the results obtained on an artificial and a real dataset.
cs.AI:Open answer set programming (OASP) is an extension of answer set programming where one may ground a program with an arbitrary superset of the program's constants. We define a fixed point logic (FPL) extension of Clark's completion such that open answer sets correspond to models of FPL formulas and identify a syntactic subclass of programs, called (loosely) guarded programs. Whereas reasoning with general programs in OASP is undecidable, the FPL translation of (loosely) guarded programs falls in the decidable (loosely) guarded fixed point logic (mu(L)GF). Moreover, we reduce normal closed ASP to loosely guarded OASP, enabling for the first time, a characterization of an answer set semantics by muLGF formulas. We further extend the open answer set semantics for programs with generalized literals. Such generalized programs (gPs) have interesting properties, e.g., the ability to express infinity axioms. We restrict the syntax of gPs such that both rules and generalized literals are guarded. Via a translation to guarded fixed point logic, we deduce 2-exptime-completeness of satisfiability checking in such guarded gPs (GgPs). Bound GgPs are restricted GgPs with exptime-complete satisfiability checking, but still sufficiently expressive to optimally simulate computation tree logic (CTL). We translate Datalog lite programs to GgPs, establishing equivalence of GgPs under an open answer set semantics, alternation-free muGF, and Datalog lite.
cs.AI:Consistency check has been the only criterion for theory evaluation in logic-based approaches to reasoning about actions. This work goes beyond that and contributes to the metatheory of actions by investigating what other properties a good domain description in reasoning about actions should have. We state some metatheoretical postulates concerning this sore spot. When all postulates are satisfied together we have a modular action theory. Besides being easier to understand and more elaboration tolerant in McCarthy's sense, modular theories have interesting properties. We point out the problems that arise when the postulates about modularity are violated and propose algorithmic checks that can help the designer of an action theory to overcome them.
cs.AI:The estimation of linear causal models (also known as structural equation models) from data is a well-known problem which has received much attention in the past. Most previous work has, however, made an explicit or implicit assumption of gaussianity, limiting the identifiability of the models. We have recently shown (Shimizu et al, 2005; Hoyer et al, 2006) that for non-gaussian distributions the full causal model can be estimated in the no hidden variables case. In this contribution, we discuss the estimation of the model when confounding latent variables are present. Although in this case uniqueness is no longer guaranteed, there is at most a finite set of models which can fit the data. We develop an algorithm for estimating this set, and describe numerical simulations which confirm the theoretical arguments and demonstrate the practical viability of the approach. Full Matlab code is provided for all simulations.
cs.AI:Shock physics experiments are often complicated and expensive. As a result, researchers are unable to conduct as many experiments as they would like - leading to sparse data sets. In this paper, Support Vector Machines for regression are applied to velocimetry data sets for shock damaged and melted tin metal. Some success at interpolating between data sets is achieved. Implications for future work are discussed.
cs.AI:In this paper, we study clustering with respect to the k-modes objective function, a natural formulation of clustering for categorical data. One of the main contributions of this paper is to establish the connection between k-modes and k-median, i.e., the optimum of k-median is at most twice the optimum of k-modes for the same categorical data clustering problem. Based on this observation, we derive a deterministic algorithm that achieves an approximation factor of 2. Furthermore, we prove that the distance measure in k-modes defines a metric. Hence, we are able to extend existing approximation algorithms for metric k-median to k-modes. Empirical results verify the superiority of our method.
cs.AI:A model of an organism as an autonomous intelligent system has been proposed. This model was used to analyze learning of an organism in various environmental conditions. Processes of learning were divided into two types: strong and weak processes taking place in the absence and the presence of aprioristic information about an object respectively. Weak learning is synonymous to adaptation when aprioristic programs already available in a system (an organism) are started. It was shown that strong learning is impossible for both an organism and any autonomous intelligent system. It was shown also that the knowledge base of an organism cannot be updated. Therefore, all behavior programs of an organism are congenital. A model of a conditioned reflex as a series of consecutive measurements of environmental parameters has been advanced. Repeated measurements are necessary in this case to reduce the error during decision making.
cs.AI:This paper presents two new promising rules of combination for the fusion of uncertain and potentially highly conflicting sources of evidences in the framework of the theory of belief functions in order to palliate the well-know limitations of Dempster's rule and to work beyond the limits of applicability of the Dempster-Shafer theory. We present both a new class of adaptive combination rules (ACR) and a new efficient Proportional Conflict Redistribution (PCR) rule allowing to deal with highly conflicting sources for static and dynamic fusion applications.
cs.AI:Fuzzy automata, whose input alphabet is a set of numbers or symbols, are a formal model of computing with values. Motivated by Zadeh's paradigm of computing with words rather than numbers, Ying proposed a kind of fuzzy automata, whose input alphabet consists of all fuzzy subsets of a set of symbols, as a formal model of computing with all words. In this paper, we introduce a somewhat general formal model of computing with (some special) words. The new features of the model are that the input alphabet only comprises some (not necessarily all) fuzzy subsets of a set of symbols and the fuzzy transition function can be specified arbitrarily. By employing the methodology of fuzzy control, we establish a retraction principle from computing with words to computing with values for handling crisp inputs and a generalized extension principle from computing with words to computing with all words for handling fuzzy inputs. These principles show that computing with values and computing with all words can be respectively implemented by computing with words. Some algebraic properties of retractions and generalized extensions are addressed as well.
cs.AI:Through the Internet and the World-Wide Web, a vast number of information sources has become available, which offer information on various subjects by different providers, often in heterogeneous formats. This calls for tools and methods for building an advanced information-processing infrastructure. One issue in this area is the selection of suitable information sources in query answering. In this paper, we present a knowledge-based approach to this problem, in the setting where one among a set of information sources (prototypically, data repositories) should be selected for evaluating a user query. We use extended logic programs (ELPs) to represent rich descriptions of the information sources, an underlying domain theory, and user queries in a formal query language (here, XML-QL, but other languages can be handled as well). Moreover, we use ELPs for declarative query analysis and generation of a query description. Central to our approach are declarative source-selection programs, for which we define syntax and semantics. Due to the structured nature of the considered data items, the semantics of such programs must carefully respect implicit context information in source-selection rules, and furthermore combine it with possible user preferences. A prototype implementation of our approach has been realized exploiting the DLV KR system and its plp front-end for prioritized ELPs. We describe a representative example involving specific movie databases, and report about experimental results.
cs.AI:It is well known that perspective alignment plays a major role in the planning and interpretation of spatial language. In order to understand the role of perspective alignment and the cognitive processes involved, we have made precise complete cognitive models of situated embodied agents that self-organise a communication system for dialoging about the position and movement of real world objects in their immediate surroundings. We show in a series of robotic experiments which cognitive mechanisms are necessary and sufficient to achieve successful spatial language and why and how perspective alignment can take place, either implicitly or based on explicit marking.
cs.AI:We extend the 0-approximation of sensing actions and incomplete information in [Son and Baral 2000] to action theories with static causal laws and prove its soundness with respect to the possible world semantics. We also show that the conditional planning problem with respect to this approximation is NP-complete. We then present an answer set programming based conditional planner, called ASCP, that is capable of generating both conformant plans and conditional plans in the presence of sensing actions, incomplete information about the initial state, and static causal laws. We prove the correctness of our implementation and argue that our planner is sound and complete with respect to the proposed approximation. Finally, we present experimental results comparing ASCP to other planners.
cs.AI:Computing and storing probabilities is a hard problem as soon as one has to deal with complex distributions over multiple random variables. The problem of efficient representation of probability distributions is central in term of computational efficiency in the field of probabilistic reasoning. The main problem arises when dealing with joint probability distributions over a set of random variables: they are always represented using huge probability arrays. In this paper, a new method based on binary-tree representation is introduced in order to store efficiently very large joint distributions. Our approach approximates any multidimensional joint distributions using an adaptive discretization of the space. We make the assumption that the lower is the probability mass of a particular region of feature space, the larger is the discretization step. This assumption leads to a very optimized representation in term of time and memory. The other advantages of our approach are the ability to refine dynamically the distribution every time it is needed leading to a more accurate representation of the probability distribution and to an anytime representation of the distribution.
cs.AI:In order to more effectively cope with the real-world problems of vagueness, {\it fuzzy discrete event systems} (FDESs) were proposed recently, and the supervisory control theory of FDESs was developed. In view of the importance of failure diagnosis, in this paper, we present an approach of the failure diagnosis in the framework of FDESs. More specifically: (1) We formalize the definition of diagnosability for FDESs, in which the observable set and failure set of events are {\it fuzzy}, that is, each event has certain degree to be observable and unobservable, and, also, each event may possess different possibility of failure occurring. (2) Through the construction of observability-based diagnosers of FDESs, we investigate its some basic properties. In particular, we present a necessary and sufficient condition for diagnosability of FDESs. (3) Some examples serving to illuminate the applications of the diagnosability of FDESs are described. To conclude, some related issues are raised for further consideration.
cs.AI:Classification of ordinal data is one of the most important tasks of relation learning. In this thesis a novel framework for ordered classes is proposed. The technique reduces the problem of classifying ordered classes to the standard two-class problem. The introduced method is then mapped into support vector machines and neural networks. Compared with a well-known approach using pairwise objects as training samples, the new algorithm has a reduced complexity and training time. A second novel model, the unimodal model, is also introduced and a parametric version is mapped into neural networks. Several case studies are presented to assert the validity of the proposed models.
cs.AI:Imagination is the critical point in developing of realistic artificial intelligence (AI) systems. One way to approach imagination would be simulation of its properties and operations. We developed two models: AI-Brain Network Hierarchy of Languages and Semantical Holographic Calculus as well as simulation system ScriptWriter that emulate the process of imagination through an automatic animation of English texts. The purpose of this paper is to demonstrate the model and to present ScriptWriter system http://nvo.sdsc.edu/NVO/JCSG/get_SRB_mime_file2.cgi//home/tamara.sdsc/test/demo.zip?F=/home/tamara.sdsc/test/demo.zip&M=application/x-gtar for simulation of the imagination.
cs.AI:In Dempster-Shafer belief theory, general beliefs are expressed as belief mass distribution functions over frames of discernment. In Subjective Logic beliefs are expressed as belief mass distribution functions over binary frames of discernment. Belief representations in Subjective Logic, which are called opinions, also contain a base rate parameter which express the a priori belief in the absence of evidence. Philosophically, beliefs are quantitative representations of evidence as perceived by humans or by other intelligent agents. The basic operators of classical probability calculus, such as addition and multiplication, can be applied to opinions, thereby making belief calculus practical. Through the equivalence between opinions and Beta probability density functions, this also provides a calculus for Beta probability density functions. This article explains the basic elements of belief calculus.
cs.AI:The problem of combining beliefs in the Dempster-Shafer belief theory has attracted considerable attention over the last two decades. The classical Dempster's Rule has often been criticised, and many alternative rules for belief combination have been proposed in the literature. The consensus operator for combining beliefs has nice properties and produces more intuitive results than Dempster's rule, but has the limitation that it can only be applied to belief distribution functions on binary state spaces. In this paper we present a generalisation of the consensus operator that can be applied to Dirichlet belief functions on state spaces of arbitrary size. This rule, called the cumulative rule of belief combination, can be derived from classical statistical theory, and corresponds well with human intuition.
cs.AI:Artificial Intelligence (AI) has recently become a real formal science: the new millennium brought the first mathematically sound, asymptotically optimal, universal problem solvers, providing a new, rigorous foundation for the previously largely heuristic field of General AI and embedded agents. At the same time there has been rapid progress in practical methods for learning true sequence-processing programs, as opposed to traditional methods limited to stationary pattern association. Here we will briefly review some of the new results, and speculate about future developments, pointing out that the time intervals between the most notable events in over 40,000 years or 2^9 lifetimes of human history have sped up exponentially, apparently converging to zero within the next few decades. Or is this impression just a by-product of the way humans allocate memory space to past events?
cs.AI:In this paper we propose a new family of Belief Conditioning Rules (BCRs) for belief revision. These rules are not directly related with the fusion of several sources of evidence but with the revision of a belief assignment available at a given time according to the new truth (i.e. conditioning constraint) one has about the space of solutions of the problem.
cs.AI:In this note we introduce the notion of islands for restricting local search. We show how we can construct islands for CNF SAT problems, and how much search space can be eliminated by restricting search to the island.
cs.AI:Knowing the norms of a domain is crucial, but there exist no repository of norms. We propose a method to extract them from texts: texts generally do not describe a norm, but rather how a state-of-affairs differs from it. Answers concerning the cause of the state-of-affairs described often reveal the implicit norm. We apply this idea to the domain of driving, and validate it by designing algorithms that identify, in a text, the "basic" norms to which it refers implicitly.
cs.AI:Norms are essential to extend inference: inferences based on norms are far richer than those based on logical implications. In the recent decades, much effort has been devoted to reason on a domain, once its norms are represented. How to extract and express those norms has received far less attention. Extraction is difficult: as the readers are supposed to know them, the norms of a domain are seldom made explicit. For one thing, extracting norms requires a language to represent them, and this is the topic of this paper. We apply this language to represent norms in the domain of driving, and show that it is adequate to reason on the causes of accidents, as described by car-crash reports.
cs.AI:In this paper we consider and analyze the behavior of two combinational rules for temporal (sequential) attribute data fusion for target type estimation. Our comparative analysis is based on Dempster's fusion rule proposed in Dempster-Shafer Theory (DST) and on the Proportional Conflict Redistribution rule no. 5 (PCR5) recently proposed in Dezert-Smarandache Theory (DSmT). We show through very simple scenario and Monte-Carlo simulation, how PCR5 allows a very efficient Target Type Tracking and reduces drastically the latency delay for correct Target Type decision with respect to Demspter's rule. For cases presenting some short Target Type switches, Demspter's rule is proved to be unable to detect the switches and thus to track correctly the Target Type changes. The approach proposed here is totally new, efficient and promising to be incorporated in real-time Generalized Data Association - Multi Target Tracking systems (GDA-MTT) and provides an important result on the behavior of PCR5 with respect to Dempster's rule. The MatLab source code is provided in
cs.AI:This paper introduces the notion of qualitative belief assignment to model beliefs of human experts expressed in natural language (with linguistic labels). We show how qualitative beliefs can be efficiently combined using an extension of Dezert-Smarandache Theory (DSmT) of plausible and paradoxical quantitative reasoning to qualitative reasoning. We propose a new arithmetic on linguistic labels which allows a direct extension of classical DSm fusion rule or DSm Hybrid rules. An approximate qualitative PCR5 rule is also proposed jointly with a Qualitative Average Operator. We also show how crisp or interval mappings can be used to deal indirectly with linguistic labels. A very simple example is provided to illustrate our qualitative fusion rules.
cs.AI:The management and combination of uncertain, imprecise, fuzzy and even paradoxical or high conflicting sources of information has always been, and still remains today, of primal importance for the development of reliable modern information systems involving artificial reasoning. In this introduction, we present a survey of our recent theory of plausible and paradoxical reasoning, known as Dezert-Smarandache Theory (DSmT) in the literature, developed for dealing with imprecise, uncertain and paradoxical sources of information. We focus our presentation here rather on the foundations of DSmT, and on the two important new rules of combination, than on browsing specific applications of DSmT available in literature. Several simple examples are given throughout the presentation to show the efficiency and the generality of this new approach.
cs.AI:We study an alternative to the prevailing approach to modelling qualitative spatial reasoning (QSR) problems as constraint satisfaction problems. In the standard approach, a relation between objects is a constraint whereas in the alternative approach it is a variable. The relation-variable approach greatly simplifies integration and implementation of QSR. To substantiate this point, we discuss several QSR algorithms from the literature which in the relation-variable approach reduce to the customary constraint propagation algorithm enforcing generalised arc-consistency.
cs.AI:I explore the use of sets of probability measures as a representation of uncertainty.
cs.AI:We present a state-based regression function for planning domains where an agent does not have complete information and may have sensing actions. We consider binary domains and employ a three-valued characterization of domains with sensing actions to define the regression function. We prove the soundness and completeness of our regression formulation with respect to the definition of progression. More specifically, we show that (i) a plan obtained through regression for a planning problem is indeed a progression solution of that planning problem, and that (ii) for each plan found through progression, using regression one obtains that plan or an equivalent one.
cs.AI:A modification of OWL-S regarding parameter description is proposed. It is strictly based on Description Logic. In addition to class description of parameters it also allows the modelling of relations between parameters and the precise description of the size of data to be supplied to a service. In particular, it solves two major issues identified within current proposals for a Semantic Web Service annotation standard.
cs.AI:The paper describes the ALVIS annotation format designed for the indexing of large collections of documents in topic-specific search engines. This paper is exemplified on the biological domain and on MedLine abstracts, as developing a specialized search engine for biologists is one of the ALVIS case studies. The ALVIS principle for linguistic annotations is based on existing works and standard propositions. We made the choice of stand-off annotations rather than inserted mark-up. Annotations are encoded as XML elements which form the linguistic subsection of the document record.
cs.AI:The aim of this paper is to provide a sound framework for addressing a difficult problem: the automatic construction of an autonomous agent's modular architecture. We combine results from two apparently uncorrelated domains: Autonomous planning through Markov Decision Processes and a General Data Clustering Approach using a kernel-like method. Our fundamental idea is that the former is a good framework for addressing autonomy whereas the latter allows to tackle self-organizing problems.
cs.AI:In this paper we elaborate on a specific application in the context of hybrid description logic programs (hybrid DLPs), namely description logic Semantic Web type systems (DL-types) which are used for term typing of LP rules based on a polymorphic, order-sorted, hybrid DL-typed unification as procedural semantics of hybrid DLPs. Using Semantic Web ontologies as type systems facilitates interchange of domain-independent rules over domain boundaries via dynamically typing and mapping of explicitly defined type ontologies.
cs.AI:In this paper we describe an architecture of a system that answer the question : Why did the accident happen? from the textual description of an accident. We present briefly the different parts of the architecture and then we describe with more detail the semantic part of the system i.e. the part in which the norm-based reasoning is performed on the explicit knowlege extracted from the text.
cs.AI:We develop a system which must be able to perform the same inferences that a human reader of an accident report can do and more particularly to determine the apparent causes of the accident. We describe the general framework in which we are situated, linguistic and semantic levels of the analysis and the inference rules used by the system.
cs.AI:The k-modes algorithm has become a popular technique in solving categorical data clustering problems in different application domains. However, the algorithm requires random selection of initial points for the clusters. Different initial points often lead to considerable distinct clustering results. In this paper we present an experimental study on applying a farthest-point heuristic based initialization method to k-modes clustering to improve its performance. Experiments show that new initialization method leads to better clustering accuracy than random selection initialization method for k-modes clustering.
cs.AI:The opening book is an important component of a chess engine, and thus computer chess programmers have been developing automated methods to improve the quality of their books. For chess, which has a very rich opening theory, large databases of high-quality games can be used as the basis of an opening book, from which statistics relating to move choices from given positions can be collected. In order to find out whether the opening books used by modern chess engines in machine versus machine competitions are ``comparable'' to those used by chess players in human versus human competitions, we carried out analysis on 26 test positions using statistics from two opening books one compiled from humans' games and the other from machines' games. Our analysis using several nonparametric measures, shows that, overall, there is a strong association between humans' and machines' choices of opening moves when using a book to guide their choices.
cs.AI:We present a new local approximation algorithm for computing Maximum a Posteriori (MAP) and log-partition function for arbitrary exponential family distribution represented by a finite-valued pair-wise Markov random field (MRF), say $G$. Our algorithm is based on decomposition of $G$ into {\em appropriately} chosen small components; then computing estimates locally in each of these components and then producing a {\em good} global solution. We show that if the underlying graph $G$ either excludes some finite-sized graph as its minor (e.g. Planar graph) or has low doubling dimension (e.g. any graph with {\em geometry}), then our algorithm will produce solution for both questions within {\em arbitrary accuracy}. We present a message-passing implementation of our algorithm for MAP computation using self-avoiding walk of graph. In order to evaluate the computational cost of this implementation, we derive novel tight bounds on the size of self-avoiding walk tree for arbitrary graph.   As a consequence of our algorithmic result, we show that the normalized log-partition function (also known as free-energy) for a class of {\em regular} MRFs will converge to a limit, that is computable to an arbitrary accuracy.
cs.AI:Creation procedure of associative patterns ensemble in terms of formal logic with using neural net-work (NN) model is formulated. It is shown that the associative patterns set is created by means of unique procedure of NN work which having individual parameters of entrance stimulus transformation. It is ascer-tained that the quantity of the selected associative patterns possesses is a constant.
cs.AI:In case-based reasoning, the adaptation step depends in general on domain-dependent knowledge, which motivates studies on adaptation knowledge acquisition (AKA). CABAMAKA is an AKA system based on principles of knowledge discovery from databases. This system explores the variations within the case base to elicit adaptation knowledge. It has been successfully tested in an application of case-based decision support to breast cancer treatment.
cs.AI:Recently, the diagnosability of {\it stochastic discrete event systems} (SDESs) was investigated in the literature, and, the failure diagnosis considered was {\it centralized}. In this paper, we propose an approach to {\it decentralized} failure diagnosis of SDESs, where the stochastic system uses multiple local diagnosers to detect failures and each local diagnoser possesses its own information. In a way, the centralized failure diagnosis of SDESs can be viewed as a special case of the decentralized failure diagnosis presented in this paper with only one projection. The main contributions are as follows: (1) We formalize the notion of codiagnosability for stochastic automata, which means that a failure can be detected by at least one local stochastic diagnoser within a finite delay. (2) We construct a codiagnoser from a given stochastic automaton with multiple projections, and the codiagnoser associated with the local diagnosers is used to test codiagnosability condition of SDESs. (3) We deal with a number of basic properties of the codiagnoser. In particular, a necessary and sufficient condition for the codiagnosability of SDESs is presented. (4) We give a computing method in detail to check whether codiagnosability is violated. And (5) some examples are described to illustrate the applications of the codiagnosability and its computing method.
cs.AI:The management and combination of uncertain, imprecise, fuzzy and even paradoxical or high conflicting sources of information has always been and still remains of primal importance for the development of reliable information fusion systems. In this short survey paper, we present the theory of plausible and paradoxical reasoning, known as DSmT (Dezert-Smarandache Theory) in literature, developed for dealing with imprecise, uncertain and potentially highly conflicting sources of information. DSmT is a new paradigm shift for information fusion and recent publications have shown the interest and the potential ability of DSmT to solve fusion problems where Dempster's rule used in Dempster-Shafer Theory (DST) provides counter-intuitive results or fails to provide useful result at all. This paper is focused on the foundations of DSmT and on its main rules of combination (classic, hybrid and Proportional Conflict Redistribution rules). Shafer's model on which is based DST appears as a particular and specific case of DSm hybrid model which can be easily handled by DSmT as well. Several simple but illustrative examples are given throughout this paper to show the interest and the generality of this new theory.
cs.AI:Reaction RuleML is a general, practical, compact and user-friendly XML-serialized language for the family of reaction rules. In this white paper we give a review of the history of event / action /state processing and reaction rule approaches and systems in different domains, define basic concepts and give a classification of the event, action, state processing and reasoning space as well as a discussion of relevant / related work
cs.AI:A fuzzy logic based classification engine has been developed for classifying mass spectra obtained with an imaging internal source Fourier transform mass spectrometer (I^2LD-FTMS). Traditionally, an operator uses the relative abundance of ions with specific mass-to-charge (m/z) ratios to categorize spectra. An operator does this by comparing the spectrum of m/z versus abundance of an unknown sample against a library of spectra from known samples. Automated positioning and acquisition allow I^2LD-FTMS to acquire data from very large grids, this would require classification of up to 3600 spectrum per hour to keep pace with the acquisition. The tedious job of classifying numerous spectra generated in an I^2LD-FTMS imaging application can be replaced by a fuzzy rule base if the cues an operator uses can be encapsulated. We present the translation of linguistic rules to a fuzzy classifier for mineral phases in basalt. This paper also describes a method for gathering statistics on ions, which are not currently used in the rule base, but which may be candidates for making the rule base more accurate and complete or to form new rule bases based on data obtained from known samples. A spatial method for classifying spectra with low membership values, based on neighboring sample classifications, is also presented.
cs.AI:Description Logics (DLs) are appropriate, widely used, logics for managing structured knowledge. They allow reasoning about individuals and concepts, i.e. set of individuals with common properties. Typically, DLs are limited to dealing with crisp, well defined concepts. That is, concepts for which the problem whether an individual is an instance of it is yes/no question. More often than not, the concepts encountered in the real world do not have a precisely defined criteria of membership: we may say that an individual is an instance of a concept only to a certain degree, depending on the individual's properties. The DLs that deal with such fuzzy concepts are called fuzzy DLs. In order to deal with fuzzy, incomplete, indeterminate and inconsistent concepts, we need to extend the fuzzy DLs, combining the neutrosophic logic with a classical DL. In particular, concepts become neutrosophic (here neutrosophic means fuzzy, incomplete, indeterminate, and inconsistent), thus reasoning about neutrosophic concepts is supported. We'll define its syntax, its semantics, and describe its properties.
cs.AI:Support Vector Machines (SVMs) are well-established Machine Learning (ML) algorithms. They rely on the fact that i) linear learning can be formalized as a well-posed optimization problem; ii) non-linear learning can be brought into linear learning thanks to the kernel trick and the mapping of the initial search space onto a high dimensional feature space. The kernel is designed by the ML expert and it governs the efficiency of the SVM approach. In this paper, a new approach for the automatic design of kernels by Genetic Programming, called the Evolutionary Kernel Machine (EKM), is presented. EKM combines a well-founded fitness function inspired from the margin criterion, and a co-evolution framework ensuring the computational scalability of the approach. Empirical validation on standard ML benchmark demonstrates that EKM is competitive using state-of-the-art SVMs with tuned hyper-parameters.
cs.AI:Functional brain imaging is a source of spatio-temporal data mining problems. A new framework hybridizing multi-objective and multi-modal optimization is proposed to formalize these data mining problems, and addressed through Evolutionary Computation (EC). The merits of EC for spatio-temporal data mining are demonstrated as the approach facilitates the modelling of the experts' requirements, and flexibly accommodates their changing goals.
cs.AI:The paper suggests the use of Multi-Valued Decision Diagrams (MDDs) as the supporting data structure for a generic global constraint. We give an algorithm for maintaining generalized arc consistency (GAC) on this constraint that amortizes the cost of the GAC computation over a root-to-terminal path in the search tree. The technique used is an extension of the GAC algorithm for the regular language constraint on finite length input. Our approach adds support for skipped variables, maintains the reduced property of the MDD dynamically and provides domain entailment detection. Finally we also show how to adapt the approach to constraint types that are closely related to MDDs, such as AOMDDs and Case DAGs.
cs.AI:Did natural consciousness and intelligent systems arise out of a path that was co-evolutionary to evolution? Can we explain human self-consciousness as having risen out of such an evolutionary path? If so how could it have been?   In this first part of a two-part paper (titled IXI), we take a learning system perspective to the problem of consciousness and intelligent systems, an approach that may look unseasonable in this age of fMRI's and high tech neuroscience.   We posit conscious intelligent systems in natural environments and wonder how natural factors influence their design paths. Such a perspective allows us to explain seamlessly a variety of natural factors, factors ranging from the rise and presence of the human mind, man's sense of I, his self-consciousness and his looping thought processes to factors like reproduction, incubation, extinction, sleep, the richness of natural behavior, etc. It even allows us to speculate on a possible human evolution scenario and other natural phenomena.
cs.AI:This is the second part of a paper on Conscious Intelligent Systems. We use the understanding gained in the first part (Conscious Intelligent Systems Part 1: IXI (arxiv id cs.AI/0612056)) to look at understanding. We see how the presence of mind affects understanding and intelligent systems; we see that the presence of mind necessitates language. The rise of language in turn has important effects on understanding. We discuss the humanoid question and how the question of self-consciousness (and by association mind/thought/language) would affect humanoids too.
cs.AI:A product configurator which is complete, backtrack free and able to compute the valid domains at any state of the configuration can be constructed by building a Binary Decision Diagram (BDD). Despite the fact that the size of the BDD is exponential in the number of variables in the worst case, BDDs have proved to work very well in practice. Current BDD-based techniques can only handle interactive configuration with small finite domains. In this paper we extend the approach to handle string variables constrained by regular expressions. The user is allowed to change the strings by adding letters at the end of the string. We show how to make a data structure that can perform fast valid domain computations given some assignment on the set of string variables.   We first show how to do this by using one large DFA. Since this approach is too space consuming to be of practical use, we construct a data structure that simulates the large DFA and in most practical cases are much more space efficient. As an example a configuration problem on $n$ string variables with only one solution in which each string variable is assigned to a value of length of $k$ the former structure will use $\Omega(k^n)$ space whereas the latter only need $O(kn)$. We also show how this framework easily can be combined with the recent BDD techniques to allow both boolean, integer and string variables in the configuration problem.
cs.AI:Recently, M. Chertkov and V.Y. Chernyak derived an exact expression for the partition sum (normalization constant) corresponding to a graphical model, which is an expansion around the Belief Propagation solution. By adding correction terms to the BP free energy, one for each "generalized loop" in the factor graph, the exact partition sum is obtained. However, the usually enormous number of generalized loops generally prohibits summation over all correction terms. In this article we introduce Truncated Loop Series BP (TLSBP), a particular way of truncating the loop series of M. Chertkov and V.Y. Chernyak by considering generalized loops as compositions of simple loops. We analyze the performance of TLSBP in different scenarios, including the Ising model, regular random graphs and on Promedas, a large probabilistic medical diagnostic system. We show that TLSBP often improves upon the accuracy of the BP solution, at the expense of increased computation time. We also show that the performance of TLSBP strongly depends on the degree of interaction between the variables. For weak interactions, truncating the series leads to significant improvements, whereas for strong interactions it can be ineffective, even if a high number of terms is considered.
cs.AI:In this paper, the traditional k-modes clustering algorithm is extended by weighting attribute value matches in dissimilarity computation. The use of attribute value weighting technique makes it possible to generate clusters with stronger intra-similarities, and therefore achieve better clustering performance. Experimental results on real life datasets show that these value weighting based k-modes algorithms are superior to the standard k-modes algorithm with respect to clustering accuracy.
cs.AI:In Verification and in (optimal) AI Planning, a successful method is to formulate the application as boolean satisfiability (SAT), and solve it with state-of-the-art DPLL-based procedures. There is a lack of understanding of why this works so well. Focussing on the Planning context, we identify a form of problem structure concerned with the symmetrical or asymmetrical nature of the cost of achieving the individual planning goals. We quantify this sort of structure with a simple numeric parameter called AsymRatio, ranging between 0 and 1. We run experiments in 10 benchmark domains from the International Planning Competitions since 2000; we show that AsymRatio is a good indicator of SAT solver performance in 8 of these domains. We then examine carefully crafted synthetic planning domains that allow control of the amount of structure, and that are clean enough for a rigorous analysis of the combinatorial search space. The domains are parameterized by size, and by the amount of structure. The CNFs we examine are unsatisfiable, encoding one planning step less than the length of the optimal plan. We prove upper and lower bounds on the size of the best possible DPLL refutations, under different settings of the amount of structure, as a function of size. We also identify the best possible sets of branching variables (backdoors). With minimum AsymRatio, we prove exponential lower bounds, and identify minimal backdoors of size linear in the number of variables. With maximum AsymRatio, we identify logarithmic DPLL refutations (and backdoors), showing a doubly exponential gap between the two structural extreme cases. The reasons for this behavior -- the proof arguments -- illuminate the prototypical patterns of structure causing the empirical behavior observed in the competition benchmarks.
cs.AI:This short paper introduces two new fusion rules for combining quantitative basic belief assignments. These rules although very simple have not been proposed in literature so far and could serve as useful alternatives because of their low computation cost with respect to the recent advanced Proportional Conflict Redistribution rules developed in the DSmT framework.
cs.AI:Constraint Programming (CP) has been successfully applied to both constraint satisfaction and constraint optimization problems. A wide variety of specialized global constraints provide critical assistance in achieving a good model that can take advantage of the structure of the problem in the search for a solution. However, a key outstanding issue is the representation of 'ad-hoc' constraints that do not have an inherent combinatorial nature, and hence are not modeled well using narrowly specialized global constraints. We attempt to address this issue by considering a hybrid of search and compilation. Specifically we suggest the use of Reduced Ordered Multi-Valued Decision Diagrams (ROMDDs) as the supporting data structure for a generic global constraint. We give an algorithm for maintaining generalized arc consistency (GAC) on this constraint that amortizes the cost of the GAC computation over a root-to-leaf path in the search tree without requiring asymptotically more space than used for the MDD. Furthermore we present an approach for incrementally maintaining the reduced property of the MDD during the search, and show how this can be used for providing domain entailment detection. Finally we discuss how to apply our approach to other similar data structures such as AOMDDs and Case DAGs. The technique used can be seen as an extension of the GAC algorithm for the regular language constraint on finite length input.
cs.AI:For academics and practitioners concerned with computers, business and mathematics, one central issue is supporting decision makers. In this paper, we propose a generalization of Decision Matrix Method (DMM), using Neutrosophic logic. It emerges as an alternative to the existing logics and it represents a mathematical model of uncertainty and indeterminacy. This paper proposes the Neutrosophic Decision Matrix Method as a more realistic tool for decision making. In addition, a de-neutrosophication process is included.
cs.AI:This paper constructs a tree structure for the music rhythm using the L-system. It models the structure as an automata and derives its complexity. It also solves the complexity for the L-system. This complexity can resolve the similarity between trees. This complexity serves as a measure of psychological complexity for rhythms. It resolves the music complexity of various compositions including the Mozart effect K488.   Keyword: music perception, psychological complexity, rhythm, L-system, automata, temporal associative memory, inverse problem, rewriting rule, bracketed string, tree similarity
cs.AI:Using qualitative reasoning with geographic information, contrarily, for instance, with robotics, looks not only fastidious (i.e.: encoding knowledge Propositional Logics PL), but appears to be computational complex, and not tractable at all, most of the time. However, knowledge fusion or revision, is a common operation performed when users merge several different data sets in a unique decision making process, without much support. Introducing logics would be a great improvement, and we propose in this paper, means for deciding -a priori- if one application can benefit from a complete revision, under only the assumption of a conjecture that we name the "containment conjecture", which limits the size of the minimal conflicts to revise. We demonstrate that this conjecture brings us the interesting computational property of performing a not-provable but global, revision, made of many local revisions, at a tractable size. We illustrate this approach on an application.
cs.AI:In case-based reasoning, the adaptation of a source case in order to solve the target problem is at the same time crucial and difficult to implement. The reason for this difficulty is that, in general, adaptation strongly depends on domain-dependent knowledge. This fact motivates research on adaptation knowledge acquisition (AKA). This paper presents an approach to AKA based on the principles and techniques of knowledge discovery from databases and data-mining. It is implemented in CABAMAKA, a system that explores the variations within the case base to elicit adaptation knowledge. This system has been successfully tested in an application of case-based reasoning to decision support in the domain of breast cancer treatment.
cs.AI:In these notes we formally describe the functionality of Calculating Valid Domains from the BDD representing the solution space of valid configurations. The formalization is largely based on the CLab configuration framework.
cs.AI:Motivation: Profile hidden Markov Models (pHMMs) are a popular and very useful tool in the detection of the remote homologue protein families. Unfortunately, their performance is not always satisfactory when proteins are in the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm and tool that tries to improve pHMM performance by using structural information while training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs. Each pHMM is constructed by weighting each residue in an aligned protein according to a specific structural property of the residue. Properties used were primary, secondary and tertiary structures, accessibility and packing. HMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP database to perform our experiments. Throughout, we apply leave-one-family-out cross-validation over protein superfamilies. First, we used the MAMMOTH-mult structural aligner to align the training set proteins. Then, we performed two sets of experiments. In a first experiment, we compared structure weighted models against standard pHMMs and against each other. In a second experiment, we compared the voting model against individual pHMMs. We compare method performance through ROC curves and through Precision/Recall curves, and assess significance through the paired two tailed t-test. Our results show significant performance improvements of all structurally weighted models over default HMMER, and a significant improvement in sensitivity of the combined models over both the original model and the structurally weighted models.
cs.AI:This paper proposes an approach to training rough set models using Bayesian framework trained using Markov Chain Monte Carlo (MCMC) method. The prior probabilities are constructed from the prior knowledge that good rough set models have fewer rules. Markov Chain Monte Carlo sampling is conducted through sampling in the rough set granule space and Metropolis algorithm is used as an acceptance criteria. The proposed method is tested to estimate the risk of HIV given demographic data. The results obtained shows that the proposed approach is able to achieve an average accuracy of 58% with the accuracy varying up to 66%. In addition the Bayesian rough set give the probabilities of the estimated HIV status as well as the linguistic rules describing how the demographic parameters drive the risk of HIV.
cs.AI:Noise, corruptions and variations in face images can seriously hurt the performance of face recognition systems. To make such systems robust, multiclass neuralnetwork classifiers capable of learning from noisy data have been suggested. However on large face data sets such systems cannot provide the robustness at a high level. In this paper we explore a pairwise neural-network system as an alternative approach to improving the robustness of face recognition. In our experiments this approach is shown to outperform the multiclass neural-network system in terms of the predictive accuracy on the face images corrupted by noise.
cs.AI:Evolutionary Learning proceeds by evolving a population of classifiers, from which it generally returns (with some notable exceptions) the single best-of-run classifier as final result. In the meanwhile, Ensemble Learning, one of the most efficient approaches in supervised Machine Learning for the last decade, proceeds by building a population of diverse classifiers. Ensemble Learning with Evolutionary Computation thus receives increasing attention. The Evolutionary Ensemble Learning (EEL) approach presented in this paper features two contributions. First, a new fitness function, inspired by co-evolution and enforcing the classifier diversity, is presented. Further, a new selection criterion based on the classification margin is proposed. This criterion is used to extract the classifier ensemble from the final population only (Off-line) or incrementally along evolution (On-line). Experiments on a set of benchmark problems show that Off-line outperforms single-hypothesis evolutionary learning and state-of-art Boosting and generates smaller classifier ensembles.
q-bio.BM:We consider the regime in which the bands of the torsional acoustic (TA) and the hydrogen-bond-stretch (HBS) modes of the DNA interpenetrate each other. Within the framework of a model that accommodates the structure of the double helix, we find the three-wave interaction between the TA- and the HBS-modes, and show that microwave radiation could bring about torsional vibrations that could serve as a pump mode for maintaining the HBS-one. Rayleigh's threshold condition for the parametric resonance provides an estimate for the power density of the mw-field necessary for generating the HBS-mode.
q-bio.BM:Identifying the driving forces and the mechanism of association of huntingtin-exon1, a close marker for the progress of Huntington's disease, is an important prerequisite towards finding potential drug targets, and ultimately a cure. We introduce here a modelling framework based on a key analogy of the physico-chemical properties of the exon1 fragment to block copolymers. We use a systematic mesoscale methodology, based on Dissipative Particle Dynamics, which is capable of overcoming kinetic barriers, thus capturing the dynamics of significantly larger systems over longer times than considered before. Our results reveal that the relative hydrophobicity of the poly-glutamine block as compared to the rest of the (proline-based) exon1 fragment, ignored to date, constitutes a major factor in the initiation of the self-assembly process. We find that the assembly is governed by both the concentration of exon1 and the length of the poly-glutamine stretch, with a low length threshold for association even at the lowest volume fractions we considered. Moreover, this self-association occurs irrespective of whether the glutamine stretch is in random coil or hairpin configuration, leading to spherical or cylindrical assemblies, respectively. We discuss the implications of these results for reinterpretation of existing research within this context, including that the routes towards aggregation of exon1 may be distinct to those of the widely studied homopolymeric poly-glutamine peptides.
q-bio.BM:The molecular mechanism of the solvent motion that is required to instigate the protein structural relaxation above a critical hydration level or transition temperature has yet to be determined. In this work we use quasi-elastic neutron scattering (QENS) and molecular dynamics simulation to investigate hydration water dynamics near a greatly simplified protein surface. We consider the hydration water dynamics near the completely deuterated N-acetyl-leucine-methylamide (NALMA) solute, a hydrophobic amino acid side chain attached to a polar blocked polypeptide backbone, as a function of concentration between 0.5M-2.0M, under ambient conditions. In this Communication, we focus our results of hydration dynamics near a model protein surface on the issue of how enzymatic activity is restored once a critical hydration level is reached, and provide a hypothesis for the molecular mechanism of the solvent motion that is required to trigger protein structural relaxation when above the hydration transition.
q-bio.BM:We analyze the dependence of thermal denaturation transition and folding rates of globular proteins on the number of amino acid residues, N. Using lattice Go models we show that DeltaT/T_F ~ N^-1, where T_F is the folding transition temperature and DeltaT is the folding transition width. This finding is consistent with finite size effects expected for the systems undergoing a phase transition from a disordered to an ordered phase. The dependence of the folding rates k_F on N for lattice models and the dataset of 57 proteins and peptides shows that k_F = k_F^0 exp(-CN^beta) provides a good fit, if 0 < beta <= 2/3 and C is a constant. We find that k_F = k_F^0 exp(-1.1N^0.5) with k_F^0 =(0.4x10^-6 s)^-1 can estimate optimal protein folding rates to within an order of magnitude in most cases. By using this fit for a set of proteins with beta-sheet topology we find that k_F^0 is approximately equal to k_U^0, the prefactor for unfolding rates. The maximum ratio of k_U^0/k_F^0 is 10 for this class of proteins.
q-bio.BM:The asymmetry in the shapes of folded and unfolded states are probed using two parameters, one being a measure of the sphericity and the other that describes the shape. For the folded states, whose interiors are densely packed, the radii of gyration (Rg) and these two parameters are calculated using the coordinates of the experimentally determined structures. Although Rg scales as expected for maximally compact structures, the distributions of the shape parameters show that there is considerable asymmetry in the shapes of folded structures. The degree of asymmetry is greater for proteins that form oligomers. Analysis of the two- and three-body contacts in the native structures shows that the presence of near equal number of contacts between backbone and side-chains and between side-chains gives rise to dense packing. We suggest that proteins with relatively large values of shape parameters can tolerate volume mutations without greatly affecting the network of contacts or their stability. To probe shape characteristics of denatured states we have developed a model of a WW-like domain. The shape parameters, which are calculated using Langevin simulations, change dramatically in the course of coil to globule transition. Comparison of the values of shape parameters between the globular state and the folded state of WW domain shows that both energetic (especially dispersion in the hydrophobic interactions) and steric effects are important in determining packing in proteins.
q-bio.BM:Instead of conformation states of single residues, refined conformation states of quintuplets are proposed to reflect conformation correlation. Simple hidden Markov models combining with sliding window scores are used for predicting secondary structure of a protein from its amino acid sequence. Since the length of protein conformation segments varies in a narrow range, we ignore the duration effect of the length distribution. The window scores for residues are a window version of the Chou-Fasman propensities estimated under an approximation of conditional independency. Different window widths are examined, and the optimal width is found to be 17. A high accuracy about 70% is achieved.
q-bio.BM:Is protein secondary structure primarily determined by local interactions between residues closely spaced along the amino acid backbone, or by non-local tertiary interactions? To answer this question we have measured the entropy densities of primary structure and secondary structure sequences, and the local inter-sequence mutual information density. We find that the important inter-sequence interactions are short ranged, that correlations between neighboring amino acids are essentially uninformative, and that only 1/4 of the total information needed to determine the secondary structure is available from local inter-sequence correlations. Since the remaining information must come from non-local interactions, this observation supports the view that the majority of most proteins fold via a cooperative process where secondary and tertiary structure form concurrently. To provide a more direct comparison to existing secondary structure prediction methods, we construct a simple hidden Markov model (HMM) of the sequences. This HMM achieves a prediction accuracy comparable to other single sequence secondary structure prediction algorithms, and can extract almost all of the inter-sequence mutual information. This suggests that these algorithms are almost optimal, and that we should not expect a dramatic improvement in prediction accuracy. However, local correlations between secondary and primary structure are probably of under-appreciated importance in many tertiary structure prediction methods, such as threading.
q-bio.BM:The determination of the folding mechanisms of proteins is critical to understand the topological change that can propagate Alzheimer and Creutzfeld-Jakobs diseases, among others. The computational community has paid considerable attention to this problem; however, the associated time scale, typically on the order of milliseconds or more, represents a formidable challenge. Ab initio protein folding from long molecular dynamics (MD) simulations or ensemble dynamics is not feasible with ordinary computing facilities and new techniques must be introduced. Here we present a detailed study of the folding of a 16-residue beta-hairpin, described by a generic energy model and using the activation-relaxation technique. From a total of 90 trajectories at 300 K, three folding pathways emerge. All involve a simultaneous optimization of the complete hydrophobic and hydrogen bonding interactions. The first two follow closely those observed by previous theoretical studies. The third pathway, never observed by previous all-atom folding, unfolding and equilibrium simulations, can be described as a reptation move of one strand of the beta-sheet with respect to the other. This reptation move indicates that non-native interactions can play a dominant role in the folding of secondary structures. These results point to a more complex folding picture than expected for a simple beta-hairpin.
q-bio.BM:Analytic estimates for the forces and free energy generated by bilayer deformation reveal a compelling and intuitive model for MscL channel gating analogous to the nucleation of a second phase. We argue that the competition between hydrophobic mismatch and tension results in a surprisingly rich story which can provide both a quantitative comparison to measurements of opening tension for MscL when reconstituted in bilayers of different thickness and qualitative insights into the function of the MscL channel and other transmembrane proteins.
q-bio.BM:It is important to understand how protein folding and evolution influences each other. Several studies based on entropy calculation correlating experimental measurement of residue participation in folding nucleus and sequence conservation have reached different conclusions. Here we report analysis of conservation of folding nucleus using an evolutionary model alternative to entropy based approaches. We employ a continuous time Markov model of codon substitution to distinguish mutation fixed by evolution and mutation fixed by chance. This model takes into account bias in codon frequency, bias favoring transition over transversion, as well as explicit phylogenetic information. We measure selection pressure using the ratio $\omega$ of synonymous vs. non-synonymous substitution at individual residue site. The $\omega$-values are estimated using the {\sc Paml} method, a maximum-likelihood estimator. Our results show that there is little correlation between the extent of kinetic participation in protein folding nucleus as measured by experimental $\phi$-value and selection pressure as measured by $\omega$-value. In addition, two randomization tests failed to show that folding nucleus residues are significantly more conserved than the whole protein. These results suggest that at the level of codon substitution, there is no indication that folding nucleus residues are significantly more conserved than other residues. We further reconstruct candidate ancestral residues of the folding nucleus and suggest possible test tube mutation studies of ancient folding nucleus.
q-bio.BM:Many signalling functions in molecular biology require proteins bind to substrates such as DNA in response to environmental signals such as the simultaneous binding to a small molecule. Examples are repressor proteins which may transmit information via a conformational change in response to the ligand binding. An alternative entropic mechanism of ``allostery'' suggests that the inducer ligand changes the intramolecular vibrational entropy not just the static structure. We present a quantitative, coarse-grained model of entropic allostery that suggests design rules for internal cohesive potentials in proteins employing this effect. It also addresses the issue of how the signal information to bind or unbind is transmitted through the protein. The model may be applicable to a wide range of repressors and also to signalling in transmembrane proteins.
q-bio.BM:How DNA repair enzymes find the relatively rare sites of damage is not known in great detail. Recent experiments and molecular data suggest that the individual repair enzymes do not work independently of each other, but rather interact with each other through currents exchanged along DNA. A damaged site in DNA hinders this exchange and this makes it possible to quickly free up resources from error free stretches of DNA. Here the size of the speedup gained from this current exchange mechanism is calculated and the characteristic length and time scales are identified. In particular for Escherichia coli we estimate the speedup to be 50000/N, where N is the number of repair enzymes participating in the current exchange mechanism. Even though N is not exactly known a speedup of order 10 is not entirely unreasonable. Furthermore upon over expression of repair enzymes the detection time only varies as one over the squareroot of N and not as 1/N. This behavior is of interest in assessing the impact of stress full and radioactive environments on individual cell mutation rates.
q-bio.BM:We study DNA adsorption and renaturation in a water-phenol two-phase system, with or without shaking. In very dilute solutions, single-stranded DNA is adsorbed at the interface in a salt-dependent manner. At high salt concentrations the adsorption is irreversible. The adsorption of the single-stranded DNA is specific to phenol and relies on stacking and hydrogen bonding. We establish the interfacial nature of a DNA renaturation at a high salt concentration. In the absence of shaking, this reaction involves an efficient surface diffusion of the single-stranded DNA chains. In the presence of a vigorous shaking, the bimolecular rate of the reaction exceeds the Smoluchowski limit for a three-dimensional diffusion-controlled reaction. DNA renaturation in these conditions is known as the Phenol Emulsion Reassociation Technique or PERT. Our results establish the interfacial nature of PERT. A comparison of this interfacial reaction with other approaches shows that PERT is the most efficient technique and reveals similarities between PERT and the renaturation performed by single-stranded nucleic acid binding proteins. Our results lead to a better understanding of the partitioning of nucleic acids in two-phase systems, and should help design improved extraction procedures for damaged nucleic acids. We present arguments in favor of a role of phenol and water-phenol interface in prebiotic chemistry. The most efficient renaturation reactions (in the presence of condensing agents or with PERT) occur in heterogeneous systems. This reveals the limitations of homogeneous approaches to the biochemistry of nucleic acids. We propose a heterogeneous approach to overcome the limitations of the homogeneous viewpoint.
q-bio.BM:Hydrophobicity is thought to be one of the primary forces driving the folding of proteins. On average, hydrophobic residues occur preferentially in the core, whereas polar residues tends to occur at the surface of a folded protein. By analyzing the known protein structures, we quantify the degree to which the hydrophobicity sequence of a protein correlates with its pattern of surface exposure. We have assessed the statistical significance of this correlation for several hydrophobicity scales in the literature, and find that the computed correlations are significant but far from optimal. We show that this less than optimal correlation arises primarily from the large degree of mutations that naturally occurring proteins can tolerate. Lesser effects are due in part to forces other than hydrophobicity and we quantify this by analyzing the surface exposure distributions of all amino acids. Lastly we show that our database findings are consistent with those found from an off-lattice hydrophobic-polar model of protein folding.
q-bio.BM:The approach for the description of the DNA conformational transformations on the mesoscopic scales in the frame of the double helix is presented. Due to consideration of the joint motions of DNA structural elements along the conformational pathways the models for different transformations may be constructed in the unifying two-component form. One component of the model is the degree of freedom of the elastic rod and another component -- the effective coordinate of the conformational transformation. The internal and external model components are interrelated, as it is characteristic for the DNA structure organization. It is shown that the kinetic energy of the conformational transformation of heterogeneous DNA may be put in homogeneous form. In the frame of the developed approach the static excitations of the DNA structure under the transitions between the stable states are found for internal and external components. The comparison of the data obtained with the experiment on intrinsic DNA deformability shows good qualitative agreement. The conclusion is made that the found excitations in the DNA structure may be classificated as the static conformational solitons.
q-bio.BM:Molecular combing is a powerful and simple method for aligning DNA molecules onto a surface. Using this technique combined with fluorescence microscopy, we observed that the length of lambda-DNA molecules was extended to about 1.6 times their contour length (unextended length, 16.2 micrometers) by the combing method on hydrophobic polymethylmetacrylate (PMMA) coated surfaces. The effects of sodium and magnesium ions and pH of the DNA solution were investigated. Interestingly, we observed force-induced melting of single DNA molecules.
q-bio.BM:Using a Brownian dynamics simulation, we numerically studied the interaction of DNA with histone and proposed an octamer-rotation model to describe the process of nucleosome formation. Nucleosome disruption under stretching was also simulated. The theoretical curves of extension versus time as well as of force versus extension are consistent with previous experimental results.
q-bio.BM:We propose a two-dimensional model for a complete description of the dynamics of molecular motors, including both the processive movement along track filaments and the dissociation from the filaments. The theoretical results on the distributions of the run length and dwell time at a given ATP concentration, the dependences of mean run length, mean dwell time and mean velocity on ATP concentration and load are in good agreement with the previous experimental results.
q-bio.BM:Kinesin motors have been studied extensively both experimentally and theoretically. However, the microscopic mechanism of the processive movement of kinesin is still an open question. In this paper, we propose a hand-over-hand model for the processivity of kinesin, which is based on chemical, mechanical, and electrical couplings. In the model the processive movement does not need to rely on the two heads' coordination in their ATP hydrolysis and mechanical cycles. Rather, the ATP hydrolyses at the two heads are independent. The much higher ATPase rate at the trailing head than the leading head makes the motor walk processively in a natural way, with one ATP being hydrolyzed per step. The model is consistent with the structural study of kinesin and the measured pathway of the kinesin ATPase. Using the model the estimated driving force of ~ 5.8 pN is in agreements with the experimental results (5~7.5 pN). The prediction of the moving time in one step (~10 microseconds) is also consistent with the measured values of 0~50 microseconds. The previous observation of substeps within the 8-nm step is explained. The shapes of velocity-load (both positive and negative) curves show resemblance to previous experimental results.
q-bio.BM:Myosin V and myosin VI are two classes of two-headed molecular motors of the myosin superfamily that move processively along helical actin filaments in opposite directions. Here we present a hand-over-hand model for their processive movements. In the model, the moving direction of a dimeric molecular motor is automatically determined by the relative orientation between its two heads at free state and its head's binding orientation on track filament. This determines that myosin V moves toward the barbed end and myosin VI moves toward the pointed end of actin. During the moving period in one step, one head remains bound to actin for myosin V whereas two heads are detached for myosin VI: The moving manner is determined by the length of neck domain. This naturally explains the similar dynamic behaviors but opposite moving directions of myosin VI and mutant myosin V (the neck of which is truncated to only one-sixth of the native length). Because of different moving manners, myosin VI and mutant myosin V exhibit significantly broader step-size distribution than native myosin V. However, all three motors give the same mean step size of 36 nm (the pseudo-repeat of actin helix). Using the model we study the dynamics of myosin V quantitatively, with theoretical results in agreement with previous experimental ones.
q-bio.BM:We describe a faster and more accurate algorithm for computing the statistical mechanics of DNA denaturation according to the Poland-Scheraga type. Nearest neighbor thermodynamics is included in a complete and general way. The algorithm represents an optimization with respect to algorithmic complexity of the partition function algorithm of Yeramian et al.: We reduce the computation time for a base-pairing probability profile from O(N2) to O(N). This speed-up comes in addition to the speed-up due to a multiexponential approximation of the loop entropy factor as introduced by Fixman and Freire. The speed-up, however, is independent of the multiexponential approximation and reduces time from O(N3) to O(N2) in the exact case. In addition to calculating the standard base-pairing probability profiles, we propose to use the algorithm to calculate various other probabilities (loops, helices, tails) for a more direct view of the melting regions and their positions and sizes.
q-bio.BM:A joint experimental / theoretical investigation of the elastin-like octapeptide GVG(VPGVG) was carried out. In this paper a comprehensive molecular dynamics study of the temperature dependent folding and unfolding of the octapeptide is presented. The current study, as well as its experimental counterpart find that this peptide undergoes an "inverse temperature transition", ITT, leading to a folding at about 310-330 K. In addition, an unfolding transition is identified at unusually high temperatures approaching the boiling point of water. Due to the small size of the system two broad temperature regimes are found: the "ITT regime" (at about 280-320 K) and the "unfolding regime" at about T > 330 K, where the peptide has a maximum probability of being folded at approximately 330 K. A detailed molecular picture involving a thermodynamic order parameter, or reaction coordinate, for this process is presented along with a time-correlation function analysis of the hydrogen bond dynamics within the peptide as well as between the peptide and solvating water molecules. Correlation with experimental evidence and ramifications on the properties of elastin are discussed.
q-bio.BM:A simplified model for the closed circular DNA (ccDNA) is proposed to describe some specific features of the helix-coil transition in such molecule. The Hamiltonian of ccDNA is related to the one introduced earlier for the linear DNA. The basic assumption is that the reduced energy of the hydrogen bond is not constant through the transition process but depends effectively on the fraction of already broken bonds. A transformation formula is obtained which relates the temperature of ccDNA at a given degree of helicity during the transition to the temperature of the corresponding linear chain at the same degree of helicity. The formula provides a simple method to calculate the melting curve for the ccDNA from the experimental melting curve of the linear DNA with the same nucleotide sequence.
q-bio.BM:We develop a simple but rigorous model of protein-protein association kinetics based on diffusional association on free energy landscapes obtained by sampling configurations within and surrounding the native complex binding funnels. Guided by results obtained on exactly solvable model problems, we transform the problem of diffusion in a potential into free diffusion in the presence of an absorbing zone spanning the entrance to the binding funnel. The free diffusion problem is solved using a recently derived analytic expression for the rate of association of asymmetrically oriented molecules. Despite the required high steric specificity and the absence of long-range attractive interactions, the computed rates are typically on the order of 10^4-10^6 M-1 s-1, several orders of magnitude higher than rates obtained using a purely probabilistic model in which the association rate for free diffusion of uniformly reactive molecules is multiplied by the probability of a correct alignment of the two partners in a random collision. As the association rates of many protein-protein complexes are also in the 10^5-10^6 M-1 s-1, our results suggest that free energy barriers arising from desolvation and/or side-chain freezing during complex formation or increased ruggedness within the binding funnel, which are completely neglected in our simple diffusional model, do not contribute significantly to the dynamics of protein-protein association. The transparent physical interpretation of our approach that computes association rates directly from the size and geometry of protein-protein binding funnels makes it a useful complement to Brownian dynamics simulations.
q-bio.BM:Functional proteins must fold with some minimal stability to a structure that can perform a biochemical task. Here we use a simple model to investigate the relationship between the stability requirement and the capacity of a protein to evolve the function of binding to a ligand. Although our model contains no built-in tradeoff between stability and function, proteins evolved function more efficiently when the stability requirement was relaxed. Proteins with both high stability and high function evolved more efficiently when the stability requirement was gradually increased than when there was constant selection for high stability. These results show that in our model, the evolution of function is enhanced by allowing proteins to explore sequences corresponding to marginally stable structures, and that it is easier to improve stability while maintaining high function than to improve function while maintaining high stability. Our model also demonstrates that even in the absence of a fundamental biophysical tradeoff between stability and function, the speed with which function can evolve is limited by the stability requirement imposed on the protein.
q-bio.BM:Using the model for the processive movement of a dimeric kinesin we proposed before, we study the dynamics of a number of mutant homodimeric and heterodimeric kinesins that were constructed by Kaseda et al. (Kaseda, K., Higuchi, H. and Hirose, K. PNAS 99, 16058 (2002)). The theoretical results of ATPase rate per head, moving velocity, and stall force of the motors show good agreement with the experimental results by Kaseda et al.: The puzzling dynamic behaviors of heterodimeric kinesin that consists of two distinct heads compared with its parent homodimers can be easily explained by using independent ATPase rates of the two heads in our model. We also study the collective kinetic behaviors of kinesins in MT-gliding motility. The results explains well that the average MT-gliding velocity is independent of the number of bound motors and is equal to the moving velocity of a single kinesin relative to MT.
q-bio.BM:The simplest approximation of interaction potential between amino-acids in proteins is the contact potential, which defines the effective free energy of a protein conformation by a set of amino acid contacts formed in this conformation. Finding a contact potential capable of predicting free energies of protein states across a variety of protein families will aid protein folding and engineering in silico on a computationally tractable time-scale. We test the ability of contact potentials to accurately and transferably (across various protein families) predict stability changes of proteins upon mutations. We develop a new methodology to determine the contact potentials in proteins from experimental measurements of changes in protein thermodynamic stabilities (ddG) upon mutations. We apply our methodology to derive sets of contact interaction parameters for a hierarchy of interaction models including solvation and multi-body contact parameters. We test how well our models reproduce experimental measurements by statistical tests. We evaluate the maximum accuracy of predictions obtained by using contact potentials and the correlation between parameters derived from different data-sets of experimental ddG values. We argue that it is impossible to reach experimental accuracy and derive fully transferable contact parameters using the contact models of potentials. However, contact parameters can yield reliable predictions of ddG for datasets of mutations confined to specific amino-acid positions in the sequence of a single protein.
q-bio.BM:We first review how to determine the rate of vibrational energy relaxation (VER) using perturbation theory. We then apply those theoretical results to the problem of VER of a CD stretching mode in the protein cytochrome c. We model cytochrome c in vacuum as a normal mode system with the lowest-order anharmonic coupling elements. We find that, for the ``lifetime'' width parameter $\gamma=3 \sim 30$ cm$^{-1}$, the VER time is $0.2 \sim 0.3$ ps, which agrees rather well with the previous classical calculation using the quantum correction factor method, and is consistent with spectroscopic experiments by Romesberg's group. We decompose the VER rate into separate contributions from two modes, and find that the most significant contribution, which depends on the ``lifetime'' width parameter, comes from those modes most resonant with the CD vibrational mode.
q-bio.BM:The three-dimensional structures of two common repeat motifs Val$^1$-Pro$^2$-Gly$^3$-Val$^4$-Gly$^5$ and Val$^1$-Gly$^2$-Val$^3$-Pro$^4$-Gly$^5$-Val$^6$-Gly$^7$-Val$^8$-Pro$^9$ of tropoelastin are investigated by using the multicanonical simulation procedure. By minimizing the energy structures along the trajectory the thermodynamically most stable low-energy microstates of the molecule are determined. The structural predictions are in good agreement with X-ray diffraction experiments.
q-bio.BM:We address the controversial hot question concerning the validity of the loose-coupling versus the lever-arm models in the actomyosin dynamics by re-interpreting and extending the washboard potential model proposed by some of us in a previous paper. In the new theory, a loose-coupling mechanism co-exists with the deterministic lever-arm model. The synergetic action of a random component, originating from the harnessed thermal energy, and of the power-stroke generated by the lever-arm classical mechanism is seen to yield an excellent fit of the set of data obtained in T. Yanagida's laboratory on the sliding of Myosin II heads on actin filaments under various load conditions. Our theoretical arguments are complemented by accurate numerical simulations, and the robustness of theory is tested via different combination of parameters and potential profiles.
q-bio.BM:In simple models side chains are often represented implicitly (e.g., by spin-states) or simplified as one atom. We study side chain effects using square lattice and tetrahedral lattice models, with explicitly side chains of two atoms. We distinguish effects due to chirality and effects due to side chain flexibilities, since residues in proteins are L-residues, and their side chains adopt different rotameric states. Short chains are enumerated exhaustively. For long chains, we sample effectively rare events (eg, compact conformations) and obtain complete pictures of ensemble properties of these models at all compactness region. We find that both chirality and reduced side chain flexibility lower the folding entropy significantly for globally compact conformations, suggesting that they are important properties of residues to ensure fast folding and stable native structure. This corresponds well with our finding that natural amino acid residues have reduced effective flexibility, as evidenced by analysis of rotamer libraries and side chain rotatable bonds. We further develop a method calculating the exact side-chain entropy for a given back bone structure. We show that simple rotamer counting often underestimates side chain entropy significantly, and side chain entropy does not always correlate well with main chain packing. Among compact backbones with maximum side chain entropy, helical structures emerges as the dominating configurations. Our results suggest that side chain entropy may be an important factor contributing to the formation of alpha helices for compact conformations.
q-bio.BM:We show that the contact map of the native structure of globular proteins can be reconstructed starting from the sole knowledge of the contact map's principal eigenvector, and present an exact algorithm for this purpose. Our algorithm yields a unique contact map for all 221 globular structures of PDBselect25 of length $N \le 120$. We also show that the reconstructed contact maps allow in turn for the accurate reconstruction of the three-dimensional structure. These results indicate that the reduced vectorial representation provided by the principal eigenvector of the contact map is equivalent to the protein structure itself. This representation is expected to provide a useful tool in bioinformatics algorithms for protein structure comparison and alignment, as well as a promising intermediate step towards protein structure prediction.
q-bio.BM:Function of proteins or a network of interacting proteins often involves communication between residues that are well separated in sequence. The classic example is the participation of distant residues in allosteric regulation. Bioinformatic and structural analysis methods have been introduced to infer residues that are correlated. Recently, increasing attention has been paid to obtain the sequence properties that determine the tendency of disease related proteins (Abeta peptides, prion proteins, transthyretin etc.) to aggregate and form fibrils. Motivated in part by the need to identify sequence characteristics that indicate a tendency to aggregate, we introduce a general method that probes covariations in charged residues along the sequence in a given protein family. The method, which involves computing the Sequence Correlation Entropy (SCE) using the quenched probability Psk(i,j) of finding a residue pair at a given sequence separation sk, allows us to classify protein families in terms of their SCE. Our general approach may be a useful way in obtaining evolutionary covariations of amino acid residues on a genome wide level.
q-bio.BM:We present an analysis of the effects of global topology on the structural stability of folded proteins in thermal equilibrium with a heat bath. For a large class of single domain proteins, we computed the harmonic spectrum within the Gaussian Network Model (GNM) and determined the spectral dimension, a parameter describing the low frequency behaviour of the density of modes. We find a surprisingly strong correlation between the spectral dimension and the number of amino acids of the protein. Considering that larger spectral dimension value relate to more topologically compact folded state, our results indicate that for a given temperature and length of the protein, the folded structure corresponds to the less compact folding compatible with thermodynamic stability.
q-bio.BM:We present a simple physical model which demonstrates that the native state folds of proteins can emerge on the basis of considerations of geometry and symmetry. We show that the inherent anisotropy of a chain molecule, the geometrical and energetic constraints placed by the hydrogen bonds and sterics, and hydrophobicity are sufficient to yield a free energy landscape with broad minima even for a homopolymer. These minima correspond to marginally compact structures comprising the menu of folds that proteins choose from to house their native-states in. Our results provide a general framework for understanding the common characteristics of globular proteins.
q-bio.BM:With the aim to study the relationship between protein sequences and their native structures, we adopt vectorial representations for both sequence and structure. The structural representation is based on the Principal Eigenvector of the fold's contact matrix (PE). As recently shown, the latter encodes sufficient information for reconstructing the whole contact matrix. The sequence is represented through a Hydrophobicity Profile (HP), using a generalized hydrophobicity scale that we obtain from the principal eigenvector of a residue-residue interaction matrix and denote it as interactivity scale. Using this novel scale, we define the optimal HP of a protein fold, and predict, by means of stability arguments, that it is strongly correlated with the PE of the fold's contact matrix. This prediction is confirmed through an evolutionary analysis, which shows that the PE correlates with the HP of each individual sequence adopting the same fold and, even more strongly, with the average HP of this set of sequences. Thus, protein sequences evolve in such a way that their average HP is close to the optimal one, implying that neutral evolution can be viewed as a kind of motion in sequence space around the optimal HP. Our results indicate that the correlation coefficient between N-dimensional vectors constitutes a natural metric in the vectorial space in which we represent both protein sequences and protein structures, which we call Vectorial Protein Space. In this way, we define a unified framework for sequence to sequence, sequence to structure, and structure to structure alignments. We show that the interactivity scale is nearly optimal both for the comparison of sequences with sequences and sequences with structures.
q-bio.BM:We fit the Fourier transforms of solvent accessibility and hydrophobicity profiles of a representative set of proteins to a joint multi-variable Gaussian. This allows us to separate the intrinsic tendencies of sequence and structure profiles from the interactions that correlate them; for example, the $\alpha$-helix periodicity in sequence hydrophobicity is dictated by the solvent accessibility of structures. The distinct intrinsic tendencies of sequence and structure profiles are most pronounced at long periods, where sequence hydrophobicity fluctuates more, while solvent accessibility fluctuations are less than average. Interestingly, correlations between the two profiles can be interpreted as the Boltzmann weight of the solvation energy at room temperature.
q-bio.BM:In this paper, we examine the mechanical role of the lipid bilayer in ion channel conformation and function with specific reference to the case of the mechanosensitive channel of large conductance (MscL). In a recent paper (Wiggins and Phillips, 2004), we argued that mechanotransduction very naturally arises from lipid-protein interactions by invoking a simple analytic model of the MscL channel and the surrounding lipid bilayer. In this paper, we focus on improving and expanding this analytic framework for studying lipid-protein interactions with special attention to MscL. Our goal is to generate simple scaling relations which can be used to provide qualitative understanding of the role of membrane mechanics in protein function and to quantitatively interpret experimental results. For the MscL channel, we find that the free energies induced by lipid-protein interaction are of the same order as the free energy differences between conductance states measured by Sukharev et al. (1999). We therefore conclude that the mechanics of the bilayer plays an essential role in determining the conformation and function of the channel. Finally, we compare the predictions of our model to experimental results from the recent investigations of the MscL channel by Perozo et al. (2002), Powl et al. (2003), Yoshimura et al. (2004), and others and suggest a suite of new experiments.
q-bio.BM:The conjunction of insights from structural biology, solution biochemistry, genetics and single molecule biophysics has provided a renewed impetus for the construction of quantitative models of biological processes. One area that has been a beneficiary of these experimental techniques is the study of viruses. In this paper we describe how the insights obtained from such experiments can be utilized to construct physical models of processes in the viral life cycle. We focus on dsDNA bacteriophages and show that the bending elasticity of DNA and its electrostatics in solution can be combined to determine the forces experienced during packaging and ejection of the viral genome. Furthermore, we quantitatively analyze the effect of fluid viscosity and capsid expansion on the forces experienced during packaging. Finally, we present a model for DNA ejection from bacteriophages based on the hypothesis that the energy stored in the tightly packed genome within the capsid leads to its forceful ejection. The predictions of our model can be tested through experiments in vitro where DNA ejection is inhibited by the application of external osmotic pressure.
q-bio.BM:Amyloid fibers are aggregates of proteins. They are built out of a peptide called $\beta$--amyloid (A$\beta$) containing between 41 and 43 residues, produced by the action of an enzyme which cleaves a much larger protein known as the Amyloid Precursor Protein (APP). X-ray diffraction experiments have shown that these fibrils are rich in $\beta$--structures, whereas the shape of the peptide displays an $\alpha$--helix structure within the APP in its biologically active conformation. A realistic model of fibril formation is developed based on the seventeen residues A$\beta$12--28 amyloid peptide, which has been shown to form fibrils structurally similar to those of the whole A$\beta$ peptide. With the help of physical arguments and in keeping with experimental findings, the A$\beta$12--28 monomer is assumed to be in four possible states (i.e., native helix conformation, $\beta$--hairpin, globular low--energy state and unfolded state). Making use of these monomeric states, oligomers (dimers, tertramers and octamers) were constructed. With the help of short, detailed Molecular Dynamics (MD) calculations of the three monomers and of a variety of oligomers, energies for these structures were obtained. Making use of these results within the framework of a simple yet realistic model to describe the entropic terms associated with the variety of amyloid conformations, a phase diagram can be calculated of the whole many--body system, leading to a thermodynamical picture in overall agreement with the experimental findings. In particular, the existence of micellar metastable states seem to be a key issue to determine the thermodynamical properties of the system.
q-bio.BM:The possibility of deriving the contact potentials between amino acids from their frequencies of occurence in proteins is discussed in evolutionary terms. This approach allows the use of traditional thermodynamics to describe such frequencies and, consequently, to develop a strategy to include in the calculations correlations due to the spatial proximity of the amino acids and to their overall tendency of being conserved in proteins. Making use of a lattice model to describe protein chains and defining a "true" potential, we test these strategies by selecting a database of folding model sequences, deriving the contact potentials from such sequences and comparing them with the "true" potential. Taking into account correlations allows for a markedly better prediction of the interaction potentials.
q-bio.BM:While all the information required for the folding of a protein is contained in its amino acid sequence, one has not yet learned how to extract this information to predict the three--dimensional, biologically active, native conformation of a protein whose sequence is known. Using insight obtained from simple model simulations of the folding of proteins, in particular of the fact that this phenomenon is essentially controlled by conserved (native) contacts among (few) strongly interacting ("hot"), as a rule hydrophobic, amino acids, which also stabilize local elementary structures (LES, hidden, incipient secondary structures like $\alpha$--helices and $\beta$--sheets) formed early in the folding process and leading to the postcritical folding nucleus (i.e., the minimum set of native contacts which bring the system pass beyond the highest free--energy barrier found in the whole folding process) it is possible to work out a succesful strategy for reading the native structure of designed proteins from the knowledge of only their amino acid sequence and of the contact energies among the amino acids. Because LES have undergone millions of years of evolution to selectively dock to their complementary structures, small peptides made out of the same amino acids as the LES are expected to selectively attach to the newly expressed (unfolded) protein and inhibit its folding, or to the native (fluctuating) native conformation and denaturate it. These peptides, or their mimetic molecules, can thus be used as effective non--conventional drugs to those already existing (and directed at neutralizing the active site of enzymes), displaying the advantage of not suffering from the uprise of resistance.
q-bio.BM:Methods for alignment of protein sequences typically measure similarity by using substitution matrix with scores for all possible exchanges of one amino acid with another. Although widely used, the matrices derived from homologous sequence segments, such as Dayhoff's PAM matrices and Henikoff's BLOSUM matrices, are not specific for protein conformation identification. Using a different approach, we got many amino acid segment blocks. For each of them, the protein secondary structure is identical. Based on these blocks, we have derived new amino acid substitution matrices. The application of these matrices led to marked improvements in conformation segment search and homologues detection in twilight zone.
q-bio.BM:The advent of new experimental genomic technologies and the massive increase of DNA sequence information is helping researchers better understand how our genes work. Recently, experiments on mRNA abundance (gene expression) have revealed that gene expression shows a stationary organization described by a power-law distribution (scale-free organization) (i.e., gene expression $k$ decays as $k^{-\gamma}$), which is highly conserved in all the major five kingdoms of life, from Bacteria to Human. An underlying gene expression dynamics "rich-travel-more" was suggested to recover that evolutional conservation of transcriptional organization. Here we propose a constructive approach to gene expression dynamics with larger scope. Our gene expression construction restores the stationary state, predicts the power-law exponent for different organisms with natural explanation for small correction at high and low expression levels, describes the intermediate state dynamics (time finite) and elucidates the gene expression stability. This approach requires only one assumption: Markov property.
q-bio.BM:Proteins are minimally frustrated polymers. However, for realistic protein models non-native interactions must be taken into account. In this paper we analyze the effect of non-native interactions on the folding rate and on the folding free energy barrier. We present an analytic theory to account for the modification on the free energy landscape upon introduction of non-native contacts, added as a perturbation to the strong native interactions driving folding. Our theory predicts a rate-enhancement regime at fixed temperature, under the introduction of weak, non-native interactions. We have thoroughly tested this theoretical prediction with simulations of a coarse-grained protein model, by employing an off-lattice $C_\alpha$ model of the src-SH3 domain. The strong agreement between results from simulations and theory confirm the non trivial result that a relatively small amount of non-native interaction energy can actually assist the folding to the native structure.
q-bio.BM:An effective potential function is critical for protein structure prediction and folding simulation. For simplified models of proteins where coordinates of only $C_\alpha$ atoms need to be specified, an accurate potential function is important. Such a simplified model is essential for efficient search of conformational space. In this work, we present a formulation of potential function for simplified representations of protein structures. It is based on the combination of descriptors derived from residue-residue contact and sequence-dependent local geometry. The optimal weight coefficients for contact and local geometry is obtained through optimization by maximizing margins among native and decoy structures. The latter are generated by chain growth and by gapless threading. The performance of the potential function in blind test of discriminating native protein structures from decoys is evaluated using several benchmark decoy sets. This potential function have comparable or better performance than several residue-based potential functions that require in addition coordinates of side chain centers or coordinates of all side chain atoms.
q-bio.BM:Circular permutation connects the N and C termini of a protein and concurrently cleaves elsewhere in the chain, providing an important mechanism for generating novel protein fold and functions. However, their in genomes is unknown because current detection methods can miss many occurances, mistaking random repeats as circular permutation. Here we develop a method for detecting circularly permuted proteins from structural comparison. Sequence order independent alignment of protein structures can be regarded as a special case of the maximum-weight independent set problem, which is known to be computationally hard. We develop an efficient approximation algorithm by repeatedly solving relaxations of an appropriate intermediate integer programming formulation, we show that the approximation ratio is much better then the theoretical worst case ratio of $r = 1/4$. Circularly permuted proteins reported in literature can be identified rapidly with our method, while they escape the detection by publicly available servers for structural alignment.
q-bio.BM:Motivation. Protein design aims to identify sequences compatible with a given protein fold but incompatible to any alternative folds. To select the correct sequences and to guide the search process, a design scoring function is critically important. Such a scoring function should be able to characterize the global fitness landscape of many proteins simultaneously.   Results. To find optimal design scoring functions, we introduce two geometric views and propose a formulation using mixture of nonlinear Gaussian kernel functions. We aim to solve a simplified protein sequence design problem. Our goal is to distinguish each native sequence for a major portion of representative protein structures from a large number of alternative decoy sequences, each a fragment from proteins of different fold. Our scoring function discriminate perfectly a set of 440 native proteins from 14 million sequence decoys. We show that no linear scoring function can succeed in this task. In a blind test of unrelated proteins, our scoring function misclassfies only 13 native proteins out of 194. This compares favorably with about 3-4 times more misclassifications when optimal linear functions reported in literature are used. We also discuss how to develop protein folding scoring function.
q-bio.BM:Being HIV-1-PR an essential enzyme in the viral life cycle, its inhibition can control AIDS. Because the folding of single domain proteins, like HIV-1-PR is controlled by local elementary structures (LES, folding units stabilized by strongly interacting, highly conserved amino acids) which have evolved over myriads of generations to recognize and strongly attract each other so as to make the protein fold fast, we suggest a novel type of HIV-1-PR inhibitors which interfere with the folding of the protein: short peptides displaying the same amino acid sequence of that of LES. Theoretical and experimental evidence for the specificity and efficiency of such inhibitors are presented.
q-bio.BM:Vibrational energy relaxation (VER) of a selected mode in cytochrome c (hemeprotein) in vacuum is studied using two theoretical approaches: One is the equilibrium simulation approach with quantum correction factors, and the other is the reduced model approach which describes the protein as an ensemble of normal modes coupled with nonlinear coupling elements. Both methods result in estimates of VER time (sub ps) for a CD stretching mode in the protein at room temperature, that are in accord with the experimental data of Romesberg's group. The applicability of the two methods is examined through a discussion of the validity of Fermi's golden rule on which the two methods are based.
q-bio.BM:The 16-22 amino acid fragment of the beta-amyloid peptide associated with the Alzheimer's disease, Abeta, is capable of forming amyloid fibrils. Here we study the aggregation mechanism of Abeta(16-22) peptides by unbiased thermodynamic simulations at the atomic level for systems of one, three and six Abeta(16-22) peptides. We find that the isolated Abeta(16-22) peptide is mainly a random coil in the sense that both the alpha-helix and beta-strand contents are low, whereas the three- and six-chain systems form aggregated structures with a high beta-sheet content. Furthermore, in agreement with experiments on Abeta(16-22) fibrils, we find that large parallel beta-sheets are unlikely to form. For the six-chain system, the aggregated structures can have many different shapes, but certain particularly stable shapes can be identified.
q-bio.BM:We identified latent periodicity in catalytic domains of approximately 85% of serine/threonine and tyrosine protein kinases. Similar results were obtained for other 22 protein domains. We also designed the method of noise decomposition, which is aimed to distinguish between different periodicity types of the same period length. The method is to be used in conjunction with the cyclic profile alignment, and this combination is able to reveal structure-related or function-related patterns of latent periodicity. Possible origins of the periodic structure of protein kinase active sites are discussed. Summarizing, we presume that latent periodicity is the common property of many catalytic protein domains.
q-bio.BM:We found latent periodicity of 150 protein families now. We suppose that latent periodicity can determine a spectrum of resonance oscillations in proteins.
q-bio.BM:Proteins have regular tertiary structures but irregular amino acid sequences. This made it very difficult to decode the structural information in the protein sequences. Here we demonstrate that many small alpha protein domains have hidden sequence symmetries characteristic of their pseudo-symmetric tertiary structures. We also present a modified method of recurrent plot to reveal this kind of the hidden sequence symmetry. The results may enable us understand parts of the relations between protein sequences and their tertiary structures, i.e, how the primary sequence of a protein determines its tertiary structure.
q-bio.BM:Summary: The F2CS server provides access to the software, F2CS2.00, that implements an automated prediction method of SCOP and CATH classifications of proteins, based on their FSSP Z-scores (Getz et al., 2002), Availability: Free, at http://www.weizmann.ac.il/physics/complex/compphys/f2cs/. Contact: eytan.domany@weizmann.ac.il Supplementary information: The site contains links to additional figures and tables.
q-bio.BM:Activated processes such as protein unfolding are highly sensitive to heterogeneity in the environment. We study a highly simplified model of a protein in a random heterogeneous environment, a model of the in vivo environment. It is found that if the heterogeneity is sufficiently large the total rate of the process is essentially a random variable; this may be the cause of the species-to-species variability in the rate of prion protein conversion found by Deleault et al. [Nature, 425 (2003) 717].
q-bio.BM:Water molecules and molecular chaperones efficiently help the protein folding process. Here we describe their action in the context of the energy and topological networks of proteins. In energy terms water and chaperones were suggested to decrease the activation energy between various local energy minima smoothing the energy landscape, rescuing misfolded proteins from conformational traps and stabilizing their native structure. In kinetic terms water and chaperones may make the punctuated equilibrium of conformational changes less punctuated and help protein relaxation. Finally, water and chaperones may help the convergence of multiple energy landscapes during protein-macromolecule interactions. We also discuss the possibility of the introduction of protein games to narrow the multitude of the energy landscapes when a protein binds to another macromolecule. Both water and chaperones provide a diffuse set of rapidly fluctuating weak links (low affinity and low probability interactions), which allow the generalization of all these statements to a multitude of networks.
q-bio.BM:Nucleosomes organize the folding of DNA into chromatin and significantly influence transcription, replication, regulation and repair. All atom molecular dynamics simulations of a nucleosome and of its 146 basepairs of DNA free in solution have been conducted. DNA helical parameters are extracted from each trajectory to compare the conformation, effective force constants, persistence length measures, and fluctuations of nucleosomal DNA to free DNA. A method for disassembling and reconstructing the conformation and dynamics of the nucleosome using Fourier analysis is presented. Results indicate that the superhelical path of DNA in the nucleosome is irregular. Long length variations in the conformation of nucleosomal DNA are identified other than those associated with helix repeat. These variations are required to create a proposed tetrasome conformation or to qualitatively reconstruct the 1.75 turns of the nuclesomal superhelix. Free DNA achieves enough bend and shear in solution to create an ideal nucleosome superhelix, but these deformations are not organized so the conformation is essentially linear. Reconstruction of free DNA using selected long wavelength variations in conformation can produce either a left-handed or a right-handed superhelix. DNA is less flexible in the nucleosome than when free in solution, however such measures are length scale dependent.
q-bio.BM:Gene expression analysis by means of microarrays is based on the sequence specific binding of mRNA to DNA oligonucleotide probes and its measurement using fluorescent labels. The binding of RNA fragments involving other sequences than the intended target is problematic because it adds a "chemical background" to the signal, which is not related to the expression degree of the target gene. The paper presents a molecular signature of specific and non specific hybridization with potential consequences for gene expression analysis. We analyzed the signal intensities of perfect match (PM) and mismatch (MM) probes of GeneChip microarrays to specify the effect of specific and non specific hybridization. We found that these events give rise to different relations between the PM and MM intensities as function of the middle base of the PMs, namely a triplet- (C>G=T>A>0) and a duplet-like (C=T>0>G=A) pattern of the PM-MM log-intensity difference upon binding of specific and non specific RNA fragments, respectively. The systematic behaviour of the intensity difference can be rationalized on the level of base pairings of DNA/RNA oligonucleotide duplexes in the middle of the probe sequence. Non-specific binding is characterized by the reversal of the central Watson Crick (WC) pairing for each PM/MM probe pair, whereas specific binding refers to the combination of a WC and a self complementary (SC) pairing in PM and MM probes, respectively. The intensity of complementary MM introduces a systematic source of variation which decreases the precision of expression measures based on the MM intensities.
q-bio.BM:We implement the replica exchange molecular dynamics algorithm to study the interactions of a model peptide (WALP-16) with an explicitly represented DPPC membrane bilayer. We observe the spontaneous, unbiased insertion of WALP-16 into the DPPC bilayer and its folding into an a-helix with a trans-bilayer orientation. We observe that the insertion of the peptide into the DPPC bilayer precedes secondary structure formation. Although the peptide has some propensity to form a partially helical structure in the interfacial region of the DPPC/water system, this state is not a productive intermediate but rather an off-pathway trap for WALP-16 insertion. Equilibrium simulations show that the observed insertion/folding pathway mirrors the potential of mean force (PMF). Calculation of the enthalpic and entropic contributions to this PMF show that the surface bound conformation of WALP-16 is significantly lower in energy than other conformations, and that the insertion of WALP-16 into the bilayer without regular secondary structure is enthalpically unfavorable by 5-10 kcal/mol/residue. The observed insertion/folding pathway disagrees with the dominant conceptual model, which is that a surface bound helix is an obligatory intermediate for the insertion of a-helical peptides into lipid bilayers. In our simulations, the observed insertion/folding pathway is favored because of a large (> 100 kcal/mol) increase in system entropy that occurs when the unstructured WALP-16 peptide enters the lipid bilayer interior. The insertion/folding pathway that is lowest in free energy depends sensitively on the near cancellation of large enthalpic and entropic terms. This suggests that intrinsic membrane peptides may have a diversity of insertion/folding behaviors depending on the exact system of peptide and lipid under consideration.
q-bio.BM:Analysis of data from an Affymetrix Latin Square spike-in experiment indicates that measured fluorescence intensities of features on an oligonucleotide microarray are related to spike-in RNA target concentrations via a hyperbolic response function, generally identified as a Langmuir adsorption isotherm. Furthermore the asymptotic signal at high spike-in concentrations is almost invariably lower for a mismatch feature than for its partner perfect match feature. We survey a number of theoretical adsorption models of hybridization at the microarray surface and find that in general they are unable to explain the differing saturation responses of perfect and mismatch features. On the other hand, we find that a simple and consistent explanation can be found in a model in which equilibrium hybridization followed by partial dissociation of duplexes during the post-hybridization washing phase.
q-bio.BM:A model for the processive movement of dynein is presented based on experimental observations available. In the model, the change from strong microtubule-binding to weak binding of dynein is determined naturally by the variation of the relative orientation between the two interacting surfaces of the stalk tip and the microtubule as the stalk rotates from the ADP.Vi-state orientation to the apo-state orientation. This means that the puzzling communication from the ATP binding site in the globular head to the MT-binding site in the tip of the stalk, which is prerequisite in the conventional model, is not required. Using the present model, the previous experimental results, such as (i) the step size of a dynein being an integer times of the period of the MT lattice, (ii) the dependence of the step size on load, i.e., the step size decreasing with the increase of load, and (iii) the stall force being proportional to [ATP] at low [ATP] and becoming saturated at high [ATP], are well explained.
q-bio.BM:We address the controversial hot question concerning the validity of the loose coupling versus the lever-arm theories in the actomyosin dynamics by re-interpreting and extending the phenomenological washboard potential model proposed by some of us in a previous paper. In this new model a Brownian motion harnessing thermal energy is assumed to co-exist with the deterministic swing of the lever-arm, to yield an excellent fit of the set of data obtained by some of us on the sliding of Myosin II heads on immobilized actin filaments under various load conditions. Our theoretical arguments are complemented by accurate numerical simulations, and the robustness of the model is tested via different choices of parameters and potential profiles.
q-bio.BM:In this paper we investigate the role of native geometry on the kinetics of protein folding based on simple lattice models and Monte Carlo simulations. Results obtained within the scope of the Miyazawa-Jernigan indicate the existence of two dynamical folding regimes depending on the protein chain length. For chains larger than 80 amino acids the folding performance is sensitive to the native state's conformation. Smaller chains, with less than 80 amino acids, fold via two-state kinetics and exhibit a significant correlation between the contact order parameter and the logarithmic folding times. In particular, chains with N=48 amino acids were found to belong to two broad classes of folding, characterized by different cooperativity, depending on the contact order parameter. Preliminary results based on the G\={o} model show that the effect of long range contact interaction strength in the folding kinetics is largely dependent on the native state's geometry.
q-bio.BM:Monte Carlo simulations show that long-range interactions play a major role in determining the folding rates of 48-mer three-dimensional lattice polymers modelled by the Go potential. For three target structures with different native geometries we found a sharp increase in the folding time when the relative contribution of the long-range interactions to the native state's energy is decreased from ~50% towards zero. However, the dispersion of the simulated folding times depends strongly on the native geometry and Go polymers folding to one of the target structures exhibit folding times spanning three orders of magnitude. We have also found that, depending on the target geometry, a strong geometric coupling may exist between local and long-range contacts meaning that, when this coupling exists, the formation of long-range contacts is forced by the previous formation of local contacts. The absence of a strong geometric coupling leads to kinetics that are more sensitive to the interaction energy parameters; in this case the formation of local contacts is not sufficient to promote the establishment of long-range ones when these are strongly penalized energetically, leading to longer folding times.
q-bio.BM:A simplified interaction potential for protein folding studies at the atomic level is discussed and tested on a set of peptides with about 20 residues each. The test set contains both alpha-helical (Trp cage, Fs) and beta-sheet (GB1p, GB1m2, GB1m3, Betanova, LLM) peptides. The model, which is entirely sequence-based, is able to fold these different peptides for one and the same choice of model parameters. Furthermore, the melting behavior of the peptides is in good quantitative agreement with experimental data. Apparent folded populations obtained using different observables are compared, and are found to be very different for some of the peptides (e.g., Betanova). In other cases (in particular, GB1m2 and GB1m3), the different estimates agree reasonably well, indicating a more two-state-like melting behavior.
q-bio.BM:Single molecule FRET (fluorescence resonance energy transfer) is a powerful technique for detecting real-time conformational changes and molecular interactions during biological reactions. In this review, we examine different techniques of extending observation times via immobilization and illustrate how useful biological information can be obtained from single molecule FRET time trajectories with or without absolute distance information.
q-bio.BM:An ensemble of directed macromolecules on a lattice is considered, where the constituting molecules are chosen as a random sequence of N different types. The same type of molecules experiences a hard-core (exclusion) interaction. We study the robustness of the macromolecules with respect to breaking and substituting individual molecules, using a 1/N expansion. The properties depend strongly on the density of macromolecules. In particular, the macromolecules are robust against breaking and substituting at high densities.
q-bio.BM:The vibrational dynamics of a DNA molecule with counterions neutralizing the charged phosphate groups have been studied. With the help of elaborated model the conformational vibrations of the DNA double helix with alkaline metal ions have been described both qualitatively and quantitatively. For the complexes of DNA with counterions Li+, Na+, K+, Rb+ and Cs+ the normal modes have been found, and a mode characterized by the most notable ion displacements with respect to the DNA backbone has been determined. The frequency of counterion vibrations has been established to decrease as the ion mass increases. The results of theoretical calculation have been showed to be in good agreement with the experimental data of Raman spectroscopy.
q-bio.BM:To understand the mechanism of TATA-box conformational transformations we model structure mobility and find the types of conformational excitations of DNA macromolecule in heteronomous conformation. We have constructed the two-component model for describing DNA conformational transformation with simultaneous transitions in the furanos rings of the monomer link. Internal component describes the change of the base pair position in the double helix. External component describes the displacement of mass center of the monomer link. Nonlinearity of the system is accounted with a form of potential energy describing C3'-C2' and C2'-C3' sugars transitions in monomer link, and interrelation between monomer conformational transition and macromolecule deformation. The comparison of our results with experimental data allows to confirm that the localized conformational excitations may realise in DNA TATA-box. These excitations cause the deformation of the macromolecule fragment.
q-bio.BM:A simple approach is proposed to investigate the protein structure. Using a low complexity model, a simple pairwise interaction and the concept of global optimization, we are able to calculate ground states of proteins, which are in agreement with experimental data. All possible model structures of small proteins are available below a certain energy threshold. The exact lowenergy landscapes for the trp cage protein (1L2Y) is presented showing the connectivity of all states and energy barriers.
q-bio.BM:The effective DNA-DNA interaction force is calculated by computer simulations with explicit tetravalent counterions and monovalent salt. For overcharged DNA molecules, the interaction force shows a double-minimum structure. The positions and depths of these minima are regulated by the counterion density in the bulk. Using two-dimensional lattice sum and free energy perturbation theories, the coexisting phases for DNA bundles are calculated. A DNA-condensation and redissolution transition and a stable mesocrystal with an intermediate lattice constant for high counterion concentration are obtained.
q-bio.BM:By using a mixture model for the density distribution of the three pseudobond angles formed by $C_\alpha$ atoms of four consecutive residues, the local structural states are discretized as 17 conformational letters of a protein structural alphabet. This coarse-graining procedure converts a 3D structure to a 1D code sequence. A substitution matrix between these letters is constructed based on the structural alignments of the FSSP database.
q-bio.BM:An overview of theories related to vibrational energy relaxation (VER) in proteins is presented. VER of a selected mode in cytochrome c is studied using two theoretical approaches. One is the equilibrium simulation approach with quantum correction factors, and the other is the reduced model approach which describes the protein as an ensemble of normal modes interacting through nonlinear coupling elements. Both methods result in estimates of the VER time (sub ps) for a CD stretching mode in the protein at room temperature. The theoretical predictions are in accord with the experimental data of Romesberg's group. A perspective on future directions for the detailed study of time scales and mechanisms for VER in proteins is presented.
q-bio.BM:Protein one-dimensional (1D) structures such as secondary structure and contact number provide intuitive pictures to understand how the native three-dimensional (3D) structure of a protein is encoded in the amino acid sequence. However, it has not been clear whether a given set of 1D structures contains sufficient information for recovering the underlying 3D structure. Here we show that the 3D structure of a protein can be recovered from a set of three types of 1D structures, namely, secondary structure, contact number and residue-wise contact order which is introduced here for the first time. Using simulated annealing molecular dynamics simulations, the structures satisfying the given native 1D structural restraints were sought for 16 proteins of various structural classes and of sizes ranging from 56 to 146 residues. By selecting the structures best satisfying the restraints, all the proteins showed a coordinate RMS deviation of less than 4\AA{} from the native structure, and for most of them, the deviation was even less than 2\AA{}. The present result opens a new possibility to protein structure prediction and our understanding of the sequence-structure relationship.
q-bio.BM:The lack of specificity in microarray experiments due to non-specific hybridization raises a serious problem for the analysis of microarray data because the residual chemical background intensity is not related to the expression degree of the gene of interest. We analyzed the concentration dependence of the signal intensity of perfect match (PM) and mismatch (MM) probes in terms using a microscopic binding model using a combination of mean hybridization isotherms and single base related affinity terms. The signal intensities of the PM and MM probes and their difference are assessed with regard to their sensitivity, specificity and resolution for gene expression measures. The presented theory implies the refinement of existing algorithms of probe level analysis to correct microarray data for non-specific background intensities.
q-bio.BM:Residue-wise contact order (RWCO) is a new kind of one-dimensional protein structures which represents the extent of long-range contacts. We have recently shown that a set of three types of one-dimensional structures (secondary structure, contact number, and RWCO) contains sufficient information for reconstructing the three-dimensional structure of proteins. Currently, there exist prediction methods for secondary structure and contact number from amino acid sequence, but none exists for RWCO. Also, the properties of amino acids that affect RWCO is not clearly understood. Here, we present a linear regression-based method to predict RWCO from amino acid sequence, and analyze the regression parameters to identify the properties that correlates with the RWCO. The present method achieves the significant correlation of 0.59 between the native and predicted RWCOs on average. An unusual feature of the RWCO prediction is the remarkably large optimal half window size of 26 residues. The regression parameters for the central and near-central residues of the local sequence segment highly correlate with those of the contact number prediction, and hence with hydrophobicity.
q-bio.BM:In this paper the heat signaling in microtubules (MT) is investigated. It is argued that for the description of the heat signaling phenomena in MT, the hyperbolic heat transport (HHT) equation must be used. It is shown that HHT is the Klein-Gordon (K-G) equation. The general solution for the K-G equation for MT is obtained. For the undistorted signal propagation in MT the Heisenberg uncertainty principle is formulated and discussed.   Key words: Microtubules; Heat signaling; Klein-Gordon equation; Heisenberg principle.
q-bio.BM:In the last years, tens of thousands gene expression profiles for cells of several organisms have been monitored. Gene expression is a complex transcriptional process where mRNA molecules are translated into proteins, which control most of the cell functions. In this process, the correlation among genes is crucial to determine the specific functions of genes. Here, we propose a novel multi-dimensional stochastic approach to deal with the gene correlation phenomena. Interestingly, our stochastic framework suggests that the study of the gene correlation requires only one theoretical assumption -Markov property- and the experimental transition probability, which characterizes the gene correlation system. Finally, a gene expression experiment is proposed for future applications of the model.
q-bio.BM:The importance of understanding the mechanism of protein aggregation into insoluble amyloid fibrils relies not only on its medical consequences, but also on its more basic properties of self--organization. The discovery that a large number of uncorrelated proteins can form, under proper conditions, structurally similar fibrils has suggested that the underlying mechanism is a general feature of polypeptide chains. In the present work, we address the early events preceeding amyloid fibril formation in solutions of zinc--free human insulin incubated at low pH and high temperature. Aside from being a easy--to--handle model for protein fibrillation, subcutaneous aggregation of insulin after injection is a nuisance which affects patients with diabetes. Here, we show by time--lapse atomic force microscopy (AFM) that a steady-state distribution of protein oligomers with an exponential tail is reached within few minutes after heating. This metastable phase lasts for few hours until aggregation into fibrils suddenly occurs. A theoretical explanation of the oligomer pre--fibrillar distribution is given in terms of a simple coagulation--evaporation kinetic model, in which concentration plays the role of a critical parameter. Due to high resolution and sensitivity of AFM technique, the observation of a long-lasting latency time should be considered an actual feature of the aggregation process, and not simply ascribed to instrumental inefficency. These experimental facts, along with the kinetic model used, claim for a critical role of thermal concentration fluctuations in the process of fibril nucleation.
q-bio.BM:Identical objects, regularly assembled, form a helix, which is the principal motif of nucleic acids, proteins, and viral capsids.
q-bio.BM:The ambitious and ultimate research purpose in Systems Biology is the understanding and modelling of the cell's system. Although a vast number of models have been developed in order to extract biological knowledge from complex systems composed of basic elements as proteins, genes and chemical compounds, a need remains for improving our understanding of dynamical features of the systems (i.e., temporal-dependence).   In this article, we analyze the gene expression dynamics (i.e., how the genes expression fluctuates in time) by using a new constructive approach. This approach is based on only two fundamental ingredients: symmetry and the Markov property of dynamics. First, by using experimental data of human and yeast gene expression time series, we found a symmetry in short-time transition probability from time $t$ to time $t+1$. We call it self-similarity symmetry (i.e., surprisingly, the gene expression short-time fluctuations contain a repeating pattern of smaller and smaller parts that are like the whole, but different in size). Secondly, the Markov property of dynamics reflects that the short-time fluctuation governs the full-time behaviour of the system. Here, we succeed in reconstructing naturally the global behavior of the observed distribution of gene expression (i.e., scaling-law) and the local behaviour of the power-law tail of this distribution, by using only these two ingredients: symmetry and the Markov property of dynamics. This approach may represent a step forward toward an integrated image of the basic elements of the whole cell.
q-bio.BM:In this work, the dynamics of fluctuations in gene expression time series is investigated. By using collected data of gene expression from yeast and human organisms, we found that the fluctuations of gene expression level and its average value over time are strongly correlated and obey a scaling law. As this feature is found in yeast and human organisms, it suggests that probably this coupling is a common dynamical organizing property of all living systems. To understand these observations, we propose a stochastic model which can explain these collective fluctuations, and predict the scaling exponent. Interestingly, our results indicate that the observed scaling law emerges from the self-similarity symmetry embedded in gene expression fluctuations.
q-bio.BM:We study the mechanism underlying the attraction between nucleosomes, the fundamental packaging units of DNA inside the chromatin complex. We introduce a simple model of the nucleosome, the eight-tail colloid, consisting of a charged sphere with eight oppositely charged, flexible, grafted chains that represent the terminal histone tails. We demonstrate that our complexes are attracted via the formation of chain bridges and that this attraction can be tuned by changing the fraction of charged monomers on the tails. This suggests a physical mechanism of chromatin compaction where the degree of DNA condensation can be controlled via biochemical means, namely the acetylation and deacetylation of lysines in the histone tails.
q-bio.BM:The effects of monovalent (Na+, K+) and divalent (Mg2+, Ca2+, Mn2+) ions on the interaction between DNA and histone are studied using the molecular combing technique. Lamda-DNA molecules and DNA-histone complexes incubated with metal cations (Na+, K+, Mg2+, Ca2+, Mn2+) are stretched on hydrophobic surfaces, and directly observed by fluorescence microscopy. The results indicate that when these cations are added into the DNA solution, the fluorescence intensities of the stained DNA are reduced differently. The monovalent cations (Na+, K+) inhibit binding of histone to DNA. The divalent cations (Mg2+, Ca2+, Mn2+) enhance significantly the binding of histone to DNA and the binding of the DNA-histone complex to the hydrophobic surface. Mn2+ also induces condensation and aggregation of the DNA-histone complex.
q-bio.BM:PDZ (Post-synaptic density-95/discs large/zonula occludens-1) domains are relatively small (80 to 120 residues) protein binding modules central in the organization of receptor clusters and in the association of cellular proteins. Their main function is to bind C-terminals of selected proteins that are recognized through specific amino-acids in their carboxyl end. Binding is associated with a deformation of the PDZ native structure and is responsible for dynamical changes in regions not in direct contact with the target. We investigate how this deformation is related to the harmonic dynamics of the PDZ structure and show that one low-frequency collective normal mode, characterized by the concerted movements of different secondary structures, is involved in the binding process. Our results suggest that even minimal structural changes are responsible of communication between distant regions of the protein, in agreement with recent Nuclear Magnetic Resonance (NMR) experiments. Thus PDZ domains are a very clear example of how collective normal modes are able to characterize the relation between function and dynamics of proteins, and to provide indications on the precursors of binding/unbonding events.
q-bio.BM:We introduce a new measure of antigenic distance between influenza A vaccine and circulating strains. The measure correlates well with efficacies of the H3N2 influenza A component of the annual vaccine between 1971 and 2004, as do results of a theory of the immune response to influenza following vaccination. This new measure of antigenic distance is correlated with vaccine efficacy to a greater degree than are current state-of-the-art phylogenetic sequence analyzes or ferret antisera inhibition assays. We suggest that this new measure of antigenic distance be used in the design of the annual influenza vaccine and in the interpretation of vaccine efficacy monitoring.
q-bio.BM:Prediction of one-dimensional protein structures such as secondary structures and contact numbers is useful for the three-dimensional structure prediction and important for the understanding of sequence-structure relationship. Here we present a new machine-learning method, critical random networks (CRNs), for predicting one-dimensional structures, and apply it, with position-specific scoring matrices, to the prediction of secondary structures (SS), contact numbers (CN), and residue-wise contact orders (RWCO). The present method achieves, on average, $Q_3$ accuracy of 77.8% for SS, correlation coefficients of 0.726 and 0.601 for CN and RWCO, respectively. The accuracy of the SS prediction is comparable to other state-of-the-art methods, and that of the CN prediction is a significant improvement over previous methods. We give a detailed formulation of critical random networks-based prediction scheme, and examine the context-dependence of prediction accuracies. In order to study the nonlinear and multi-body effects, we compare the CRNs-based method with a purely linear method based on position-specific scoring matrices. Although not superior to the CRNs-based method, the surprisingly good accuracy achieved by the linear method highlights the difficulty in extracting structural features of higher order from amino acid sequence beyond that provided by the position-specific scoring matrices.
q-bio.BM:We describe the results obtained from an improved model for protein folding. We find that a good agreement with the native structure of a 46 residue long, five-letter protein segment is obtained by carefully tuning the parameters of the self-avoiding energy. In particular we find an improved free-energy profile. We also compare the efficiency of the multidimensional replica exchange method with the widely used parallel tempering.
q-bio.BM:We use single-particle tracking to study the elastic properties of single microtubules grafted to a substrate. Thermal fluctuations of the free microtubule's end are recorded, in order to measure position distribution functions from which we calculate the persistence length of microtubules with contour lengths between 2.6 and 48 micrometers. We find the persistence length to vary by more than a factor of 20 over the total range of contour lengths. Our results support the hypothesis that shearing between protofilaments contributes significantly to the mechanics of microtubules.
q-bio.BM:Optimal structure of proteins is described by linear stochastic differential equation with mean decrease of free energy and volatility. Structure determining strategy is given by a twin of stochastic variables for which empirical conditions are not postulated. Optimal structure determination will be deformed to be adoptive to trading strategy employing martingale property where stochastic integral w.r.t. analytical solution of stochastic differential equation will be employed.
q-bio.BM:One of the main problems of drug design is that of optimizing the drug--target interaction. In the case in which the target is a viral protein displaying a high mutation rate, a second problem arises, namely the eventual development of resistance. We wish to suggest a scheme for the design of non--conventional drugs which do not face any of these problems and apply it to the case of HIV--1 protease. It is based on the knowledge that the folding of single--domain proteins, like e.g. each of the monomers forming the HIV--1--PR homodimer, is controlled by local elementary structures (LES), stabilized by local contacts among hydrophobic, strongly interacting and highly conserved amino acids which play a central role in the folding process. Because LES have evolved over myriads of generations to recognize and strongly interact with each other so as to make the protein fold fast as well as to avoid aggregation with other proteins, highly specific (and thus little toxic) as well as effective folding--inhibitor drugs suggest themselves: short peptides (or eventually their mimetic molecules), displaying the same amino acid sequence of that of LES (p--LES). Aside from being specific and efficient, these inhibitors are expected not to induce resistance: in fact, mutations which successfully avoid their action imply the destabilization of one or more LES and thus should lead to protein denaturation. Making use of Monte Carlo simulations within the framework of a simple although not oversimplified model, which is able to reproduce the main thermodynamic as well as dynamic properties of monoglobular proteins, we first identify the LES of the HIV--1--PR and then show that the corresponding p--LES peptides act as effective inhibitors of the folding of the protease which do not create resistance.
q-bio.BM:Protein structure is generally conceptualized as the global arrangement or of smaller, local motifs of helices, sheets, and loops. These regular, recurring secondary structural elements have well-understood and standardized definitions in terms of amino acid backbone geometry and the manner in which hydrogen bonding requirements are satisfied. Recently, "tube" models have been proposed to explain protein secondary structure in terms of the geometrically optimal packing of a featureless cylinder. However, atomically detailed simulations demonstrate that such packing considerations alone are insufficient for defining secondary structure; both excluded volume and hydrogen bonding must be explicitly modeled for helix formation. These results have fundamental implications for the construction and interpretation of realistic and meaningful biomacromolecular models.
q-bio.BM:Structure predictions of helical membrane proteins have been designed to take advantage of the structural autonomy of secondary structure elements, as postulated by the two-stage model of Engelman and Popot. In this context, we investigate structure calculation strategies for two membrane proteins with different functions, sizes, aminoacid compositions, and topologies: the glycophorin A homodimer (a paradigm for close inter-helical packing in membrane proteins) and aquaporin (a channel protein). Our structure calculations are based on two alternative folding schemes: a one-step simulated annealing from an extended chain conformation, and a two-step procedure inspired by the grid-search methods traditionally used in membrane protein predictions. In this framework, we investigate rationales for the utilization of sparse NMR data such as distance-based restraints and residual dipolar couplings in structure calculations of helical membrane proteins.
q-bio.BM:Proteins created by combinatorial methods in vitro are an important source of information for understanding sequence-structure-function relationships. Alignments of folded proteins from combinatorial libraries can be analyzed using methods developed for naturally occurring proteins, but this neglects the information contained in the unfolded sequences of the library. We introduce two algorithms, logistic regression and excess information analysis, that use both the folded and unfolded sequences and compare them against contingency table and statistical coupling analysis, which only use the former. The test set for this benchmark study is a library of fictitious proteins that fold according to a hypothetical energy model. Of the four methods studied, only logistic regression is able to correctly recapitulate the energy model from the sequence alignment. The other algorithms predict spurious interactions between alignment positions with strong but individual influences on protein stability. When present in the same protein, stabilizing amino acids tend to lower the energy below the threshold needed for folding. As a result, their frequencies in the alignment can be correlated even if the positions do not interact. We believe any algorithm that neglects the nonlinear relationship between folding and energy is susceptible to this error.
q-bio.BM:In order to extend the results obtained with minimal lattice models to more realistic systems, we study a model where proteins are described as a chain of 20 kinds of structureless amino acids moving in a continuum space and interacting through a contact potential controlled by a 20x20 quenched random matrix. The goal of the present work is to design and characterize amino acid sequences folding to the SH3 conformation, a 60-residues recognition domain common to many regulatory proteins. We show that a number of sequences can fold, starting from a random conformation, to within a distance root mean square deviation (dRMSD) of 2.6A from the native state. Good folders are those sequences displaying in the native conformation an energy lower than a sequence--independent threshold energy.
q-bio.BM:We recently introduced a physical model [Hoang et al., P. Natl. Acad. Sci. USA (2004), Banavar et al., Phys. Rev. E (2004)] for proteins which incorporates, in an approximate manner, several key features such as the inherent anisotropy of a chain molecule, the geometrical and energetic constraints placed by the hydrogen bonds and sterics, and the role played by hydrophobicity. Within this framework, marginally compact conformations resembling the native state folds of proteins emerge as broad competing minima in the free energy landscape even for a homopolymer. Here we show how the introduction of sequence heterogeneity using a simple scheme of just two types of amino acids, hydrophobic (H) and polar (P), and sequence design allows a selected putative native fold to become the free energy minimum at low temperature. The folding transition exhibits thermodynamic cooperativity, if one neglects the degeneracy between two different low energy conformations sharing the same fold topology.
q-bio.BM:In eukaryote nucleosome, DNA wraps around a histone octamer in a left-handed way. We study the process of chirality formation of nucleosome with Brownian dynamics simulation. We model the histone octamer with a quantitatively adjustable chirality: left-handed, right-handed or non-chiral, and simulate the dynamical wrapping process of a DNA molecule on it. We find that the chirality of a nucleosome formed is strongly dependent on that of the histone octamer, and different chiralities of the histone octamer induce its different rotation directions in the wrapping process of DNA. In addition, a very weak chirality of the histone octamer is quite enough for sustaining the correct chirality of the nucleosome formed. We also show that the chirality of a nucleosome may be broken at elevated temperature.
q-bio.BM:Trypsin and chymotrypsin are both serine proteases with high sequence and structural similarities, but with different substrate specificity. Previous experiments have demonstrated the critical role of the two loops outside the binding pocket in controlling the specificity of the two enzymes. To understand the mechanism of such a control of specificity by distant loops, we have used the Gaussian Network Model to study the dynamic properties of trypsin and chymotrypsin and the roles played by the two loops. A clustering method was introduced to analyze the correlated motions of residues. We have found that trypsin and chymotrypsin have distinct dynamic signatures in the two loop regions which are in turn highly correlated with motions of certain residues in the binding pockets. Interestingly, replacing the two loops of trypsin with those of chymotrypsin changes the motion style of trypsin to chymotrypsin-like, whereas the same experimental replacement was shown necessary to make trypsin have chymotrypsin's enzyme specificity and activity. These results suggest that the cooperative motions of the two loops and the substrate-binding sites contribute to the activity and substrate specificity of trypsin and chymotrypsin.
q-bio.BM:The emergence and spreading of chirality on the early Earth is considered by studying a set of reaction-diffusion equations based on a polymerization model. It is found that effective mixing of the early oceans is necessary to reach the present homochiral state. The possibility of introducing mass extinctions and modifying the emergence rate of life is discussed.
q-bio.BM:The differences between uni-directional and bi-directional polymerization are considered. The uni-directional case is discussed in the framework of the RNA world. Similar to earlier models of this type, where polymerization was assumed to proceed in a bi-directional fashion (presumed to be relevant to peptide nucleic acids), left-handed and right-handed monomers are produced via an autocatalysis from an achiral substrate. The details of the bifurcation from a racemic solution to a homochiral state of either handedness is shown to be remarkably independent of whether the polymerization in uni-directional or bi-directional. Slightly larger differences are seen when dissociation is allowed and the dissociation fragments are being recycled into the achiral substrate.
q-bio.BM:A variety of viruses tightly pack their genetic material into protein capsids that are barely large enough to enclose the genome. In particular, in bacteriophages, forces as high as 60 pN are encountered during packaging and ejection, produced by DNA bending elasticity and self-interactions. The high forces are believed to be important for the ejection process, though the extent of their involvement is not yet clear. As a result, there is a need for quantitative models and experiments that reveal the nature of the forces relevant to DNA ejection. Here we report measurements of the ejection forces for two different mutants of bacteriophage lambda, lambda b221cI26 and lambda cI60, which differ in genome length by ~30%. As expected for a force-driven ejection mechanism, the osmotic pressure at which DNA release is completely inhibited varies with the genome length: we find inhibition pressures of 15 atm and 25 atm, respectively, values that are in agreement with our theoretical calculations.
q-bio.BM:The correlations of primary and secondary structures were analyzed using proteins with known structure from Protein Data Bank. The correlation values of amino acid type and the eight secondary structure types at distant position were calculated for distances between -25 and 25. Shapes of the diagrams indicate that amino acids polarity and capability for hydrogen bonding have influence on the secondary structure at some distances. Clear preference of most of the amino acids towards certain secondary structure type classifies amino acids into four groups: alpha-helix admirers, strand admirers, turn and bend admirers and the others. Group four consists of His and Cis, the amino acids that do not show clear preference for any secondary structure. Amino acids from a group have similar physicochemical properties, and the same structural characteristics. The results suggest that amino acid preference for secondary structure type is based on the structural characteristics at Cb and Cg atoms of amino acid. alpha-helix admirers do not have polar heteroatoms on Cb and Cg atoms, nor branching or aromatic group on Cb atom. Amino acids that have aromatic groups or branching on Cb atom are strand admirers. Turn and bend admirers have polar heteroatom on Cb or Cg atoms or do not have Cb atom at all. Our results indicate that polarity and capability for hydrogen bonding have influence on the secondary structure at some distance, and that amino acid preference for secondary structure is caused by structural properties at Cb or Cg atoms.
q-bio.BM:The functionality of proteins is related to their structure in the native state. Protein structures are made up of emergent building blocks of helices and almost planar sheets. A simple coarse-grained geometrical model of a flexible tube barely subject to compaction provides a unified framework for understanding the common character of globular proteins.We argue that a recent critique of the tube idea is not well founded.
q-bio.BM:To gain a deeper insight into cellular processes such as transcription and translation, one needs to uncover the mechanisms controlling the configurational changes of nucleic acids. As a step toward this aim, we present here a novel mesoscopic-level computational model that provides a new window into nucleic acid dynamics. We model a single-stranded nucleic as a polymer chain whose monomers are the nucleosides. Each monomer comprises a bead representing the sugar molecule and a pin representing the base. The bead-pin complex can rotate about the backbone of the chain. We consider pairwise stacking and hydrogen-bonding interactions. We use a modified Monte Carlo dynamics that splits the dynamics into translational bead motion and rotational pin motion. By performing a number of tests we first show that our model is physically sound. We then focus on the study of a the kinetics of a DNA hairpin--a single-stranded molecule comprising two complementary segments joined by a non-complementary loop--studied experimentally. We find that results from our simulations agree with experimental observations, demonstrating that our model is a suitable tool for the investigation of the hybridization of single strands.
q-bio.BM:We investigate the folding behavior of protein sequences by numerically studying all sequences with maximally compact lattice model through exhaustive enumeration. We get the prion-like behavior of protein folding. Individual proteins remaining stable in the isolated native state may change their conformations when they aggregate. We observe the folding properties as the interfacial interaction strength changes, and find that the strength must be strong enough before the propagation of the most stable structures happens.
q-bio.BM:We review some of our recent results obtained within the scope of simple lattice models and Monte Carlo simulations that illustrate the role of native geometry in the folding kinetics of two state folders.
q-bio.BM:Ion channels are proteins with a hole down the middle embedded in cell membranes. Membranes form insulating structures and the channels through them allow and control the movement of charged particles, spherical ions, mostly Na+, K+, Ca++, and Cl-. Membranes contain hundreds or thousands of types of channels, fluctuating between open conducting, and closed insulating states. Channels control an enormous range of biological function by opening and closing in response to specific stimuli using mechanisms that are not yet understood in physical language. Open channels conduct current of charged particles following laws of Brownian movement of charged spheres rather like the laws of electrodiffusion of quasi-particles in semiconductors. Open channels select between similar ions using a combination of electrostatic and 'crowded charge' (Lennard-Jones) forces. The specific location of atoms and the exact atomic structure of the channel protein seems much less important than certain properties of the structure, namely the volume accessible to ions and the effective density of fixed and polarization charge. There is no sign of other chemical effects like delocalization of electron orbitals between ions and the channel protein. Channels play a role in biology as important as transistors in computers, and they use rather similar physics to perform part of that role. Understanding their fluctuations awaits physical insight into the source of the variance and mathematical analysis of the coupling of the fluctuations to the other components and forces of the system.
q-bio.BM:We propose a criterion for optimal parameter selection in coarse-grained models of proteins, and develop a refined elastic network model (ENM) of bovine trypsinogen. The unimodal density-of-states distribution of the trypsinogen ENM disagrees with the bimodal distribution obtained from an all-atom model; however, the bimodal distribution is recovered by strengthening interactions between atoms that are backbone neighbors. We use the backbone-enhanced model to analyze allosteric mechanisms of trypsinogen, and find relatively strong communication between the regulatory and active sites.
q-bio.BM:The protonation of N2 bound to the active center of nitrogenase has been investigated using state-of-the-art DFT calculations. Dinitrogen in the bridging mode is activated by forming two bonds to Fe sites, which results in a reduction of the energy for the first hydrogen transfer by 123 kJ/mol. The axial binding mode with open sulfur bridge is less reactive by 30 kJ/mol and the energetic ordering of the axial and bridged binding mode is reversed in favor of the bridging dinitrogen during the first protonation. Protonation of the central ligand is thermodynamically favorable but kinetically hindered. If the central ligand is protonated, the proton is transferred to dinitrogen following the second protonation. Protonation of dinitrogen at the Mo site does not lead to low-energy intermediates.
q-bio.BM:The ejection of DNA from a bacterial virus (``phage'') into its host cell is a biologically important example of the translocation of a macromolecular chain along its length through a membrane. The simplest mechanism for this motion is diffusion, but in the case of phage ejection a significant driving force derives from the high degree of stress to which the DNA is subjected in the viral capsid. The translocation is further sped up by the ratcheting and entropic forces associated with proteins that bind to the viral DNA in the host cell cytoplasm. We formulate a generalized diffusion equation that includes these various pushing and pulling effects and make estimates of the corresponding speed-ups in the overall translocation process. Stress in the capsid is the dominant factor throughout early ejection, with the pull due to binding particles taking over at later stages. Confinement effects are also investigated, in the case where the phage injects its DNA into a volume comparable to the capsid size. Our results suggest a series of in vitro experiments involving the ejection of DNA into vesicles filled with varying amounts of binding proteins from phage whose state of stress is controlled by ambient salt conditions or by tuning genome length.
q-bio.BM:We present a base-pairing model of oligonuleotide duplex formation and show in detail its equivalence to the Nearest-Neighbour dimer methods from fits to free energy of duplex formation data for short DNA-DNA and DNA-RNA hybrids containing only Watson Crick pairs. In this approach the connection between rank-deficient polymer and rank-determinant oligonucleotide parameter, sets for DNA duplexes is transparent. The method is generalised to include RNA/DNA hybrids where the rank-deficient model with 11 dimer parameters in fact provides marginally improved predictions relative to the standard method with 16 independent dimer parameters ($\Delta G$ mean errors of 4.5 and 5.4 % respectively).
q-bio.BM:A formalism is developed which allows to determine the locations of all local symmetry axes of three-dimensional particles with overall icosahedral symmetry. It relies on the fact that the root system of the non-crystallographic Coxeter group H_3 encodes the locations of the planes of reflection that generate the discrete rotational symmetries of the particles. Via an appropriate extension of the root system, new planes of reflection are introduced which determine local axes of rotational symmetry. An easy-to-implement formalism is derived that allows to compute the surface structure of any three-dimensional icosahedral particle with local symmetries. It can be used also for particles with overall octahedral and tetrahedral symmetry in conjunction with the root systems of the corresponding reflection groups.   Applications to viruses are discussed explicitly. It is shown that the concept of quasi-equivalence in Caspar-Klug Theory corresponds to the special case of local six-fold symmetry axes contained in the theory developed here, and the corresponding geometries can hence be obtained with this formalism based on the root system of H_3.   Moreover, as a by-product, the theory answers the long-standing open question why only certain types of capsomeres, i.e. clusters of protein subunits, are observed in the surface structures of viruses. Since the types of the capsomeres are determined by the orders of the local symmetry axes on which they are located, the possible types of capsomeres are restricted by the spectrum of local symmetry axes allowed by the theory. Based on this we determine the spectrum of all capsomere types that may occur in viral capsids and give explicit examples for the lower-order cases.
q-bio.BM:The tethered-particle method is a single-molecule technique that has been used to explore the dynamics of a variety of macromolecules of biological interest. We give a theoretical analysis of the particle motions in such experiments. Our analysis reveals that the proximity of the tethered bead to a nearby surface (the microscope slide) gives rise to a volume-exclusion effect, resulting in an entropic force on the molecule. This force stretches the molecule, changing its statistical properties. In particular, the proximity of bead and surface brings about intriguing scaling relations between key observables (statistical moments of the bead) and parameters such as the bead size and contour length of the molecule. We present both approximate analytic solutions and numerical results for these effects in both flexible and semiflexible tethers. Finally, our results give a precise, experimentally-testable prediction for the probability distribution of the distance between the polymer attachment point and the center of the mobile bead.
q-bio.BM:The distribution of inequivalent geometries occurring during self-assembly of the major capsid protein in thermodynamic equilibrium is determined based on a master equation approach. These results are implemented to characterize the assembly of SV40 virus and to obtain information on the putative pathways controlling the progressive build-up of the SV40 capsid. The experimental testability of the predictions is assessed and an analysis of the geometries of the assembly intermediates on the dominant pathways is used to identify targets for antiviral drug design.
q-bio.BM:A vital constituent of a virus is its protein shell, called the viral capsid, that encapsulates and hence provides protection for the viral genome. Assembly models are developed for viral capsids built from protein building blocks that can assume different local bonding structures in the capsid. This situation occurs, for example, for viruses in the family of Papovaviridae, which are linked to cancer and are hence of particular interest for the health sector. More specifically, the viral capsids of the (pseudo-) T=7 particles in this family consist of pentamers that exhibit two different types of bonding structures. While this scenario cannot be described mathematically in terms of Caspar-Klug Theory (Caspar and Klug 1962), it can be modelled via tiling theory (Twarock 2004). The latter is used to encode the local bonding environment of the building blocks in a combinatorial structure, called the assembly tree, which is a basic ingredient in the derivation of assembly models for Papovaviridae along the lines of the equilibrium approach of Zlotnick (Zlotnick 1994). A phase space formalism is introduced to characterize the changes in the assembly pathways and intermediates triggered by the variations in the association energies characterizing the bonds between the building blocks in the capsid. Furthermore, the assembly pathways and concentrations of the statistically dominant assembly intermediates are determined. The example of Simian Virus 40 is discussed in detail.
q-bio.BM:We calculate the equation of state of DNA under tension for the case that the DNA features loops. Such loops occur transiently during DNA condensation in the presence of multivalent ions or sliding cationic protein linkers. The force-extension relation of such looped DNA modelled as a wormlike chain is calculated via path integration in the semiclassical limit. This allows us to determine rigorously the high stretching asymptotics. Notably the functional form of the force-extension curve resembles that of straight DNA, yet with a strongly renormalized apparent persistence length. That means that the experimentally extracted single molecule elasticity does not necessarily reflect the bare DNA stiffness only, but can also contain additional contributions that depend on the overall chain conformation and length.
q-bio.BM:A generalized computational method for folding proteins with a fully transferable potential and geometrically realistic all-atom model is presented and tested on seven different helix bundle proteins. The protocol, which includes graph-theoretical analysis of the ensemble of resulting folded conformations, was systematically applied and consistently produced structure predictions of approximately 3 Angstroms without any knowledge of the native state. To measure and understand the significance of the results, extensive control simulations were conducted. Graph theoretic analysis provides a means for systematically identifying the native fold and provides physical insight, conceptually linking the results to modern theoretical views of protein folding. In addition to presenting a method for prediction of structure and folding mechanism, our model suggests that a accurate all-atom amino acid representation coupled with a physically reasonable atomic interaction potential (that does not require optimization to the test set) and hydrogen bonding are essential features for a realistic protein model.
q-bio.BM:Being the HIV-1 Protease (HIV-1-PR) an essential enzyme in the viral life cycle, its inhibition can control AIDS. The folding of single domain proteins, like each of the monomers forming the HIV-1-PR homodimer, is controlled by local elementary structures (LES, folding units stabilized by strongly interacting, highly conserved, as a rule hydrophobic, amino acids). These LES have evolved over myriad of generations to recognize and strongly attract each other, so as to make the protein fold fast and be stable in its native conformation. Consequently, peptides displaying a sequence identical to those segments of the monomers associated with LES are expected to act as competitive inhibitors and thus destabilize the native structure of the enzyme. These inhibitors are unlikely to lead to escape mutants as they bind to the protease monomers through highly conserved amino acids which play an essential role in the folding process. The properties of one of the most promising inhibitors of the folding of the HIV-1-PR monomers found among these peptides is demonstrated with the help of spectrophotometric assays and CD spectroscopy.
q-bio.BM:It is shown that a small subset of modes which are likely to be involved in protein functional motions of large amplitude can be determined by retaining the most robust normal modes obtained using different protein models. This result should prove helpful in the context of several applications proposed recently, like for solving difficult molecular replacement problems or for fitting atomic structures into low-resolution electron density maps. Moreover, it may also pave the way for the development of methods allowing to predict such motions accurately.
q-bio.BM:A new formalism for calculation of the partition function of single stranded nucleic acids is presented. Secondary structures and the topology of structure elements are the level of resolution that is used. The folding model deals with matches, mismatches, symmetric and asymmetric interior loops, stacked pairs in loop and dangling end regions, multi-branched loops, bulges and single base stacking that might exist at duplex ends or at the ends of helices. Calculations on short and long sequences show, that for short oligonucleotides, a duplex formation often displays a two-state transition. However, for longer oligonucleotides, the thermodynamic properties of the single self-folding transition affects the transition nature of the duplex formation, resulting in a population of intermediate hairpin species in the solution. The role of intermediate hairpin species is analyzed in the case when a short oligonucleotides (molecular beacons) have to reliably identify and hybridize to accessible nucleotides within their targeted mRNA sequences. It is shown that the enhanced specificity of the molecular beacons is a result of their constrained conformational flexibility and the all-or-none mechanism of their hybridization to the target sequence.
q-bio.BM:A vital constituent of a virus is its protein shell, called the viral capsid, that encapsulates and hence provides protection for the viral genome. Viral capsids are usually spherical, and for a significant number of viruses exhibit overall icosahedral symmetry. The corresponding surface lattices, that encode the locations of the capsid proteins and intersubunit bonds, can be modelled by Viral Tiling Theory.   It has been shown in vitro that under a variation of the experimental boundary conditions, such as the pH value and salt concentration, tubular particles may appear instead of, or in addition to, spherical ones. In order to develop models that describe the simultaneous assembly of both spherical and tubular variants, and hence study the possibility of triggering tubular malformations as a means of interference with the replication mechanism, Viral Tiling Theory has to be extended to include tubular lattices with end caps. This is done here for the case of Papovaviridae, which play a distinguished role from the viral structural point of view as they correspond to all pentamer lattices, i.e. lattices formed from clusters of five protein subunits throughout. These results pave the way for a generalisation of recently developed assembly models.
q-bio.BM:Experimental investigations of the biosynthesis of a number of proteins have pointed out that part of the native structure can be acquired already during translation. We carried out a comprehensive statistical analysis of some average structural properties of proteins that have been put forward as possible signatures of this progressive buildup process. Contrary to a widespread belief, it is found that there is no major propensity of the amino acids to form contacts with residues that are closer to the N terminus. Moreover, it is found that the C terminus is significantly more compact and locally-organized than the N one. Also this bias, though, is unlikely to be related to vectorial effects, since it correlates with subtle differences in the primary sequence. These findings indicate that even if proteins aquire their structure vectorially no signature of this seems to be detectable in their average structural properties.
q-bio.BM:The aim of this article is to present a developed method that decomposes the autofluorescence spectrum into the spectra of naturally occurring biochemical components of biotissue. It requires knowledge of detailed spectrum behaviour of different endogenous fluorophores. We have studied the main bio-markers in human tissue and proposed a simple modelling algorithm for their spectra shapes. The empirical method was tested theoretically by quantum-mechanical calculations of the spectra in the unharmonic Morse potential approach.
q-bio.BM:Experimental evidence suggests that the folding and aggregation of the amyloid $\beta$-protein (A$\beta$) into oligomers is a key pathogenetic event in Alzheimer's disease (AD). Inhibiting the pathologic folding and oligomerization of A$\beta$ could be effective in the prevention and treatment of AD. Here, using all-atom molecular dynamics simulations in explicit solvent, we probe the initial stages of folding of a decapeptide segment of A$\beta$, A$\beta_{21-30}$, shown experimentally to nucleate the folding process. In addition, we examine the folding of a homologous decapeptide containing an amino acid substitution linked to hereditary cerebral hemorrhage with amyloidosis--Dutch type, [Gln22]A$\beta_{21-30}$. We find that: (i) when the decapeptide is in water, hydrophobic interactions and transient salt bridges between Lys28 and either Glu22 or Asp23 are important in the formation of a loop in the Val24--Lys28 region of the wild type decapeptide; (ii) in the presence of salt ions, salt bridges play a more prominent role in the stabilization of the loop; (iii) in water with a reduced density, the decapeptide forms a helix, indicating the sensitivity of folding to different aqueous environments; (iv) the ``Dutch'' peptide in water, in contrast to the wild type peptide, fails to form a long-lived Val24--Lys28 loop, suggesting that loop stability is a critical factor in determining whether A$\beta$ folds into pathologic structures. Our results are relevant to understand the mechanism of A$\beta$ peptide folding in different environments, such as intra- and extracellular milieus or cell membranes, and how amino acid substitutions linked to familial forms of amyloidosis cause disease.
q-bio.BM:This paper was withdrawn by the authors.
q-bio.BM:We develop a class of models with which we simulate the assembly of particles into T1 capsid-like objects using Newtonian dynamics. By simulating assembly for many different values of system parameters, we vary the forces that drive assembly. For some ranges of parameters, assembly is facile, while for others, assembly is dynamically frustrated by kinetic traps corresponding to malformed or incompletely formed capsids. Our simulations sample many independent trajectories at various capsomer concentrations, allowing for statistically meaningful conclusions. Depending on subunit (i.e., capsomer) geometries, successful assembly proceeds by several mechanisms involving binding of intermediates of various sizes. We discuss the relationship between these mechanisms and experimental evaluations of capsid assembly processes.
q-bio.BM:In this paper the heat transport in microtubules (MT) is investigated. When the dimension of the structure is of the order of the de Broglie wave length the transport phenomena must be analyzed within quantum mechanics. In this paper we developed the Dirac type thermal equation for MT .The solution of the equation-the temperature fields for electrons can be wave type or diffusion type depending on the dynamics of the scattering. Key words: Microtubules ultrashort laser pulses, Dirac thermal equation, temperature fields.
q-bio.BM:Mouse prion protein PrP106-126 is a peptide corresponding to the residues 107-127 of human prion protein. It has been shown that PrP106-126 can reproduce the main neuropathological features of prionrelated transmissible spongiform encephalopathies and can form amyloid-like fibrils in vitro. The conformational characteristics of PrP106-126 fibril have been investigated by electron microscopy, CD spectroscopy, NMR and molecular dynamics simulations. Recent researches have found out that PrP106-126 in water assumes a stable structure consisting of two parallel beta-sheets that are tightly packed against each other. In this work we perform molecular dynamics simulation to reveal the elongation mechanism of PrP106-126 fibril. Influenced by the edge strands of the fibril which already adopt beta-sheets conformation, single PrP106-126 peptide forms beta-structure and becomes a new element of the fibril. Under acidic condition, single PrP106-126 peptide adopts a much larger variety of conformations than it does under neural condition, which makes a peptide easier to be influenced by the edge strands of the fibril. However, acidic condition dose not largely affect the stability of PrP106-126 peptide fibril. Thus, the speed of fibril elongation can be dramatically increased by lowering the pH value of the solution. The pH value was adjusted by either changing the protonation state of the residues or adding hydronium ions (acidic solution) or hydroxyl ions (alkaline solution). The differences between these two approaches are analyzed here.
q-bio.BM:The thermodynamics of the small SH3 protein domain is studied by means of a simplified model where each bead-like amino acid interacts with the others through a contact potential controlled by a 20x20 random matrix. Good folding sequences, characterized by a low native energy, display three main thermodynamical phases, namely a coil-like phase, an unfolded globule and a folded phase (plus other two phases, namely frozen and random coil, populated only at extremes temperatures). Interestingly, the unfolded globule has some regions already structured. Poorly designed sequences, on the other hand, display a wide transition from the random coil to a frozen state. The comparison with the analytic theory of heteropolymers is discussed.
q-bio.BM:In a seminal paper Caspar and Klug established a theory that provides a family of polyhedra as blueprints for the structural organisation of viral capsids. In particular, they encode the locations of the proteins in the shells that encapsulate, and hence provide protection for, the viral genome. Despite of its huge success and numerous applications in virology experimental results have provided evidence for the fact that the theory is too restrictive to describe all known viruses. Especially, the family of Papovaviridae, which contains cancer-causing viruses, falls out of the scope of this theory.   In a recent paper we have shown that certain members of the family of Papovaviridae can be described via tilings. In this paper, we develop a comprehensive mathematical framework for the derivation of all surface structures of viral particles in this family. We show that this formalism fixes the structure and relative sizes of all particles collectively so that there exists only one scaling factor that relates the sizes of all particles with their biological counterparts.   The series of polyhedra derived here complements the Caspar-Klug family of polyhedra. It is the first mathematical result that provides a common organisational principle for different types of viral particles in the family of Papovaviridae and paves the way for an understanding of Papovaviridae polymorphism. Moreover, it provides crucial input for the construction of assembly models.
q-bio.BM:The amino acid sequences of proteins provide rich information for inferring distant phylogenetic relationships and for predicting protein functions. Estimating the rate matrix of residue substitutions from amino acid sequences is also important because the rate matrix can be used to develop scoring matrices for sequence alignment. Here we use a continuous time Markov process to model the substitution rates of residues and develop a Bayesian Markov chain Monte Carlo method for rate estimation. We validate our method using simulated artificial protein sequences. Because different local regions such as binding surfaces and the protein interior core experience different selection pressures due to functional or stability constraints, we use our method to estimate the substitution rates of local regions. Our results show that the substitution rates are very different for residues in the buried core and residues on the solvent exposed surfaces. In addition, the rest of the proteins on the binding surfaces also have very different substitution rates from residues. Based on these findings, we further develop a method for protein function prediction by surface matching using scoring matrices derived from estimated substitution rates for residues located on the binding surfaces. We show with examples that our method is effective in identifying functionally related proteins that have overall low sequence identity, a task known to be very challenging.
q-bio.BM:This chapter discusses geometric models of biomolecules and geometric constructs, including the union of ball model, the weigthed Voronoi diagram, the weighted Delaunay triangulation, and the alpha shapes. These geometric constructs enable fast and analytical computaton of shapes of biomoleculres (including features such as voids and pockets) and metric properties (such as area and volume). The algorithms of Delaunay triangulation, computation of voids and pockets, as well volume/area computation are also described. In addition, applications in packing analysis of protein structures and protein function prediction are also discussed.
q-bio.BM:This chapter discusses theoretical framework and methods for developing knowledge-based potential functions essential for protein structure prediction, protein-protein interaction, and protein sequence design. We discuss in some details about the Miyazawa-Jernigan contact statistical potential, distance-dependent statistical potentials, as well as geometric statistical potentials. We also describe a geometric model for developing both linear and non-linear potential functions by optimization. Applications of knowledge-based potential functions in protein-decoy discrimination, in protein-protein interactions, and in protein design are then described. Several issues of knowledge-based potential functions are finally discussed.
q-bio.BM:$\beta$-barrel membrane proteins are found in the outer membrane of gram-negative bacteria, mitochondria, and chloroplasts. We have developed probabilistic models to quantify propensities of residues for different spatial locations and for interstrand pairwise contact interactions involving strong H-bonds, side-chain interactions, and weak H-bonds. The propensity values and p-values measuring statistical significance are calculated exactly by analytical formulae we have developed. Contrary to the ``positive-inside'' rule for helical membrane proteins, $\beta$-barrel membrane proteins follow a significant albeit weaker ``positive-outside'' rule, in that the basic residues Arg and Lys are disproportionately favored in the extracellular cap region and disfavored in the periplasmic cap region. Different residue pairs prefer strong backbone H-bonded interstrand pairings (e.g. Gly-Aromatic) or non-H-bonded pairings (e.g. Aromatic-Aromatic). In addition, Tyr and Phe participate in aromatic rescue by shielding Gly from polar environments. These propensities can be used to predict the registration of strand pairs, an important task for the structure prediction of $\beta$-barrel membrane proteins. Our accuracy of 44% is considerably better than random (7%) and other studies. Our results imply several experiments that can help to elucidate the mechanisms of in vitro and in vivo folding of $\beta$-barrel membrane proteins. See supplementary material after the bibliography for detailed techniques.
q-bio.BM:An effective potential function is critical for protein structure prediction and folding simulation. Simplified protein models such as those requiring only $C_\alpha$ or backbone atoms are attractive because they enable efficient search of the conformational space. We show residue specific reduced discrete state models can represent the backbone conformations of proteins with small RMSD values. However, no potential functions exist that are designed for such simplified protein models. In this study, we develop optimal potential functions by combining contact interaction descriptors and local sequence-structure descriptors. The form of the potential function is a weighted linear sum of all descriptors, and the optimal weight coefficients are obtained through optimization using both native and decoy structures. The performance of the potential function in test of discriminating native protein structures from decoys is evaluated using several benchmark decoy sets. Our potential function requiring only backbone atoms or $C_\alpha$ atoms have comparable or better performance than several residue-based potential functions that require additional coordinates of side chain centers or coordinates of all side chain atoms. By reducing the residue alphabets down to size 5 for local structure-sequence relationship, the performance of the potential function can be further improved. Our results also suggest that local sequence-structure correlation may play important role in reducing the entropic cost of protein folding.
q-bio.BM:Without invoking the Markov approximation, we derive formulas for vibrational energy relaxation (VER) and dephasing for an anharmonic system oscillator using a time-dependent perturbation theory. The system-bath Hamiltonian contains more than the third order coupling terms since we take a normal mode picture as a zeroth order approximation. When we invoke the Markov approximation, our theory reduces to the Maradudin-Fein formula which is used to describe VER properties of glass and proteins. When the system anharmonicity and the renormalization effect due to the environment vanishes, our formulas reduce to those derived by Mikami and Okazaki invoking the path-integral influence functional method [J. Chem. Phys. 121 (2004) 10052]. We apply our formulas to VER of the amide I mode of a small amino-acide like molecule, N-methylacetamide, in heavy water.
q-bio.BM:Simplified Go models, where only native contacts interact favorably, have proven useful to characterize some aspects of the folding of small proteins. The success of these models is limited by the fact that all residues interact in the same way, so that the folding features of a protein are determined only by the geometry of its native conformation. We present an extended version of a C-alpha based Go model where different residues interact with different energies. The model is used to calculate the thermodynamics of three small proteins (Protein G, SrcSH3 and CI2) and the effect of mutations on the wildtype sequence. The model allows to investigate some of the most controversial areas in protein folding such as its earliest stages, a subject which has lately received particular attention. The picture which emerges for the three proteins under study is that of a hierarchical process, where local elementary structures (LES) (not necessarily coincident with elements of secondary structure) are formed at the early stages of the folding and drive the protein, through the transition state and the postcritical folding nucleus (FN), resulting from the docking of the LES, to the native conformation.
q-bio.BM:The chiral nature of DNA plays a crucial role in cellular processes. Here we use magnetic tweezers to explore one of the signatures of this chirality, the coupling between stretch and twist deformations. We show that the extension of a stretched DNA molecule increases linearly by 0.42 nm per excess turn applied to the double helix. This result contradicts the intuition that DNA should lengthen as it is unwound and get shorter with overwinding. We then present numerical results of energy minimizations of torsionally restrained DNA that display a behaviour similar to the experimental data and shed light on the molecular details of this surprising effect.
q-bio.BM:PCR (Polymerase Chain Reaction), a method which replicates a selected sequence of DNA, has revolutionized the study of genomic material, but mathematical study of the process has been limited to simple deterministic models or descriptions relying on stochastic processes. In this paper we develop a suite of deterministic models for the reactions of quantitative PCR (Polymerase Chain Reaction) based on the law of mass action. Maps are created from DNA copy number in one cycle to the next, with ordinary differential equations describing the evolution of difference molecular species during each cycle. Qualitative analysis is preformed at each stage and parameters are estimated by fitting each model to data from Roche LightCycler (TM) runs.
q-bio.BM:Kinetics of folding of a protein held in a force-clamp are compared to an unconstrained folding. The comparison is made within a simple topology-based dynamical model of ubiquitin. We demonstrate that the experimentally observed variations in the end-to-end distance reflect microscopic events during folding. However, the folding scenarios in and out of the force-clamp are distinct.
q-bio.BM:In the template-assistance model, normal prion protein (PrPC), the pathogenic cause of prion diseases such as Creutzfeldt-Jakob (CJD) in human, Bovine Spongiform Encephalopathy (BSE) in cow, and scrapie in sheep, converts to infectious prion (PrPSc) through an autocatalytic process triggered by a transient interaction between PrPC and PrPSc. Conventional studies suggest the S1-H1-S2 region in PrPC to be the template of S1-S2 $\beta$-sheet in PrPSc, and the conformational conversion of PrPC into PrPSc may involve an unfolding of H1 in PrPC and its refolding into the $\beta$-sheet in PrPSc. Here we conduct a series of simulation experiments to test the idea of transient interaction of the template-assistance model. We find that the integrity of H1 in PrPC is vulnerable to a transient interaction that alters the native dihedral angles at residue Asn$^{143}$, which connects the S1 flank to H1, but not to interactions that alter the internal structure of the S1 flank, nor to those that alter the relative orientation between H1 and the S2 flank.
q-bio.BM:The Yakushevich model of DNA torsion dynamics supports soliton solutions, which are supposed to be of special interest for DNA transcription. In the discussion of the model, one usually adopts the approximation $\ell_0 \to 0$, where $\ell_0$ is a parameter related to the equilibrium distance between bases in a Watson-Crick pair. Here we analyze the Yakushevich model without $\ell_0 \to 0$. The model still supports soliton solutions indexed by two winding numbers $(n,m)$; we discuss in detail the fundamental solitons, corresponding to winding numbers (1,0) and (0,1) respectively.
q-bio.BM:The Yakushevich (Y) model provides a very simple pictures of DNA torsion dynamics, yet yields remarkably correct predictions on certain physical characteristics of the dynamics. In the standard Y model, the interaction between bases of a pair is modelled by a harmonic potential, which becomes anharmonic when described in terms of the rotation angles; here we substitute to this different types of improved potentials, providing a more physical description of the H-bond mediated interactions between the bases. We focus in particular on soliton solutions; the Y model predicts the correct size of the nonlinear excitations supposed to model the ``transcription bubbles'', and this is essentially unchanged with the improved potential. Other features of soliton dynamics, in particular curvature of soliton field configurations and the Peierls-Nabarro barrier, are instead significantly changed.
q-bio.BM:Simple coarse-grained models, such as the Gaussian Network Model, have been shown to capture some of the features of equilibrium protein dynamics. We extend this model by using atomic contacts to define residue interactions and introducing more than one interaction parameter between residues. We use B-factors from 98 ultra-high resolution X-ray crystal structures to optimize the interaction parameters. The average correlation between GNM fluctuation predictions and the B-factors is 0.64 for the data set, consistent with a previous large-scale study. By separating residue interactions into covalent and noncovalent, we achieve an average correlation of 0.74, and addition of ligands and cofactors further improves the correlation to 0.75. However, further separating the noncovalent interactions into nonpolar, polar, and mixed yields no significant improvement. The addition of simple chemical information results in better prediction quality without increasing the size of the coarse-grained model.
q-bio.BM:Background: One-dimensional protein structures such as secondary structures or contact numbers are useful for three-dimensional structure prediction and helpful for intuitive understanding of the sequence-structure relationship. Accurate prediction methods will serve as a basis for these and other purposes. Results: We implemented a program CRNPRED which predicts secondary structures, contact numbers and residue-wise contact orders. This program is based on a novel machine learning scheme called critical random networks. Unlike most conventional one-dimensional structure prediction methods which are based on local windows of an amino acid sequence, CRNPRED takes into account the whole sequence. CRNPRED achieves, on average per chain, Q3 = 81% for secondary structure prediction, and correlation coefficients of 0.75 and 0.61 for contact number and residue-wise contact order predictions, respectively. Conclusion: CRNPRED will be a useful tool for computational as well as experimental biologists who need accurate one-dimensional protein structure predictions.
q-bio.BM:To confer high specificity and affinity in binding, contacts at interfaces between two interacting macromolecules are expected to exhibit pair preferences for types of atoms or residues. Here we quantify these preferences by measuring the mutual information of contacts for 895 protein-protein interfaces. The information content is significant and is highest at the atomic resolution. A simple phenomenological theory reveals a connection between information at interfaces and the free energy spectrum of association. The connection is presented in the form of a relation between mutual information and the energy gap of the native bound state to off-target bound states. Measurement of information content in designed lattice interfaces show the predicted scaling behavior to the energy gap. Our theory also suggests that mutual information in contacts emerges by a selection mechanism, and that strong selection, or high conservation, of residues should lead to correspondingly high mutual information. Amino acids which contribute more heavily to information content are then expected to be more conserved. We verify this by showing a statistically significant correlation between the conservation of each of the twenty amino acids and their individual contribution to the information content at protein-protein interfaces
q-bio.BM:It was first suggested by Englander et al to model the nonlinear dynamics of DNA relevant to the transcription process in terms of a chain of coupled pendulums. In a related paper [q-bio.BM/0604014] we argued for the advantages of an extension of this approach based on considering a chain of double pendulums with certain characteristics. Here we study a simplified model of this kind, focusing on its general features and nonlinear travelling wave excitations; in particular, we show that some of the degrees of freedom are actually slaved to others, allowing for an effective reduction of the relevant equations.
q-bio.BM:The Fast Fourier Transform (FFT) correlation approach to protein-protein docking can evaluate the energies of billions of docked conformations on a grid if the energy is described in the form of a correlation function. Here, this restriction is removed, and the approach is efficiently used with pairwise interactions potentials that substantially improve the docking results. The basic idea is approximating the interaction matrix by its eigenvectors corresponding to the few dominant eigenvalues, resulting in an energy expression written as the sum of a few correlation functions, and solving the problem by repeated FFT calculations. In addition to describing how the method is implemented, we present a novel class of structure based pairwise intermolecular potentials. The DARS (Decoys As the Reference State) potentials are extracted from structures of protein-protein complexes and use large sets of docked conformations as decoys to derive atom pair distributions in the reference state. The current version of the DARS potential works well for enzyme-inhibitor complexes. With the new FFT-based program, DARS provides much better docking results than the earlier approaches, in many cases generating 50\% more near-native docked conformations. Although the potential is far from optimal for antibody-antigen pairs, the results are still slightly better than those given by an earlier FFT method. The docking program PIPER is freely available for non-commercial applications.
q-bio.BM:We investigated the structural relaxation of myosin motor domain from the pre-power stroke state to the near-rigor state using molecular dynamics simulation of a coarse-grained protein model. To describe the structural change, we propose a "dual Go-model," a variant of the Go-like model that has two reference structures. The nucleotide dissociation process is also studied by introducing a coarse-grained nucleotide in the simulation. We found that the myosin structural relaxation toward the near-rigor conformation cannot be completed before the nucleotide dissociation. Moreover, the relaxation and the dissociation occurred cooperatively when the nucleotide was tightly bound to the myosin head. The result suggested that the primary role of the nucleotide is to suppress the structural relaxation.
q-bio.BM:Self-similar properties of the ribosome in terms of the mass fractal dimension are investigated. We find that both the 30S subunit and the 16S rRNA have fractal dimensions of 2.58 and 2.82, respectively; while the 50S subunit as well as the 23S rRNA has the mass fractal dimension close to 3, implying a compact three dimensional macromolecule. This finding supports the dynamic and active role of the 30S subunit in the protein synthesis, in contrast to the pass role of the 50S subunit.
q-bio.BM:We present an extremely simplified model of multiple-domains polymer stretching in an atomic force microscopy experiment. We portray each module as a binary set of contacts and decompose the system energy into a harmonic term (the cantilever) and long-range interactions terms inside each domain. Exact equilibrium computations and Monte Carlo simulations qualitatively reproduce the experimental saw-tooth pattern of force-extension profiles, corresponding (in our model) to first-order phase transitions. We study the influence of the coupling induced by the cantilever and the pulling speed on the relative heights of the force peaks. The results suggest that the increasing height of the critical force for subsequent unfolding events is an out-of-equilibrium effect due to a finite pulling speed. The dependence of the average unfolding force on the pulling speed is shown to reproduce the experimental logarithmic law.
q-bio.BM:Phi-values are experimental measures of the effects of mutations on the folding kinetics of a protein. A central question is which structural information Phi-values contain about the transition state of folding. Traditionally, a Phi-value is interpreted as the 'nativeness' of a mutated residue in the transition state. However, this interpretation is often problematic because it assumes a linear relation between the nativeness of the residue and its free-energy contribution. We present here a better structural interpretation of Phi-values for mutations within a given helix. Our interpretation is based on a simple physical model that distinguishes between secondary and tertiary free-energy contributions of helical residues. From a linear fit of our model to the experimental data, we obtain two structural parameters: the extent of helix formation in the transition state, and the nativeness of tertiary interactions in the transition state. We apply our model to all proteins with well-characterized helices for which more than 10 Phi-values are available: protein A, CI2, and protein L. The model captures nonclassical Phi-values <0 or >1 in these helices, and explains how different mutations at a given site can lead to different Phi-values.
q-bio.BM:A model for the unidirectional movement of dynein is presented based on structural observations and biochemical experimental results available. In this model, the binding affinity of dynein for microtubule is independent of its nucleotide state and the change between strong and weak microtubule-binding is determined naturally by the variation of relative orientation between the stalk and microtubule as the stalk rotates following nucleotide-state transition. Thus the enigmatic communication from the ATP binding site in the globular domain to the far MT-binding site in the tip of the stalk, which is prerequisite in conventional models, is not required. Using the present model, the previous experimental results such as the effect of ATP and ADP bindings on dissociation of dynein from microtubule, the processive movement of single-headed axonemal dyneins at saturating ATP concentration, the load dependence of step size for the processive movement of two-headed cytoplasmic dyneins and the dependence of stall force on ATP concentration can be well explained.
q-bio.BM:Over the last 10-15 years a general understanding of the chemical reaction of protein folding has emerged from statistical mechanics. The lessons learned from protein folding kinetics based on energy landscape ideas have benefited protein structure prediction, in particular the development of coarse grained models. We survey results from blind structure prediction. We explore how second generation prediction energy functions can be developed by introducing information from an ensemble of previously simulated structures. This procedure relies on the assumption of a funnelled energy landscape keeping with the principle of minimal frustration. First generation simulated structures provide an improved input for associative memory energy functions in comparison to the experimental protein structures chosen on the basis of sequence alignment.
q-bio.BM:The precise details of how myosin-V coordinates the biochemical reactions and mechanical motions of its two head elements to engineer effective processive molecular motion along actin filaments remain unresolved. We compare a quantitative kinetic model of the myosin-V walk, consisting of five basic states augmented by two further states to allow for futile hydrolysis and detachments, with experimental results for run lengths, velocities, and dwell times and their dependence on bulk nucleotide concentrations and external loads in both directions. The model reveals how myosin-V can use the internal strain in the molecule to synchronise the motion of the head elements. Estimates for the rate constants in the reaction cycle and the internal strain energy are obtained by a computational comparison scheme involving an extensive exploration of the large parameter space. This scheme exploits the fact that we have obtained analytic results for our reaction network, e.g. for the velocity but also the run length, diffusion constant and fraction of backward steps. The agreement with experiment is often reasonable but some open problems are highlighted, in particular the inability of such a general model to reproduce the reported dependence of run length on ADP. The novel way that our approach explores parameter space means that any confirmed discrepancies should give new insights into the reaction network model.
q-bio.BM:The prion protein (PrP) binds Cu2+ ions in the octarepeat domain of the N-terminal tail up to full occupancy at pH=7.4. Recent experiments show that the HGGG octarepeat subdomain is responsible for holding the metal bound in a square planar coordination. By using first principle ab initio molecular dynamics simulations of the Car-Parrinello type, the Cu coordination mode to the binding sites of the PrP octarepeat region is investigated. Simulations are carried out for a number of structured binding sites. Results for the complexes Cu(HGGGW)+(wat), Cu(HGGG) and the 2[Cu(HGGG)] dimer are presented. While the presence of a Trp residue and a H2O molecule does not seem to affect the nature of the Cu coordination, high stability of the bond between Cu and the amide Nitrogens of deprotonated Gly's is confirmed in the case of the Cu(HGGG) system. For the more interesting 2[Cu(HGGG)] dimer a dynamically entangled arrangement of the two monomers, with intertwined N-Cu bonds, emerges. This observation is consistent with the highly packed structure seen in experiments at full Cu occupancy.
q-bio.BM:We formulate a simple solvation potential based on a coarsed-grain representation of amino acids with two spheres modeling the $C_\alpha$ atom and an effective side-chain centroid. The potential relies on a new method for estimating the buried area of residues, based on counting the effective number of burying neighbours in a suitable way. This latter quantity shows a good correlation with the buried area of residues computed from all atom crystallographic structures. We check the discriminatory power of the solvation potential alone to identify the native fold of a protein from a set of decoys and show the potential to be considerably selective.
q-bio.BM:The aim of this work is to elucidate how physical principles of protein design are reflected in natural sequences that evolved in response to the thermal conditions of the environment. Using an exactly solvable lattice model, we design sequences with selected thermal properties. Compositional analysis of designed model sequences and natural proteomes reveals a specific trend in amino acid compositions in response to the requirement of stability at elevated environmental temperature, i.e. the increase of fractions of hydrophobic and charged amino acid residues at the expense of polar ones. We show that this from both ends of hydrophobicity scale trend is due to positive (to stabilize the native state) and negative (to destabilize misfolded states) components of protein design. Negative design strengthens specific repulsive nonnative interactions that appear in misfolded structures. A pressure to preserve specific repulsive interactions in non-native conformations may result in correlated mutations between amino acids which are far apart in the native state but may be in contact in misfolded conformations. Such correlated mutations are indeed found in TIM barrel and other proteins.
q-bio.BM:F-actin bundles constitute principal components of a multitude of cytoskeletal processes including stereocilia, filopodia, microvilli, neurosensory bristles, cytoskeletal stress fibers, and the sperm acrosome. The bending, buckling, and stretching behaviors of these processes play key roles in cellular functions ranging from locomotion to mechanotransduction and fertilization. Despite their central importance to cellular function, F-actin bundle mechanics remain poorly understood. Here, we demonstrate that bundle bending stiffness is a state-dependent quantity with three distinct regimes that are mediated by bundle dimensions in addition to crosslink properties. We calculate the complete state-dependence of the bending stiffness and elucidate the mechanical origin of each. A generic set of design parameters delineating the regimes in state-space is derived and used to predict the bending stiffness of a variety of F-actin bundles found in cells. Finally, the broad and direct implications that the isolated state-dependence of F-actin bundle stiffness has on the interpretation of the bending, buckling, and stretching behavior of cytoskeletal bundles is addressed.
q-bio.BM:In this work we develop a theory of interaction of randomly patterned surfaces as a generic prototype model of protein-protein interactions. The theory predicts that pairs of randomly superimposed identical (homodimeric) random patterns have always twice as large magnitude of the energy fluctuations with respect to their mutual orientation, as compared with pairs of different (heterodimeric) random patterns. The amplitude of the energy fluctuations is proportional to the square of the average pattern density, to the square of the amplitude of the potential and its characteristic length, and scales linearly with the area of surfaces. The greater dispersion of interaction energies in the ensemble of homodimers implies that strongly attractive complexes of random surfaces are much more likely to be homodimers, rather than heterodimers. Our findings suggest a plausible physical reason for the anomalously high fraction of homodimers observed in real protein interaction networks.
q-bio.BM:We extend our previously developed general approach (1) to study a phenomenological model in which the simulated packing of hard, attractive spheres on a prolate spheroid surface with convexity constraints produces structures identical to those of prolate virus capsid structures. Our simulation approach combines the traditional Monte Carlo method with the method of random sampling on an ellipsoidal surface and a convex hull searching algorithm. Using this approach we study the assembly and structural origin of non-icosahedral, elongated virus capsids, such as two aberrant flock house virus (FHV) particles and the prolate prohead of bacteriophage phi29, and discuss the implication of our simulation results in the context of recent experimental findings.
q-bio.BM:The need to understand the assembly kinetics of fibril formation has become urgent because of the realization that soluble oligomers of amyloidogenic peptides may be even more neurotoxic than the end product, namely, the amyloid fibrils. In order to fully understand the routes to fibril formation one has to characterize the major species in the assembly pathways. The characterization of the energetics and dynamics of oligomers (dimers, trimers etc) is difficult using experiments alone because they undergo large conformational fluctuations. In this context, carefully planned molecular dynamics simulation studies, computations using coarse-grained models, and bioinformatic analysis have given considerable insights into the early events in the route to fibril formation. Here, we describe progress along this direction using examples taken largely from our own work. In this chapter, we focus on aspects of protein aggregation using Abeta-peptides and prion proteins as examples.
q-bio.BM:The native three dimensional structure of a single protein is determined by the physico chemical nature of its constituent amino acids. The twenty different types of amino acids, depending on their physico chemical properties, can be grouped into three major classes - hydrophobic, hydrophilic and charged. We have studied the anatomy of the weighted and unweighted networks of hydrophobic, hydrophilic and charged residues separately for a large number of proteins. Our results show that the average degree of the hydrophobic networks has significantly larger value than that of hydrophilic and charged networks. The average degree of the hydrophilic networks is slightly higher than that of charged networks. The average strength of the nodes of hydrophobic networks is nearly equal to that of the charged network; whereas that of hydrophilic networks has smaller value than that of hydrophobic and charged networks. The average strength for each of the three types of networks varies with its degree. The average strength of a node in charged networks increases more sharply than that of the hydrophobic and hydrophilic networks. Each of the three types of networks exhibits the 'small-world' property. Our results further indicate that the all amino acids' networks and hydrophobic networks are of assortative type. While maximum of the hydrophilic and charged networks are of assortative type, few others have the characteristics of disassortative mixing of the nodes. We have further observed that all amino acids' networks and hydrophobic networks bear the signature of hierarchy; whereas the hydrophilic and charged networks do not have any hierarchical signature.
q-bio.BM:We study statistical properties of interacting protein-like surfaces and predict two strong, related effects: (i) statistically enhanced self-attraction of proteins; (ii) statistically enhanced attraction of proteins with similar structures. The effects originate in the fact that the probability to find a pattern self-match between two identical, even randomly organized interacting protein surfaces is always higher compared with the probability for a pattern match between two different, promiscuous protein surfaces. This theoretical finding explains statistical prevalence of homodimers in protein-protein interaction networks reported earlier. Further, our findings are confirmed by the analysis of curated database of protein complexes that showed highly statistically significant overrepresentation of dimers formed by structurally similar proteins with highly divergent sequences (superfamily heterodimers). We predict that significant fraction of heterodimers evolved from homodimers with the negative design evolutionary pressure applied against promiscuous homodimer formation. This is achieved through the formation of highly specific contacts formed by charged residues as demonstrated both in model and real superfamily heterodimers
q-bio.BM:Stretching of a protein by a fluid flow is compared to that in a force-clamp apparatus. The comparison is made within a simple topology-based dynamical model of a protein in which the effects of the flow are implemented using Langevin dynamics. We demonstrate that unfolding induced by a uniform flow shows a richer behavior than that in the force clamp. The dynamics of unfolding is found to depend strongly on the selection of the amino acid, usually one of the termini, which is anchored. These features offer potentially wider diagnostic tools to investigate structure of proteins compared to experiments based on the atomic force microscopy.
q-bio.BM:Secretion and role of autotaxin and lysophosphatidic acid in adipose tissue In obesity, adipocyte hypertrophy is often associated with recrutement of new fat cells (adipogenesis) under the control of circulating and local regulatory factors. Among the different lipids released in the extracellular compartment of adipocytes, our group found the presence of lysophosphatidic acid (LPA). LPA is a bioactive phospholipid able to regulate several cell responses via the activation of specific G-protein coupled membrane receptors. Our group found that LPA increases preadipocyte proliferation and inhibits adipogenesis via the activation of LPA1 receptor subtype. Extracellular LPA-synthesis is catalyzed by a lysophospholipase D secreted by adipocytes : autotaxin (ATX). Adipocyte ATX expression strongly increases with adipogenesis as well as in individuals exhibiting type 2 diabetes associated with massive obesity. A possible contribution of ATX and LPA as paracrine regulators of adipogenesis and obesity associated diabetes is proposed.
q-bio.BM:A recently proposed model of non-autocatalytic reactions in dipeptide reactions leading to spontaneous symmetry breaking and homochirality is examined. The model is governed by activation, polymerization, epimerization and depolymerization of amino acids. Symmetry breaking is primarily a consequence of the fact that the rates of reactions involving homodimers and heterodimers are different, i.e., stereoselective, and on the fact that epimerization can only occur on the N-terminal residue and not on the Cterminal residue. This corresponds to an auto-inductive cyclic process that works only in one sense. It is argued that epimerization mimics both autocatalytic behavior as well as mutual antagonism - both of which were known to be crucial for producing full homochirality.
q-bio.BM:The structural organisation of the viral genome within its protein container, called the viral capsid, is an important aspect of virus architecture. Many single-stranded (ss) RNA viruses organise a significant part of their genome in a dodecahedral cage as a RNA duplex structure that mirrors the symmetry of the capsid. Bruinsma and Rudnick have suggested a model for the structural organisation of the RNA in these cages. It is the purpose of this paper to further develop their approach based on results from the areas of graph theory and DNA network engineering. We start by suggesting a scenario for pariacoto virus, a representative of this class of viruses, that is energetically more favorable than those derived previously. We then show that it is a representative of a whole family of cage structures that abide to the same construction principle, and then derive the energetically optimal configuration for a second family of cage structures along similar lines. Finally, we give reasons for the conjecture that these two families are more likely to occur in nature than other scenarios.
q-bio.BM:The sequence-dependent elasticity of double-helical DNA on a nm length scale can be captured by the rigid base-pair model, whose strains are the relative position and orientation of adjacent base-pairs. Corresponding elastic potentials have been obtained from all-atom MD simulation and from high-resolution structural data. On the scale of a hundred nm, DNA is successfully described by a continuous worm-like chain model with homogeneous elastic properties characterized by a set of four elastic constants, which have been directly measured in single-molecule experiments. We present here a theory that links these experiments on different scales, by systematically coarse-graining the rigid base-pair model for random sequence DNA to an effective worm-like chain description. The average helical geometry of the molecule is exactly taken into account in our approach. We find that the available microscopic parameters sets predict qualitatively similar mesoscopic parameters. The thermal bending and twisting persistence lengths computed from MD data are 42 and 48 nm, respectively. The static persistence lengths are generally much higher, in agreement with cyclization experiments. All microscopic parameter sets predict negative twist-stretch coupling. The variability and anisotropy of bending stiffness in short random chains lead to non-Gaussian bend angle distributions, but become unimportant after two helical turns.
q-bio.BM:Processive molecular motors take more-or-less uniformly sized steps, along spatially periodic tracks, mostly forwards but increasingly backwards under loads. Experimentally, the major steps can be resolved clearly within the noise but one knows biochemically that one or more mechanochemical substeps remain hidden in each enzymatic cycle. In order to properly interpret experimental data for back/forward step ratios, mean conditional step-to-step dwell times, etc., a first-passage analysis has been developed that takes account of hidden substeps in $N$-state sequential models. The explicit, general results differ significantly from previous treatments that identify the observed steps with complete mechanochemical cycles; e.g., the mean dwell times $\tau_+$ and $\tau_-$ prior to forward and back steps, respectively, are normally {\it unequal} although the dwell times $\tau_{++}$ and $\tau_{--}$ between {\it successive} forward and back steps are equal. Illustrative (N=2)-state examples display a wide range of behavior. The formulation extends to the case of two or more detectable transitions in a multistate cycle with hidden substeps.
q-bio.BM:For the vast majority of naturally occurring, small, single domain proteins folding is often described as a two-state process that lacks detectable intermediates. This observation has often been rationalized on the basis of a nucleation mechanism for protein folding whose basic premise is the idea that after completion of a specific set of contacts forming the so-called folding nucleus the native state is achieved promptly. Here we propose a methodology to identify folding nuclei in small lattice polymers and apply it to the study of protein molecules with chain length N=48. To investigate the extent to which protein topology is a robust determinant of the nucleation mechanism we compare the nucleation scenario of a native-centric model with that of a sequence specific model sharing the same native fold. To evaluate the impact of the sequence's finner details in the nucleation mechanism we consider the folding of two non- homologous sequences. We conclude that in a sequence-specific model the folding nucleus is, to some extent, formed by the most stable contacts in the protein and that the less stable linkages in the folding nucleus are solely determined by the fold's topology. We have also found that independently of protein sequence the folding nucleus performs the same `topological' function. This unifying feature of the nucleation mechanism results from the residues forming the folding nucleus being distributed along the protein chain in a similar and well-defined manner that is determined by the fold's topological features.
q-bio.BM:The folding of naturally occurring, single domain proteins is usually well-described as a simple, single exponential process lacking significant trapped states. Here we further explore the hypothesis that the smooth energy landscape this implies, and the rapid kinetics it engenders, arises due to the extraordinary thermodynamic cooperativity of protein folding. Studying Miyazawa-Jernigan lattice polymers we find that, even under conditions where the folding energy landscape is relatively optimized (designed sequences folding at their temperature of maximum folding rate), the folding of protein-like heteropolymers is accelerated when their thermodynamic cooperativity enhanced by enhancing the non-additivity of their energy potentials. At lower temperatures, where kinetic traps presumably play a more significant role in defining folding rates, we observe still greater cooperativity-induced acceleration. Consistent with these observations, we find that the folding kinetics of our computational models more closely approximate single-exponential behavior as their cooperativity approaches optimal levels. These observations suggest that the rapid folding of naturally occurring proteins is, at least in part, consequences of their remarkably cooperative folding.
q-bio.BM:An increasing number of proteins are being discovered with a remarkable and somewhat surprising feature, a knot in their native structures. How the polypeptide chain is able to knot itself during the folding process to form these highly intricate protein topologies is not known. Here, we perform a computational study on the 160-amino acid homodimeric protein YibK which, like other proteins in the SpoU family of MTases, contains a deep trefoil knot in its C-terminal region. In this study, we use a coarse-grained C-alpha-chain representation and Langevin dynamics to study folding kinetics. We find that specific, attractive nonnative interactions are critical for knot formation. In the absence of these interactions, i.e. in an energetics driven entirely by native interactions, knot formation is exceedingly unlikely. Further, we find, in concert with recent experimental data on YibK, two parallel folding pathways which we attribute to an early and a late formation of the trefoil knot, respectively. For both pathways, knot formation occurs before dimerization. A bioinformatics analysis of the SpoU family of proteins reveals further that the critical nonnative interactions may originate from evolutionary conserved hydrophobic segments around the knotted region.
q-bio.BM:The structure of the self-cleaving hairpin ribozyme is well characterized, and its folding has been examined in bulk and by single-molecule fluorescence, establishing the importance of cations, especially magnesium in the stability of the native fold. Here we describe the first all-atom folding simulations of the hairpin ribozyme, using a version of a Go potential with separate secondary and tertiary structure energetic contributions. The ratio of tertiary/secondary interaction energies serves as a proxy for non-specific cation binding: a high ratio corresponds to a high concentration, while a low one mimics low concentration. By studying the unfolding behavior of the RNA over a range of temperature and tertiary/secondary energies, a three-state phase diagram emerges, with folded, unfolded (coil) and transient folding/unfolding tertiary structure species. The thermodynamics were verified by paired folding simulations in each region of the phase diagram. The three phase behaviors correspond with experimentally observed states, so this simple model captures the essential aspect of thermodynamics in RNA folding.
q-bio.BM:The refolding from stretched initial conformations of ubiquitin (PDB ID: 1ubq) under the quenched force is studied using the Go model and the Langevin dynamics. It is shown that the refolding decouples the collapse and folding kinetics. The force quench refolding times scale as tau_F ~ exp(f_q*x_F/k_B*T), where f_q is the quench force and x_F = 0.96 nm is the location of the average transition state along the reaction coordinate given by the end-to-end distance. This value is close to x_F = 0.8 nm obtained from the force-clamp experiments. The mechanical and thermal unfolding pathways are studied and compared with the experimental and all-atom simulation results in detail. The sequencing of thermal unfolding was found to be markedly different from the mechanical one. It is found that fixing the N-terminus of ubiquitin changes its mechanical unfolding pathways much more drastically compared to the case when the C-end is anchored. We obtained the distance between the native state and the transition state x_UF=0.24 nm which is in reasonable agreement with the experimental data.
q-bio.BM:Natural proteins fold to a unique, thermodynamically dominant state. Modeling of the folding process and prediction of the native fold of proteins are two major unsolved problems in biophysics. Here, we show successful all-atom ab initio folding of a representative diverse set of proteins, using a minimalist transferable energy model that consists of two-body atom-atom interactions, hydrogen-bonding, and a local sequence energy term that models sequence-specific chain stiffness. Starting from a random coil, the native-like structure was observed during replica exchange Monte Carlo (REMC) simulation for most proteins regardless of their structural classes; the lowest energy structure was close to native- in the range of 2-6 A root-mean-square deviation (RMSD). Our results demonstrate that the successful all-atom folding of a protein chain to its native state is governed by only a few crucial energetic terms.
q-bio.BM:Protein-DNA interactions are vital for many processes in living cells, especially transcriptional regulation and DNA modification. To further our understanding of these important processes on the microscopic level, it is necessary that theoretical models describe the macromolecular interaction energetics accurately. While several methods have been proposed, there has not been a careful comparison of how well the different methods are able to predict biologically important quantities such as the correct DNA binding sequence, total binding free energy, and free energy changes caused by DNA mutation. In addition to carrying out the comparison, we present two important theoretical models developed initially in protein folding that have not yet been tried on protein-DNA interactions. In the process, we find that the results of these knowledge-based potentials show a strong dependence on the interaction distance and the derivation method. Finally, we present a knowledge-based potential that gives comparable or superior results to the best of the other methods, including the molecular mechanics force field AMBER99.
q-bio.BM:The folding of the alpha-helice domain hbSBD of the mammalian mitochondrial branched-chain alpha-ketoacid dehydrogenase (BCKD) complex is studied by the circular dichroism technique in absence of urea. Thermal denaturation is used to evaluate various thermodynamic parameters defining the equilibrium unfolding, which is well described by the two-state model with the folding temperature T_f = 317.8 K and the enthalpy change Delta H_g = 19.67 kcal/mol. The folding is also studied numerically using the off-lattice coarse-grained Go model and the Langevin dynamics. The obtained results, including the population of the native basin, the free energy landscape as a function of the number of native contacts and the folding kinetics, also suggest that the hbSBD domain is a two-state folder. These results are consistent with the biological function of hbSBD in BCKD.
q-bio.BM:We analyze the dependence of cooperativity of the thermal denaturation transition and folding rates of globular proteins on the number of amino acid residues, $N$, using lattice models with side chains,off-lattice Go models and the available experimental data. A dimensionless measure of cooperativity, $\Omega_c$ ($0 < \Omega_c < \infty$), scales as $\Omega_c \sim N^{\zeta}$. The results of simulations and the analysis of experimental data further confirm the earlier prediction that $\zeta$ is universal with $\zeta = 1 +\gamma$, where exponent $\gamma$ characterizes the susceptibility of a self-avoiding walk. This finding suggests that the structural characteristics in the denaturated state are manifested in the folding cooperativity at the transition temperature. The folding rates $k_F$ for the Go models and a dataset of 69 proteins can be fit using $k_F = k_F^0 \exp(-cN^\beta)$. Both $\beta = 1/2$ and 2/3 provide a good fit of the data. We find that $k_F = k_F^0 \exp(-cN^{{1/2}})$, with the average (over the dataset of proteins) $k_F^0 \approx (0.2\mu s)^{-1}$ and $c \approx 1.1$, can be used to estimate folding rates to within an order of magnitude in most cases. The minimal models give identical $N$ dependence with $c \approx 1$. The prefactor for off-lattice Go models is nearly four orders of magnitude larger than the experimental value.
q-bio.BM:The didemnins represent a versatile class of depsipeptides of marine origin and hold a great deal of potential for biomedical application. The biological and geographical origins of the didemnins are reviewed in addition to the chemical structures of the major didemnins. The biological mechanisms behind the antiviral and anticancer effects of selected didemnins are summarized and the special case of dehydrodidemnin B (Aplidin) is expounded upon including structural characteristics, synthesis, pharmacological mechanism and a discussion of its current clinical trials as an anticancer agent.
q-bio.BM:TThe paper had many errors.
q-bio.BM:Pathological folding and oligomer formation of the amyloid beta-protein (Abeta) are widely perceived as central to Alzheimer's disease (AD). Experimental approaches to study Abeta self-assembly are problematic, because most relevant aggregates are quasi-stable and inhomogeneous. We apply a discrete molecular dynamics (DMD) approach combined with a four-bead protein model to study oligomer formation of the amyloid beta-protein (Abeta). We address the differences between the two most common Abeta alloforms, Abeta40 and Abeta42, which oligomerize differently in vitro. We study how the presence of electrostatic interactions (EIs) between pairs of charged amino acids affects Abeta40 and Abeta42 oligomer formation. Our results indicate that EIs promote formation of larger oligomers in both Abeta40 and Abeta42. The Abeta40 size distribution remains unimodal, whereas the Abeta42 distribution is trimodal, as observed experimentally. Abeta42 folded structure is characterized by a turn in the C-terminus that is not present in Abeta40. We show that the same C-terminal region is also responsible for the strongest intermolecular contacts in Abeta42 pentamers and larger oligomers. Our results suggest that this C-terminal region plays a key role in the formation of Abeta42 oligomers and the relative importance of this region increases in the presence of EIs. These results suggest that inhibitors targeting the C-terminal region of Abeta42 oligomers may be able to prevent oligomer formation or structurally modify the assemblies to reduce their toxicity.
q-bio.BM:The results of Brownian dynamics simulations of a single DNA molecule in shear flow are presented taking into account the effect of internal viscosity. The dissipative mechanism of internal viscosity is proved necessary in the research of DNA dynamics. A stochastic model is derived on the basis of the balance equation for forces acting on the chain. The Euler method is applied to the solution of the model. The extensions of DNA molecules for different Weissenberg numbers are analyzed. Comparison with the experimental results available in the literature is carried out to estimate the contribution of the effect of internal viscosity.
q-bio.BM:The network paradigm is increasingly used to describe the topology and dynamics of complex systems. Here we review the results of the topological analysis of protein structures as molecular networks describing their small-world character, and the role of hubs and central network elements in governing enzyme activity, allosteric regulation, protein motor function, signal transduction and protein stability. We summarize available data how central network elements are enriched in active centers and ligand binding sites directing the dynamics of the entire protein. We assess the feasibility of conformational and energy networks to simplify the vast complexity of rugged energy landscapes and to predict protein folding and dynamics. Finally, we suggest that modular analysis, novel centrality measures, hierarchical representation of networks and the analysis of network dynamics will soon lead to an expansion of this field.
q-bio.BM:Annealed importance sampling is a means to assign equilibrium weights to a nonequilibrium sample that was generated by a simulated annealing protocol. The weights may then be used to calculate equilibrium averages, and also serve as an ``adiabatic signature'' of the chosen cooling schedule. In this paper we demonstrate the method on the 50-atom dileucine peptide, showing that equilibrium distributions are attained for manageable cooling schedules. For this system, as naively implemented here, the method is modestly more efficient than constant temperature simulation. However, the method is worth considering whenever any simulated heating or cooling is performed (as is often done at the beginning of a simulation project, or during an NMR structure calculation), as it is simple to implement and requires minimal additional CPU expense. Furthermore, the naive implementation presented here can be improved.
q-bio.BM:Conformational transitions in macromolecular complexes often involve the reorientation of lever-like structures. Using a simple theoretical model, we show that the rate of such transitions is drastically enhanced if the lever is bendable, e.g. at a localized "hinge''. Surprisingly, the transition is fastest with an intermediate flexibility of the hinge. In this intermediate regime, the transition rate is also least sensitive to the amount of "cargo'' attached to the lever arm, which could be exploited by molecular motors. To explain this effect, we generalize the Kramers-Langer theory for multi-dimensional barrier crossing to configuration dependent mobility matrices.
q-bio.BM:We report 10 successfully folding events of trpzip2 by molecular dynamics simulation. It is found that the trizip2 can fold into its native state through different zipper pathways, depending on the ways of forming hydrophobic core. We also find a very fast non-zipper pathway. This indicates that there may be no inconsistencies in the current pictures of beta-hairpin folding mechanisms. These pathways occur with different probabilities. zip-out is the most probable one. This may explain the recent experiment that the turn formation is the rate-limiting step for beta-hairpin folding.
q-bio.BM:Structural fluctuations in the thermal equilibrium of the kinesin motor domain are studied using a lattice protein model with Go interactions. By means of the multi-self-overlap ensemble (MSOE) Monte Carlo method and the principal component analysis (PCA), the free-energy landscape is obtained. It is shown that kinesins have two subdomains that exhibit partial folding/unfolding at functionally important regions: one is located around the nucleotide binding site and the other includes the main microtubule binding site. These subdomains are consistent with structural variability that was reported recently based on experimentally-obtained structures. On the other hand, such large structural fluctuations have not been captured by B-factor or normal mode analyses. Thus, they are beyond the elastic regime, and it is essential to take into account chain connectivity for studying the function of kinesins.
q-bio.BM:We introduce a topology-based nonlinear network model of protein dynamics with the aim of investigating the interplay of spatial disorder and nonlinearity. We show that spontaneous localization of energy occurs generically and is a site-dependent process. Localized modes of nonlinear origin form spontaneously in the stiffest parts of the structure and display site-dependent activation energies. Our results provide a straightforward way for understanding the recently discovered link between protein local stiffness and enzymatic activity. They strongly suggest that nonlinear phenomena may play an important role in enzyme function, allowing for energy storage during the catalytic process.
q-bio.BM:We incorporate hydrodynamic interactions in a structure-based model of ubiquitin and demonstrate that the hydrodynamic coupling may reduce the peak force when stretching the protein at constant speed, especially at larger speeds. Hydrodynamic interactions are also shown to facilitate unfolding at constant force and inhibit stretching by fluid flows.
q-bio.BM:We demonstrate a new algorithm for finding protein conformations that minimize a non-bonded energy function. The new algorithm, called the difference map, seeks to find an atomic configuration that is simultaneously in two constraint spaces. The first constraint space is the space of atomic configurations that have a valid peptide geometry, while the second is the space of configurations that have a non-bonded energy below a given target. These two constraint spaces are used to define a deterministic dynamical system, whose fixed points produce atomic configurations in the intersection of the two constraint spaces. The rate at which the difference map produces low energy protein conformations is compared with that of a contemporary search algorithm, parallel tempering. The results indicate the difference map finds low energy protein conformations at a significantly higher rate then parallel tempering.
q-bio.BM:Vibrational energy transfer of the amide I mode of N-methylacetamide (NMA) is studied theoretically using the vibrational configuration interaction method. A quartic force field of NMA is constructed at the B3LYP/6-31G+(d) level of theory and its accuarcy is checked by comparing the resulting anharmonic frequencies with available theoretical and experimental values. Quantum dynamics calculations for the amide I mode excitation clarify the dominant energy transfer pathways, which sensitively depend on the anharmonic couplings among vibrational modes. A ratio of the anharmonic coupling to the frequency mismatch is employed to predict and interpret the dominant energy flow pathways.
q-bio.BM:It previously has been discovered that visible light irradiation of crystalline substrates can lead to enhancement of subsequent enzymatic reaction rates as sharply peaked oscillatory functions of irradiation time. The particular activating irradiation times can vary with source of a given enzyme and thus, presumably, its molecular structure. The experiments reported here demonstrate that the potential for this anomalous enzyme reaction rate enhancement can be transferred from one bacterial species to another coincident with transfer of the genetic determinant for the relevant enzyme. In particular, the effect of crystal-irradiated chloramphenicol on growth of bacterial strains in which a transferable R-factor DNA plasmid coding for chloramphenicol resistance was or was not present (S. panama R+, E. coli R+, and E. coli R-) was determined. Chloramphenicol samples irradiated 10, 35 and 60 sec produced increased growth rates (diminished inhibition) for the resistant S. panama and E. coli strains, while having no such effect on growth rate of the sensitive E. coli strain. Consistent with past findings, chloramphenicol samples irradiated 5, 30 and 55 sec produced decreased growth rates (increased inhibition) for all three strains.
q-bio.BM:Inherent structure theory is used to discover strong connections between simple characteristics of protein structure and the energy landscape of a Go model. The potential energies and vibrational free energies of inherent structures are highly correlated, and both reflect simple measures of networks of native contacts. These connections have important consequences for models of protein dynamics and thermodynamics.
q-bio.BM:The free-energy landscape of the alpha-helix of protein G is studied by means of metadynamics coupled with a solute tempering algorithm. Metadynamics allows to overcome large energy barriers, whereas solute tempering improves the sampling with an affordable computational effort. From the sampled free-energy surface we are able to reproduce a number of experimental observations, such as the fact that the lowest minimum corresponds to a globular conformation displaying some degree of beta-structure, that the helical state is metastable and involves only 65% of the chain. The calculations also show that the system populates consistently a pi-helix state and that the hydrophobic staple motif is present only in the free-energy minimum associated with the helices, and contributes to their stabilization. The use of metadynamics coupled with solute tempering results then particularly suitable to provide the thermodynamics of a short peptide, and its computational efficiency is promising to deal with larger proteins.
q-bio.BM:Using a time-dependent perturbation theory, vibrational energy relaxation (VER) of isotopically labeled amide I modes in cytochrome c solvated with water is investigated. Contributions to the VER are decomposed into two contributions from the protein and water. The VER pathways are visualized using radial and angular excitation functions for resonant normal modes. Key differences of VER among different amide I modes are demonstrated, leading to a detailed picture of the spatial anisotropy of the VER. The results support the experimental observation that amide I modes in proteins relax with sub picosecond timescales, while the relaxation mechanism turns out to be sensitive to the environment of the amide I mode.
q-bio.BM:Local minima and the saddle points separating them in the energy landscape are known to dominate the dynamics of biopolymer folding. Here we introduce a notion of a "folding funnel" that is concisely defined in terms of energy minima and saddle points, while at the same time conforming to a notion of a "folding funnel" as it is discussed in the protein folding literature.
q-bio.BM:Using magnetic tweezers to investigate the mechanical response of single chromatin fibers, we show that fibers submitted to large positive torsion transiently trap positive turns, at a rate of one turn per nucleosome. A comparison with the response of fibers of tetrasomes (the (H3-H4)2 tetramer bound with ~50 bp of DNA) obtained by depletion of H2A-H2B dimers, suggests that the trapping reflects a nucleosome chiral transition to a metastable form built on the previously documented righthanded tetrasome. In view of its low energy, <8 kT, we propose this transition is physiologically relevant and serves to break the docking of the dimers on the tetramer which in the absence of other factors exerts a strong block against elongation of transcription by the main RNA polymerase.
q-bio.BM:We perform extensive Monte Carlo simulations of a lattice model and the Go potential to investigate the existence of folding pathways at the level of contact cluster formation for two native structures with markedly different geometries. Our analysis of folding pathways revealed a common underlying folding mechanism, based on nucleation phenomena, for both protein models. However, folding to the more complex geometry (i.e. that with more non-local contacts) is driven by a folding nucleus whose geometric traits more closely resemble those of the native fold. For this geometry folding is clearly a more cooperative process.
q-bio.BM:In this study we evaluate, at full atomic detail, the folding processes of two small helical proteins, the B domain of protein A and the Villin headpiece. Folding kinetics are studied by performing a large number of ab initio Monte Carlo folding simulations using a single transferable all-atom potential. Using these trajectories, we examine the relaxation behavior, secondary structure formation, and transition-state ensembles (TSEs) of the two proteins and compare our results with experimental data and previous computational studies. To obtain a detailed structural information on the folding dynamics viewed as an ensemble process, we perform a clustering analysis procedure based on graph theory. Moreover, rigorous pfold analysis is used to obtain representative samples of the TSEs and a good quantitative agreement between experimental and simulated Fi-values is obtained for protein A. Fi-values for Villin are also obtained and left as predictions to be tested by future experiments. Our analysis shows that two-helix hairpin is a common partially stable structural motif that gets formed prior to entering the TSE in the studied proteins. These results together with our earlier study of Engrailed Homeodomain and recent experimental studies provide a comprehensive, atomic-level picture of folding mechanics of three-helix bundle proteins.
q-bio.BM:Strong experimental and theoretical evidence shows that transcription factors and other specific DNA-binding proteins find their sites using a two-mode search: alternating between 3D diffusion through the cell and 1D sliding along the DNA. We consider the role spatial effects in the mechanism on two different scales. First, we reconcile recent experimental findings by showing that the 3D diffusion of the transcription factor is often local, i.e. the transcription factor lands quite near its dissociation site. Second, we discriminate between two types of searches: global searches and local searches. We show that these searches differ significantly in average search time and the variability of search time. Using experimentally measured parameter values, we also show that 1D and 3D search is not optimally balanced, leading to much larger estimates of search time. Together, these results lead to a number of biological implications including suggestions of how prokaryotes and eukaryotes achieve rapid gene regulation and the relationship between the search mechanism and noise in gene expression.
q-bio.BM:Thermal shape fluctuations of grafted microtubules were studied using high resolution particle tracking of attached fluorescent beads. First mode relaxation times were extracted from the mean square displacement in the transverse coordinate. For microtubules shorter than 10 um, the relaxation times were found to follow an L^2 dependence instead of L^4 as expected from the standard wormlike chain model. This length dependence is shown to result from a complex length dependence of the bending stiffness which can be understood as a result of the molecular architecture of microtubules. For microtubules shorter than 5 um, high drag coefficients indicate contributions from internal friction to the fluctuation dynamics.
q-bio.BM:E. Coli. dihydrofolate reductase (DHFR) undergoes conformational transitions between the closed (CS) and occluded (OS) states which, respectively, describe whether the active site is closed or occluded by the Met20 loop. A sequence-based approach is used to identify a network of residues that represents the allostery wiring diagram. We also use a self-organized polymer model to monitor the kinetics of the CS->OS and the reverse transitions. a sliding motion of Met20 loop is observed. The residues that facilitate the Met20 loop motion are part of the network of residues that transmit allosteric signals during the CS->OS transition.
q-bio.BM:A model is presented to describe the nucleotide and repeat addition processivity by the telomerase. In the model, the processive nucleotide addition is implemented on the basis of two requirements: One is that stem IV loop stimulates the chemical reaction of nucleotide incorporation, and the other one is the existence of an ssRNA-binding site adjacent to the polymerase site that has a high affinity for the unpaired base of the template. The unpairing of DNA:RNA hybrid after the incorporation of the nucleotide paired with the last base on the template, which is the prerequisite for repeat addition processivity, is caused by a force acting on the primer. The force is resulted from the unfolding of stem III pseudoknot that is induced by the swinging of stem IV loop towards the nucleotide-bound polymerase site. Based on the model, the dynamics of processive nucleotide and repeat additions by Tetrahymena telomerase are quantitatively studied, which give good explanations to the previous experimental results. Moreover, some predictions are presented. In particular, it is predicted that the repeat addition processivity is mainly determined by the difference between the free energy required to disrupt the DNA:RNA hybrid and that required to unfold the stem III pseudoknot, with the large difference corresponding to a low repeat addition processivity while the small one corresponding to a high repeat addition processivity.
q-bio.BM:Small single-domain proteins often exhibit only a single free-energy barrier, or transition state, between the denatured and the native state. The folding kinetics of these proteins is usually explored via mutational analysis. A central question is which structural information on the transition state can be derived from the mutational data. In this article, we model and structurally interpret mutational Phi-values for two small beta-sheet proteins, the PIN and the FBP WW domain. The native structure of these WW domains comprises two beta-hairpins that form a three-stranded beta-sheet. In our model, we assume that the transition state consists of two conformations in which either one of the hairpins is formed. Such a transition state has been recently observed in Molecular Dynamics folding-unfolding simulations of a small designed three-stranded beta-sheet protein. We obtain good agreement with the experimental data (i) by splitting up the mutation-induced free-energy changes into terms for the two hairpins and for the small hydrophobic core of the proteins, and (ii) by fitting a single parameter, the relative degree to which hairpin 1 and 2 are formed in the transition state. The model helps to understand how mutations affect the folding kinetics of WW domains, and captures also negative Phi-values that have been difficult to interpret.
q-bio.BM:Simple theoretical concepts and models have been helpful to understand the folding rates and routes of single-domain proteins. As reviewed in this article, a physical principle that appears to underly these models is loop closure.
q-bio.BM:The isotopic composition, for example, 14C/12C, 13C/12C, 2H/1H, 15N/14N and 18O/16O, of the elements of matter is heterogeneous. It is ruled by physical, chemical and biological mechanisms. Isotopes can be employed to follow the fate of mineral and organic compounds during biogeochemical transformations. The determination of the isotopic composition of organic substances occurring at trace level in very complex mixtures such as sediments, soils and blood, has been made possible during the last 20 years due to the rapid development of molecular level isotopic techniques. After a brief glance at pioneering studies revealing isotopic breakthroughs at the molecular and intramolecular levels, this paper reviews selected applications of compound-specific isotope analysis in various scientific fields.
q-bio.BM:The conformational dynamics of a single protein molecule in a shear flow is investigated using Brownian dynamics simulations. A structure-based coarse grained model of a protein is used. We consider two proteins, ubiquitin and integrin, and find that at moderate shear rates they unfold through a sequence of metastable states - a pattern which is distinct from a smooth unraveling found in homopolymers. Full unfolding occurs only at very large shear rates. Furthermore, the hydrodynamic interactions between the amino acids are shown to hinder the shear flow unfolding. The characteristics of the unfolding process depend on whether a protein is anchored or not, and if it is, on the choice of an anchoring point.
q-bio.BM:We demonstrate that a common-line method can assemble a 3D oversampled diffracted intensity distribution suitable for high-resolution structure solution from a set of measured 2D diffraction patterns, as proposed in experiments with an X-ray free electron laser (XFEL) (Neutze {\it et al.}, 2000). Even for a flat Ewald sphere, we show how the ambiguities due to Friedel's Law may be overcome. The method breaks down for photon counts below about 10 per detector pixel, almost 3 orders of magnitude higher than expected for scattering by a 500 kDa protein with an XFEL beam focused to a 0.1 micron diameter spot. Even if 10**3 orientationally similar diffraction patterns could be identified and added to reach the requisite photon count per pixel, the need for about 10**6 orientational classes for high-resolution structure determination suggests that about ~ 10**9 diffraction patterns must be recorded. Assuming pulse and read-out rates of 100 Hz, such measurements would require ~ 10**7 seconds, i.e. several months of continuous beam time.
q-bio.BM:Background. All-atom crystallographic refinement of proteins is a laborious manually driven procedure, as a result of which, alternative and multiconformer interpretations are not routinely investigated.   Results. We describe efficient loop sampling procedures in Rappertk and demonstrate that single loops in proteins can be automatically and accurately modelled with few positional restraints. Loops constructed with a composite CNS/Rappertk protocol consistently have better Rfree than those with CNS alone. This approach is extended to a more realistic scenario where there are often large positional uncertainties in loops along with small imperfections in the secondary structural framework. Both ensemble and collection methods are used to estimate the structural heterogeneity of loop regions.   Conclusion. Apart from benchmarking Rappertk for the all-atom protein refinement task, this work also demonstrates its utility in both aspects of loop modelling - building a single conformer and estimating structural heterogeneity the loops can exhibit.
q-bio.BM:Background. Dramatic increases in RNA structural data have made it possible to recognize its conformational preferences much better than a decade ago. This has created an opportunity to use discrete restraint-based conformational sampling for modelling RNA and automating its crystallographic refinement. Results. All-atom sampling of entire RNA chains, termini and loops is achieved using the Richardson RNA backbone rotamer library and an unbiased distribution for glycosidic dihedral angle. Sampling behaviour of Rappertk on a diverse dataset of RNA chains under varying spatial restraints is benchmarked. The iterative composite crystallographic refinement protocol developed here is demonstrated to outperform CNS-only refinement on parts of tRNA(Asp) structure. Conclusion. This work opens exciting possibilities for further work in RNA modelling and crystallography.
q-bio.BM:DNA torsion dynamics is essential in the transcription process; simple models for it have been proposed by several authors, in particular Yakushevich (Y model). These are strongly related to models of DNA separation dynamics such as the one first proposed by Peyrard and Bishop (and developed by Dauxois, Barbi, Cocco and Monasson among others), but support topological solitons. We recently developed a ``composite'' version of the Y model, in which the sugar-phosphate group and the base are described by separate degrees of freedom. This at the same time fits experimental data better than the simple Y model, and shows dynamical phenomena, which are of interest beyond DNA dynamics. Of particular relevance are the mechanism for selecting the speed of solitons by tuning the physical parameters of the non linear medium and the hierarchal separation of the relevant degrees of freedom in ``master'' and ``slave''. These mechanisms apply not only do DNA, but also to more general macromolecules, as we show concretely by considering polyethylene.
q-bio.BM:The Caspar-Klug classification of viruses whose protein shell, called viral capsid, exhibits icosahedral symmetry, has recently been extended to incorporate viruses whose capsid proteins are exclusively organised in pentamers. The approach, named `Viral Tiling Theory', is inspired by the theory of quasicrystals, where aperiodic Penrose tilings enjoy 5-fold and 10-fold local symmetries. This paper analyzes the extent to which this classification approach informs dynamical properties of the viral capsids, in particular the pattern of Raman active modes of vibrations, which can be observed experimentally.
q-bio.BM:Position-specific scoring matrices (PSSMs) are useful for detecting weak homology in protein sequence analysis, and they are thought to contain some essential signatures of the protein families. In order to elucidate what kind of ingredients constitute such family-specific signatures, we apply singular value decomposition to a set of PSSMs and examine the properties of dominant right and left singular vectors. The first right singular vectors were correlated with various amino acid indices including relative mutability, amino acid composition in protein interior, hydropathy, or turn propensity, depending on proteins. A significant correlation between the first left singular vector and a measure of site conservation was observed. It is shown that the contribution of the first singular component to the PSSMs act to disfavor potentially but falsely functionally important residues at conserved sites. The second right singular vectors were highly correlated with hydrophobicity scales, and the corresponding left singular vectors with contact numbers of protein structures. It is suggested that sequence alignment with a PSSM is essentially equivalent to threading supplemented with functional information. The presented method may be used to separate functionally important sites from structurally important ones, and thus it may be a useful tool for predicting protein functions.
q-bio.BM:A method to search for local structural similarities in proteins at atomic resolution is presented. It is demonstrated that a huge amount of structural data can be handled within a reasonable CPU time by using a conventional relational database management system with appropriate indexing of geometric data. This method, which we call geometric indexing, can enumerate ligand binding sites that are structurally similar to sub-structures of a query protein among more than 160,000 possible candidates within a few hours of CPU time on an ordinary desktop computer. After detecting a set of high scoring ligand binding sites by the geometric indexing search, structural alignments at atomic resolution are constructed by iteratively applying the Hungarian algorithm, and the statistical significance of the final score is estimated from an empirical model based on a gamma distribution. Applications of this method to several protein structures clearly shows that significant similarities can be detected between local structures of non-homologous as well as homologous proteins.
q-bio.BM:In this paper we enumerate $k$-noncrossing RNA pseudoknot structures with given minimum stack-length. We show that the numbers of $k$-noncrossing structures without isolated base pairs are significantly smaller than the number of all $k$-noncrossing structures. In particular we prove that the number of 3- and 4-noncrossing RNA structures with stack-length $\ge 2$ is for large $n$ given by $311.2470 \frac{4!}{n(n-1)...(n-4)}2.5881^n$ and $1.217\cdot 10^{7} n^{-{21/2}} 3.0382^n$, respectively. We furthermore show that for $k$-noncrossing RNA structures the drop in exponential growth rates between the number of all structures and the number of all structures with stack-size $\ge 2$ increases significantly. Our results are of importance for prediction algorithms for pseudoknot-RNA and provide evidence that there exist neutral networks of RNA pseudoknot structures.
q-bio.BM:Network science is already making an impact on the study of complex systems and offers a promising variety of tools to understand their formation and evolution (1-4) in many disparate fields from large communication networks (5,6), transportation infrastructures (7) and social communities (8,9) to biological systems (1,10,11). Even though new highthroughput technologies have rapidly been generating large amounts of genomic data, drug design has not followed the same development, and it is still complicated and expensive to develop new single-target drugs. Nevertheless, recent approaches suggest that multi-target drug design combined with a network-dependent approach and large-scale systems-oriented strategies (12-14) create a promising framework to combat complex multigenetic disorders like cancer or diabetes. Here, we investigate the human network corresponding to the interactions between all US approved drugs and human therapies, defined by known drug-therapy relationships. Our results show that the key paths in this network are shorter than three steps, indicating that distant therapies are separated by a surprisingly low number of chemical compounds. We also identify a sub-network composed by drugs with high centrality measures (15), which represent the structural back-bone of the drug-therapy system and act as hubs routing information between distant parts of the network. These findings provide for the first time a global map of the largescale organization of all known drugs and associated therapies, bringing new insights on possible strategies for future drug development. Special attention should be given to drugs which combine the two properties of (a) having a high centrality value and (b) acting on multiple targets.
q-bio.BM:In this paper we enumerate $k$-noncrossing RNA pseudoknot structures with given minimum arc- and stack-length. That is, we study the numbers of RNA pseudoknot structures with arc-length $\ge 3$, stack-length $\ge \sigma$ and in which there are at most $k-1$ mutually crossing bonds, denoted by ${\sf T}_{k,\sigma}^{[3]}(n)$. In particular we prove that the numbers of 3, 4 and 5-noncrossing RNA structures with arc-length $\ge 3$ and stack-length $\ge 2$ satisfy ${\sf T}_{3,2}^{[3]}(n)^{}\sim K_3 n^{-5} 2.5723^n$, ${\sf T}^{[3]}_{4,2}(n)\sim K_4 n^{-{21/2}} 3.0306^n$, and ${\sf T}^{[3]}_{5,2}(n)\sim K_5 n^{-18} 3.4092^n$, respectively, where $K_3,K_4,K_5$ are constants. Our results are of importance for prediction algorithms for RNA pseudoknot structures.
q-bio.BM:We have developed a new extended replica exchange method to study thermodynamics of a system in the presence of external force. Our idea is based on the exchange between different force replicas to accelerate the equilibrium process. We have shown that the refolding pathways of single ubiquitin depend on which terminus is fixed. If the N-end is fixed then the folding pathways are different compared to the case when both termini are free, but fixing the C-terminal does not change them. Surprisingly, we have found that the anchoring terminal does not affect the pathways of individual secondary structures of three-domain ubiquitin, indicating the important role of the multi-domain construction. Therefore, force-clamp experiments, in which one end of a protein is kept fixed, can probe the refolding pathways of a single free-end ubiquitin if one uses either the poly-ubiquitin or a single domain with the C-terminus anchored. However, it is shown that anchoring one end does not affect refolding pathways of the titin domain I27, and the force-clamp spectroscopy is always capable to predict folding sequencing of this protein. We have obtained the reasonable estimate for unfolding barrier of ubiqutin. The linkage between residue Lys48 and the C-terminal of ubiquitin is found to have the dramatic effect on the location of the transition state along the end-to-end distance reaction coordinate, but the multi-domain construction leaves the transition state almost unchanged. We have found that the maximum force in the force-extension profile from constant velocity force pulling simulations depends on temperature nonlinearly. However, for some narrow temperature interval this dependence becomes linear, as have been observed in recent experiments.
q-bio.BM:A construction method for duplex cage structures with icosahedral sym- metry made out of single-stranded DNA molecules is presented and applied to an icosidodecahedral cage. It is shown via a mixture of analytic and computer techniques that there exist realisations of this graph in terms of two circular DNA molecules. These blueprints for the organisation of a cage structure with a noncrystallographic symmetry may assist in the design of containers made from DNA for applications in nanotechnology.
q-bio.BM:We analyzed folding routes predicted by a variational model in terms of a generalized formalism of the capillarity scaling theory for 28 two-state proteins. The scaling exponent ranged from 0.2 to 0.45 with an average of 0.33. This average value corresponds to packing of rigid objects.That is, on average the folded core of the nucleus is found to be relatively diffuse. We also studied the growth of the folding nucleus and interface along the folding route in terms of the density or packing fraction. The evolution of the folded core and interface regions can be classified into three patterns of growth depending on how the growth of the folded core is balanced by changes in density of the interface. Finally, we quantified the diffuse versus polarized structure of the critical nucleus through direct calculation of the packing fraction of the folded core and interface regions. Our results support the general picture of describing protein folding as the capillarity-like growth of folding nuclei.
q-bio.BM:Biomolecular structures are assemblies of emergent anisotropic building modules such as uniaxial helices or biaxial strands. We provide an approach to understanding a marginally compact phase of matter that is occupied by proteins and DNA. This phase, which is in some respects analogous to the liquid crystal phase for chain molecules, stabilizes a range of shapes that can be obtained by sequence-independent interactions occurring intra- and intermolecularly between polymeric molecules. We present a singularityfree self-interaction for a tube in the continuum limit and show that this results in the tube being positioned in the marginally compact phase. Our work provides a unified framework for understanding the building blocks of biomolecules.
q-bio.BM:The mean time required by a transcription factor (TF) or an enzyme to find a target in the nucleus is of prime importance for the initialization of transcription, gene activation or the start of DNA repair. We obtain new estimates for the mean search time when the TF or enzyme, confined to the cell nucleus, can switch from a one dimensional motion along the DNA and a free Brownian regime inside the crowded nucleus. We give analytical expressions for the mean time the particle stays bound to the DNA, $\tau_{DNA}$, and the mean time it diffuses freely, $\tau_{free}$. Contrary to previous results but in agreement with experimental data, we find a factor $\tau_{DNA} \approx 3.7 \tau_{free}$ for the Lac-I TF. The formula obtained for the time required to bind to a target site is found to be coherent with observed data. We also conclude that a higher DNA density leads to a more efficient search process.
q-bio.BM:We develop coarse-grained models that describe the dynamic encapsidation of functionalized nanoparticles by viral capsid proteins. We find that some forms of cooperative interactions between protein subunits and nanoparticles can dramatically enhance rates and robustness of assembly, as compared to the spontaneous assembly of subunits into empty capsids. For large core-subunit interactions, subunits adsorb onto core surfaces en masse in a disordered manner, and then undergo a cooperative rearrangement into an ordered capsid structure. These assembly pathways are unlike any identified for empty capsid formation. Our models can be directly applied to recent experiments in which viral capsid proteins assemble around the functionalized inorganic nanoparticles [Sun et al., Proc. Natl. Acad. Sci (2007) 104, 1354]. In addition, we discuss broader implications for understanding the dynamic encapsidation of single-stranded genomic molecules during viral replication and for developing multicomponent nanostructured materials.
q-bio.BM:The total conformational energy is assumed to consist of pairwise interaction energies between atoms or residues, each of which is expressed as a product of a conformation-dependent function (an element of a contact matrix, C-matrix) and a sequence-dependent energy parameter (an element of a contact energy matrix, E-matrix). Such pairwise interactions in proteins force native C-matrices to be in a relationship as if the interactions are a Go-like potential [N. Go, Annu. Rev. Biophys. Bioeng. 12. 183 (1983)] for the native C-matrix, because the lowest bound of the total energy function is equal to the total energy of the native conformation interacting in a Go-like pairwise potential. This relationship between C- and E-matrices corresponds to (a) a parallel relationship between the eigenvectors of the C- and E-matrices and a linear relationship between their eigenvalues, and (b) a parallel relationship between a contact number vector and the principal eigenvectors of the C- and E-matrices; the E-matrix is expanded in a series of eigenspaces with an additional constant term, which corresponds to a threshold of contact energy that approximately separates native contacts from non-native ones. These relationships are confirmed in 182 representatives from each family of the SCOP database by examining inner products between the principal eigenvector of the C-matrix, that of the E-matrix evaluated with a statistical contact potential, and a contact number vector. In addition, the spectral representation of C- and E-matrices reveals that pairwise residue-residue interactions, which depends only on the types of interacting amino acids but not on other residues in a protein, are insufficient and other interactions including residue connectivities and steric hindrance are needed to make native structures the unique lowest energy conformations.
q-bio.BM:We consider an elastic rod model for twisted DNA in the plectonemic regime. The molecule is treated as an impenetrable tube with an effective, adjustable radius. The model is solved analytically and we derive formulas for the contact pressure, twisting moment and geometrical parameters of the supercoiled region. We apply our model to magnetic tweezer experiments of a DNA molecule subjected to a tensile force and a torque, and extract mechanical and geometrical quantities from the linear part of the experimental response curve. These reconstructed values are derived in a self-contained manner, and are found to be consistent with those available in the literature.
q-bio.BM:Nicodemi and Prisco recently proposed a model for X-chromosome inactivation in mammals, explaining this phenomenon in terms of a spontaneous symmetry-breaking mechanism [{\it Phys. Rev. Lett.} 99 (2007), 108104]. Here we provide a mean-field version of their model.
q-bio.BM:We present a theoretical investigation on possible selection of olfactory receptors (ORs) as sensing components of nanobiosensors. Accordingly, we generate the impedance spectra of the rat OR I7 in the native and activated state and analyze their differences. In this way, we connect the protein morphological transformation, caused by the sensing action, with its change of electrical impedance. The results are compared with those obtained by studying the best known protein of the GPCR family: bovine rhodopsin. Our investigations indicate that a change in morphology goes with a change in impedance spectrum mostly associated with a decrease of the static impedance up to about 60 % of the initial value, in qualitative agreement with existing experiments on rat OR I7. The predictiveness of the model is tested successfully for the case of recent experiments on bacteriorhodopsin. The present results point to a promising development of a new class of nanobiosensors based on the electrical properties of GPCR and other sensing proteins.
q-bio.BM:How molecular motors like Kinesin regulates the affinity to the rail protein in the process of ATP hydrolysis remains to be uncovered. To understand the regulation mechanism, we investigate the structural fluctuation of KIF1A in different nucleotide states that are realized in the ATP hydrolysis process by molecular dynamics simulations of Go-like model. We found that "alpha4 helix", which is a part of the microtubule (MT) binding site, changes its fluctuation systematically according to the nucleotide states. In particular, the frequency of large fluctuations of alpha4 strongly correlates with the affinity of KIF1A for microtubule. We also show how the strength of the thermal fluctuation and the interaction with the nucleotide affect the dynamics of microtubule binding site. These results suggest that KIF1A regulates the affinity to MT by changing the flexibility of alpha4 helix according to the nucleotide states.
q-bio.BM:A theoretical framework is developed to study the dynamics of protein folding. The key insight is that the search for the native protein conformation is influenced by the rate r at which external parameters, such as temperature, chemical denaturant or pH, are adjusted to induce folding. A theory based on this insight predicts that (1) proteins with non-funneled energy landscapes can fold reliably to their native state, (2) reliable folding can occur as an equilibrium or out-of-equilibrium process, and (3) reliable folding only occurs when the rate r is below a limiting value, which can be calculated from measurements of the free energy. We test these predictions against numerical simulations of model proteins with a single energy scale.
q-bio.BM:Despite the spontaneity of some in vitro protein folding reactions, native folding in vivo often requires the participation of barrel-shaped multimeric complexes known as chaperonins. Although it has long been known that chaperonin substrates fold upon sequestration inside the chaperonin barrel, the precise mechanism by which confinement within this space facilitates folding remains unknown. In this study, we examine the possibility that the chaperonin mediates a favorable reorganization of the solvent for the folding reaction. We begin by discussing the effect of electrostatic charge on solvent-mediated hydrophobic forces in an aqueous environment. Based on these initial physical arguments, we construct a simple, phenomenological theory for the thermodynamics of density and hydrogen bond order fluctuations in liquid water. Within the framework of this model, we investigate the effect of confinement within a chaperonin-like cavity on the configurational free energy of water by calculating solvent free energies for cavities corresponding to the different conformational states in the ATP- driven catalytic cycle of the prokaryotic chaperonin GroEL. Our findings suggest that one function of chaperonins may be to trap unfolded proteins and subsequently expose them to a micro-environment in which the hydrophobic effect, a crucial thermodynamic driving force for folding, is enhanced.
q-bio.BM:We present a top-down approach to the study of the dynamics of icosahedral virus capsids, in which each protein is approximated by a point mass. Although this represents a rather crude coarse-graining, we argue that it highlights several generic features of vibrational spectra which have been overlooked so far. We furthermore discuss the consequences of approximate inversion symmetry as well as the role played by Viral Tiling Theory in the study of virus capsid vibrations.
q-bio.BM:We study the coupled dynamics of primary and secondary structure formation (i.e. slow genetic sequence selection and fast folding) in the context of a solvable microscopic model that includes both short-range steric forces and and long-range polarity-driven forces. Our solution is based on the diagonalization of replicated transfer matrices, and leads in the thermodynamic limit to explicit predictions regarding phase transitions and phase diagrams at genetic equilibrium. The predicted phenomenology allows for natural physical interpretations, and finds satisfactory support in numerical simulations.
q-bio.BM:We analyze the thermodynamic properties of a simplified model for folded RNA molecules recently studied by G. Vernizzi, H. Orland, A. Zee (in {\it Phys. Rev. Lett.} {\bf 94} (2005) 168103). The model consists of a chain of one-flavor base molecules with a flexible backbone and all possible pairing interactions equally allowed. The spatial pseudoknot structure of the model can be efficiently studied by introducing a $N \times N$ hermitian random matrix model at each chain site, and associating Feynman diagrams of these models to spatial configurations of the molecules. We obtain an exact expression for the topological expansion of the partition function of the system. We calculate exact and asymptotic expressions for the free energy, specific heat, entanglement and chemical potential and study their behavior as a function of temperature. Our results are consistent with the interpretation of $1/N$ as being a measure of the concentration of $\rm{Mg}^{++}$ in solution.
q-bio.BM:Blueprints of polyhedral cages with icosahedral symmetry made of circular DNA molecules are provided. The basic rule is that every edge of the cage is met twice in opposite directions by the DNA strand, and vertex junctions are realised by a set of admissible junction types. As nanocontainers for cargo storage and delivery, the icosidodecahedral cages are of special interest as they have the largest volume per surface ratio of all cages discussed here.
q-bio.BM:Group theoretical arguments combined with normal mode analysis techniques are applied to a coarse-grained approximation of icosahedral viral capsids which incorporates areas of variable flexibility. This highlights a remarkable structure of the low-frequency spectrum in this approximation, namely the existence of a plateau of 24 near zero-modes with universal group theory content.
q-bio.BM:The low-frequency Raman spectra of Na-and Cs-DNA water solutions have been studied to determine the mode of counterion vibrations with respect to phosphate groups of the DNA double helix. The obtained spectra are characterized by the water band near 180 cm-1 and by several DNA bands near 100 cm-1. The main difference between Na- and Cs-DNA spectra is observed in case of the band 100 cm-1. In Cs-DNA spectra this band has about twice higher intensity than in Na-DNA spectra. The comparison of obtained spectra with the calculated frequencies of Na- and Cs-DNA conformational vibrations [Perepelytsya S.M., Volkov S.N. Eur. Phys. J. E. 24, 261 (2007)] show that the band 100 cm-1 in the spectra of Cs-DNA is formed by the modes of both H-bond stretching vibrations and vibrations of caesium counterions, while in Na-DNA spectra the band 100 cm-1 is formed by the mode of H-bond stretching vibrations only. The modes of sodium counterion vibrations have a frequency 180 cm-1, and they do not rise above the water band. Thus, the increase in intensity of the band 100 cm-1 in the spectra of Cs-DNA as compared with Na-DNA is caused by the mode of ion-phosphate vibrations.
q-bio.BM:The Ca-sensitive regulatory switch of cardiac muscle is a paradigmatic example of protein assemblies that communicate ligand binding through allosteric change. The switch is a dimeric complex of troponin C (TnC), an allosteric sensor for Ca, and troponin I (TnI), an allosteric reporter. Time-resolved equilibrium FRET measurements suggest that the switch activates in two steps: a TnI-independent Ca-priming step followed by TnI-dependent opening. To resolve the mechanistic role of TnI in activation we performed stopped-flow FRET measurements of activation following rapid addition of a lacking component (Ca or TnI) and deactivation following rapid chelation of Ca. The time-resolved measurements, stopped-flow measurements, and Ca-titration measurements were globally analyzed in terms of a new quantitative dynamic model of TnC-TnI allostery. The analysis provided a mesoscopic parameterization of distance changes, free energy changes, and transition rates among the accessible coarse-grained states of the system. The results reveal (i) the Ca-induced priming step, which precedes opening, is the rate limiting step in activation, (ii) closing is the rate limiting step in deactivation, (iii) TnI induces opening, (iv) an incompletely deactivated population when regulatory Ca is not bound, which generates an accessory pathway of activation, and (v) incomplete activation by Ca--when regulatory Ca is bound, a 3:2 mixture of dynamically inter-converting open (active) and primed-closed (partially active) conformers is observed (15 C). Temperature-dependent stopped-flow FRET experiments provide a near complete thermo-kinetic parametrization of opening. <Abstract Truncated>
q-bio.BM:We explore the use of a top-down approach to analyse the dynamics of icosahedral virus capsids and complement the information obtained from bottom-up studies of viral vibrations available in the literature. A normal mode analysis based on protein association energies is used to study the frequency spectrum, in which we reveal a universal plateau of low-frequency modes shared by a large class of Caspar-Klug capsids. These modes break icosahedral symmetry and are potentially relevant to the genome release mechanism. We comment on the role of viral tiling theory in such dynamical considerations.
q-bio.BM:In many cases, transcriptional regulation involves the binding of transcription factors at sites on the DNA that are not immediately adjacent to the promoter of interest. This action at a distance is often mediated by the formation of DNA loops: Binding at two or more sites on the DNA results in the formation of a loop, which can bring the transcription factor into the immediate neighborhood of the relevant promoter. Though there have been a variety of insights into the combinatorial aspects of transcriptional control, the mechanism of DNA looping as an agent of combinatorial control in both prokaryotes and eukaryotes remains unclear. We use single-molecule techniques to dissect DNA looping in the lac operon. In particular, we measure the propensity for DNA looping by the Lac repressor as a function of the concentration of repressor protein and as a function of the distance between repressor binding sites. As with earlier single-molecule studies, we find (at least) two distinct looped states and demonstrate that the presence of these two states depends both upon the concentration of repressor protein and the distance between the two repressor binding sites. We find that loops form even at interoperator spacings considerably shorter than the DNA persistence length, without the intervention of any other proteins to prebend the DNA. The concentration measurements also permit us to use a simple statistical mechanical model of DNA loop formation to determine the free energy of DNA looping, or equivalently, the J-factor for looping.
q-bio.BM:We apply a simulational proxy of the phi-value analysis and perform extensive mutagenesis experiments to identify the nucleating residues in the folding reactions of two small lattice Go polymers with different native geometries. These results are compared with those obtained from an accurate analysis based on the reaction coordinate folding probability Pfold, and on structural clustering methods. For both protein models, the transition state ensemble is rather heterogeneous and splits-up into structurally different populations. For the more complex geometry the identified subpopulations are actually structurally disjoint. For the less complex native geometry we found a broad transition state with microscopic heterogeneity. For both geometries, the identification of the folding nucleus via the Pfold analysis agrees with the identification of the folding nucleus carried out with the phi-value analysis. For the most complex geometry, however, the apllied methodologies give more consistent results than for the more local geometry. The study of the transition state' structure reveals that the nucleus residues are not necessarily fully native in the transition state. Indeed, it is only for the more complex geometry that two of the five critical residues show a considerably high probability of having all its native bonds formed in the transition state. Therefore, one concludes that in general the phi-value correlates with the acceleration/deceleration of folding induced by mutation, rather than with the degree of nativeness of the transition state, and that the traditional interpretation of phi-values may provide a more realistic picture of the structure of the transition state only for more complex native geometries.
q-bio.BM:Associative memory Hamiltonian structure prediction potentials are not overly rugged, thereby suggesting their landscapes are like those of actual proteins. In the present contribution we show how basin-hopping global optimization can identify low-lying minima for the corresponding mildly frustrated energy landscapes. For small systems the basin-hopping algorithm succeeds in locating both lower minima and conformations closer to the experimental structure than does molecular dynamics with simulated annealing. For large systems the efficiency of basin-hopping decreases for our initial implementation, where the steps consist of random perturbations to the Cartesian coordinates. We implemented umbrella sampling using basin-hopping to further confirm when the global minima are reached. We have also improved the energy surface by employing bioinformatic techniques for reducing the roughness or variance of the energy surface. Finally, the basin-hopping calculations have guided improvements in the excluded volume of the Hamiltonian, producing better structures. These results suggest a novel and transferable optimization scheme for future energy function development.
q-bio.BM:The performance of single folding predictors and combination scores is critically evaluated. We test mean packing, mean pairwise energy and the new index gVSL2 on a dataset of 743 folded proteins and 81 natively unfolded proteins. These predictors have an individual performance comparable or even better than other proposed methods. We introduce here a strictly unanimous score S_{SU} that combines them but leaves undecided those sequences differently classified by two single predictors. The performance of the single predictors on a dataset purged from the proteins left unclassified by S_{SU}, significantly increases, indicating that unclassified proteins are mainly false predictions. Amino acid composition is the main determinant considered by these predictors, therefore unclassified proteins have a composition compatible with both folded and unfolded status. This is why purging a dataset from these ambiguous proteins increases the performance of single predictors. The percentage of proteins predicted as natively unfolded by S_{SU} in the three kingdoms are: 4.1% for Bacteria, 1.0% for Archaea and 20.0% for Eukarya; compatible with previous determinations. Evidence is given of a scaling law relating the number of natively unfolded proteins with the total number of proteins in a genome; a first estimate of the critical exponent is 1.95 +- 0.21
q-bio.BM:The sequence-dependent structural variability and conformational dynamics of DNA play pivotal roles in many biological milieus, such as in the site-specific binding of transcription factors to target regulatory elements. To better understand DNA structure, function, and dynamics in general, and protein-DNA recognition in the 'kB' family of genetic regulatory elements in particular, we performed molecular dynamics simulations of a 20-base pair DNA encompassing a cognate kB site recognized by the proto-oncogenic 'c-Rel' subfamily of NF-kB transcription factors. Simulations of the kB DNA in explicit water were extended to microsecond duration, providing a broad, atomically-detailed glimpse into the structural and dynamical behavior of double helical DNA over many timescales. Of particular note, novel (and structurally plausible) conformations of DNA developed only at the long times sampled in this simulation -- including a peculiar state arising at ~ 0.7 us and characterized by cross-strand intercalative stacking of nucleotides within a longitudinally-sheared base pair, followed (at ~ 1 us) by spontaneous base flipping of a neighboring thymine within the A-rich duplex. Results and predictions from the us-scale simulation include implications for a dynamical NF-kB recognition motif, and are amenable to testing and further exploration via specific experimental approaches that are suggested herein.
q-bio.BM:The interaction cutoff contribution to the ruggedness of protein-protein energy landscape (the artificial ruggedness) is studied in terms of relative energy fluctuations for 1/r^n potentials based on a simplistic model of a protein complex. Contradicting the principle of minimal frustration, the artificial ruggedness exists for short cutoffs and gradually disappears with the cutoff increase. The critical values of the cutoff were calculated for each of eleven popular power-type potentials with n=0-9, 12 and for two thresholds of 5% and 10%. The artificial ruggedness decreases to tolerable thresholds for cutoffs longer than the critical ones. The results showed that for both thresholds the critical cutoff is a non-monotonic function of the potential power n. The functions reach the maximum at n=3-4 and then decrease with the increase of the potential power. The difference between two cutoffs for 5% and 10% artificial ruggedness becomes negligible for potentials decreasing faster than 1/r^12. The results suggest that cutoffs longer than critical ones can be recommended for protein-protein potentials.
q-bio.BM:Mechanical characterization of protein molecules has played a role on gaining insight into the biological functions of proteins, since some proteins perform the mechanical function. Here, we present the mesoscopic model of biological protein materials composed of protein crystals prescribed by Go potential for characterization of elastic behavior of protein materials. Specifically, we consider the representative volume element (RVE) containing the protein crystals represented by alpha-carbon atoms, prescribed by Go potential, with application of constant normal strain to RVE. The stress-strain relationship computed from virial stress theory provides the nonlinear elastic behavior of protein materials and their mechanical properties such as Young's modulus, quantitatively and/or qualitatively comparable to mechanical properties of biological protein materials obtained from experiments and/or atomistic simulations. Further, we discuss the role of native topology on the mechanical properties of protein crystals. It is shown that parallel strands (hydrogen bonds in parallel) enhances the mechanical resilience of protein materials.
q-bio.BM:Unfolded proteins may contain native or non-native residual structure, which has important implications for the thermodynamics and kinetics of folding as well as for misfolding and aggregation diseases. However, it has been universally accepted that residual structure should not affect the global size scaling of the denatured chain, which obeys the statistics of random coil polymers. Here we use a single-molecule optical technique, fluorescence correlation spectroscopy, to probe the denatured state of set of repeat proteins containing an increasing number of identical domains, from two to twenty. The availability of this set allows us to obtain the scaling law for the unfolded state of these proteins, which turns out to be unusually compact, strongly deviating from random-coil statistics. The origin of this unexpected behavior is traced to the presence of extensive non-native polyproline II helical structure, which we localize to specific segments of the polypeptide chain. We show that the experimentally observed effects of PPII on the size scaling of the denatured state can be well-described by simple polymer models. Our findings suggest an hitherto unforeseen potential of non-native structure to induce significant compaction of denatured proteins, affecting significantly folding pathways and kinetics.
q-bio.BM:Renaturation and hybridization reactions lead to the pairing of complementary single-stranded nucleic acids. We present here a theoretical investigation of the mechanism of these reactions in vitro under thermal conditions (dilute solutions of single-stranded chains, in the presence of molar concentrations of monovalent salts and at elevated temperatures). The mechanism follows a Kramers' process, whereby the complementary chains overcome a potential barrier through Brownian motion. The barrier originates from a single rate-limiting nucleation event in which the first complementary base pairs are formed. The reaction then proceeds through a fast growth of the double helix. For the DNA of bacteriophages T7, T4 and $\phi$X174 as well as for Escherichia coli DNA, the bimolecular rate $k_2$ of the reaction increases as a power law of the average degree of polymerization $<N>$ of the reacting single- strands: $k_2 \prop <N>^\alpha$. This relationship holds for $100 \leq <N> \leq 50 000$ with an experimentally determined exponent $\alpha = 0.51 \pm 0.01$. The length dependence results from a thermodynamic excluded-volume effect. The reacting single-stranded chains are predicted to be in universal good solvent conditions, and the scaling law is determined by the relevant equilibrium monomer contact probability. The value theoretically predicted for the exponent is $\alpha = 1-\nu \theta_2$, where $\nu$ is Flory's swelling exponent ($nu approx 0.588$) and $\theta_2$ is a critical exponent introduced by des Cloizeaux ($\theta_2 \approx 0.82$), yielding $\alpha = 0.52 \pm 0.01$, in agreement with the experimental results.
q-bio.BM:This article is interested in the origin of the genetic code, it puts forward a scenario of a simultaneous selection of the bases and amino acids and setting up of a correlation between them. Each amino acid is associated with a pair of its own kind, called the binding pair and each binding pair is associated with the codon(s) corresponding to the same amino acid. An explanation is also proposed about the origin of the start and stop codons.
q-bio.BM:We develop equilibrium and kinetic theories that describe the assembly of viral capsid proteins on a charged central core, as seen in recent experiments in which brome mosaic virus (BMV) capsids assemble around nanoparticles functionalized with polyelectrolyte. We model interactions between capsid proteins and nanoparticle surfaces as the interaction of polyelectrolyte brushes with opposite charge, using the nonlinear Poisson Boltzmann equation. The models predict that there is a threshold density of functionalized charge, above which capsids efficiently assemble around nanoparticles, and that light scatter intensity increases rapidly at early times, without the lag phase characteristic of empty capsid assembly. These predictions are consistent with, and enable interpretation of, preliminary experimental data. However, the models predict a stronger dependence of nanoparticle incorporation efficiency on functionalized charge density than measured in experiments, and do not completely capture a logarithmic growth phase seen in experimental light scatter. These discrepancies may suggest the presence of metastable disordered states in the experimental system. In addition to discussing future experiments for nanoparticle-capsid systems, we discuss broader implications for understanding assembly around charged cores such as nucleic acids.
q-bio.BM:The binding of a ligand molecule to a protein is often accompanied by conformational changes of the protein. A central question is whether the ligand induces the conformational change (induced-fit), or rather selects and stabilizes a complementary conformation from a pre-existing equilibrium of ground and excited states of the protein (selected-fit). We consider here the binding kinetics in a simple four-state model of ligand-protein binding. In this model, the protein has two conformations, which can both bind the ligand. The first conformation is the ground state of the protein when the ligand is off, and the second conformation is the ground state when the ligand is bound. The induced-fit mechanism corresponds to ligand binding in the unbound ground state, and the selected-fit mechanism to ligand binding in the excited state. We find a simple, characteristic difference between the on- and off-rates in the two mechanisms if the conformational relaxation into the ground states is fast. In the case of selected-fit binding, the on-rate depends on the conformational equilibrium constant, while the off-rate is independent. In the case of induced-fit binding, in contrast, the off-rate depends on the conformational equilibrium, while the on-rate is independent. Whether a protein binds a ligand via selected-fit or induced-fit thus may be revealed by mutations far from the protein's binding pocket, or other "perturbations" that only affect the conformational equilibrium. In the case of selected-fit, such mutations will only change the on-rate, and in the case of induced-fit, only the off-rate.
q-bio.BM:We study a matrix model of RNA in which an external perturbation acts on n nucleotides of the polymer chain. The effect of the perturbation appears in the exponential generating function of the partition function as a factor $(1-\frac{n\alpha}{L})$ [where $\alpha$ is the ratio of strengths of the original to the perturbed term and L is length of the chain]. The asymptotic behaviour of the genus distribution functions for the extended matrix model are analyzed numerically when (i) $n=L$ and (ii) $n=1$. In these matrix models of RNA, as $n\alpha/L$ is increased from 0 to 1, it is found that the universality of the number of diagrams $a_{L, g}$ at a fixed length L and genus g changes from $3^{L}$ to $(3-\frac{n\alpha}{L})^{L}$ ($2^{L}$ when $n\alpha/L=1$) and the asymptotic expression of the total number of diagrams $\cal N$ at a fixed length L but independent of genus g, changes in the factor $\exp^{\sqrt{L}}$ to $\exp^{(1-\frac{n\alpha}{L})\sqrt{L}}$ ($exp^{0}=1$ when $n\alpha/L=1$)
q-bio.BM:In protein folding the term plasticity refers to the number of alternative folding pathways encountered in response to free energy perturbations such as those induced by mutation. Here we explore the relation between folding plasticity and a gross, generic feature of the native geometry, namely, the relative number of local and non-local native contacts. The results from our study, which is based on Monte Carlo simulations of simple lattice proteins, show that folding to a structure that is rich in local contacts is considerably more plastic than folding to a native geometry characterized by having a very large number of long-range contacts (i.e., contacts between amino acids that are separated by more than 12 units of backbone distance). The smaller folding plasticity of `non-local' native geometries is probably a direct consequence of their higher folding cooperativity that renders the folding reaction more robust against single- and multiple-point mutations.
q-bio.BM:Significant overweight represents a major health problem in industrialized countries. Besides its known metabolic origins, this condition may also have an infectious cause, as recently postulated. Here, it is surmised that the potentially causative adenovirus 36 contributes to such disorder by inactivating the retinoblastoma tumor suppressor protein (RB) in a manner reminiscent of a mechanism employed by both another pathogenic adenoviral agent and insulin. The present insight additionally suggests novel modes of interfering with obesity-associated pathology.
q-bio.BM:Biological forces govern essential cellular and molecular processes in all living organisms. Many cellular forces, e.g. those generated in cyclic conformational changes of biological machines, have repetitive components. However, little is known about how proteins process repetitive mechanical stresses. To obtain first insights into dynamic protein mechanics, we probed the mechanical stability of single and multimeric ubiquitins perturbed by periodic forces. Using coarse-grained molecular dynamics simulations, we were able to model repetitive forces with periods about two orders of magnitude longer than the relaxation time of folded ubiquitins. We found that even a small periodic force weakened the protein and shifted its unfolding pathways in a frequency- and amplitude-dependent manner. Our results also showed that the dynamic response of even a small protein can be complex with transient refolding of secondary structures and an increasing importance of local interactions in asymmetric protein stability. These observations were qualitatively and quantitatively explained using an energy landscape model and discussed in the light of dynamic single-molecule measurements and physiological forces. We believe that our approach and results provide first steps towards a framework to better understand dynamic protein biomechanics and biological force generation.
q-bio.BM:It is a standard exercise in mechanical engineering to infer the external forces and torques on a body from its static shape and known elastic properties. Here we apply this kind of analysis to distorted double-helical DNA in complexes with proteins. We extract the local mean forces and torques acting on each base-pair of bound DNA from high-resolution complex structures. Our method relies on known elastic potentials and a careful choice of coordinates of the well-established rigid base-pair model of DNA. The results are robust with respect to parameter and conformation uncertainty. They reveal the complex nano-mechanical patterns of interaction between proteins and DNA. Being non-trivially and non-locally related to observed DNA conformations, base-pair forces and torques provide a new view on DNA-protein binding that complements structural analysis.
q-bio.BM:Molecular dynamics studies within a coarse-grained structure based model were used on two similar proteins belonging to the transcarbamylase family to probe the effects in the native structure of a knot. The first protein, N-acetylornithine transcarbamylase, contains no knot whereas human ormithine transcarbamylase contains a trefoil knot located deep within the sequence. In addition, we also analyzed a modified transferase with the knot removed by the appropriate change of a knot-making crossing of the protein chain. The studies of thermally- and mechanically-induced unfolding processes suggest a larger intrinsic stability of the protein with the knot.
q-bio.BM:Comprehensive knowledge of protein-ligand interactions should provide a useful basis for annotating protein functions, studying protein evolution, engineering enzymatic activity, and designing drugs. To investigate the diversity and universality of ligand binding sites in protein structures, we conducted the all-against-all atomic-level structural comparison of over 180,000 ligand binding sites found in all the known structures in the Protein Data Bank by using a recently developed database search and alignment algorithm. By applying a hybrid top-down-bottom-up clustering analysis to the comparison results, we determined approximately 3000 well-defined structural motifs of ligand binding sites. Apart from a handful of exceptions, most structural motifs were found to be confined within single families or superfamilies, and to be associated with particular ligands. Furthermore, we analyzed the components of the similarity network and enumerated more than 4000 pairs of ligand binding sites that were shared across different protein folds.
q-bio.BM:Protein electrostatic states have been demonstrated to play crucial roles in catalysis, ligand binding, protein stability, and in the modulation of allosteric effects. Electrostatic states are demonstrated to appear conserved among DEAD-box motifs and evidence is presented that the structural changes that occur to DEAD box proteins upon ligand binding alter the DEAD-box motif electrostatics in a way the facilitates the catalytic role of the DEAD-box glutatmate.
q-bio.BM:ESPSim is an open source JAVA program that enables the comparisons of protein electrostatic potential maps via the computation of an electrostatic similarity measure. This program has been utilized to demonstrate a high degree of electrostatic similarity among the potential maps of lysozyme proteins, suggesting that protein electrostatic states are conserved within lysozyme proteins. ESPSim is freely available under the AGPL License from http://www.bioinformatics.org/project/?group_id=830
q-bio.BM:Protein electrostatics have been demonstrated to play a vital role in protein functionality, with many functionally important amino acid residues exhibiting an electrostatic state that is altered from that of a normal amino acid residue. Residues with altered electrostatic states can be identified by the presence of a pKa value that is perturbed by 2 or more pK units, and such residues have been demonstrated to play critical roles in catalysis, ligand binding, and protein stability. Within the HCV helicase and polymerase, as well as the HIV reverse transcriptase, highly conserved regions were demonstrated to possess a greater number and magnitude of perturbations than lesser conserved regions, suggesting that there is an interrelationship present between protein electrostatics and evolution.
q-bio.BM:Protein dynamics in cells may be different from that in dilute solutions in vitro since the environment in cells is highly concentrated with other macromolecules. This volume exclusion due to macromolecular crowding is predicted to affect both equilibrium and kinetic processes involving protein conformational changes. To quantify macromolecular crowding effects on protein folding mechanisms, here we have investigated the folding energy landscape of an alpha/beta protein, apoflavodoxin, in the presence of inert macromolecular crowding agents using in silico and in vitro approaches. By coarse-grained molecular simulations and topology-based potential interactions, we probed the effects of increased volume fraction of crowding agents (phi_c) as well as of crowding agent geometry (sphere or spherocylinder) at high phi_c. Parallel kinetic folding experiments with purified Desulfovibro desulfuricans apoflavodoxin in vitro were performed in the presence of Ficoll (sphere) and Dextran (spherocylinder) synthetic crowding agents. In conclusion, we have identified in silico crowding conditions that best enhance protein stability and discovered that upon manipulation of the crowding conditions, folding routes experiencing topological frustrations can be either enhanced or relieved. The test-tube experiments confirmed that apoflavodoxin's time-resolved folding path is modulated by crowding agent geometry. We propose that macromolecular crowding effects may be a tool for manipulation of protein folding and function in living cells.
q-bio.BM:The force generated between actin and myosin acts predominantly along the direction of the actin filament, resulting in relative sliding of the thick and thin filaments in muscle or transport of myosin cargos along actin tracks. Previous studies have also detected lateral forces or torques that are generated between actin and myosin, but the origin and biological role of these sideways forces is not known. Here we adapt an actin gliding filament assay in order to measure the rotation of an actin filament about its axis (twirling) as it is translocated by myosin. We quantify the rotation by determining the orientation of sparsely incorporated rhodamine-labeled actin monomers, using polarized total internal reflection (polTIRF) microscopy. In order to determine the handedness of the filament rotation, linear incident polarizations in between the standard s- and p-polarizations were generated, decreasing the ambiguity of our probe orientation measurement four-fold. We found that whole myosin II and myosin V both twirl actin with a relatively long (micron), left-handed pitch that is insensitive to myosin concentration, filament length and filament velocity.
q-bio.BM:Most of the theoretical models describing the translocation of a polymer chain through a nanopore use the hypothesis that the polymer is always relaxed during the complete process. In other words, models generally assume that the characteristic relaxation time of the chain is small enough compared to the translocation time that non-equilibrium molecular conformations can be ignored. In this paper, we use Molecular Dynamics simulations to directly test this hypothesis by looking at the escape time of unbiased polymer chains starting with different initial conditions. We find that the translocation process is not quite in equilibrium for the systems studied, even though the translocation time tau is about 10 times larger than the relaxation time tau_r. Our most striking result is the observation that the last half of the chain escapes in less than ~12% of the total escape time, which implies that there is a large acceleration of the chain at the end of its escape from the channel.
q-bio.BM:We present a self-contained theory for the mechanical response of DNA in single molecule experiments. Our model is based on a 1D continuum description of the DNA molecule and accounts both for its elasticity and for DNA-DNA electrostatic interactions. We consider the classical loading geometry used in experiments where one end of the molecule is attached to a substrate and the other one is pulled by a tensile force and twisted by a given number of turns. We focus on configurations relevant to the limit of a large number of turns, which are made up of two phases, one with linear DNA and the other one with superhelical DNA. The model takes into account thermal fluctuations in the linear phase and electrostatic interactions in the superhelical phase. The values of the torsional stress, of the supercoiling radius and angle, and key features of the experimental extension-rotation curves, namely the slope of the linear region and thermal buckling threshold, are predicted. They are found in good agreement with experimental data.
q-bio.BM:While slowly turning the ends of a single molecule of DNA at constant applied force, a discontinuity was recently observed at the supercoiling transition, when a small plectoneme is suddenly formed. This can be understood as an abrupt transition into a state in which stretched and plectonemic DNA coexist. We argue that there should be discontinuities in both the extension and the torque at the transition, and provide experimental evidence for both. To predict the sizes of these discontinuities and how they change with the overall length of DNA, we organize a theory for the coexisting plectonemic state in terms of four length-independent parameters. We also test plectoneme theories, including our own elastic rod simulation, finding discrepancies with experiment that can be understood in terms of the four coexisting state parameters.
q-bio.BM:We introduce a simple "patchy particle" model to study the thermodynamics and dynamics of self-assembly of homomeric protein complexes. Our calculations allow us to rationalize recent results for dihedral complexes. Namely, why evolution of such complexes naturally takes the system into a region of interaction space where (i) the evolutionarily newer interactions are weaker, (ii) subcomplexes involving the stronger interactions are observed to be thermodynamically stable on destabilization of the protein-protein interactions and (iii) the self-assembly dynamics are hierarchical with these same subcomplexes acting as kinetic intermediates.
q-bio.BM:We perform molecular dynamics simulations for a simple coarse-grained model of crambin placed inside of a softly repulsive sphere of radius R. The confinement makes folding at the optimal temperature slower and affects the folding scenarios, but both effects are not dramatic. The influence of crowding on folding are studied by placing several identical proteins within the sphere, denaturing them, and then by monitoring refolding. If the interactions between the proteins are dominated by the excluded volume effects, the net folding times are essentially like for a single protein. An introduction of inter-proteinic attractive contacts hinders folding when the strength of the attraction exceeds about a half of the value of the strength of the single protein contacts. The bigger the strength of the attraction, the more likely is the occurrence of aggregation and misfolding.
q-bio.BM:We have developed a new simulation method to estimate the distance between the native state and the first transition state, and the distance between the intermediate state and the second transition state of a protein which mechanically unfolds via intermediates. Assuming that the end-to-end extension $\Delta R$ is a good reaction coordinate to describe the free energy landscape of proteins subjected to an external force, we define the midpoint extension $\Delta R^*$ between two transition states from either constant-force or constant loading rate pulling simulations. In the former case, $\Delta R^*$ is defined as a middle point between two plateaus in the time-dependent curve of $\Delta R$, while, in the latter one, it is a middle point between two peaks in the force-extension curve. Having determined $\Delta R^*$, one can compute times needed to cross two transition state barriers starting from the native state. With the help of the Bell and microscopic kinetic theory, force dependencies of these unfolding times can be used to locate the intermediate state and to extract unfolding barriers. We have applied our method to the titin domain I27 and the fourth domain of {\em Dictyostelium discoideum} filamin (DDFLN4), and obtained reasonable agreement with experiments, using the C$_{\alpha}$-Go model.
q-bio.BM:The protective effect exerted by polyamines (Put and Spd) against cadmium (Cd) stress was investigated in Brassica juncea plants. Treatment with CdCl2 (75 micro-Mole) resulted in a rise of Cd accumulation, a decrease of fresh and dry weights in every plant organ, an increase of free polyamine content at limb and stem levels as well as a decrease at root level. On the other hand, the total conjugated polyamine levels in the stem tissues were unaffected by Cd. In the leaf tissues, this metal caused a reduction of chlorophyll a content, a rise of guaiacol peroxidase (GPOX) activity and an increase of malondialdehyde (MDA), soluble glucide, proline and amino acid contents. Exogenous application, by spraying, of putrescine (Put) and spermidine (Spd) to leaf tissues reduced CdCl2-induced stress. These polyamines proved to exert a partial, though significant, protection of the foliar fresh weight and to alleviate the oxidative stress generated by Cd through reductions of MDA amounts and GPOX (E.C.1.11.1.7) activity. The enhancement of chlorophyll a content in plants by Put and those of Chl a and Chl b by Spd both constitute evidences of their efficacy against the Cd2+-induced loss of pigments. Conversely to Put, Spd caused a decrease of Cd content in leave tissues and a rise in the stems and roots; these findings are in favour of a stimulation of Cd uptake by Spd. The proline stimulation observed with Cd was reduced further to the spraying of Put onto tissues, but the decrease induced by Spd was more limited. In the plants treated with Cd, the amino acid contents in the leaves were unaffected by Put and Spd spraying; on the other hand, Cd2+ disturbed polyamine levels (free and acido-soluble conjugated-forms); we notice the rise of total free PAs and the decrease of their conjugated-ones.
q-bio.BM:Three coarse-grained models of the double-stranded DNA are proposed and compared in the context of mechanical manipulation such as twisting and various schemes of stretching. The models differ in the number of effective beads (between two and five) representing each nucleotide. They all show similar behavior and, in particular, lead to a torque-force phase diagrams qualitatively consistent with experiments and all-atom simulations.
q-bio.BM:We incorporate hydrodynamic interactions (HI) in a coarse-grained and structure-based model of proteins by employing the Rotne-Prager hydrodynamic tensor. We study several small proteins and demonstrate that HI facilitate folding. We also study HIV-1 protease and show that HI make the flap closing dynamics faster. The HI are found to affect time correlation functions in the vicinity of the native state even though they have no impact on same time characteristics of the structure fluctuations around the native state.
q-bio.BM:Peptides and proteins exhibit a common tendency to assemble into highly ordered fibrillar aggregates, whose formation proceeds in a nucleation-dependent manner that is often preceded by the formation of disordered oligomeric assemblies. This process has received much attention because disordered oligomeric aggregates have been associated with neurodegenerative disorders such as Alzheimer's and Parkinson's diseases. Here we describe a self-templated nucleation mechanism that determines the transition between the initial condensation of polypeptide chains into disordered assemblies and their reordering into fibrillar structures. The results that we present show that at the molecular level this transition is due to the ability of polypeptide chains to reorder within oligomers into fibrillar assemblies whose surfaces act as templates that stabilise the disordered assemblies.
q-bio.BM:The presence of oligomeric aggregates, which is often observed during the process of amyloid formation, has recently attracted much attention since it has been associated with neurodegenerative conditions such as Alzheimer's and Parkinson's diseases. We provide a description of a sequence-indepedent mechanism by which polypeptide chains aggregate by forming metastable oligomeric intermediate states prior to converting into fibrillar structures. Our results illustrate how the formation of ordered arrays of hydrogen bonds drives the formation of beta-sheets within the disordered oligomeric aggregates that form early under the effect of hydrophobic forces. Initially individual beta-sheets form with random orientations, which subsequently tend to align into protofilaments as their lengths increases. Our results suggest that amyloid aggregation represents an example of the Ostwald step rule of first order phase transitions by showing that ordered cross-beta structures emerge preferentially from disordered compact dynamical intermediate assemblies.
q-bio.BM:It has been recently argued that the depletion attraction may play an important role in different aspects of the cellular organization, ranging from the organization of transcriptional activity in transcription factories to the formation of the nuclear bodies. In this paper we suggest a new application of these ideas in the context of the splicing process, a crucial step of messanger RNA maturation in Eukaryotes. We shall show that entropy effects and the resulting depletion attraction may explain the relevance of the aspecific intron length variable in the choice of the splice-site recognition modality. On top of that, some qualitative features of the genome architecture of higher Eukaryotes can find an evolutionary realistic motivation in the light of our model.
q-bio.BM:Translocation through a nanopore is a new experimental technique to probe physical properties of biomolecules. A bulk of theoretical and computational work exists on the dependence of the time to translocate a single unstructured molecule on the length of the molecule. Here, we study the same problem but for RNA molecules for which the breaking of the secondary structure is the main barrier for translocation. To this end, we calculate the mean translocation time of single-stranded RNA through a nanopore of zero thickness and at zero voltage for many randomly chosen RNA sequences. We find the translocation time to depend on the length of the RNA molecule with a power law. The exponent changes as a function of temperature and exceeds the naively expected exponent of two for purely diffusive transport at all temperatures. We interpret the power law scaling in terms of diffusion in a one-dimensional energy landscape with a logarithmic barrier.
q-bio.BM:Cellular cargo can be bound to cytoskeletal filaments by one or multiple active or passive molecular motors. Recent experiments have shown that the presence of auxiliary, nondriving motors, results in an enhanced processivity of the cargo, compared to the case of a single active motor alone. We model the observed cooperative transport process using a stochastic model that describes the dynamics of two molecular motors, an active one that moves cargo unidirectionally along a filament track and a passive one that acts as a tether. Analytical expressions obtained from our analysis are fit to experimental data to estimate the microscopic kinetic parameters of our model. Our analysis reveals two qualitatively distinct processivity-enhancing mechanisms: the passive tether can decrease the typical detachment rate of the active motor from the filament track or it can increase the corresponding reattachment rate. Our estimates unambiguously show that in the case of microtubular transport, a higher average run length arises mainly from the ability of the passive motor to keep the cargo close to the filament, enhancing the reattachment rate of an active kinesin motor that has recently detached. Instead, for myosin-driven transport along actin, the passive motor tightly tethers the cargo to the filament, suppressing the detachment rate of the active myosin.
q-bio.BM:FoF1-ATP synthase is the enzyme that provides the 'chemical energy currency' adenosine triphosphate, ATP, for living cells. The formation of ATP is accomplished by a stepwise internal rotation of subunits within the enzyme. Briefly, proton translocation through the membrane-bound Fo part of ATP synthase drives a 10-step rotary motion of the ring of c subunits with respect to the non-rotating subunits a and b. This rotation is transmitted to the gamma and epsilon subunits of the F1 sector resulting in 120 degree steps. In order to unravel this symmetry mismatch we monitor subunit rotation by a single-molecule fluorescence resonance energy transfer (FRET) approach using three fluorophores specifically attached to the enzyme: one attached to the F1 motor, another one to the Fo motor, and the third one to a non-rotating subunit. To reduce photophysical artifacts due to spectral fluctuations of the single fluorophores, a duty cycle-optimized alternating three-laser scheme (DCO-ALEX) has been developed. Simultaneous observation of the stepsizes for both motors allows the detection of reversible elastic deformations between the rotor parts of Fo and F1.
q-bio.BM:In this paper, we model the mechanics of a collagen pair in the connective tissue extracellular matrix that exists in abundance throughout animals, including the human body. This connective tissue comprises repeated units of two main structures, namely collagens as well as axial, parallel and regular anionic glycosaminoglycan between collagens. The collagen fibril can be modeled by Hooke's law whereas anionic glycosaminoglycan behaves more like a rubber-band rod and as such can be better modeled by the worm-like chain model. While both computer simulations and continuum mechanics models have been investigated the behavior of this connective tissue typically, authors either assume a simple form of the molecular potential energy or entirely ignore the microscopic structure of the connective tissue. Here, we apply basic physical methodologies and simple applied mathematical modeling techniques to describe the collagen pair quantitatively. We find that the growth of fibrils is intimately related to the maximum length of the anionic glycosaminoglycan and the relative displacement of two adjacent fibrils, which in return is closely related to the effectiveness of anionic glycosaminoglycan in transmitting forces between fibrils. These reveal the importance of the anionic glycosaminoglycan in maintaining the structural shape of the connective tissue extracellular matrix and eventually the shape modulus of human tissues. We also find that some macroscopic properties, like the maximum molecular energy and the breaking fraction of the collagen, are also related to the microscopic characteristics of the anionic glycosaminoglycan.
q-bio.BM:The wobble hypothesis does not discriminate between uracil and thymine. Methylation could favor further stabilization of uracil in the keto form. Thymine is present in keto form only and can pair up but with adenine. Uracil can easily construct the enol form; that is why it forms the U-G pair.
q-bio.BM:In this paper we analyze the vibrational spectra of a large ensemble of non-homologous protein structures by means of a novel tool, that we coin the Hierarchical Network Model (HNM). Our coarse-grained scheme accounts for the intrinsic heterogeneity of force constants displayed by protein arrangements and also incorporates side-chain degrees of freedom.   Our analysis shows that vibrational entropy per unit residue correlates with the content of secondary structure. Furthermore, we assess the individual contribution to vibrational entropy of the novel features of our scheme as compared with the predictions of state-of-the-art network models. This analysis highlights the importance of properly accounting for the intrinsic hierarchy in force strengths typical of the different atomic bonds that build up and stabilize protein scaffolds.   Finally, we discuss possible implications of our findings in the context of protein aggregation phenomena.
q-bio.BM:Because of the double-helical structure of DNA, in which two strands of complementary nucleotides intertwine around each other, a covalently closed DNA molecule with no interruptions in either strand can be viewed as two interlocked single-stranded rings. Two closed space curves have long been known by mathematicians to exhibit a property called the linking number, a topologically invariant integer, expressible as the sum of two other quantities, the twist of one of the curves about the other, and the writhing number, or writhe, a measure of the chiral distortion from planarity of one of the two closed curves. We here derive expressions for the twist of supercoiled DNA and the writhe of a closed molecule consistent with the modern view of DNA as a sequence of base-pair steps. Structural biologists commonly characterize the spatial disposition of each step in terms of six rigid-body parameters, one of which, coincidentally, is also called the twist. Of interest is the difference in the mathematical properties between this step-parameter twist and the twist of supercoiling associated with a given base-pair step. For example, it turns out that the latter twist, unlike the former, is sensitive to certain translational shearing distortions of the molecule that are chiral in nature. Thus, by comparing the values for the two twists for each step of a high-resolution structure of a protein-DNA complex, the nucleosome considered here, for example, we may be able to determine how the binding of various proteins contributes to chiral structural changes of the DNA.
q-bio.BM:The AGBNP2 implicit solvent model, an evolution of the Analytical Generalized Born plus Non-Polar (AGBNP) model we have previously reported, is presented with the aim of modeling hydration effects beyond those described by conventional continuum dielectric representations. A new empirical hydration free energy component based on a procedure to locate and score hydration sites on the solute surface is introduced to model first solvation shell effects, such as hydrogen bonding, which are poorly described by continuum dielectric models. This new component is added to the Generalized Born and non-polar AGBNP models which have been improved with respect to the description of the solute volume description. We have introduced an analytical Solvent Excluding Volume (SEV) model which reduces the effect of spurious high-dielectric interstitial spaces present in conventional van der Waals representations of the solute volume. The AGBNP2 model is parametrized and tested with respect to experimental hydration free energies of small molecules and the results of explicit solvent simulations. Modeling the granularity of water is one of the main design principles employed for the the first shell solvation function and the SEV model, by requiring that water locations have a minimum available volume based on the size of a water molecule. We show that the new volumetric model produces Born radii and surface areas in good agreement with accurate numerical evaluations. The results of Molecular Dynamics simulations of a series of mini-proteins show that the new model produces conformational ensembles in substantially better agreement with reference explicit solvent ensembles than the original AGBNP model with respect to both structural and energetics measures.
q-bio.BM:It is presented that the positions of amino acids within Genetic Code Table follow from strict their physical and chemical properties as well as from a pure formal determination by the Golden mean.
q-bio.BM:Although DNA is often bent in vivo, it is unclear how DNA-bending forces modulate DNA-protein binding affinity. Here, we report how a range of DNA-bending forces modulates the binding of the Integration Host Factor (IHF) protein to various DNAs. Using solution fluorimetry and electrophoretic mobility shift assays, we measured the affinity of IHF for DNAs with different bending forces and sequence mutations. Bending force was adjusted by varying the fraction of double-stranded DNA in a circular substrate, or by changing the overall size of the circle (1). DNA constructs contained a pair of Forster Resonance Energy Transfer dyes that served as probes for affinity assays, and read out bending forces measured by optical force sensors (2). Small bending forces significantly increased binding affinity; this effect saturated beyond ~3 pN. Surprisingly, when DNA sequences that bound IHF only weakly were mechanically bent by circularization, they bound IHF more tightly than the linear "high-affinity" binding sequence. These findings demonstrate that small bending forces can greatly augment binding at sites that deviate from a protein's consensus binding sequence. Since cellular DNA is subject to mechanical deformation and condensation, affinities of architectural proteins determined in vitro using short linear DNAs may not reflect in vivo affinities.
q-bio.BM:A statistical model of protein families, called profile conditional random fields (CRFs), is proposed. This model may be regarded as an integration of the profile hidden Markov model (HMM) and the Finkelstein-Reva (FR) theory of protein folding. While the model structure of the profile CRF is almost identical to the profile HMM, it can incorporate arbitrary correlations in the sequences to be aligned to the model. In addition, like in the FR theory, the profile CRF can incorporate long-range pairwise interactions between model states via mean-field-like approximations. We give the detailed formulation of the model, self-consistent approximations for treating long-range interactions, and algorithms for computing partition functions and marginal probabilities. We also outline the methods for the global optimization of model parameters as well as a Bayesian framework for parameter learning and selection of optimal alignments.
q-bio.BM:Mathew-Fenn et al. (Science (2008) 322, 446-9) measured end-to-end distances of short DNA and concluded that stretching fluctuations in several consecutive turns of the double helix should be strongly correlated. I argue that this conclusion is based on incorrect assumptions, notably, on a simplistic treatment of the excluded volume effect of reporter labels. Contrary to the author's claim, their conclusion is not supported by other data.
q-bio.BM:The folding dynamics of small single-domain proteins is a current focus of simulations and experiments. Many of these proteins are 'two-state folders', i.e. proteins that fold rather directly from the denatured state to the native state, without populating metastable intermediate states. A central question is how to characterize the instable, partially folded conformations of two-state proteins, in particular the rate-limiting transition-state conformations between the denatured and the native state. These partially folded conformations are short-lived and cannot be observed directly in experiments. However, experimental data from detailed mutational analyses of the folding dynamics provide indirect access to transition states. The interpretation of these data, in particular the reconstruction of transition-state conformations, requires simulation and modeling. The traditional interpretation of the mutational data aims to reconstruct the degree of structure formation of individual residues in the transition state, while a novel interpretation aims at degrees of structure formation of cooperative substructures such as alpha-helices and beta-hairpins. By splitting up mutation-induced free energy changes into secondary and tertiary structural components, the novel interpretation resolves some of the inconsistencies of the traditional interpretation.
q-bio.BM:In Sphingomonas CHY-1, a single ring-hydroxylating dioxygenase is responsible for the initial attack of a range of polycyclic aromatic hydrocarbons (PAHs) composed of up to five rings. The components of this enzyme were separately purified and characterized. The oxygenase component (ht-PhnI) was shown to contain one Rieske-type [2Fe-2S] cluster and one mononuclear Fe center per alpha subunit, based on EPR measurements and iron assay. Steady-state kinetic measurements revealed that the enzyme had a relatively low apparent Michaelis constant for naphthalene (Km= 0.92 $\pm$ 0.15 $\mu$M), and an apparent specificity constant of 2.0 $\pm$ 0.3 $\mu$M-1 s-1. Naphthalene was converted to the corresponding 1,2-dihydrodiol with stoichiometric oxidation of NADH. On the other hand, the oxidation of eight other PAHs occurred at slower rates, and with coupling efficiencies that decreased with the enzyme reaction rate. Uncoupling was associated with hydrogen peroxide formation, which is potentially deleterious to cells and might inhibit PAH degradation. In single turnover reactions, ht-PhnI alone catalyzed PAH hydroxylation at a faster rate in the presence of organic solvent, suggesting that the transfer of substrate to the active site is a limiting factor. The four-ring PAHs chrysene and benz[a]anthracene were subjected to a double ring-dihydroxylation, giving rise to the formation of a significant proportion of bis-cis-dihydrodiols. In addition, the dihydroxylation of benz[a]anthracene yielded three dihydrodiols, the enzyme showing a preference for carbons in positions 1,2 and 10,11. This is the first characterization of a dioxygenase able to dihydroxylate PAHs made up of four and five rings.
q-bio.BM:Initial reactions involved in the bacterial degradation of polycyclic aromatic hydrocarbons (PAHs) include a ring-dihydroxylation catalyzed by a dioxygenase and a subsequent oxidation of the dihydrodiol products by a dehydrogenase. In this study, the dihydrodiol dehydrogenase from the PAH-degrading Sphingomonas strain CHY-1 has been characterized. The bphB gene encoding PAH dihydrodiol dehydrogenase (PDDH) was cloned and overexpressed as a His-tagged protein. The recombinant protein was purified as a homotetramer with an apparent Mr of 110,000. PDDH oxidized the cis-dihydrodiols derived from biphenyl and eight polycyclic hydrocarbons, including chrysene, benz[a]anthracene, and benzo[a]pyene, to corresponding catechols. Remarkably, the enzyme oxidized pyrene 4,5-dihydrodiol, whereas pyrene is not metabolized by strain CHY-1. The PAH catechols produced by PDDH rapidly auto-oxidized in air but were regenerated upon reaction of the o-quinones formed with NADH. Kinetic analyses performed under anoxic conditions revealed that the enzyme efficiently utilized two- to four-ring dihydrodiols, with Km values in the range of 1.4 to 7.1 $\mu$M, and exhibited a much higher Michaelis constant for NAD+ (Km of 160 $\mu$M). At pH 7.0, the specificity constant ranged from (1.3 $\pm$ 0.1) x 106 M?1 s?1 with benz[a]anthracene 1,2-dihydrodiol to (20.0 $\pm$ 0.8) x 106 M?1 s?1 with naphthalene 1,2-dihydrodiol. The catalytic activity of the enzyme was 13-fold higher at pH 9.5. PDDH was subjected to inhibition by NADH and by 3,4-dihydroxyphenanthrene, and the inhibition patterns suggested that the mechanism of the reaction was ordered Bi Bi. The regulation of PDDH activity appears as a means to prevent the accumulation of PAH catechols in bacterial cells.
q-bio.BM:2-Ethyhexyl nitrate (2-EHN) is a major additive of fuel which is used to comply with the cetane number of diesel. Because of its wide use and possible accidental release, 2-EHN is a potential pollutant of the environment. In this study, Mycobacterium austroafricanum IFP 2173 was selected among several strains as the best 2-EHN degrader. The 2-EHN biodegradation rate was increased in biphasic cultures where the hydrocarbon was dissolved in an inert non-aqueous phase liquid (NAPL), suggesting that the transfer of the hydrophobic substrate to the cells was a growth-limiting factor. Carbon balance calculation as well as organic carbon measurement indicated a release of metabolites in the culture medium. Further analysis by gas chromatography revealed that a single metabolite accumulated during growth. This metabolite had a molecular mass of 114 Da as determined by GC/MS and was provisionally identified as 4-ethyldihydrofuran-2(3H)-one by LC-MS/MS analysis. Identification was confirmed by analysis of the chemically synthesized lactone. Based on these results, a plausible catabolic pathway is proposed whereby 2-EHN is converted to 4-ethyldihydrofuran-2(3H)-one, which cannot be metabolised further by strain IFP 2173. This putative pathway provides an explanation for the low energetic efficiency of 2-EHN degradation and its poor biodegradability.
q-bio.BM:In this study, the genes involved in the initial attack on fluorene by Sphingomonas sp. LB126 were investigated. The ? and ? subunits of a dioxygenase complex (FlnA1A2), showing 63% and 51% sequence identity respectively, with the subunits of an angular dioxygenase from Gram-positive Terrabacter sp. DBF63, were identified. When overexpressed in E. coli, FlnA1A2 was responsible for the angular oxidation of fluorene, fluorenol, fluorenone, dibenzofuran and dibenzo-p-dioxin. Moreover, FlnA1A2 was able to oxidize polycyclic aromatic hydrocarbons and heteroaromatics, some of which were not oxidized by the dioxygenase from Terrabacter sp. DBF63. Quantification of resulting oxidation products showed that fluorene and phenanthrene were preferred substrates.
q-bio.BM:We study a simplified model of the RNA molecule proposed by G. Vernizzi, H. Orland and A. Zee in the regime of strong concentration of positive ions in solution. The model considers a flexible chain of equal bases that can pairwise interact with any other one along the chain, while preserving the property of saturation of the interactions. In the regime considered, we observe the emergence of a critical temperature T_c separating two phases that can be characterized by the topology of the predominant configurations: in the large temperature regime, the dominant configurations of the molecule have very large genera (of the order of the size of the molecule), corresponding to a complex topology, whereas in the opposite regime of low temperatures, the dominant configurations are simple and have the topology of a sphere. We determine that this topological phase transition is of first order and provide an analytic expression for T_c. The regime studied for this model exhibits analogies with that for the dense polymer systems studied by de Gennes
q-bio.BM:The kinetics for the assembly of viral proteins into a population of capsids can be measured in vitro with size exclusion chromatography or dynamic light scattering, but extracting mechanistic information from these studies is challenging. For example, it is not straightforward to determine the critical nucleus size or the elongation time (the time required for a nucleated partial capsid to grow completion). We show that, for two theoretical models of capsid assembly, the critical nucleus size can be determined from the concentration dependence of the assembly reaction half-life and the elongation time is revealed by the length of the lag phase. Furthermore, we find that the system becomes kinetically trapped when nucleation becomes fast compared to elongation. Implications of this constraint for determining elongation mechanisms from experimental assembly data are discussed.
q-bio.BM:Single molecule Forster resonance energy transfer (FRET) experiments are used to infer the properties of the denatured state ensemble (DSE) of proteins. From the measured average FRET efficiency, <E>, the distance distribution P(R) is inferred by assuming that the DSE can be described as a polymer. The single parameter in the appropriate polymer model (Gaussian chain, Wormlike chain, or Self-avoiding walk) for P(R) is determined by equating the calculated and measured <E>. In order to assess the accuracy of this "standard procedure," we consider the generalized Rouse model (GRM), whose properties [<E> and P(R)] can be analytically computed, and the Molecular Transfer Model for protein L for which accurate simulations can be carried out as a function of guanadinium hydrochloride (GdmCl) concentration. Using the precisely computed <E> for the GRM and protein L, we infer P(R) using the standard procedure. We find that the mean end-to-end distance can be accurately inferred (less than 10% relative error) using <E> and polymer models for P(R). However, the value extracted for the radius of gyration (Rg) and the persistence length (lp) are less accurate. The relative error in the inferred R-g and lp, with respect to the exact values, can be as large as 25% at the highest GdmCl concentration. We propose a self-consistency test, requiring measurements of <E> by attaching dyes to different residues in the protein, to assess the validity of describing DSE using the Gaussian model. Application of the self-consistency test to the GRM shows that even for this simple model the Gaussian P(R) is inadequate. Analysis of experimental data of FRET efficiencies for the cold shock protein shows that at there are significant deviations in the DSE P(R) from the Gaussian model.
q-bio.BM:The high computational cost of carrying out molecular dynamics simulations of even small-size proteins is a major obstacle in the study, at atomic detail and in explicit solvent, of the physical mechanism which is at the basis of the folding of proteins. Making use of a biasing algorithm, based on the principle of the ratchet-and-pawl, we have been able to calculate eight folding trajectories (to an RMSD between 1.2A and 2.5A) of the B1 domain of protein G in explicit solvent without the need of high-performance computing. The simulations show that in the denatured state there is a complex network of cause-effect relationships among contacts, which results in a rather hierarchical folding mechanism. The network displays few local and nonlocal native contacts which are cause of most of the others, in agreement with the NOE signals obtained in mildly-denatured conditions. Also nonnative contacts play an active role in the folding kinetics. The set of conformations corresponding to the transition state display phi-values with a correlation coefficient of 0.69 with the experimental ones. They are structurally quite homogeneous and topologically native-like, although some of the side chains and most of the hydrogen bonds are not in place.
q-bio.BM:Rigidity analysis using the "pebble game" has been applied to protein crystal structures to obtain information on protein folding, assembly and t he structure-function relationship. However, previous work using this technique has not made clear how the set of hydrogen-bond constraints included in the rigidity analysis should be chosen, nor how sensitive the results of rigidity analysis are to small structural variations. We present a comparative study in which "pebble game" rigidity analysis is applied to multiple protein crystal structures, for each of six differen t protein families. We find that the mainchain rigidity of a protein structure at a given hydrogen-bond energy cutoff is quite sensitive to small structural variations, and conclude that the hydrogen bond constraints in rigidity analysis should be chosen so as to form and test specific hypotheses about the rigidity o f a particular protein. Our comparative approach highlights two different characteristic patterns ("sudden" or "gradual") for protein rigidity loss as constraints are re moved, in line with recent results on the rigidity transitions of glassy networks.
q-bio.BM:We carry out a theoretical study on the isotropic-nematic phase transition and phase separation in amyloid fibril solutions. Borrowing the thermodynamic model employed in the study of cylindrical micelles, we investigate the variations in the fibril length distribution and phase behavior with respect to changes in the protein concentration, fibril's rigidity, and binding energy. We then relate our theoretical findings to the nematic ordering observed in Hen Lysozyme fibril solution.
q-bio.BM:Homeodomain containing proteins are a broad class of DNA binding proteins that are believed to primarily function as transcription factors. Electrostatics interactions have been demonstrated to be critical for the binding of the homeodomain to DNA. An examination of the electrostatic state of homeodomain residues involved in DNA phosphate binding has demonstrated the conserved presence of upward shifted pKa values among the basic residue of lysine and arginine. It is believed that these pKa perturbations work to facilitate binding to DNA since they ensure that the basic residues always retain a positive charge.
q-bio.BM:2D display is a fast and economical way of visualizing polymorphism and comparing genomes, which is based on the separation of DNA fragments in two steps, according first to their size and then to their sequence composition. In this paper, we present an exhaustive study of the numerical issues associated with a model aimed at predicting the final absolute locations of DNA fragments in 2D display experiments. We show that simple expressions for the mobility of DNA fragments in both dimensions allow one to reproduce experimental final absolute locations to better than experimental uncertainties. On the other hand, our simulations also point out that the results of 2D display experiments are not sufficient to determine the best set of parameters for the modeling of fragments separation in the second dimension and that additional detailed measurements of the mobility of a few sequences are necessary to achieve this goal. We hope that this work will help in establishing simulations as a powerful tool to optimize experimental conditions without having to perform a large number of preliminary experiments and to estimate whether 2D DNA display is suited to identify a mutation or a genetic difference that is expected to exist between the genomes of closely related organisms.
q-bio.BM:Proteins are large and complex molecular machines. In order to perform their function, most of them need energy, e.g. either in the form of a photon, like in the case of the visual pigment rhodopsin, or through the breaking of a chemical bond, as in the presence of adenosine triphosphate (ATP). Such energy, in turn, has to be transmitted to specific locations, often several tens of Angstroms away from where it is initially released. Here we show, within the framework of a coarse-grained nonlinear network model, that energy in a protein can jump from site to site with high yields, covering in many instances remarkably large distances. Following single-site excitations, few specific sites are targeted, systematically within the stiffest regions. Such energy transfers mark the spontaneous formation of a localized mode of nonlinear origin at the destination site, which acts as an efficient energy-accumulating centre. Interestingly, yields are found to be optimum for excitation energies in the range of biologically relevant ones.
q-bio.BM:A protein undergoes conformational dynamics with multiple time scales, which results in fluctuating enzyme activities. Recent studies in single molecule enzymology have observe this "age-old" dynamic disorder phenomenon directly. However, the single molecule technique has its limitation. To be able to observe this molecular effect with real biochemical functions {\it in situ}, we propose to couple the fluctuations in enzymatic activity to noise propagations in small protein interaction networks such as zeroth order ultra-sensitive phosphorylation-dephosphorylation cycle. We showed that enzyme fluctuations could indeed be amplified by orders of magnitude into fluctuations in the level of substrate phosphorylation | a quantity widely interested in cellular biology. Enzyme conformational fluctuations sufficiently slower than the catalytic reaction turn over rate result in a bimodal concentration distribution of the phosphorylated substrate. In return, this network amplified single enzyme fluctuation can be used as a novel biochemical "reporter" for measuring single enzyme conformational fluctuation rates.
q-bio.BM:The microtubule assembly process has been extensively studied, but the underlying molecular mechanism remains poorly understood. The structure of an artificially generated sheet polymer that alternates two types of lateral contacts and that directly converts into microtubules, has been proposed to correspond to the intermediate sheet structure observed during microtubule assembly. We have studied the self-assembly process of GMPCPP tubulins into sheet and microtubule structures using thermodynamic analysis and stochastic simulations. With the novel assumptions that tubulins can laterally interact in two different forms, and allosterically affect neighboring lateral interactions, we can explain existing experimental observations. At low temperature, the allosteric effect results in the observed sheet structure with alternating lateral interactions as the thermodynamically most stable form. At normal microtubule assembly temperature, our work indicates that a class of sheet structures resembling those observed at low temperature is transiently trapped as an intermediate during the assembly process. This work may shed light on the tubulin molecular interactions, and the role of sheet formation during microtubule assembly.
q-bio.BM:Metamorphic proteins like Lymphotactin are a notable exception of the empirical principle that structured natural proteins possess a unique three dimensional structure. In particular, the human chemokine lymphotactin protein (Ltn) exists in two distinct conformations (one monomeric and one dimeric) under physiological conditions. In this work we use a Ca Go-model to show how this very peculiar behavior can be reproduced. From the study of the thermodynamics and of the kinetics we characterize the interconversion mechanism. In particular, this takes place through the docking of the two chains living in a third monomeric, partially unfolded, state which shows a residual structure involving a set of local contacts common to the two native conformations. The main feature of two-fold proteins appears to be the sharing of a common set of local contacts between the two distinct folds as confirmed by the study of two designed two-fold proteins. Metamorphic proteins may be more common than expected.
q-bio.BM:Computing the similarity between two protein structures is a crucial task in molecular biology, and has been extensively investigated. Many protein structure comparison methods can be modeled as maximum clique problems in specific k-partite graphs, referred here as alignment graphs. In this paper, we propose a new protein structure comparison method based on internal distances (DAST) which is posed as a maximum clique problem in an alignment graph. We also design an algorithm (ACF) for solving such maximum clique problems. ACF is first applied in the context of VAST, a software largely used in the National Center for Biotechnology Information, and then in the context of DAST. The obtained results on real protein alignment instances show that our algorithm is more than 37000 times faster than the original VAST clique solver which is based on Bron & Kerbosch algorithm. We furthermore compare ACF with one of the fastest clique finder, recently conceived by Ostergard. On a popular benchmark (the Skolnick set) we observe that ACF is about 20 times faster in average than the Ostergard's algorithm.
q-bio.BM:We use computer simulations to study a model, first proposed by Wales [1], for the reversible and monodisperse self-assembly of simple icosahedral virus capsid structures. The success and efficiency of assembly as a function of thermodynamic and geometric factors can be qualitatively related to the potential energy landscape structure of the assembling system. Even though the model is strongly coarse-grained, it exhibits a number of features also observed in experiments, such as sigmoidal assembly dynamics, hysteresis in capsid formation and numerous kinetic traps. We also investigate the effect of macromolecular crowding on the assembly dynamics. Crowding agents generally reduce capsid yields at optimal conditions for non-crowded assembly, but may increase yields for parameter regimes away from the optimum. Finally, we generalize the model to a larger triangulation number T = 3, and observe more complex assembly dynamics than that seen for the original T = 1 model.
q-bio.BM:Why reaction rate constants for enzymatic reactions are typically inversely proportional to fractional power exponents of solvent viscosity remains to be already a thirty years old puzzle. Available interpretations of the phenomenon invoke to either a modification of 1. the conventional Kramers' theory or that of 2. the Stokes law. We show that there is an alternative interpretation of the phenomenon at which neither of these modifications is in fact indispensable. We reconcile 1. and 2. with the experimentally observable dependence. We assume that an enzyme solution in solvent with or without cosolvent molecules is an ensemble of samples with different values of the viscosity for the movement of the system along the reaction coordinate. We assume that this viscosity consists of the contribution with the weight $q$ from cosolvent molecules and that with the weight $1-q$ from protein matrix and solvent molecules. We introduce heterogeneity in our system with the help of a distribution over the weight $q$. We verify the obtained solution of the integral equation for the unknown function of the distribution by direct substitution. All parameters of the model are related to experimentally observable values. General formalism is exemplified by the analysis of literature experimental data for oxygen escape from hemerythin.
q-bio.BM:A simple explanation for the symmetry and degeneracy of the genetic code has been suggested. An alternative to the wobble hypothesis has been proposed. This hypothesis offers explanations for: i) the difference between thymine and uracil, ii) encoding of tryptophan by only one codon, iii) why E. coli have no inosine in isoleucine tRNA, but isoleucine is encoded by three codons. The facts revealed in this study offer a new insight into physical mechanisms of the functioning of the genetic code.
q-bio.BM:A new theoretical survey of proteins' resistance to constant speed stretching is performed for a set of 17 134 proteins as described by a structure-based model. The proteins selected have no gaps in their structure determination and consist of no more than 250 amino acids. Our previous studies have dealt with 7510 proteins of no more than 150 amino acids. The proteins are ranked according to the strength of the resistance. Most of the predicted top-strength proteins have not yet been studied experimentally. Architectures and folds which are likely to yield large forces are identified. New types of potent force clamps are discovered. They involve disulphide bridges and, in particular, cysteine slipknots. An effective energy parameter of the model is estimated by comparing the theoretical data on characteristic forces to the corresponding experimental values combined with an extrapolation of the theoretical data to the experimental pulling speeds. These studies provide guidance for future experiments on single molecule manipulation and should lead to selection of proteins for applications. A new class of proteins, involving cystein slipknots, is identified as one that is expected to lead to the strongest force clamps known. This class is characterized through molecular dynamics simulations.
q-bio.BM:We have developed a generalized semi-analytic approach for efficiently computing cyclization and looping $J$ factors of DNA under arbitrary binding constraints. Many biological systems involving DNA-protein interactions impose precise boundary conditions on DNA, which necessitates a treatment beyond the Shimada-Yamakawa model for ring cyclization. Our model allows for DNA to be treated as a heteropolymer with sequence-dependent intrinsic curvature and stiffness. In this framework, we independently compute enthlapic and entropic contributions to the $J$ factor and show that even at small length scales $(\sim \ell_{p})$ entropic effects are significant. We propose a simple analytic formula to describe our numerical results for a homogenous DNA in planar loops, which can be used to predict experimental cyclization and loop formation rates as a function of loop size and binding geometry. We also introduce an effective torsional persistence length that describes the coupling between twist and bending of DNA when looped.
q-bio.BM:We use the Dominant Reaction Pathway (DRP) approach to study the dynamics of the folding of a beta-hairpin, within a model which accounts for both native and non-native interactions. We compare the most probable folding pathways calculated with the DRP method with those obtained directly from molecular dynamics (MD) simulations. We find that the two approaches give completely consistent results. We investigate the effects of the non-native hydrophobic interactions on the folding dynamics found them to be small.
q-bio.BM:Mechanical unfolding of the fourth domain of Distyostelium discoideum filamin (DDFLN4) was studied in detail using the C$_{\alpha}$-Go model. We show that unfolding pathways of this protein depend on the pulling speed. The agreement between theoretical and experimental results on the sequencing of unfolding events is achieved at low loading rates. The unfolding free energy landscape is also constructed using dependencies of unfolding forces on pulling speeds.
q-bio.BM:Mechanical unfolding of the fourth domain of Distyostelium discoideum filamin (DDFLN4) was studied by all-atom molecular dynamics simulations, using the GROMOS96 force field 43a1 and the simple point charge explicit water solvent. Our study reveals an important role of non-native interactions in the unfolding process. Namely, the existence of a peak centered at the end-to-end extension 22 nm in the force-extension curve, is associated with breaking of non-native hydrogen bonds. Such a peak has been observed in experiments but not in Go models, where non-native interactions are neglected. We predict that an additional peak occurs at 2 nm using not only GROMOS96 force field 43a1 but also Amber 94 and OPLS force fields. This result would stimulate further experimental studies on elastic properties of DDFLN4.
q-bio.BM:With the aid of quantum mechanical calculations we investigate the electronic structure of the full length (FL) potassium channel protein, FL-KcsA, in its closed conformation, and the electronic structure of the ClC chloride channel. The results indicate that both ion channels are strongly polarized towards the extracellular region with respect to the membrane mean plane. FL-KcsA possesses an electric dipole moment of magnitude 403 Debye while ClC has a macrodipole whose magnitude is about five times larger, 1983 Debye, thereby contributing to differentiate their membrane electric barriers. The dipole vectors of both proteins are aligned along the corresponding selectivity filters. This result suggests that potassium and chloride ion channels are not passive with respect to the movement of ions across the membrane and the ionic motion might be partially driven by the electric field of the protein in conjunction with the electrochemical potential of the membrane.
q-bio.BM:We show that minuscule entropic forces, on the order of 100 fN, can prevent the formation of DNA loops--a ubiquitous means of regulating the expression of genes. We observe a tenfold decrease in the rate of LacI-mediated DNA loop formation when a tension of 200 fN is applied to the substrate DNA, biasing the thermal fluctuations that drive loop formation and breakdown events. Conversely, once looped, the DNA-protein complex is insensitive to applied force. Our measurements are in excellent agreement with a simple polymer model of loop formation in DNA, and show that an anti-parallel topology is the preferred LacI-DNA loop conformation for a generic loop-forming construct.
q-bio.BM:The Electron Microscopy Data Bank (EMDB) is a rapidly growing repository for the dissemination of structural data from single-particle reconstructions of supramolecular protein assemblies including motors, chaperones, cytoskeletal assemblies, and viral capsids. While the static structure of these assemblies provides essential insight into their biological function, their conformational dynamics and mechanics provide additional important information regarding the mechanism of their biological function. Here, we present an unsupervised computational framework to analyze and store for public access the conformational dynamics of supramolecular protein assemblies deposited in the EMDB. Conformational dynamics are analyzed using normal mode analysis in the finite element framework, which is used to compute equilibrium thermal fluctuations, cross-correlations in molecular motions, and strain energy distributions for 452 of the 681 entries stored in the EMDB at present. Results for the viral capsid of hepatitis B, ribosome-bound termination factor RF2, and GroEL are presented in detail and validated with all-atom based models. The conformational dynamics of protein assemblies in the EMDB may be useful in the interpretation of their biological function, as well as in the classification and refinement of EM-based structures.
q-bio.BM:The dynamical characterization of proteins is crucial to understand protein function. From a microscopic point of view, protein dynamics is governed by the local atomic interactions that, in turn, trigger the functional conformational changes. Unfortunately, the relationship between local atomic fluctuations and global protein rearrangements is still elusive. Here, atomistic molecular dynamics simulations in conjunction with complex network analysis show that fast peptide relaxations effectively build the backbone of the global free-energy landscape, providing a connection between local and global atomic rearrangements. A minimum-spanning-tree representation, built on the base of transition gradients networks, results in a high resolution mapping of the system dynamics and thermodynamics without requiring any a priori knowledge of the relevant degrees of freedom. These results suggest the presence of a local mechanism for the high communication efficiency generally observed in complex systems.
q-bio.BM:The functional correlation of missense mutations which cause disease remains a challenge to understanding the basis of genetic diseases. This is particularly true for proteins related to diseases for which there are no available three dimensional structures. One such disease is Shwachman Diamond syndrome SDS OMIM 260400, a multi system disease arising from loss of functional mutations. The Homo sapiens Shwachman Bodian Diamond Syndrome gene hSBDS is responsible for SDS. hSBDS is expressed in all tissues and encodes a protein of 250 amino acids SwissProt accession code Q9Y3A5. Sequence analysis of disease associated alleles has identified more than 20 different mutations in affected individuals. While a number of these mutations have been described as leading to the loss of protein function due to truncation, translation or surface epitope association, the structural basis for these mutations has yet to be determined due to the lack of a three-dimensional structure for SBDS.
q-bio.BM:Using the perturbation-response scanning (PRS) technique, we study a set of 23 proteins that display a variety of conformational motions upon ligand binding (e.g. shear, hinge, allosteric). In most cases, PRS determines residues that may be manipulated to achieve the resulting conformational change. PRS reveals that for some proteins, binding induced conformational change may be achieved through the perturbation of residues scattered throughout the protein, whereas in others, perturbation of specific residues confined to a highly specific region are necessary. Correlations between the experimental and calculated atomic displacements are always better or equivalent to those obtained from a modal analysis of elastic network models. Furthermore, best correlations obtained by the latter approach do not always appear in the most collective modes. We show that success of the modal analysis depends on the lack of redundant paths that exist in the protein. PRS thus demonstrates that several relevant modes may simultaneously be induced by perturbing a single select residue on the protein. We also illustrate the biological relevance of applying PRS on the GroEL and ADK structures in detail, where we show that the residues whose perturbation lead to the precise conformational changes usually correspond to those experimentally determined to be functionally important.
q-bio.BM:Living cells provide a fluctuating, out-of-equilibrium environment in which genes must coordinate cellular function. DNA looping, which is a common means of regulating transcription, is very much a stochastic process; the loops arise from the thermal motion of the DNA and other fluctuations of the cellular environment. We present single-molecule measurements of DNA loop formation and breakdown when an artificial fluctuating force, applied to mimic a fluctuating cellular environment, is imposed on the DNA. We show that loop formation is greatly enhanced in the presence of noise of only a fraction of $k_B T$, yet find that hypothetical regulatory schemes that employ mechanical tension in the DNA--as a sensitive switch to control transcription--can be surprisingly robust due to a fortuitous cancellation of noise effects.
q-bio.BM:Capsids of many viruses assemble around nucleic acids or other polymers. Understanding how the properties of the packaged polymer affect the assembly process could promote biomedical efforts to prevent viral assembly or nanomaterials applications that exploit assembly. To this end, we simulate on a lattice the dynamical assembly of closed, hollow shells composed of several hundred to 1000 subunits, around a flexible polymer. We find that assembly is most efficient at an optimum polymer length that scales with the surface area of the capsid; significantly longer than optimal polymers often lead to partial-capsids with unpackaged polymer `tails' or a competition between multiple partial-capsids attached to a single polymer. These predictions can be tested with bulk experiments in which capsid proteins assemble around homopolymeric RNA or synthetic polyelectrolytes. We also find that the polymer can increase the net rate of subunit accretion to a growing capsid both by stabilizing the addition of new subunits and by enhancing the incoming flux of subunits; the effects of these processes may be distinguishable with experiments that monitor the assembly of individual capsids.
q-bio.BM:We study the control parameters that govern the dynamics of in vitro DNA ejection in bacteriophage lambda. Past work has demonstrated that bacteriophage DNA is highly pressurized; this pressure has been hypothesized to help drive DNA ejection. Ions influence this process by screening charges on DNA; however, a systematic variation of salt concentrations to explore these effects has not been undertaken. To study the nature of the forces driving DNA ejection, we performed in vitro measurements of DNA ejection in bulk and at the single-phage level. We present measurements on the dynamics of ejection and on the self-repulsion force driving ejection. We examine the role of ion concentration and identity in both measurements, and show that the charge of counter-ions is an important control parameter. These measurements show that the frictional force acting on the ejecting DNA is subtly dependent on ionic concentrations for a given amount of DNA in the capsid. We also present evidence that phage DNA forms loops during ejection; we confirm that this effect occurs using optical tweezers. We speculate this facilitates circularization of the genome in the cytoplasm.
q-bio.BM:A relationship between the preexponent of the rate constant and the distribution over activation barrier energies for enzymatic/protein reactions is revealed. We consider an enzyme solution as an ensemble of individual molecules with different values of the activation barrier energy described by the distribution. From the solvent viscosity effect on the preexponent we derive the integral equation for the distribution and find its approximate solution. Our approach enables us to attain a twofold purpose. On the one hand it yields a simple interpretation of the solvent viscosity dependence for enzymatic/protein reactions that requires neither a modification of the Kramers' theory nor that of the Stokes law. On the other hand our approach enables us to deduce the form of the distribution over activation barrier energies. The obtained function has a familiar bell-shaped form and is in qualitative agreement with the results of single enzyme kinetics measurements. General formalism is exemplified by the analysis of literature experimental data.
q-bio.BM:A molecular-level model is used to study the mechanical response of empty cowpea chlorotic mottle virus (CCMV) and cowpea mosaic virus (CPMV) capsids. The model is based on the native structure of the proteins that consitute the capsids and is described in terms of the C-alpha atoms. Nanoindentation by a large tip is modeled as compression between parallel plates. Plots of the compressive force versus plate separation for CCMV are qualitatively consistent with continuum models and experiments, showing an elastic region followed by an irreversible drop in force. The mechanical response of CPMV has not been studied, but the molecular model predicts an order of magnitude higher stiffness and a much shorter elastic region than for CCMV. These large changes result from small structural changes that increase the number of bonds by only 30% and would be difficult to capture in continuum models. Direct comparison of local deformations in continuum and molecular models of CCMV shows that the molecular model undergoes a gradual symmetry breaking rotation and accommodates more strain near the walls than the continuum model. The irreversible drop in force at small separations is associated with rupturing nearly all of the bonds between capsid proteins in the molecular model while a buckling transition is observed in continuum models.
q-bio.BM:Using lattice models we explore the factors that determine the tendencies of polypeptide chains to aggregate by exhaustively sampling the sequence and conformational space. The morphologies of the fibril-like structures and the time scales ($\tau_{fib}$) for their formation depend on a subtle balance between hydrophobic and coulomb interactions. The extent of population of a fibril-prone structure in the spectrum of monomer conformations is the major determinant of $\tau_{fib}$. This observation is used to determine the aggregation-prone consensus sequences by exhaustively exploring the sequence space. Our results provide a basis for genome wide search of fragments that are aggregation prone.
q-bio.BM:Cancer is a proliferation disease affecting a genetically unstable cell population, in which molecular alterations can be somatically inherited by genetic, epigenetic or extragenetic transmission processes, leading to a cooperation of neoplastic cells within tumoral tissue. The efflux protein P-glycoprotein (P gp) is overexpressed in many cancer cells and has known capacity to confer multidrug resistance to cytotoxic therapies. Recently, cell-to-cell P-gp transfers have been shown. Herein, we combine experimental evidence and a mathematical model to examine the consequences of an intercellular P-gp trafficking in the extragenetic transfer of multidrug resistance from resistant to sensitive cell subpopulations. We report cell-to-cell transfers of functional P-gp in co-cultures of a P-gp overexpressing human breast cancer MCF-7 cell variant, selected for its resistance towards doxorubicin, with the parental sensitive cell line. We found that P-gp as well as efflux activity distribution are progressively reorganized over time in co-cultures analyzed by flow cytometry. A mathematical model based on a Boltzmann type integro-partial differential equation structured by a continuum variable corresponding to P-gp activity describes the cell populations in co-culture. The mathematical model elucidates the population elements in the experimental data, specifically, the initial proportions, the proliferative growth rates, and the transfer rates of P-gp in the sensitive and resistant subpopulations. We confirmed cell-to-cell transfer of functional P-gp. The transfer process depends on the gradient of P-gp expression in the donor-recipient cell interactions, as they evolve over time. Extragenetically acquired drug resistance is an additional aptitude of neoplastic cells which has implications in the diagnostic value of P-gp expression and in the design of chemotherapy regimens
q-bio.BM:We discuss the appropriate techniques for modelling the geometry of open ended elastic polymer molecules. The molecule is assumed to have fixed endpoints on a boundary surface. In particular we discuss the concept of the winding number, a directional measure of the linking of two curves, which can be shown to be invariant to the set of continuous deformations vanishing at the polymer's end-point and which forbid it from passing through itself. This measure is shown to be the appropriate constraint required to evaluate the geometrical properties of a constrained DNA molecule. Using the net winding measure we define a model of an open ended constrained DNA molecule which combines the necessary constraint of self-avoidance with being analytically tractable. This model builds upon the local models of Bouchiat and Mezard (2000). In particular, we present a new derivation of the polar writhe expression, which detects both the local winding of the curve and non local winding between different sections of the curve. We then show that this expression correctly tracks the net twisting of a DNA molecule subject to rotation at the endpoints, unlike other definitions used in the literature.
q-bio.BM:The electronic structure of charybdotoxin (ChTX), a scorpion venom peptide that is known to act as a potassium channel blocker, is investigated with the aid of quantum mechanical calculations. The dipole moment vector (145 D) of ChTX can be stirred by the full length KcsA potassium channel's macrodipole (403 D) thereby assuming the proper orientation before binding the ion channel on the cell surface. The localization of the frontier orbitals of ChTX has been revealed for the first time. HOMO is localized on Trp14 while the three lowest-energy MOs (LUMO, LUMO+1, and LUMO+2) are localized on the three disulfide bonds that characterize this pepetide. An effective way to engineer the HOMO-LUMO (H-L) gap of ChTX is that of replacing its Trp14 residue with Ala14 whereas deletion of the LUMO-associated disulfide bond with the insertion of a pair of L-alpha-aminobutyric acid residues does not affect the H-L energy gap.
q-bio.BM:We propose a mechanism that explains in a simple and natural form the l-homochiralization of prebiotic aminoacids in a volume of water where a geothermal gradient exists.
q-bio.BM:The coat proteins of many viruses spontaneously form icosahedral capsids around nucleic acids or other polymers. Elucidating the role of the packaged polymer in capsid formation could promote biomedical efforts to block viral replication and enable use of capsids in nanomaterials applications. To this end, we perform Brownian dynamics on a coarse-grained model that describes the dynamics of icosahedral capsid assembly around a flexible polymer. We identify several mechanisms by which the polymer plays an active role in its encapsulation, including cooperative polymer-protein motions. These mechanisms are related to experimentally controllable parameters such as polymer length, protein concentration, and solution conditions. Furthermore, the simulations demonstrate that assembly mechanisms are correlated to encapsulation efficiency, and we present a phase diagram that predicts assembly outcomes as a function of experimental parameters. We anticipate that our simulation results will provide a framework for designing in vitro assembly experiments on single-stranded RNA virus capsids.
q-bio.BM:The assumption of linear response of protein molecules to thermal noise or structural perturbations, such as ligand binding or detachment, is broadly used in the studies of protein dynamics. Conformational motions in proteins are traditionally analyzed in terms of normal modes and experimental data on thermal fluctuations in such macromolecules is also usually interpreted in terms of the excitation of normal modes. We have chosen two important protein motors - myosin V and kinesin KIF1A - and performed numerical investigations of their conformational relaxation properties within the coarse-grained elastic network approximation. We have found that the linearity assumption is deficient for ligand-induced conformational motions and can even be violated for characteristic thermal fluctuations. The deficiency is particularly pronounced in KIF1A where the normal mode description fails completely in describing functional mechanochemical motions. These results indicate that important assumptions of the theory of protein dynamics may need to be reconsidered. Neither a single normal mode, nor a superposition of such modes yield an approximation of strongly nonlinear dynamics.
q-bio.BM:We perform a quantum mechanical study of the peptides that are part of the LH2 complex from Rhodopseudomonas acidophila, a non-sulfur purple bacteria that has the ability of producing chemical energy from photosynthesis. The electronic structure calculations indicate that the transmembrane helices of these peptides are characterized by dipole moments with a magnitude of ~150 D. When the full nonamer assembly made of eighteen peptides is considered, then a macrodipole of magnitude 704 D is built up from the vector sum of each monomer dipole. The macrodipole is oriented normal to the membrane plane and with the positive tip toward the cytoplasm thereby indicating that the electronic charge of the protein scaffold is polarized toward the periplasm. The results obtained here suggest that the asymmetric charge distribution of the protein scaffold contributes an anisotropic electrostatic environment which differentiates the absorption properties of the bacteriochlorophyll pigments, B800 and B850, embedded in the LH2 complex.
q-bio.BM:The approach for calculation of the mode intensities of DNA conformational vibrations in the Raman spectra is developed. It is based on the valence-optic theory and the model for description of conformational vibrations of DNA with counterions. The calculations for Na- and Cs-DNA low-frequency Raman spectra show that the vibrations of DNA backbone chains near 15 cm-1 have the greatest intensity. In the spectrum of Na-DNA at frequency range upper than 40 cm-1 the modes of H-bond stretching in base pairs have the greatest intensities, while the modes of ion-phosphate vibrations have the lowest intensity. In Cs-DNA spectra at this frequency range the mode of ion-phosphate vibrations is prominent. Its intensity is much higher than the intensities of Na-DNA modes of this spectra range. Other modes of Cs-DNA have much lower intensities than in the case of Na-DNA. The comparison of our calculations with the experimental data shows that developed approach gives the understanding of the sensitivity of DNA low-frequency Raman bands to the neutralization of the double helix by light and heavy counterions.
q-bio.BM:The protein folding is regarded as a quantum transition between torsion states on polypeptide chain. The deduction of the folding rate formula in our previous studies is reviewed. The rate formula is generalized to the case of frequency variation in folding. Then the following problems about the application of the rate theory are discussed: 1) The unified theory on the two-state and multi-state protein folding is given based on the concept of quantum transition. 2) The relationship of folding and unfolding rates vs denaturant concentration is studied. 3) The temperature dependence of folding rate is deduced and the non-Arrhenius behaviors of temperature dependence are interpreted in a natural way. 4) The inertial moment dependence of folding rate is calculated based on the model of dynamical contact order and consistent results are obtained by comparison with one-hundred-protein experimental dataset. 5) The exergonic and endergonic foldings are distinguished through the comparison between theoretical and experimental rates for each protein. The ultrafast folding problem is viewed from the point of quantum folding theory and a new folding speed limit is deduced from quantum uncertainty relation. And finally, 6) since only the torsion-accessible states are manageable in the present formulation of quantum transition how the set of torsion-accessible states can be expanded by using statistical energy landscape approach is discussed. All above discussions support the view that the protein folding is essentially a quantum transition between conformational states.
q-bio.BM:Homologous recombination plays a key role in generating genetic diversity, while maintaining protein functionality. The mechanisms by which RecA enables a single-stranded segment of DNA to recognize a homologous tract within a whole genome are poorly understood. The scale by which homology recognition takes place is of a few tens of base pairs, after which the quest for homology is over. To study the mechanism of homology recognition, RecA-promoted homologous recombination between short DNA oligomers with different degrees of heterology was studied in vitro, using fluorescence resonant energy transfer. RecA can detect single mismatches at the initial stages of recombination, and the efficiency of recombination is strongly dependent on the location and distribution of mismatches. Mismatches near the 5' end of the incoming strand have a minute effect, whereas mismatches near the 3' end hinder strand exchange dramatically. There is a characteristic DNA length above which the sensitivity to heterology decreases sharply. Experiments with competitor sequences with varying degrees of homology yield information about the process of homology search and synapse lifetime. The exquisite sensitivity to mismatches and the directionality in the exchange process support a mechanism for homology recognition that can be modeled as a kinetic proofreading cascade.
q-bio.BM:Cell-penetrating peptides (CPPs) such as HIV's trans-activating transcriptional activator (TAT) and polyarginine rapidly pass through the plasma membranes of mammalian cells by an unknown mechanism called transduction. They may be medically useful when fused to well-chosen chains of fewer than about 35 amino acids. I offer a simple model of transduction in which phosphatidylserines and CPPs effectively form two plates of a capacitor with a voltage sufficient to cause the formation of transient pores (electroporation). The model is consistent with experimental data on the transduction of oligoarginine into mouse C2-C12 myoblasts and makes three testable predictions.
q-bio.BM:In recent years, single molecule force techniques have opened a new avenue to decipher the folding landscapes of biopolymers by allowing us to watch and manipulate the dynamics of individual proteins and nucleic acids. In single molecule force experiments, quantitative analyses of measurements employing sound theoretical models and molecular simulations play central role more than any other field. With a brief description of basic theories for force mechanics and molecular simulation technique using self-organized polymer (SOP) model, this chapter will discuss various issues in single molecule force spectroscopy (SMFS) experiments, which include pulling speed dependent unfolding pathway, measurement of energy landscape roughness, the in uence of molecular handles in optical tweezers on measurement and molecular motion, and folding dynamics of biopolymers under force quench condition.
q-bio.BM:We explore in detail the structural, mechanical and thermodynamic properties of a coarse-grained model of DNA similar to that introduced in Thomas E. Ouldridge, Ard A. Louis, Jonathan P.K. Doye, Phys. Rev. Lett. 104 178101 (2010). Effective interactions are used to represent chain connectivity, excluded volume, base stacking and hydrogen bonding, naturally reproducing a range of DNA behaviour. We quantify the relation to experiment of the thermodynamics of single-stranded stacking, duplex hybridization and hairpin formation, as well as structural properties such as the persistence length of single strands and duplexes, and the torsional and stretching stiffness of double helices. We also explore the model's representation of more complex motifs involving dangling ends, bulged bases and internal loops, and the effect of stacking and fraying on the thermodynamics of the duplex formation transition.
q-bio.BM:In this and the associated article 'BioBlender: A Software for Intuitive Representation of Surface Properties of Biomolecules', (Andrei et al) we present BioBlender as a complete instrument for the elaboration of motion (here) and the visualization (Andrei et al) of proteins and other macromolecules, using instruments of computer graphics. A vast number of protein (if not most) exert their function through some extent of motion. Despite recent advances in higly performant methods, it is very difficult to obtain direct information on conformational changes of molecules. However, several systems exist that can shed some light on the variability of conformations of a single peptide chain; among them, NMR methods provide collections of a number of static 'shots' of a moving protein. Starting from this data, and assuming that if a protein exists in more than 1 conformation it must be able to transit between the different states, we have elaborated a system that makes ample use of the computational power of 3D computer graphics technology. Considering information of all (heavy) atoms, we use animation and game engine of Blender to obtain transition states. The model we chose to elaborate our system is Calmodulin, a protein favorite among structural and dynamic studies due to its (relative) simplicity of structure and small dimension. Using Calmodulin we show a procedure that enables the building of a 'navigation map' of NMR models, that can help in the identification of movements. In the process, a number of intermediate conformations is generated, all of which respond to strict bio-physical and bio-chemical criteria. The BioBlender system is available for download from the website www.bioblender.net, together with examples, tutorial and other useful material.
q-bio.BM:Nested sampling is a Bayesian sampling technique developed to explore probability distributions lo- calised in an exponentially small area of the parameter space. The algorithm provides both posterior samples and an estimate of the evidence (marginal likelihood) of the model. The nested sampling algo- rithm also provides an efficient way to calculate free energies and the expectation value of thermodynamic observables at any temperature, through a simple post-processing of the output. Previous applications of the algorithm have yielded large efficiency gains over other sampling techniques, including parallel tempering (replica exchange). In this paper we describe a parallel implementation of the nested sampling algorithm and its application to the problem of protein folding in a Go-type force field of empirical potentials that were designed to stabilize secondary structure elements in room-temperature simulations. We demonstrate the method by conducting folding simulations on a number of small proteins which are commonly used for testing protein folding procedures: protein G, the SH3 domain of Src tyrosine kinase and chymotrypsin inhibitor 2. A topological analysis of the posterior samples is performed to produce energy landscape charts, which give a high level description of the potential energy surface for the protein folding simulations. These charts provide qualitative insights into both the folding process and the nature of the model and force field used.
q-bio.BM:The electrochemical behaviour of the biomedical and metallic alloys, especially in the orthopaedic implants fields, raises many questions. This study is dedicated for studying the Ti-6Al-4V alloy, by electrochemical impedance spectroscopy, EIS, in various physiological media,: Ringer solution, phosphate buffered solution (PBS), PBS solution and albumin, PBS solution with calf serum and PBS solution with calf serum and an antioxidant (sodium azide). Moreover, the desionised water was considered as the reference solution. The tests reproducibility was investigated. The time-frequency-Module graphs highlighted that the desionised water is the most protective for the Ti-6Al-4V alloy. This biomedical alloy is the less protected in the solution constituted by PBS and albumin. The time-frequency graph allows pointing out the graphic signatures of adsorption for organic and inorganic species (differences between the modules means in studied solution and the modules mean in the reference solution). --- Le comportement \'electrochimique des alliages m\'etalliques biom\'edicaux, notamment dans le domaine des implants orthop\'ediques, pose encore de nombreuses questions. Ce travail propose d'\'etudier l'alliage de titane Ti-6Al-4V, par spectroscopie d'imp\'edance \'electrochimique, SIE, dans diff\'erents milieux physiologiques : solution de Ringer, solution \`a base d'un tampon phosphate (PBS), solution PBS avec de l'albumine, solution PBS avec du s\'erum bovin et une solution PBS avec du s\'erum bovin et un antioxydant (azoture de sodium). De plus, une solution d'eau ultra-pure servira de r\'ef\'erence. La reproductibilit\'e des tests a \'et\'e \'etudi\'ee. Les repr\'esentations temps-fr\'equence des modules ont mis en \'evidence que l'eau d\'esionis\'ee est la solution qui pr\'esente le caract\`ere le plus protecteur pour le Ti-6Al-4V. Cet alliage de titane est le moins prot\'eg\'e dans la solution de PBS contenant de l'albumine. Cette repr\'esentation permet de mettre en \'evidence des signatures graphiques d'adsorption des esp\`eces inorganiques et organiques (diff\'erences entre les moyennes des modules dans les solutions \'etudi\'ees et la moyenne des modules dans la solution de r\'ef\'erence).
q-bio.BM:We present a rigidity analysis on a large number of X-ray crystal structures of the enzyme HIV-1 protease using the 'pebble game' algorithm of the software FIRST. We find that although the rigidity profile remains similar across a comprehensive set of high resolution structures, the profile changes significantly in the presence of an inhibitor. Our study shows that the action of the inhibitors is to restrict the flexibility of the beta-hairpin flaps which allow access to the active site. The results are discussed in the context of full molecular dynamics simulations as well as data from NMR experiments.
q-bio.BM:Conventional kinesin is a two-headed homodimeric motor protein, which is able to walk along microtubules processively by hydrolyzing ATP. Its neck linkers, which connect the two motor domains and can undergo a docking/undocking transition, are widely believed to play the key role in the coordination of the chemical cycles of the two motor domains and, consequently, in force production and directional stepping. Although many experiments, often complemented with partial kinetic modeling of specific pathways, support this idea, the ultimate test of the viability of this hypothesis requires the construction of a complete kinetic model. Considering the two neck linkers as entropic springs that are allowed to dock to their head domains and incorporating only the few most relevant kinetic and structural properties of the individual heads, here we develop the first detailed, thermodynamically consistent model of kinesin that can (i) explain the cooperation of the heads (including their gating mechanisms) during walking and (ii) reproduce much of the available experimental data (speed, dwell time distribution, randomness, processivity, hydrolysis rate, etc.) under a wide range of conditions (nucleotide concentrations, loading force, neck linker length and composition, etc.). Besides revealing the mechanism by which kinesin operates, our model also makes it possible to look into the experimentally inaccessible details of the mechanochemical cycle and predict how certain changes in the protein affect its motion.
q-bio.BM:Fifteen years ago Monique Tirion showed that the low-frequency normal modes of a protein are not significantly altered when non-bonded interactions are replaced by Hookean springs, for all atom pairs whose distance is smaller than a given cutoff value. Since then, it has been shown that coarse-grained versions of Tirion's model are able to provide fair insights on many dynamical properties of biological macromolecules. In this text, theoretical tools required for studying these so-called Elastic Network Models are described, focusing on practical issues and, in particular, on possible artifacts. Then, an overview of some typical results that have been obtained by studying such models is given.
q-bio.BM:A recent survey of 17 134 proteins has identified a new class of proteins which are expected to yield stretching induced force-peaks in the range of 1 nN. Such high force peaks should be due to forcing of a slip-loop through a cystine ring, i.e. by generating a cystine slipknot. The survey has been performed in a simple coarse grained model. Here, we perform all-atom steered molecular dynamics simulations on 15 cystine knot proteins and determine their resistance to stretching. In agreement with previous studies within a coarse grained structure based model, the level of resistance is found to be substantially higher than in proteins in which the mechanical clamp operates through shear. The large stretching forces arise through formation of the cystine slipknot mechanical clamp and the resulting steric jamming. We elucidate the workings of such a clamp in an atomic detail. We also study the behavior of five top strength proteins with the shear-based mechanostability in which no jamming is involved. We show that in the atomic model, the jamming state is relieved by moving one amino acid at a time and there is a choice in the selection of the amino acid that advances the first. In contrast, the coarse grained model also allows for a simultaneous passage of two amino acids.
q-bio.BM:A quantum theory on conformation-electron system is presented. Protein folding is regarded as the quantum transition between torsion states on polypeptide chain, and the folding rate is calculated by nonadiabatic operator method. The theory is used to study the temperature dependences of folding rate of 15 proteins and their non-Arrhenius behavior can all be deduced in a natural way. A general formula on the rate-temperature dependence has been deduced which is in good accordance with experimental data. These temperature dependences are further analyzed in terms of torsion potential parameters. Our results show it is necessary to move outside the realm of classical physics when the temperature dependence of protein folding is studied quantitatively.
q-bio.BM:Lasso peptides constitute a class of bioactive peptides sharing a knotted structure where the C-terminal tail of the peptide is threaded through and trapped within an N-terminalmacrolactamring. The structural characterization of lasso structures and differentiation from their unthreaded topoisomers is not trivial and generally requires the use of complementary biochemical and spectroscopic methods. Here we investigated two antimicrobial peptides belonging to the class II lasso peptide family and their corresponding unthreaded topoisomers: microcin J25 (MccJ25), which is known to yield two-peptide product ions specific of the lasso structure under collisioninduced dissociation (CID), and capistruin, for which CID does not permit to unambiguously assign the lasso structure. The two pairs of topoisomers were analyzed by electrospray ionization Fourier transform ion cyclotron resonance mass spectrometry (ESI-FTICR MS) upon CID, infrared multiple photon dissociation (IRMPD), and electron capture dissociation (ECD). CID and ECDspectra clearly permitted to differentiate MccJ25 from its non-lasso topoisomer MccJ25-Icm, while for capistruin, only ECD was informative and showed different extent of hydrogen migration (formation of c\bullet/z from c/z\bullet) for the threaded and unthreaded topoisomers. The ECD spectra of the triply-charged MccJ25 and MccJ25-lcm showed a series of radical b-type product ions {\eth}b0In{\TH}. We proposed that these ions are specific of cyclic-branched peptides and result from a dual c/z\bullet and y/b dissociation, in the ring and in the tail, respectively. This work shows the potentiality of ECD for structural characterization of peptide topoisomers, as well as the effect of conformation on hydrogen migration subsequent to electron capture.
q-bio.BM:Nanospray and collisionally-induced dissociation are used to evaluate the presence and absence of interstrand co-chelation of zinc ions in dimers of metallothionein. As was reported in a previous publication from this laboratory, co-chelation stabilizes the dimer to collisional activation, and facilitates asymmetrical zinc ion transfers during fragmentation. In the case of metallothionein, dimers of the holoprotein are found to share zinc ions, while dimers of metallothionein, in which one domain has been denatured, do not. Zinc ions are silent to most physicochemical probes, e.g., NMR and Mossbauer spectroscopies, and the capability of mass spectrometry to provide information on zinc complexes has widespread potential application in biochemistry.
q-bio.BM:Polymers can be modeled as open polygonal paths and their closure generates knots. Knotted proteins detection is currently achieved via high-throughput methods based on a common framework insensitive to the handedness of knots. Here we propose a topological framework for the computation of the HOMFLY polynomial, an handedness-sensitive invariant. Our approach couples a multi-component reduction scheme with the polynomial computation. After validation on tabulated knots and links the framework was applied to the entire Protein Data Bank along with a set of selected topological checks that allowed to discard artificially entangled structures. This led to an up-to-date table of knotted proteins that also includes two newly detected right-handed trefoil knots in recently deposited protein structures. The application range of our framework is not limited to proteins and it can be extended to the topological analysis of biological and synthetic polymers and more generally to arbitrary polygonal paths.
q-bio.BM:Atomic-accuracy structure prediction of macromolecules is a long-sought goal of computational biophysics. Accurate modeling should be achievable by optimizing a physically realistic energy function but is presently precluded by incomplete sampling of a biopolymer's many degrees of freedom. We present herein a working hypothesis, called the "stepwise ansatz", for recursively constructing well-packed atomic-detail models in small steps, enumerating several million conformations for each monomer and covering all build-up paths. By implementing the strategy in Rosetta and making use of high-performance computing, we provide first tests of this hypothesis on a benchmark of fifteen RNA loop modeling problems drawn from riboswitches, ribozymes, and the ribosome, including ten cases that were not solvable by prior knowledge based modeling approaches. For each loop problem, this deterministic stepwise assembly (SWA) method either reaches atomic accuracy or exposes flaws in Rosetta's all-atom energy function, indicating the resolution of the conformational sampling bottleneck. To our knowledge, SWA is the first enumerative, ab initio build-up method to systematically outperform existing Monte Carlo and knowledge-based methods for 3D structure prediction. As a rigorous experimental test, we have applied SWA to a small RNA motif of previously unknown structure, the C7.2 tetraloop/tetraloop-receptor, and stringently tested this blind prediction with nucleotide-resolution structure mapping data.
q-bio.BM:The surface accessibility of {\alpha}-bungarotoxin has been investigated by using Gd2L7, a newly designed paramagnetic NMR probe. Signal attenuations induced by Gd2L7 on {\alpha}-bungarotoxin C{\alpha}H peaks of 1H-13C HSQC spectra have been analyzed and compared with the ones previously obtained in the presence of GdDTPA-BMA. In spite of the different molecular size and shape, for the two probes a common pathway of approach to the {\alpha}-bungarotoxin surface can be observed with an equally enhanced access of both GdDTPA-BMA and Gd2L7 towards the protein surface side where the binding site is located. Molecular dynamics simulations suggest that protein backbone flexibility and surface hydration contribute to the observed preferential approach of both gadolinium complexes specifically to the part of the {\alpha}-bungarotoxin surface which is involved in the interaction with its physiological target, the nicotinic acetylcholine receptor.
q-bio.BM:The rates of protein folding with photon absorption or emission and the cross section of photon -protein inelastic scattering are calculated from the quantum folding theory by use of standard field-theoretical method. All these protein photo-folding processes are compared with common protein folding without interaction of photons (nonradiative folding). It is demonstrated that there exists a common factor (thermo-averaged overlap integral of vibration wave function, TAOI) for protein folding and protein photo-folding. Based on this finding it is predicted that: 1) the stimulated photo-folding rates show the same temperature dependence as protein folding; 2) the spectral line of electronic transition is broadened to a band which includes abundant vibration spectrum without and with conformational transition and the width of the vibration spectral line is largely reduced; 3) the resonance fluorescence cross section changes with temperature obeying the same law (Luo-Lu's law). The particular form of the folding rate - temperature relation and the abundant spectral structure imply the existence of a set of quantum oscillators in the transition process and these oscillators are mainly of torsion type of low frequency, imply the quantum tunneling between protein conformations does exist in folding and photo-folding processes and the tunneling is rooted deeply in the coherent motion of the conformational-electronic system.
q-bio.BM:In this paper we will review various aspects of the biology of prions and focus on what is currently known about the mammalian PrP prion. Also we briefly describe the prions of yeast and other fungi. Prions are infectious proteins behaving like genes, i.e. proteins that not only contain genetic information in its tertiary structure, i.e. its shape, but are also able to transmit and replicate in a manner analogous to genes but through very different mechanisms. The term prion is derived from "proteinaceous infectious particle" and arose from the Prusiner hypothesis that the infectious agent of certain neurodegenerative diseases was only in a protein, without the participation of nucleic acids. Currently there are several known types of prion, in addition to the originally described, which are pathogens of mammals, yeast and other fungi. Prion proteins are ubiquitous and not always detrimental to their hosts. This vision of the prion as a causative agent of disease is changing, finding more and more evidence that they could have important roles in cells and contribute to the phenotypic plasticity of organisms through the mechanisms of evolution.
q-bio.BM:Genomic DNA is constantly subjected to various mechanical stresses arising from its biological functions and cell packaging. If the local mechanical properties of DNA change under torsional and tensional stress, the activity of DNA-modifying proteins and transcription factors can be affected and regulated allosterically. To check this possibility, appropriate steady forces and torques were applied in the course of all-atom molecular dynamics simulations of DNA with AT- and GC-alternating sequences. It is found that the stretching rigidity grows with tension as well as twisting. The torsional rigidity is not affected by stretching, but it varies with twisting very strongly, and differently for the two sequences. Surprisingly, for AT-alternating DNA it passes through a minimum with the average twist close to the experimental value in solution. For this fragment, but not for the GC-alternating sequence, the bending rigidity noticeably changes with both twisting and stretching. The results have important biological implications and shed light upon earlier experimental observations.
q-bio.BM:The 3'-monofunctional adduct of cisplatin and d(CTCTG*G*TCTC)2 duplex DNA in solvent with explicit counter ions and water molecules were subjected to MD- simulation with AMBER force field on a nanosecond time scale. In order to simulate the closure of the bond between the Pt and 5'-guanine-N7 atoms, the forces acting between them were gradually increased during MD. After 500-800 ps the transformation of the mono-adduct (straight DNA with the cisplatin residue linked to one guanine-N7) to the bus-adduct (bent DNA where Pt atom is connected through the N7 atoms of neighboring guanines) was observed. A cavity between palatinate guanines is formed and filled with solvent molecules. The rapid inclination of the center base pairs initiates a slow transition of the whole molecule from the linear to the bent conformation. After about 1000-1300 ps a stable structure was reached, which is very similar to the one described experimentally. The attractive force between the Pt- atom and the N7 of the second guanine plays the main role in the large conformational changes induced by formation of the adduct-adduct. X-N-Pt-N-torsions accelerate the bending but a torsion force constant greater than 0.2 Kcal/mol lead to the breaking of the H-bonds within the base pairs. The present study is the first dynamical simulation that demonstrates in real time scale such a large conformational perturbation of DNA.
q-bio.BM:Despite the recognized importance of the multi-scale spatio-temporal organization of proteins, most computational tools can only access a limited spectrum of time and spatial scales, thereby ignoring the effects on protein behavior of the intricate coupling between the different scales. Starting from a physico-chemical atomistic network of interactions that encodes the structure of the protein, we introduce a methodology based on multi-scale graph partitioning that can uncover partitions and levels of organization of proteins that span the whole range of scales, revealing biological features occurring at different levels of organization and tracking their effect across scales. Additionally, we introduce a measure of robustness to quantify the relevance of the partitions through the generation of biochemically-motivated surrogate random graph models. We apply the method to four distinct conformations of myosin tail interacting protein, a protein from the molecular motor of the malaria parasite, and study properties that have been experimentally addressed such as the closing mechanism, the presence of conserved clusters, and the identification through computational mutational analysis of key residues for binding.
q-bio.BM:In this work two archaea microorganisms (Haloferax volcanii and Natrialba magadii) used as biocatalyst at a microbial fuel cell (MFC) anode were evaluated. Both archaea are able to grow at high salt concentrations. By increasing the media conductivity, the internal resistance was diminished, improving the MFCs performance. Without any added redox mediator, maximum power (Pmax) and current at Pmax were 11.87 / 4.57 / 0.12 {\mu}W cm-2 and 49.67 / 22.03 / 0.59 {\mu}A cm-2 for H. volcanii, N. magadii and E. coli, respectively. When neutral red was used as redox mediator, Pmax was 50.98 and 5.39 {\mu}W cm-2 for H. volcanii and N. magadii respectively. In this paper an archaea MFC is described and compared with other MFC systems; the high salt concentration assayed here, comparable with that used in Pt-catalyzed alkaline hydrogen fuel cells will open new options when MFC scaling-up is the objective, necessary for practical applications.
q-bio.BM:Three-dimensional RNA models fitted into crystallographic density maps exhibit pervasive conformational ambiguities, geometric errors and steric clashes. To address these problems, we present enumerative real-space refinement assisted by electron density under Rosetta (ERRASER), coupled to Python-based hierarchical environment for integrated 'xtallography' (PHENIX) diffraction-based refinement. On 24 data sets, ERRASER automatically corrects the majority of MolProbity-assessed errors, improves the average Rfree factor, resolves functionally important discrepancies in noncanonical structure and refines low-resolution models to better match higher-resolution models.
q-bio.BM:This paper has been withdrawn by the author due to a missing figure
q-bio.BM:We develop a theory of aggregation using statistical mechanical methods. An example of a complicated aggregation system with several levels of structures is peptide/protein self-assembly. The problem of protein aggregation is important for the understanding and treatment of neurodegenerative diseases and also for the development of bio-macromolecules as new materials. We write the effective Hamiltonian in terms of interaction energies between protein monomers, protein and solvent, as well as between protein filaments. The grand partition function can be expressed in terms of a Zimm-Bragg-like transfer matrix, which is calculated exactly and all thermodynamic properties can be obtained. We start with two-state and three-state descriptions of protein monomers using Potts models that can be generalized to include q-states, for which the exactly solvable feature of the model remains. We focus on n X N lattice systems, corresponding to the ordered structures observed in some real fibrils. We have obtained results on nucleation processes and phase diagrams, in which a protein property such as the sheet content of aggregates is expressed as a function of the number of proteins on the lattice and inter-protein or interfacial interaction energies. We have applied our methods to A{\beta}(1-40) and Curli fibrils and obtained results in good agreement with experiments.
q-bio.BM:By studying the literature about Tetracyclines (TCs), it becomes clearly evident that TCs are very dynamic molecules. In some cases, their structure-activity-relationship (SAR) are known, especially against bacteria, while against other targets, they are virtually unknown. In other diverse yields of research, such as neurology, oncology and virology the utility and activity of the tetracyclines are being discovered and are also emerging as new technological fronts. The first aim of this paper is classify the compounds already used in therapy and prepare the schematic structure in which include the next generation of TCs. The aim of this work is introduce a new framework for the classification of old and new TCs, using a medicinal chemistry approach to the structure of that drugs. A fully documented Structure-Activity-Relationship (SAR) is presented with the analysis data of antibacterial and nonantibacterial (antifungal, antiviral and anticancer) tetracyclines. Lipophilicity of functional groups and conformations interchangeably are determining rules in biological activities of TCs.
q-bio.BM:The consequences of recent experimental finding that hydrogen bonds of the anti-parallel $\beta $-sheet in nonspecific binding site of serine proteases become significantly shorter and stronger synchronously with the catalytic act are examined. We investigate the effect of the transformation of an ordinary hydrogen bond into a low-barrier one on the crankshaft motion a peptide group in the anti-parallel $\beta $-sheet. For this purpose we make use of a realistic model of the peptide chain with stringent microscopically derived coupling interaction potential and effective on-site potential. The coupling interaction characterizing the peptide chain rigidity is found to be surprisingly weak and repulsive in character. The effective on-site potential is found to be a hard one, i.e., goes more steep than a harmonic one. At transformation of the ordinary hydrogen bond into the low-barrier one the frequency of crankshaft motion of the corresponding peptide group in the anti-parallel $\beta $-sheet is roughly doubled.
q-bio.BM:During this era of new drug designing, medicinal plants had become a very interesting object of further research. Pharmacology screening of active compound of medicinal plants would be time consuming and costly. Molecular docking is one of the in silico method which is more efficient compare to in vitro or in vivo method for its capability of finding the active compound in medicinal plants. In this method, three-dimensional structure becomes very important in the molecular docking methods, so we need a database that provides information on three-dimensional structures of chemical compounds from medicinal plants in Indonesia. Therefore, this study will prepare a database which provides information of the three dimensional structures of chemical compounds of medicinal plants. The database will be prepared by using MySQL format and is designed to be placed in http://herbaldb.farmasi.ui.ac.id website so that eventually this database can be accessed quickly and easily by users via the Internet.
q-bio.BM:We investigate the possibility that prebiotic homochirality can be achieved exclusively through chiral-selective reaction rate parameters without any other explicit mechanism for chiral bias. Specifically, we examine an open network of polymerization reactions, where the reaction rates can have chiral-selective values. The reactions are neither autocatalytic nor do they contain explicit enantiomeric cross-inhibition terms. We are thus investigating how rare a set of chiral-selective reaction rates needs to be in order to generate a reasonable amount of chiral bias. We quantify our results adopting a statistical approach: varying both the mean value and the rms dispersion of the relevant reaction rates, we show that moderate to high levels of chiral excess can be achieved with fairly small chiral bias, below 10%. Considering the various unknowns related to prebiotic chemical networks in early Earth and the dependence of reaction rates to environmental properties such as temperature and pressure variations, we argue that homochirality could have been achieved from moderate amounts of chiral selectivity in the reaction rates.
q-bio.BM:Channels are Catalysts for Diffusion and in that sense are Enzymes. This idea is useful for the design and interpretation of experiments.
q-bio.BM:Ahmad et al. recently presented an NMR-based model for a bacterial DnaJ J domain:DnaK(Hsp70):ADP complex(1) that differs significantly from the crystal structure of a disulfide linked mammalian auxilin J domain:Hsc70 complex that we previously published(2). They claimed that their model could better account for existing mutational data, was in better agreement with previous NMR studies, and that the presence of a cross-link in our structure made it irrelevant to understanding J:Hsp70 interactions. Here we detail extensive NMR and mutational data relevant to understanding J:Hsp70 function and show that, in fact, our structure is much better able to account for the mutational data and is in much better agreement with a previous NMR study of a mammalian polyoma virus T-ag J domain:Hsc70 complex than is the Ahmad et al. complex, and that our structure is predictive and provides insight into J:Hsp70 interactions and mechanism of ATPase activation.
q-bio.BM:Protein function frequently involves conformational changes with large amplitude on timescales which are difficult and computationally expensive to access using molecular dynamics. In this paper, we report on the combination of three computationally inexpensive simulation methods-normal mode analysis using the elastic network model, rigidity analysis using the pebble game algorithm, and geometric simulation of protein motion-to explore conformational change along normal mode eigenvectors. Using a combination of ELNEMO and FIRST/FRODA software, large-amplitude motions in proteins with hundreds or thousands of residues can be rapidly explored within minutes using desktop computing resources. We apply the method to a representative set of six proteins covering a range of sizes and structural characteristics and show that the method identifies specific types of motion in each case and determines their amplitude limits.
q-bio.BM:The enzyme FoF1-ATP synthase provides the 'chemical energy currency' adenosine triphosphate (ATP) for living cells. Catalysis is driven by mechanochemical coupling of subunit rotation within the enzyme with conformational changes in the three ATP binding sites. Proton translocation through the membrane-bound Fo part of ATP synthase powers a 10-step rotary motion of the ring of c subunits. This rotation is transmitted to the gamma and epsilon subunits of the F1 part. Because gamma and epsilon subunits rotate in 120 deg steps, we aim to unravel this symmetry mismatch by real time monitoring subunit rotation using single-molecule Forster resonance energy transfer (FRET). One fluorophore is attached specifically to the F1 motor, another one to the Fo motor of the liposome-reconstituted enzyme. Photophysical artifacts due to spectral fluctuations of the single fluorophores are minimized by a previously developed duty cycle-optimized alternating laser excitation scheme (DCO-ALEX). We report the detection of reversible elastic deformations between the rotor parts of Fo and F1 and estimate the maximum angular displacement during the load-free rotation using Monte Carlo simulations
q-bio.BM:A strain of Halomonas bacteria, GFAJ-1, has been reported to be able to use arsenate as a nutrient when phosphate is limiting, and to specifically incorporate arsenic into its DNA in place of phosphorus. However, we have found that arsenate does not contribute to growth of GFAJ-1 when phosphate is limiting and that DNA purified from cells grown with limiting phosphate and abundant arsenate does not exhibit the spontaneous hydrolysis expected of arsenate ester bonds. Furthermore, mass spectrometry showed that this DNA contains only trace amounts of free arsenate and no detectable covalently bound arsenate.
q-bio.BM:The fundamental law for protein folding is the Thermodynamic Principle: the amino acid sequence of a protein determines its native structure and the native structure has the minimum Gibbs free energy. If all chemical problems can be answered by quantum mechanics, there should be a quantum mechanics derivation of Gibbs free energy formula G(X) for every possible conformation X of the protein. We apply quantum statistics to derive such a formula. For simplicity, only monomeric self folding globular proteins are covered. We point out some immediate applications of the formula. We show that the formula explains the observed phenomena very well. It gives a unified explanation to both folding and denaturation; it explains why hydrophobic effect is the driving force of protein folding and clarifies the role played by hydrogen bonding; it explains the successes and deficients of various surface area models. The formula also gives a clear kinetic force of the folding: Fi(X) = - \nablaxi G(X). This also gives a natural way to perform the ab initio prediction of protein structure, minimizing G(X) by Newton's fastest desciending method.
q-bio.BM:Learning how proteins fold will hardly have any impact in the way conventional -- active site centered -- drugs are designed. On the other hand, this knowledge is proving instrumental in defining a new paradigm for the identification of drugs against any target protein: folding inhibition. Targeting folding renders drugs less prone to elicit spontaneous genetic mutations which in many cases, notably in connection with viruses like the Human Immunodeficiency Virus (HIV), can block therapeutic action. From the progress which has taken place during the last years in the understanding of the becoming of a protein, and how to read from the corresponding sequences the associated three-dimensional, biologically active, native structure, the idea of non-conventional (folding) inhibitors and thus of leads to eventual drugs to fight disease, arguably, without creating resistance, emerges as a distinct possibility.
q-bio.BM:Ever since the disorder of proteins is the main cause for many diseases. As compared with other disorders, the major reason that causes disease is of structural inability of many proteins. The potentially imminent availability of recent datasets helps one to discover the protein disorders, however in majority of cases, the stability of proteins depend on the carbon content. Addressing this distinct feature, it is possible to hit upon the carbon distribution along the sequence and can easily recognize the stable nature of protein. There are certain reported mental disorders which fall in to this category. Regardless, such kind of disorder prone protein FMR1p (Fragile X mental retardation 1 protein) is identified as the main cause for the disease Fragile X syndrome. This paper deals with the identification of defects in the FMR1 protein sequence considering the carbon contents along the sequence. This attempt is to evaluate the stability of proteins, accordingly the protein disorders in order to improvise the certain Biological functions of proteins to prevent disease. The transition of the disorder to order protein involves careful considerations and can be achieved by detecting the unstable region that lacks hydrophobicity. This work focuses the low carbon content in the FMR1 protein so as to attain the stable status in future to reduce the morbidity rate caused by Fragile X syndrome for the society.
q-bio.BM:Influenza virus evolves to escape from immune system antibodies that bind to it. We used free energy calculations with Einstein crystals as reference states to calculate the difference of antibody binding free energy ($\Delta\Delta G$) induced by amino acid substitution at each position in epitope B of the H3N2 influenza hemagglutinin, the key target for antibody. A substitution with positive $\Delta\Delta G$ value decreases the antibody binding constant. On average an uncharged to charged amino acid substitution generates the highest $\Delta\Delta G$ values. Also on average, substitutions between small amino acids generate $\Delta\Delta G$ values near to zero. The 21 sites in epitope B have varying expected free energy differences for a random substitution. Historical amino acid substitutions in epitope B for the A/Aichi/2/1968 strain of influenza A show that most fixed and temporarily circulating substitutions generate positive $\Delta\Delta G$ values. We propose that the observed pattern of H3N2 virus evolution is affected by the free energy landscape, the mapping from the free energy landscape to virus fitness landscape, and random genetic drift of the virus. Monte Carlo simulations of virus evolution are presented to support this view.
q-bio.BM:Force field and first principles molecular dynamics simulations on complexes of pig liver esterase (pig liver isoenzymes and a mutant) and selected substrates (1-phenyl-1-ethyl acetate, 1- phenyl-2-butylacetate, proline-{\beta}-naphthylamide and methyl butyrate) are presented. By restrained force field simulations the access of the substrate to the hidden active site was probed. For a few substrates spontaneous access to the active site via a well defined entrance channel was found. The structure of the tetrahedral intermediate was simulated for several substrates and our previous assignment of GLU 452 instead of GLU 336 was confirmed. It was shown that the active site readily adapts to the embedded substrate involving a varying number of hydrophobic residues in the neighborhood. This puts into question key-lock models for enantioselectivity. Ab initio molecular dynamics showed that the structures we found for the tetrahedral intermediate in force field simulations are consistent with the presumed mechanism of ester cleavage. Product release from the active site as final step of the enzymatic reaction revealed to be very slow and took already more than 20ns for the smallest product, methanol.
q-bio.BM:Protein function often involves changes between different conformations. Central questions are how these conformational changes are coupled to the binding or catalytic processes during which they occur, and how they affect the catalytic rates of enzymes. An important model system is the enzyme dihydrofolate reductase (DHFR) from E. coli, which exhibits characteristic conformational changes of the active-site loop during the catalytic step and during unbinding of the product. In this article, we present a general kinetic framework that can be used (1) to identify the ordering of events in the coupling of conformational changes, binding and catalysis and (2) to determine the rates of the substeps of coupled processes from a combined analysis of NMR R2 relaxation dispersion experiments and traditional enzyme kinetics measurements. We apply this framework to E. coli DHFR and find that the conformational change during product unbinding follows a conformational-selection mechanism, i.e. the conformational change occurs predominantly prior to unbinding. The conformational change during the catalytic step, in contrast, is an induced change, i.e. the change occurs after the chemical reaction. We propose that the reason for these conformational changes, which are absent in human and other vertebrate DHFRs, is robustness of the catalytic rate against large pH variations and changes to substrate/product concentrations in E. coli.
q-bio.BM:Ion channels are proteins with holes down their middle that control the flow of ions and electric current across otherwise impermeable biological membranes. The flow of sodium, potassium, calcium (divalent), and chloride ions have been central issues in biology for more than a century. The flow of current is responsible for the signals of the nervous system that propagate over long distances (meters). The concentration of divalent calcium ions is a 'universal' signal that controls many different systems inside cells. The concentration of divalent calcium and other messenger ions has a role in life rather like the role of the voltage in different wires of a computer. Ion channels also help much larger solutes (e.g., organic acid and bases; perhaps polypeptides) to cross membranes but much less is known about these systems. Ion channels can select and control the movement of different types of ions because the holes in channel proteins are a few times larger than the (crystal radii of the) ions themselves. Biology uses ion channels as selective valves to control flow and thus concentration of crucial chemical signals. For example, the concentration of divalent calcium ions determines whether muscles contract or not. Ion channels have a role in biology similar to the role of transistors in computers and technology. Ion Channels Control Concentrations Important To Life The Way Computers Control Voltages Important To Computers.
q-bio.BM:Chemistry is about chemical reactions. Chemistry is about electrons changing their configurations as atoms and molecules react. Chemistry studies reactions as if they occurred in ideal infinitely dilute solutions. But most reactions occur in nonideal solutions. Then everything (charged) interacts with everything else (charged) through the electric field, which is short and long range extending to boundaries of the system. Mathematics has recently been developed to deal with interacting systems of this sort. The variational theory of complex fluids has spawned the theory of liquid crystals. In my view, ionic solutions should be viewed as complex fluids. In both biology and electrochemistry ionic solutions are mixtures highly concentrated (~10M) where they are most important, near electrodes, nucleic acids, enzymes, and ion channels. Calcium is always involved in biological solutions because its concentration in a particular location is the signal that controls many biological functions. Such interacting systems are not simple fluids, and it is no wonder that analysis of interactions, such as the Hofmeister series, rooted in that tradition, has not succeeded as one would hope. We present a variational treatment of hard spheres in a frictional dielectric. The theory automatically extends to spatially nonuniform boundary conditions and the nonequilibrium systems and flows they produce. The theory is unavoidably self-consistent since differential equations are derived (not assumed) from models of (Helmholtz free) energy and dissipation of the electrolyte. The origin of the Hofmeister series is (in my view) an inverse problem that becomes well posed when enough data from disjoint experimental traditions are interpreted with a self-consistent theory.
q-bio.BM:A quantum mechanical model on histone modification is proposed. Along with the methyl / acetate or other groups bound to the modified residues the torsion angles of the nearby histone chain are supposed to participate in the quantum transition cooperatively. The transition rate W is calculated based on the non-radiative quantum transition theory in adiabatic approximation. By using W's the reaction equations can be written for histone modification and the histone modification level can be calculable from the equations, which is decided by not only the atomic group bound to the modified residue, but also the nearby histone chain. The theory can explain the mechanism for the correlation between a pair of chromatin markers observed in histone modification. The temperature dependence and the coherence-length dependence of histone modification are deduced. Several points for checking the proposed theory and the quantum nature of histone modification are suggested as follows: 1, The relationship between lnW and 1/T is same as usual protein folding. The non-Arhenius temperature dependence of the histone modification level is predicted. 2, The variation of histone modification level through point mutation of some residues on the chain is predicted since the mutation may change the coherence-length of the system. 3, Multi-site modification obeys the quantum superposition law and the comparison between multi-site transition and single modification transition gives an additional clue to the testing of the quantum nature of histone modification.
q-bio.BM:Inverted repeat (IR) sequences in DNA can form non-canonical cruciform structures to relieve torsional stress. We use Monte Carlo simulations of a recently developed coarse-grained model of DNA to demonstrate that the nucleation of a cruciform can proceed through a cooperative mechanism. Firstly, a twist-induced denaturation bubble must diffuse so that its midpoint is near the centre of symmetry of the IR sequence. Secondly, bubble fluctuations must be large enough to allow one of the arms to form a small number of hairpin bonds. Once the first arm is partially formed, the second arm can rapidly grow to a similar size. Because bubbles can twist back on themselves, they need considerably fewer bases to resolve torsional stress than the final cruciform state does. The initially stabilised cruciform therefore continues to grow, which typically proceeds synchronously, reminiscent of the S-type mechanism of cruciform formation. By using umbrella sampling techniques we calculate, for different temperatures and superhelical densities, the free energy as a function of the number of bonds in each cruciform along the correlated but non-synchronous nucleation pathways we observed in direct simulations.
q-bio.BM:Emerging high-throughput technologies have led to a deluge of putative non-coding RNA (ncRNA) sequences identified in a wide variety of organisms. Systematic characterization of these transcripts will be a tremendous challenge. Homology detection is critical to making maximal use of functional information gathered about ncRNAs: identifying homologous sequence allows us to transfer information gathered in one organism to another quickly and with a high degree of confidence. ncRNA presents a challenge for homology detection, as the primary sequence is often poorly conserved and de novo secondary structure prediction and search remains difficult. This protocol introduces methods developed by the Rfam database for identifying "families" of homologous ncRNAs starting from single "seed" sequences using manually curated sequence alignments to build powerful statistical models of sequence and structure conservation known as covariance models (CMs), implemented in the Infernal software package. We provide a step-by-step iterative protocol for identifying ncRNA homologs, then constructing an alignment and corresponding CM. We also work through an example for the bacterial small RNA MicA, discovering a previously unreported family of divergent MicA homologs in genus Xenorhabdus in the process.
q-bio.BM:DNA is subject to large deformations in a wide range of biological processes. Two key examples illustrate how such deformations influence the readout of the genetic information: the sequestering of eukaryotic genes by nucleosomes, and DNA looping in transcriptional regulation in both prokaryotes and eukaryotes. These kinds of regulatory problems are now becoming amenable to systematic quantitative dissection with a powerful dialogue between theory and experiment. Here we use a single-molecule experiment in conjunction with a statistical mechanical model to test quantitative predictions for the behavior of DNA looping at short length scales, and to determine how DNA sequence affects looping at these lengths. We calculate and measure how such looping depends upon four key biological parameters: the strength of the transcription factor binding sites, the concentration of the transcription factor, and the length and sequence of the DNA loop. Our studies lead to the surprising insight that sequences that are thought to be especially favorable for nucleosome formation because of high flexibility lead to no systematically detectable effect of sequence on looping, and begin to provide a picture of the distinctions between the short length scale mechanics of nucleosome formation and looping.
q-bio.BM:For decades, dimethyl sulfate (DMS) mapping has informed manual modeling of RNA structure in vitro and in vivo. Here, we incorporate DMS data into automated secondary structure inference using a pseudo-energy framework developed for 2'-OH acylation (SHAPE) mapping. On six non-coding RNAs with crystallographic models, DMS- guided modeling achieves overall false negative and false discovery rates of 9.5% and 11.6%, comparable or better than SHAPE-guided modeling; and non-parametric bootstrapping provides straightforward confidence estimates. Integrating DMS/SHAPE data and including CMCT reactivities give small additional improvements. These results establish DMS mapping - an already routine technique - as a quantitative tool for unbiased RNA structure modeling.
q-bio.BM:Hydrogen bonds are a common feature in protein folding and aggregation. Due to their chemical peculiarities in terms of strength and directionality, a particular attention must be paid to the definition of the hydrogen bond potential itself. This global target has been tackled through a computational approach based on a minimalist description of the protein and the proper design of algorithms, mainly using Monte Carlo and Kinetic Monte Carlo methods. We have designed a hydrogen bond potential, see J. Chem. Phys. 132, 235102 (2010). We have been performed a complete study of sequenceless peptide systems under different conditions, such as temperature and concentration. To carry out full protein studies, we need additional potentials to describe tertiary interactions. We have discussed two different points of view. The first one is the combination of the hydrogen bond potential with a structure-based one. We have evaluated the implications of a proper definition of hydrogen bonds in the thermodynamic and dynamic aspects of protein folding. See Biophys. J. 101, 1474-1482 (2011). We have undertaken a second strategy, combining a generic hydrophobic model with the hydrogen bond one. The two main factors of folding and aggregation are merged, then, to create a simple but complete potential. Thanks to it, we have re-studied peptide aggregation including sequence. Besides, we have simulated complete proteins with different folded shapes. We have analyzed the competition between folding and aggregation, and how sequence and hydrogen bonds can influence the interplay between them. See J. Chem. Phys. 136, 215103 (2012).
q-bio.BM:Consistently predicting biopolymer structure at atomic resolution from sequence alone remains a difficult problem, even for small sub-segments of large proteins. Such loop prediction challenges, which arise frequently in comparative modeling and protein design, can become intractable as loop lengths exceed 10 residues and if surrounding side-chain conformations are erased. This article introduces a modeling strategy based on a 'stepwise ansatz', recently developed for RNA modeling, which posits that any realistic all-atom molecular conformation can be built up by residue-by-residue stepwise enumeration. When harnessed to a dynamic-programming-like recursion in the Rosetta framework, the resulting stepwise assembly (SWA) protocol enables enumerative sampling of a 12 residue loop at a significant but achievable cost of thousands of CPU-hours. In a previously established benchmark, SWA recovers crystallographic conformations with sub-Angstrom accuracy for 19 of 20 loops, compared to 14 of 20 by KIC modeling with a comparable expenditure of computational power. Furthermore, SWA gives high accuracy results on an additional set of 15 loops highlighted in the biological literature for their irregularity or unusual length. Successes include cis-Pro touch turns, loops that pass through tunnels of other side-chains, and loops of lengths up to 24 residues. Remaining problem cases are traced to inaccuracies in the Rosetta all-atom energy function. In five additional blind tests, SWA achieves sub-Angstrom accuracy models, including the first such success in a protein/RNA binding interface, the YbxF/kink-turn interaction in the fourth RNA-puzzle competition. These results establish all-atom enumeration as a systematic approach to protein structure that can leverage high performance computing and physically realistic energy functions to more consistently achieve atomic resolution.
q-bio.BM:Self-associates of nucleic acid components (stacking trimers and tetramers of the base pairs of nucleic acids) and short fragments of nucleic acids are nanoparticles (linear sizes of these particles are more than 10 A. Modern quantum-mechanical methods and softwares allow one to perform ab initio calculations of the systems consisting of 150-200 atoms with enough large basis sets (for example, 6-31G*). The aim of this work is to reveal the peculiarities of molecular and electronic structures, as well as the energy features of nanoparticles of nucleic acid components.
q-bio.BM:Influenza virus contains two highly variable envelope glycoproteins, hemagglutinin (HA) and neuraminidase (NA). The structure and properties of HA, which is responsible for binding the virus to the cell that is being infected, change significantly when the virus is transmitted from avian or swine species to humans. Here we focus on much smaller human individual evolutionary amino acid mutational changes in NA, which cleaves sialic acid groups and is required for influenza virus replication. We show that very small amino acid changes can be monitored very accurately across many Uniprot and NCBI strains using hydropathicity scales to quantify the roughness of water film packages. Quantitative sequential analysis is most effective with the differential hydropathicity scale based on protein self-organized criticality (SOC). NA exhibits punctuated evolution at the molecular scale, millions of times smaller than the more familiar species scale, and thousands of times smaller than the genomic scale. Our analysis shows that large-scale vaccination programs have been responsible for a very large convergent reduction in influenza severity in the last century, a reduction which is hidden from short-term studies of vaccine effectiveness. Hydropathic analysis is capable of interpreting and even predicting trends of functional changes in mutation prolific viruses.
q-bio.BM:Influenza virus contains two highly variable envelope glycoproteins, hemagglutinin (HA) and neuraminidase (NA). The structure and properties of HA, which is responsible for binding the virus to the cell that is being infected, change significantly when the virus is transmitted from avian or swine species to humans. Previously we identified much smaller human individual evolutionary amino acid mutational changes in NA, which cleaves sialic acid groups and is required for influenza virus replication. We showed that these smaller changes can be monitored very accurately across many Uniprot and NCBI strains using hydropathicity scales to quantify the roughness of water film packages, which increases gradually due to migration, but decreases abruptly under large-scale vaccination pressures. Here we show that, while HA evolution is much more complex, it still shows abrupt punctuation changes linked to those of NA. HA exhibits proteinquakes, which resemble earthquakes and are related to hydropathic shifting of sialic acid binding regions. HA proteinquakes based on sialic acid interactions are required for optimal balance between the receptor-binding and receptor-destroying activities of HA and NA for efficient virus replication. Our comprehensive results present an historical (1945-2011) panorama of HA evolution over thousands of strains, and are consistent with many studies of HA and NA interactions based on a few mutations of a few strains. While the common influenza virus discussed here has been rendered almost harmless by decades of vaccination programs, the sequential decoding lessons learned here are applicable to other viruses that are emerging as powerful weapons for controlling and even curing common organ cancers. Those engineered oncolytic drugs will be discussed in future papers.
q-bio.BM:While the concepts involved in Self-Organized Criticality have stimulated thousands of theoretical models, only recently have these models addressed problems of biological and clinical importance. Here we outline how SOC can be used to engineer hybrid viral proteins whose properties, extrapolated from those of known strains, may be sufficiently effective to cure cancer.
q-bio.BM:Although mechanical properties of DNA are well characterized at the kilo base-pair range, a number of recent experiments have suggested that DNA is more flexible at shorter length scales, which correspond to the regime that is crucial for cellular processes such as DNA packaging and gene regulation. Here, we perform a systematic study of the effective elastic properties of DNA at different length scales by probing the conformation and fluctuations of DNA from single base-pair level up to four helical turns, using trajectories from atomistic simulation. We find evidence that supports cooperative softening of the stretch modulus and identify the essential modes that give rise to this effect. The bend correlation exhibits modulations that reflect the helical periodicity, while it yields a reasonable value for the effective persistence length, and the twist modulus undergoes a smooth crossover---from a relatively smaller value at the single base-pair level to the bulk value---over half a DNA-turn.
q-bio.BM:Mutations and oxidative modification in the protein Cu,Zn superoxide dismutase (SOD1) have been implicated in the death of motor neurons in amyotrophic lateral sclerosis (ALS), a presently incurable, invariably fatal neurodegenerative disease. Here we employ steered, all-atom molecular dynamics simulations in implicit solvent to investigate the significance of either mutations or post-translational modifications (PTMs) to SOD1 on metal affinity, dimer stability, and mechanical malleability. The work required to induce moderate structural deformations as a function of sequence index constitutes a "mechanical fingerprint" measuring structural rigidity in the native basin, from which we are able to unambiguously distinguish wild-type (WT) SOD1 from PTM variants, and measure the severity of a given PTM on structural integrity. The cumulative distribution of work values provided a way to cleanly discriminate between SOD1 variants. Disulfide reduction destabilizes dimer stability more than the removal of either metal, but not moreso than the removal of both metals. Intriguingly, we found that disulfide reduction mechanically stabilizes apo SOD1 monomer, underscoring the differences between native basin mechanical properties and equilibrium thermodynamic stabilities, and elucidating the presence of internal stress in the apo state. All PTMs and ALS-associated mutants studied showed an increased tendency to lose either Cu or Zn, and to monomerize- processes known to be critical in the progression of ALS. The valence of Cu strongly modulates its binding free energy. As well, several mutants were more susceptible to loss of metals and monomerization than the disulfide-reduced or apo forms of SOD1. Distance constraints are required to calculate free energies for metal binding and dimer separation, which are validated using thermodynamic cycles.
q-bio.BM:Availability of high-resolution crystal structures of ribosomal subunits of different species opens a route to investigate about molecular interactions between its constituents and stabilization strategy. Structural analysis of the small ribosomal subunit shows that primary binder proteins are mainly employed in stabilizing the folded ribosomal RNA by their high negative free energy of association, where tertiary binders mainly help to stabilize protein-protein interfaces. Secondary binders perform both the functions. Conformational changes of prokaryotic and eukaryotic ribosomal proteins due to complexation with 16S ribosomal RNA are linearly correlated with their RNA-interface area and free energy of association. The proteins having long extensions buried within ribosomal RNA have more flexible structures than those found on the subunit surface. Thermus thermophilus ribosomal proteins undergo high conformational changes compared to those of Escherichia coli, assuring structural stability at high temperature environment. The general stabilization strategy of ribosomal protein-RNA interfaces is shown, where high interface polarity ensures high surface density of Hydrogen bonds even with low base/backbone ratio. Polarity is regulated in evolutionary strategy of ribosomal proteins. Thus, the habitat environmental conditions of the two species sweet up their ribosomal protein-RNA interfaces to alter its physical parameters in order of stabilization.
q-bio.BM:Motivation: Protein surface roughness is fractal in nature. Mass, hydrophobicity, polarizability distributions of protein interior are fractal too, as are the distributions of dipole moments, aromatic residues, and many other structural determinants. The open-access server ProtFract, presents a reliable way to obtain numerous fractal-dimension and correlation-dimension based results to quantify the symmetry of self-similarity in distributions of various properties of protein interior and exterior.   Results: Fractal dimension based comparative analyses of various biophysical properties of Ras superfamily proteins were conducted. Though the extent of sequence and functional overlapping across Ras superfamily structures is extremely high, results obtained from ProtFract investigation are found to be sensitive to detect differences in the distribution of each of the properties. For example, it was found that the RAN proteins are structurally most stable amongst all Ras superfamily proteins, the ARFs possess maximum extent of unused hydrophobicity in their structures, RAB protein interiors have electrostatically least conducive environment, GEM/REM/RAD proteins possess exceptionally high symmetry in the structural organization of their active chiral centres, neither hydrophobicity nor columbic interactions play significant part in stabilizing the RAS proteins but aromatic interactions do, though cation-pi interactions are found to be more dominant in RAN than in RAS proteins. Ras superfamily proteins can best be classified with respect to their class-specific pi-pi and cation-pi interaction symmetries.   Availability: ProtFract is freely available online at the URL: http://bioinfo.net.in/protfract/index.html
q-bio.BM:Upon studying the B-Factors of all the atoms of all non-redundant proteins belonging to 76 most commonly found structural domains of all four major structural classes, it was found that the residue mobility has decreased during the course of evolution. Though increased residue-flexibility was preferred in the early stages of protein structure evolution, less flexibility is preferred in the medieval and recent stages. GLU is found to be the most flexible residue while VAL recorded to have the least flexibility. General trends in decrement of B-Factors conformed to the general trend in the order of emergence of protein structural domains. Decrement of B-Factor is observed to be most decisive (monotonic and uniform) for VAL, while evolution of CYS and LYS flexibility is found to be most skewed. Barring CYS, flexibility of all the residues is found to have increased during evolution of alpha by beta folds, however flexibility of all the residues (barring CYS) is found to have decreased during evolution of all beta folds. Only in alpha by beta folds the tendency of preferring higher residue mobility could be observed, neither alpha plus beta, nor all alpha nor all beta folds were found to support higher residue-mobility. In all the structural classes, the effect of evolutionary constraint on polar residues is found to follow an exactly identical trend as that on hydrophobic residues, only the extent of these effects are found to be different. Though protein size is found to be decreasing during evolution, residue mobility of proteins belonging to ancient and old structural domains showed strong positive dependency upon protein size, however for medieval and recent domains such dependency vanished. It is found that to optimize residue fluctuations, alpha by beta class of proteins are subjected to more stringent evolutionary constraints.
q-bio.BM:Recent experimental data indicate that the elastic wormlike rod model of DNA that works well on long length scales may break down on shorter scales relevant to biology. According to Noy and Golestanian (Phys. Rev. Lett. 109, 228101, 2012) molecular dynamics (MD) simulations predict DNA rigidity close to experimental data and confirm one scenario of such breakdown, namely, that for lengths of a few helical turns, DNA dynamics exhibit long-range bending and stretching correlations. Earlier studies using similar forcefields concluded that (i) MD systematically overestimate the DNA rigidity, and (ii) no deviations from the WLR model are detectable. Here it is argued that the data analysis in the above mentioned paper was incorrect and that the earlier conclusions are valid.
q-bio.BM:Superoxide dismutase-1 (SOD1) is a ubiquitous, Cu and Zn binding, free radical defense enzyme whose misfolding and aggregation play a potential key role in amyotrophic lateral sclerosis, an invariably fatal neurodegenerative disease. Over 150 mutations in SOD1 have been identified with a familial form of the disease, but it is presently not clear what unifying features, if any, these mutants share to make them pathogenic. Here, we develop several new computational assays for probing the thermo-mechanical properties of both ALS-associated and rationally-designed SOD1 variants. Allosteric interaction free energies between residues and metals are calculated, and a series of atomic force microscopy experiments are simulated with variable tether positions, to quantify mechanical rigidity "fingerprints" for SOD1 variants. Mechanical fingerprinting studies of a series of C-terminally truncated mutants, along with an analysis of equilibrium dynamic fluctuations while varying native constraints, potential energy change upon mutation, frustratometer analysis, and analysis of the coupling between local frustration and metal binding interactions for a glycine scan of 90 residues together reveal that the apo protein is internally frustrated, that these internal stresses are partially relieved by mutation but at the expense of metal-binding affinity, and that the frustration of a residue is directly related to its role in binding metals. This evidence points to apo SOD1 as a strained intermediate with "self-allostery" for high metal-binding affinity. Thus, the prerequisites for the function of SOD1 as an antioxidant compete with apo state thermo-mechanical stability, increasing the susceptibility of the protein to misfold in the apo state.
q-bio.BM:Reply to Comment on 'Length Scale Dependence of DNA Mechanical Properties'
q-bio.BM:The conformational change of biological macromolecule is investigated from the point of quantum transition. A quantum theory on protein folding is proposed. Compared with other dynamical variables such as mobile electrons, chemical bonds and stretching-bending vibrations the molecular torsion has the lowest energy and can be looked as the slow variable of the system. Simultaneously, from the multi-minima property of torsion potential the local conformational states are well defined. Following the idea that the slow variables slave the fast ones and using the nonadiabaticity operator method we deduce the Hamiltonian describing conformational change. It is proved that the influence of fast variables on the macromolecule can fully be taken into account through a phase transformation of slow variable wave function. Starting from the conformation- transition Hamiltonian the nonradiative matrix element is calculated in two important cases: A, only electrons are fast variables and the electronic state does not change in the transition process; B, fast variables are not limited to electrons but the perturbation approximation can be used. Then, the general formulas for protein folding rate are deduced. The analytical form of the formula is utilized to study the temperature dependence of protein folding rate and the curious non-Arrhenius temperature relation is interpreted. The decoherence time of quantum torsion state is estimated and the quantum coherence degree of torsional angles in the protein folding is studied by using temperature dependence data. The proposed folding rate formula gives a unifying approach for the study of a large class problems of biological conformational change.
q-bio.BM:It is established that prion protein is the sole causative agent in a number of diseases in humans and animals. However, the nature of conformational changes that the normal cellular form PrPC undergoes in the conversion process to a self-replicating state is still not fully understood. The ordered C-terminus of PrPC proteins has three helices (H1, H2, and H3). Here, we use the Statistical Coupling Analysis (SCA) to infer co-variations at various locations using a family of evolutionarily related sequences, and the response of mouse and human PrPCs to mechanical force to decipher the initiation sites for transition from PrPC to an aggregation prone PrP* state. The sequence-based SCA predicts that the clustered residues in non-mammals are localized in the stable core (near H1) of PrPC whereas in mammalian PrPC they are localized in the frustrated helices H2 and H3 where most of the pathogenic mutations are found. Force-extension curves and free energy profiles as a function of extension of mouse and human PrPC in the absence of disulfide (SS) bond between residues Cys179 and Cys214, generated by applying mechanical force to the ends of the molecule, show a sequence of unfolding events starting first with rupture of H2 and H3. This is followed by disruption of structure in two strands. Helix H1, stabilized by three salt-bridges, resists substantial force before unfolding. Force extension profiles and the dynamics of rupture of tertiary contacts also show that even in the presence of SS bond the instabilities in most of H3 and parts of H2 still determine the propensity to form the PrP* state. In mouse PrPC with SS bond there are about ten residues that retain their order even at high forces.
q-bio.BM:Antimicrobial peptides are a class of small, usually positively charged amphiphilic peptides that are used by the innate immune system to combat bacterial infection in multicellular eukaryotes. Antimicrobial peptides are known for their broad-spectrum antimicrobial activity and thus can be used as a basis for a development of new antibiotics against multidrug-resistant bacteria. The most challengeous task on the way to a therapeutic use of antimicrobial peptides is a rational design of new peptides with enhanced activity and reduced toxicity. Here we report a molecular dynamics and circular dichroism study of a novel synthetic antimicrobial peptide D51. This peptide was earlier designed by Loose et al. using a linguistic model of natural antimicrobial peptides. Molecular dynamics simulation of the peptide folding in explicit solvent shows fast formation of two antiparallel beta strands connected by a beta-turn that is confirmed by circular dichroism measurements. Obtained from simulation amphipatic conformation of the peptide is analysed and possible mechanism of its interaction with bacterial membranes together with ways to enhance its antibacterial activity are suggested.
physics.optics:A numerical study of the properties of Gaussian pulses propagating in planar waveguide under the combined effect of positive Kerr-type nonlinearity, diffraction in planar waveguides and anomalous or normal dispersion, is presented. It is demonstrated how the relative strength of dispersion and diffraction, the strength of nonlinearity and the initial spatial and temporal pulse chirps effect on the parameters of pulse compression, such as the maximal compression factor and the distance to the point of maximal compression.
physics.optics:We report on a theoretical and numerical investigation of the switching of power in new hybrid models of nonlinear coherent couplers consisting of optical slab waveguides with various orders of nonlinearity. The first model consists of two guides with second-order instead of the usual third-order susceptibilities as typified by the Jensen coupler. This second-order system is shown to have a power self-trapping transition at a critical power greater than the third-order susceptibility coupler. Next, we consider a mixed coupler composed of a second-order guide coupled to a third-order guide and show that, although it does not display a rigorous self-trapping transition, for a particular choice of parameters it does show a fairly abrupt trapping of power at a lower power than in the third-order coupler. By coupling this mixed nonlinear pair to a third, purely linear guide, the power trapping can be brought to even lower levels and in this way a satisfactory switching profile can be achieved at less than one sixth the input power needed in the Jensen coupler.
physics.optics:It is noted that the Jones-matrix formalism for polarization optics is a six-parameter two-by-two representation of the Lorentz group. It is shown that the four independent Stokes parameters form a Minkowskian four-vector, just like the energy-momentum four-vector in special relativity. The optical filters are represented by four-by-four Lorentz-transformation matrices. This four-by-four formalism can deal with partial coherence described by the Stokes parameters. A four-by-four matrix formulation is given for decoherence effects on the Stokes parameters, and a possible experiment is proposed. It is shown also that this Lorentz-group formalism leads to optical filters with a symmetry property corresponding to that of two-dimensional Euclidean transformations.
physics.optics:We study the electromagnetic scattering by multilayered biperiodic aggregates of dielectric layers and gratings of conducting plates. We show that the characteristic lengths of such structures provide a good control of absorption bands. The influence of the physical parameters of the problem (sizes, impedances) is discussed.
physics.optics:The propagation of an electromagnetic pulse in a plasma is studied for pulse durations that are comparable to the plasma period. When the carrier frequency of the incident pulse is much higher than the plasma frequency, the pulse propagates without distortion at its group speed. When the carrier frequency is comparable to the plasma frequency, the pulse is distorted and leaves behind it an electromagnetic wake.
physics.optics:We present scattering from many body systems in a new light. In place of the usual van Hove treatment, (applicable to a wide range of scattering processes using both photons and massive particles) based on plane waves, we calculate the scattering amplitude as a space-time integral over the scattering sample for an incident wave characterized by its correlation function which results from the shaping of the wave field by the apparatus. Instrument resolution effects - seen as due to the loss of correlation caused by the path differences in the different arms of the instrument are automatically included and analytic forms of the resolution function for different instruments are obtained. The intersection of the moving correlation volumes (those regions where the correlation functions are significant) associated with the different elements of the apparatus determines the maximum correlation lengths (times) that can be observed in a sample, and hence, the momentum (energy) resolution of the measurement. This geometrical picture of moving correlation volumes derived by our technique shows how the interaction of the scatterer with the wave field shaped by the apparatus proceeds in space and time. Matching of the correlation volumes so as to maximize the intersection region yields a transparent, graphical method of instrument design. PACS: 03.65.Nk, 3.80 +r, 03.75, 61.12.B
physics.optics:In this paper we extend for the case of Maxwell equations the "X-shaped" solutions previously found in the case of scalar (e.g., acoustic) wave equations. Such solutions are localized in theory, i.e., diffraction-free and particle-like (wavelets), in that they maintain their shape as they propagate. In the electromagnetic case they are particularly interesting, since they are expected to be Superluminal. We address also the problem of their practical, approximate production by finite (dynamic) radiators. Finally, we discuss the appearance of the X-shaped solutions from the purely geometric point of view of the Special Relativity theory.   [PACS nos.: 03.50.De; 1.20.Jb; 03.30.+p; 03.40.Kf; 14.80.-j.   Keywords: X-shaped waves; localized solutions to Maxwell equations; Superluminal waves; Bessel beams; Limited-dispersion beams; electromagnetic wavelets; Special Relativity; Extended Relativity].
physics.optics:This paper has been withdrawn by the authors until some changes are made.
physics.optics:The effect of dispersion or diffraction on zero-velocity solitons is studied for the generalized massive Thirring model describing a nonlinear optical fiber with grating or parallel-coupled planar waveguides with misaligned axes. The Thirring solitons existing at zero dispersion/diffraction are shown numerically to be separated by a finite gap from three isolated soliton branches. Inside the gap, there is an infinity of multi-soliton branches. Thus, the Thirring solitons are structurally unstable. In another parameter region (far from the Thirring limit), solitons exist everywhere.
physics.optics:We theoretically study reflection of light by a phase-conjugating mirror preceded by a partially reflecting normal mirror. The presence of a suitably chosen normal mirror in front of the phase conjugator is found to greatly enhance the total phase-conjugate reflected power, even up to an order of magnitude. Required conditions are that the phase-conjugating mirror itself amplifies upon reflection and that constructive interference of light in the region between the mirrors takes place. We show that the phase-conjugate reflected power then exhibits a maximum as a function of the transmittance of the normal mirror.
physics.optics:Reliable control of the deposition process of optical films and coatings frequently requires monitoring of the refractive index profile throughout the layer. In the present work a simple in situ approach is proposed which uses a WKBJ matrix representation of the optical transfer function of a single thin film on a substrate. Mathematical expressions are developed which represent the minima and maxima envelopes of the curves transmittance-vs-time and reflectance-vs-time. The refractive index and extinction coefficient depth profiles of different films are calculated from simulated spectra as well as from experimental data obtained during PECVD of silicon-compound films. Variation of the deposition rate with time is also evaluated from the position of the spectra extrema as a function of time. The physical and mathematical limitations of the method are discussed.
physics.optics:A new definition for the electromagnetic field velocity is proposed. The velocity depends on the physical fields.
physics.optics:We have fabricated light emitting diodes (LEDs) with Schottky contacts on Si-nanocrystals formed by simple techniques as used for standard Si devices. Orange electroluminescence (EL) from these LEDs could be seen with the naked eye at room temperature when a reverse bias voltage was applied. The EL spectrum has a major peak with a photon energy of 1.9 eV and a minor peak with a photon energy of 2.2 eV. Since the electrons and holes are injected into the radiative recombination centers related to nanocrystals through avalanche breakdown, the voltage needed for a visible light emission is reduced to 4.0 - 4.5 V, which is low enough to be applied by a standard Si transistor.
physics.optics:A general model is presented for coupling of high-$Q$ whispering-gallery modes in optical microsphere resonators with coupler devices possessing discrete and continuous spectrum of propagating modes. By contrast to conventional high-Q optical cavities, in microspheres independence of high intrinsic quality-factor and controllable parameters of coupling via evanescent field offer variety of regimes earlier available in RF devices. The theory is applied to the earlier-reported data on different types of couplers to microsphere resonators and complemented by experimental demonstration of enhanced coupling efficiency (about 80%) and variable loading regimes with Q>10^8 fused silica microspheres.
physics.optics:The mechanism of DC-Electric-Field-Induced Second-Harmonic (EFISH) generation at weakly nonlinear buried Si(001)-SiO$_2$ interfaces is studied experimentally in planar Si(001)-SiO$_2$-Cr MOS structures by optical second-harmonic generation (SHG) spectroscopy with a tunable Ti:sapphire femtosecond laser. The spectral dependence of the EFISH contribution near the direct two-photon $E_1$ transition of silicon is extracted. A systematic phenomenological model of the EFISH phenomenon, including a detailed description of the space charge region (SCR) at the semiconductor-dielectric interface in accumulation, depletion, and inversion regimes, has been developed. The influence of surface quantization effects, interface states, charge traps in the oxide layer, doping concentration and oxide thickness on nonlocal screening of the DC-electric field and on breaking of inversion symmetry in the SCR is considered. The model describes EFISH generation in the SCR using a Green function formalism which takes into account all retardation and absorption effects of the fundamental and second harmonic (SH) waves, optical interference between field-dependent and field-independent contributions to the SH field and multiple reflection interference in the SiO$_2$ layer. Good agreement between the phenomenological model and our recent and new EFISH spectroscopic results is demonstrated. Finally, low-frequency electromodulated EFISH is demonstrated as a useful differential spectroscopic technique for studies of the Si-SiO$_2$ interface in silicon-based MOS structures.
physics.optics:The new mechanism for obtaining a nonlinear phase shift has been proposed and the schemes are described for its implementation. As it is shown, the interference of two waves with intensity-dependent amplitude ratio coming from the second harmonic generation should produce the nonlinear phase shift. The sign and amount of nonlinear distortion of a beam wavefront is dependent of the relative phase of the waves that is introduced by the phase element. Calculated value of $n_2^{eff}$ exceeds that connected with cascaded quadratic nonlinearity, at the same conditions.
physics.optics:We analyze the guiding problem in a realistic photonic crystal fiber using a novel full-vector modal technique, a biorthogonal modal method based on the nonselfadjoint character of the electromagnetic propagation in a fiber. Dispersion curves of guided modes for different fiber structural parameters are calculated along with the 2D transverse intensity distribution of the fundamental mode. Our results match those achieved in recent experiments, where the feasibility of this type of fiber was shown.
physics.optics:A new method for investigation of x-ray propagation in a rough narrow dielectric waveguide is proposed on the basis of the numerical integration of the quazioptical equation. In calculations a model rough surface was used with the given statistical properties. It was shown that the losses in the narrow waveguides strongly depend on the wall roughness and on the input angle. The losses are not zero even at zero input angle if the width of the waveguide is smaller or about 1 mkm. The effect is accounted for as the influence of diffraction. The angular spread of the transmitted X-ray radiation is much more narrow than the Fresnel angle of the total external reflection.
physics.optics:We study a generalized notion of two-mode squeezing for the Stokes and anti-Stokes fields in a model of a cavity Raman laser, which leads to a significant reduction in decoherence or quantum noise. The model comprises a loss-less cavity with classical pump, unsaturated medium and arbitrary homogeneous broadening and dispersion. Allowing for arbitrary linear combinations of the two modes in the definition of quadrature variables, we find that there always exists a combination of the two output modes which exhibits quadrature squeezing with noise reduction below the vacuum level. The number of noise photons for this combination mode is proportional to the square root of the number of Stokes noise photons.
physics.optics:We study the effects of higher order transversal modes in a model of a singly-resonant OPO, using both numerical solutions and mode expansions including up to two radial modes. The numerical and two-mode solutions predict lower threshold and higher conversion than the single-mode solution at negative dispersion. Relative power in the zero order radial mode ranges from about 88% at positive and small negative dispersion to 48% at larger negative dispersion, with most of the higher mode content in the first mode, and less than 2% in higher modes.
physics.optics:This paper presents a detailed numerical study of the effect of focusing on the conversion efficiency of low-loss singly-resonant parametric oscillators with collinear focusing of pump and signal. Results are given for the maximal pump depletion and for pump power levels required for various amounts of depletion, as functions of pump and signal confocal parameters, for kI/kP=0.33 and 0.50. It is found that the ratio of pump depletion to maximal depletion as a function of the ratio of pump power to threshold power agrees with the plane-wave prediction to within 5%, for a wide range of focusing conditions. The observed trends are explained as resulting from intensity and phase dependent mechanisms.
physics.optics:Via solution of appropriate variational problem it is shown that light beams with Gaussian spatial profile and sufficiently short duration provide maximal destruction of global coherence under nonlinear self-modulation.
physics.optics:The dynamics of Fabry-Perot cavity with suspended mirrors is described. The suspended mirrors are nonlinear oscillators interacting with each other through the laser circulating in the cavity. The degrees of freedom decouple in normal coordinates, which are the position of the center of mass and the length of the cavity. We introduce two parameters and study how the dynamics changes with respect to these parameters. The first parameter specifies how strong the radiation pressure is. It determines whether the cavity is multistable or not. The second parameter is the control parameter, which determines location of the cavity equilibrium states. The equilibrium state shows hysteresis if the control parameter varies within a wide range. We analyze stability of the equilibrium states and identify the instability region. The instability is explained in terms of the effective potential: the stable states correspond to local minima of the effective potential and unstable states correspond to local maxima. The minima of the effective potential defines the resonant frequencies for the oscillations of the cavity length. We find the frequencies, and analyze how to tune them. Multistability of the cavity with a feedback control system is analyzed in terms of the servo potential. The results obtained in this paper are general and apply to all Fabry-Perot cavities with suspended mirrors.
physics.optics:We show that an azimuthally-periodically-modulated bright ring "necklace" beam can self-trap in self-focusing Kerr media and can exhibit stable propagation for very large distances. These are the first bright (2+1) D beams to exhibit stable self-trapping in a system described by the cubic (2+1) D Nonlinear Schrodinger Equation (NLSE).
physics.optics:We present a new class of micro lasers based on nanoporous molecular sieve host-guest systems. Organic dye guest molecules of 1-Ethyl-4-(4-(p-Dimethylaminophenyl)-1,3-butadienyl)-pyridinium Perchlorat were inserted into the 0.73-nm-wide channel pores of a zeolite AlPO$_4$-5 host. The zeolitic micro crystal compounds where hydrothermally synthesized according to a particular host-guest chemical process. The dye molecules are found not only to be aligned along the host channel axis, but to be oriented as well. Single mode laser emission at 687 nm was obtained from a whispering gallery mode oscillating in a 8-$\mu$m-diameter monolithic micro resonator, in which the field is confined by total internal reflection at the natural hexagonal boundaries inside the zeolitic microcrystals.
physics.optics:We report a quantum ring-like toroidal cavity naturally formed in a vertical-cavity-like active microdisk plane due to Rayleigh's band of whispering gallery modes. The $\sqrt{T}$-dependent redshift and a square-law property of microampere-range threshold currents down to 2 $\mu$A are consistent with a photonic quantum wire view, due to whispering gallery mode-induced dimensional reduction.
physics.optics:The effect of capture of X-ray beam into narrow submicron capillary was investigated with account for diffraction and decay of coherency by roughness scattering in transitional boundary layer. In contrast to well-known Andronov-Leontovich approach the losses do not vanish at zero gliding angle and scale proportional to the first power of roughness amplitude for small gliding angles. It was shown that for small correlation radius of roughness the scattering decay of coherency can be made of the same order as absorption decay of lower channeling modes to produce angular collimation of X-ray beams. Estimates were given for optimum capillary length at different roughness amplitudes for angular sensitivity of X-ray transmission and chenneling effects that can be usefull for designing of detector systems.
physics.optics:We report the measurement of the photons flux produced in parametric down-conversion, performed in photon counting regime with actively quenched silicon avalanche photodiodes as single photon detectors. Measurements are done with the detector in a well defined geometrical and spectral situation. By comparison of the experimental data with the theory, a value for the second order susceptibilities of the non linear crystal can be inferred.
physics.optics:In a frame of quasi-crystal approximation the dispersion equations are obtained for the wave vector of a coherent electromagnetic wave propagating in a media which contains a random set of parallel dielectric cylinders with possible overlapping. The results are compared with that for the case when a regularity at the cylinder placement exists.
physics.optics:Accurate calculation of internal and surface scattering losses in fused silica microspheres is done. We show that in microspheres internal scattering is partly inhibited as compared to losses in the bulk material. We pay attention on the effect of frozen thermodynamical capillary waves on surface roughness. We calculate also the value of mode splitting due to backscattering and other effects of this backscattering.
physics.optics:We analytically compute a localization criterion in double scattering approximation for a set of dielectric spheres or perfectly conducting disks uniformly distributed in a spatial volume which can be either spherical or layered. For every disordered medium, we numerically investigate a localization criterion, and examine the influence of the system parameters on the wavelength localization domains.
physics.optics:The use of specific symmetry properties of the optical second-harmonic generation (the s,s-exclusion rule) has allowed us to observe high-contrast hyper-Rayleigh interference patterns in a completely diffuse light - an effect having no analog in case of linear (Rayleigh) scattering.
physics.optics:We report detailed measurements of the pump-current dependency of the self-pulsating frequency of semiconductor CD lasers. A distinct kink in this dependence is found and explained using rate-equation model. The kink denotes a transition between a region where the self-pulsations are weakly sustained relaxation oscillations and a region where Q-switching takes place. Simulations show that spontaneous emission noise plays a crucial role for the cross-over.
physics.optics:A new method is proposed to produce population inversion on transitions involving the ground state of atoms. The method is realized experimentally with sodium atoms. Lasing at the frequency corresponding to the sodium D_2 line is achieved in the presence of pump radiation resonant to the D_1 line with helium as a buffer gas.
physics.optics:A moving dielectric appears to light as an effective gravitational field. At low flow velocities the dielectric acts on light in the same way as a magnetic field acts on a charged matter wave. We develop in detail the geometrical optics of moving dispersionless media. We derive a Hamiltonian and a Lagrangian to describe ray propagation. We elucidate how the gravitational and the magnetic model of light propagation are related to each other. Finally, we study light propagation around a vortex flow. The vortex shows an optical Aharonov--Bohm effect at large distances from the core, and, at shorter ranges, the vortex may resemble an optical black hole.
physics.optics:We report the first observation of a nonlinear mode in a cylindrical nonlinear Fabry-Perot cavity. The field enhancement from cavity buildup, as well as the large chi3 optical nonlinearity due to resonantly-excited Rb-85 vapor, allows the nonlinear mode to form at low incident optical powers of less than a milliwatt. The mode is observed to occur for both the self-focusing and self-defocusing nonlinearity.
physics.optics:Optical second harmonic generation (SHG) is used as a noninvasive probe of two-dimensional (2D) ferroelectricity in Langmuir-Blodgett (LB) films of copolymer vinylidene fluoride with trifluorethylene. The surface 2D ferroelectric-paraelectric phase transition in the topmost layer of LB films and a thickness independent (almost 2D) transition in the bulk of these films are observed in temperature studies of SHG.
physics.optics:An all optical set-reset flip flop is presented that is based on two coupled identical laser diodes. The lasers are coupled so that when one of the lasers lases it quenches lasing in the other laser. The state of the flip flop is determined by which laser is currently lasing. Rate equations are used to model the flip flop and obtain steady state characteristics. The flip flop is experimentally demonstrated by use of antireflection coated laser diodes and free space optics.
physics.optics:We report on the fabrication of what we believe is the first example of a two dimensional nonlinear periodic crystal\cite{berger}, where the refractive index is constant but in which the 2nd order nonlinear susceptibility is spatially periodic. Such a crystal allows for efficient quasi-phase matched 2nd harmonic generation using multiple reciprocal lattice vectors of the crystal lattice. External 2nd harmonic conversion efficiencies > 60% were measured with picosecond pulses. The 2nd harmonic light can be simultaneously phase matched by multiple reciprocal lattice vectors, resulting in the generation of multiple coherent beams. The fabrication technique is extremely versatile and allows for the fabrication of a broad range of 2-D crystals including quasi-crystals.
physics.optics:The influence of linearly and circularly polarized laser fields on the dynamics of fast electron-impact excitation in atomic helium is discussed. A detailed analysis is made in the excitation of 2^1S, 3^1S and 3^1D dressed states of helium target.
physics.optics:The nonlinear dynamics of dissipative quantum systems in incoherent laser fields is studied in the framework of master equation with random model describing the laser noise and Markovian approximation for dealing with the system-bath couplings.
physics.optics:We present a theoretical study of strong laser-atom interactions, when the laser field parameters are subjected to random processes. The atom is modelled by a two-level and three-level systems, while the statistical fluctuations of the laser field are described by a pre-Gaussian model.
physics.optics:We consider the effect of spatial correlations on sources of polarized electromagnetic radiation. The sources, assumed to be monochromatic, are constructed out of dipoles aligned along a line such that their orientation is correlated with their position. In one representative example, the dipole orientations are prescribed by a generalized form of the standard von Mises distribution for angular variables such that the azimuthal angle of dipoles is correlated with their position. In another example the tip of the dipole vector traces a helix around the symmetry axis of the source, thereby modelling the DNA molecule. We study the polarization properties of the radiation emitted from such sources in the radiation zone. For certain ranges of the parameters we find a rather striking angular dependence of polarization. This may find useful applications in certain biological systems as well as in astrophysical sources.
physics.optics:We study the dynamics of the reduced density matrix(RDM) of the field in the micromaser. The resonator is pumped by N-atomic clusters of two-level atoms. At each given instant there is only one cluster in the cavity. We find the conditions of the independent evolution of the matrix elements of RDM belonging to a (sub)diagonal of the RDM, i.e. conditions of the diagonal invariance for the case of pumping by N-atomic clusters. We analyze the spectrum of the evolution operator of the RDM and discover the existence of the quasitrapped states of the field mode. These states exist for a wide range of number of atoms in the cluster as well as for a broad range of relaxation rates. We discuss the hierarchy of dynamical processes in the micromaser and find an important property of the field states corresponding to the quasi-equilibrium: these states are close to either Fock states or to a superposition of the Fock states. A possibility to tune the distribution function of photon numbers is discussed.
physics.optics:Temporal and angular correlations in atom-mediated photon-photon scattering are measured. Good agreement is found with the theory presented in Part~I.
physics.optics:The mediated photon-photon interaction due to the resonant Kerr nonlinearity in an inhomogeneously broadened atomic vapor is considered. The time-scale for photon-photon scattering is computed and found to be determined by the inhomogeneous broadening and the magnitude of the momentum transfer. This time can be shorter than the atomic relaxation time. Effects of atom statistics are included and the special case of small-angle scattering is considered. In the latter case the time-scale of the nonlinear response remains fast, even though the linear response slows as the inverse of the momentum transfer.
physics.optics:A simple variation of the traditional Young's double slit experiment can demonstrate several subtleties of interference with polarized light, including Berry and Pancharatnam's phase. Since the position of the fringes depends on the polarization state of the light at the input, the apparatus can also be used to measure the light's polarization without a quarter-wave plate or an accurate measurement of the light's intensity. In principle this technique can be used for any wavelength of photon as long as one can effectively polarize the incoming radiation.
physics.optics:The combination of charge separation induced by the formation of a single photorefractive screening soliton and an applied external bias field in a paraelectric is shown to lead to a family of useful electro-optic guiding patterns and properties.
physics.optics:The nonlinear pulse propagation in an optical fibers with varying parameters is investigated. The capture of moving in the frequency domain femtosecond colored soliton by a dispersive trap formed in an amplifying fiber makes it possible to accumulate an additional energy and to reduce significantly the soliton pulse duration. Nonlinear dynamics of the chirped soliton pulses in the dispersion managed systems is also investigated. The methodology developed does provide a systematic way to generate infinite ``ocean'' of the chirped soliton solutions of the nonlinear Schr\"odinger equation (NSE) with varying coefficients.
physics.optics:The Jaynes-Cummings model describing the interaction of a single linearly- polarized mode of the quantized electromagnetic field with an isolated two- level atom is generalized to the case of atomic levels degenerate in the projections of the angular momenta on the quantization axis, which is a usual case in the experiments. This generalization, like the original model, obtains the explicit solution. The model is applied to calculate the dependence of the atomic level populations on the angle between the polarization of cavity field mode and that of the laser excitation pulse in the experiment with one-atom micromaser.
physics.optics:We deduce the simplest form for an axicon Gaussian laser beam, i.e., one with radial polarization of the electric field.
physics.optics:We consider a linearly polarized electromagnetic wave incident on an opaque screen with square aperture of edge a. An application of Faraday's law to a loop parallel to the screen, on the side away from the source, shows that the wave must have longitudinal components there. The ratio of the longitudinal to transverse field is a measure of the diffraction angle.
physics.optics:We show that a time-reversed formulation of Huygens-Kirchhoff diffraction can be used to deduce the transverse and longitudinal fields of a Gaussian laser beam, starting from a simple assumption of a Gaussian beam profile in the far field. An attempt to apply this technique to the far fields of a Hertzian dipole shows how the laws of diffraction do not permit a wave to be focused to a volume smaller than a cubic wavelength in a charge-free region.
physics.optics:Slow light generated by Electromagnetically Induced Transparency is extremely susceptible with respect to Doppler detuning. Consequently, slow-light gyroscopes should have ultrahigh sensitivity.
physics.optics:The second-harmonic interferometric spectroscopy (SHIS) which combines both amplitude (intensity) and phase spectra of the second-harmonic (SH) radiation is proposed as a new spectroscopic technique being sensitive to the type of critical points (CP's) of combined density of states at semiconductor surfaces. The increased sensitivity of SHIS technique is demonstrated for the buried Si(111)-SiO$_2$ interface for SH photon energies from 3.6 eV to 5 eV and allows to separate the resonant contributions from $E^\prime_0/E_1$, $E_2$ and $E^\prime_1$ CP's of silicon.
physics.optics:The frequency of a 700mW monolithic non-planar Nd:YAG ring laser (NPRO) depends with a large coupling coefficient (some MHz/mW) on the power of its laser-diode pump source. Using this effect we demonstrate the frequency stabilization of an NPRO to a frequency reference by feeding back to the current of its pump diodes. We achieved an error point frequency noise smaller than 1mHz/sqrt(Hz), and simultaneously a reduction of the power noise of the NPRO by 10dB without an additional power stabilization feed-back system.
physics.optics:We deduce the emissivity of radiation from a metallic surface as a function of angle and polarization. This effect has found application in the calibration of detectors for cosmic microwave background radiation.
physics.optics:We present the first experimental observation of modulation instability of partially spatially incoherent light beams in non-instantaneous nonlinear media. We show that even in such a nonlinear partially coherent system (of weakly-correlated particles) patterns can form spontaneously. Incoherent MI occurs above a specific threshold that depends on the beams' coherence properties (correlation distance), and leads to a periodic train of one-dimensional (1D) filaments. At a higher value of nonlinearity, incoherent MI displays a two-dimensional (2D) instability and leads to self-ordered arrays of light spots.
physics.optics:We study the polarization of light emitted by spatially correlated sources. We show that in general polarization acquires nontrivial spectral dependence due to spatial correlations. The spectral dependence is found to be absent only for a special class of sources where the correlation length scales as the wavelength of light. We further study the cross correlations between two spatially distinct points that are generated due to propagation. It is found that such cross correlation leads to sufficiently strong spectral dependence of polarization which can be measured experimentally.
physics.optics:We demonstrate experimentally that in a centrosymmetric paraelectric non-stationary boundary conditions can dynamically halt the intrinsic instability of quasi-steady-state photorefractive self-trapping, driving beam evolution into a stable oscillating two-soliton-state configuration.
physics.optics:Mugnai et al. have reported an experiment in which microwave packets appear to travel in air with a speed substantially greater than c. They calculate the group velocity of their packets and find that it agrees with their experimental result. That calculation is incorrect. A correct calculation gives a group velocity less than c. The reported experimental result cannot be reconciled with the Maxwell equations.
physics.optics:Scalar Bessel beams are derived both via the wave equation and via diffraction theory. While such beams have a group velocity that exceeds the speed of light, this is a manifestation of the "scissors paradox" of special relativty. The signal velocity of a modulated Bessel beam is less than the speed of light. Forms of Bessel beams that satisfy Maxwell's equations are also given.
physics.optics:Various algebraic structures of degenerate four-wave mixing equations of optical phase conjugation are analyzed. Two approaches (the spinorial and the Lax-pair based), complementary to each other, are utilized for a systematic derivation of conserved quantities. Symmetry groups of both the equations and the conserved quantities are determined, and the corresponding generators are written down explicitly. Relation between these two symmetry groups is found. Conserved quantities enable the introduction of new methods for integration of the equations in the cases when the coupling $\Gamma$ is either purely real or purely imaginary. These methods allow for both geometries of the process, namely the transmission and the reflection, to be treated on an equal basis. One approach to introduction of Hamiltonian and Lagrangian structures for the 4WM systems is explored, and the obstacles in successful implementation of that programe are identified. In case of real coupling these obstacles are removable, and full Hamiltonian and Lagrangian formulations of the initial system are possible.
physics.optics:Instead of using frequency dependent refractive index, we propose to use the extinction theorem to describe reflection and transmission of an ultrashort pulse passing through the boundary. When the duration of the pulse is comparable with the relaxation time, the results differ significantly from those given by the traditional method, especially if the carrier frequency is close to an absorbtion line. We compare the two approaches using the data of GaAs in the infrared domain.
physics.optics:The Classification of Polarization elements, the polarization affecting optical devices which have a Jones matrix representation, according to the types of eigenvectors they possess, is given a new visit through the Group-theoretical connection of polarization elements. The diattenuators and retarders are recognized as the elements corresponding to boosts and rotations respectively. The structure of homogeneous elements other than diattenuators and retarders are identified by giving the quaternion corresponding to these elements. The set of degenerate polarization elements is identified with the so called `null' elements of the Lorentz Group. Singular polarization elements are examined in their more illustrative Mueller matrix representation and finally the eigenstructure of a special class of singular Mueller matrices is studied.
physics.optics:Complex photonic band structures (CPBS) of transmission metallic gratings with rectangular slits are shown to exhibit strong discontinuities that are not evidenced in the usual energetic band structures. These discontinuities are located on Wood's anomalies and reveal unambiguously two different types of resonances, which are identified as horizontal and vertical surface-plasmon resonances. Spectral position and width of peaks in the transmission spectrum can be directly extracted from CPBS for both kinds of resonances.
physics.optics:We present a brief classical discussion of a process to reduce the group velocity of an electromagnetic pulse by many orders of magnitude.
physics.optics:The properties of pulse propagation in a nonlinear fiber including linear damped term added in the usual nonlinear Schr\"odinger equation is analyzed analytically. We apply variational modified approach based on the lagrangian that describe the dynamic of system and with a trial function we obtain a solution which is more accuracy when compared with a pertubative solution. As a result, the problem of pulse propagation in a fiber with loss can be described in good agreement with exact results.
physics.optics:The group velocity for pulses in an optical medium can be negative at frequencies between those of a pair of laser-pumped spectral lines. The gain medium then can amplify the leading edge of a pulse resulting in a time advance of the pulse when it exits the medium, as has been recently demonstrated in the laboratory. This effect has been called superluminal, but, as a classical analysis shows, it cannot result in signal propgation at speeds greater than that of light in vacuum.
physics.optics:In two models it is shown that a light pulse propagates from a vacuum into certain media with velocity greater than that of a light in a vacuum (c). By numerical calculation the propagating properties of such a light are given.
physics.optics:The results of the study of ultra-short pulse generation in continuous-wave Kerr-lens mode-locked (KLM) solid-state lasers with semiconductor saturable absorbers are presented. The issues of extremely short pulse generation are addressed in the frames of the theory that accounts for the coherent nature of the absorber-pulse interaction. We developed an analytical model that bases on the coupled generalized Landau-Ginzburg laser equation and Bloch equations for a coherent absorber. We showed, that in the absence of KLM semiconductor absorber produces 2pi - non-sech-pulses of self-induced transparency, while the KLM provides an extremely short sech-shaped pulse generation. 2pi- and pi-sech-shaped solutions and variable-area chirped pulses have been found. It was shown, that the presence of KLM removes the limitation on the minimal modulation depth in absorber. An automudulational stability and self-starting ability were analyzed, too.
physics.optics:Based on self - consistent field theory we study a soliton generation in cw solid-state lasers with semiconductor saturable absorber. Various soliton destabilizations, i.e. the switch from femtosecond to picosecond generation (''picosecond collapse''), an automodulation regime, breakdown of soliton generation and hysteresis behavior, are predicted.
physics.optics:The effect of transmission of x-ray beams through submicron capillaries was investigated with account for diffraction and roughness scattering. Possible explanation of anomalous energy dependence of transmission through thin Cr/C/Cr channeles was given due to effect of periodic deformations.
physics.optics:Nonstationary pulse regimes associated with self modulation of a Kerr-lens modelocked Ti:sapphire laser have been studied experimentally and theoretically. Such laser regimes occur at an intracavity group delay dispersion that is smaller or larger than what is required for stable modelocking and exhibit modulation in pulse amplitude and spectra at frequencies of several hundred kHz. Stabilization of such modulations, leading to an increase in the pulse peak power by a factor of ten, were accomplished by weakly modulating the pump laser with the self-modulation frequency. The main experimental observations can be explained with a round trip model of the fs laser taking into account gain saturation, Kerr lensing, and second- and third-order dispersion.
physics.optics:The theoretical calculation for nonlinear refractive index in Cr: ZnSe - active medium predicts the strong defocusing cascaded second-order nonlinearity within 2000 - 3000 nm spectral range. On the basis of this result the optimal cavity configuration for Kerr-lens mode locking is proposed that allows to achieve a sub-100 fs pulse duration. The numerical simulations testify about strong destabilizing processes in the laser resulting from a strong self-phase modulation. The stabilization of the ultrashort pulse generation is possible due to spectral filtering that increases the pulse duration up to 300 fs.
physics.optics:The influence of nonlinear properties of semiconductor saturable absorbers on ultrashort pulse generation was investigated. It was shown, that linewidth enhancement, quadratic and linear ac Stark effect contribute essentially to the mode locking in cw solid-state lasers, that can increase the pulse stability, decrease pulse duration and reduce the mode locking threshold
physics.optics:We demonstrate that the shift of the stop band position with increasing oblique angle in periodic structures results in a wide transverse exponential field distribution corresponding to strong angular confinement of the radiation. The beam expansion follows an effective diffusive equation depending only upon the spectral mode width. In the presence of gain, the beam cross section is limited only by the size of the gain area. As an example of an active periodic photonic medium, we calculate and measure laser emission from a dye-doped cholesteric liquid crystal film.
physics.optics:The frequency of the Calcium ^3P_1--^1S_0 intercombination line at 657 nm is phase-coherently measured in terms of the output of a primary cesium frequency standard using an optical frequency comb generator comprising a sub-10 fs Kerr-lens mode-locked Ti:Sapphire laser and an external microstructure fiber for self-phase-modulation. The measured frequency of \nu_Ca = 455 986 240 494 276 Hz agrees within its relative uncertainty of 4 10^-13 with the values previously measured with a conceptually different harmonic frequency chain and with the value recommended for the realization of the SI unit of length.
physics.optics:Accurate phase-locked 3:1 division of an optical frequency was achieved, by using a continuous-wave (cw) doubly resonant optical parametric oscillator. A fractional frequency stability of 2*10^(-17) of the division process has been achieved for 100s integration time. The technique developed in this work can be generalized to the accurate phase and frequency control of any cw optical parametric oscillator.
physics.optics:It was usually assumed that the resonator based on a waveguide has the eigen oscillations that are formed by interference of two waves which propagate in different directions and have equal amplitudes. These patterns are usually called standing waves. We have shown that the eigen oscillations of a resonator which is filled by a layered dielectric can be base on the evanescent (non-propagating) waves. In some cases we need only one eigen wave to compose the eigen oscillation of a closed cavity.
physics.optics:The plane-wave dynamics of 3*omega => (2*omega, omega) subharmonic optical parametric oscillators containing a second harmonic generator of the idler wave omega is analyzed analytically by using the meanfield approximation and numerically by taking into account the field propagation inside the media. The resonant Chi(2):Chi(2) cascaded second-order nonlinearities induce a mutual injection-locking of the signal and idler waves that leads to coherent self phase-locking of the pump and subharmonic waves, freezing the phase diffusion noise. In case of signal-and-idler resonant devices, largely detuned sub-threshold states occur due to a subcritical bifurcation, broadening out the self-locking frequency range to a few cavity linewidths.
physics.optics:For the first time an all optical flip-flop is demonstrated based on two coupled Mach-Zehnder interferometers which contain semiconductor optical amplifiers in their arms. The flip-flop operation is discussed and it is demonstrated using commercially available fiber pigtailed devices. Being based on Mach-Zehnder interferometers, the flip-flop has potential for very high speed operation.
physics.optics:The strong asymmetry in charge distribution supporting a single non-interacting spatial needle soliton in a paraelectric photorefractive is directly observed by means of electroholographic readout. Whereas in trapping conditions a quasi-circular wave is supported, the underlying double-dipolar structure can be made to support two distinct propagation modes.
physics.optics:I present a theoretical treatment of parametric scattering in strong coupling semiconductor microcavities to model experiments in which parametric oscillator behaviour has been observed. The model consists of a non-linear excitonic oscillator coupled to a cavity mode which is driven by the external fields, and predicts the output power, below threshold gain and spectral blue shifts of the parametric oscillator. The predictions are found to be in excellent agreement with the experimental data.
physics.optics:A number of factors that influence spectral position of the femtosecond pulse in a Kerr-lens modelocked Cr:LiSGaF laser have been identified: high-order dispersion, gain saturation, reabsorption from the ground state, and stimulated Raman scattering. Using the one-dimensional numerical model for the simulation of the laser cavity, the relative contributions of different factors have been compared. The Raman effect provides the largest self-frequency shift from the gain peak (up to 60 nm), followed by the gain saturation (25 nm), while the high-order dispersion contribution is insignificant (5 nm). Comparison with the experimental data confirm that the stimulated Raman scattering is a main cause of the ultrashort pulse self-frequency shift observed in Cr:LiSGaF and Cr:LiSAF lasers
physics.optics:Simultaneous measurements of the intensity and phase of a probe wave reflected from an interface between silica and elemental alpha-gallium reveal its very strong optical nonlinearity, affecting both these parameters of the reflected wave. The data corroborate with a non-thermal mechanism of optical response which assumes appearance of a homogeneous highly metallic layer, only a few nanometer thick, between the silica and bulk alpha-gallium.
physics.optics:We consider pulse propagation in a linear anomalously dispersive medium where the group velocity exceeds the speed of light in vacuum (c) or even becomes negative. A signal velocity is defined operationally based on the optical signal-to-noise ratio, and is computed for cases appropriate to the recent experiment where such a negative group velocity was observed. It is found that quantum fluctuations limit the signal velocity to values less than c.
physics.optics:Polarization dynamics of femtosecond light pulses propagating in air is studied by computer simulation. A rich variety of dynamics is found that depends on the initial polarization state and power of the pulse. Effects of polarization on the plasma and supercontinuum generation are also discussed.
physics.optics:We report measurements of thermal self-locking of a Fabry-Perot cavity containing a potassium niobate (KNbO3) crystal. We develop a method to determine linear and nonlinear optical absorption coefficients in intracavity crystals by detailed analysis of the transmission lineshapes. These lineshapes are typical of optical bistability in thermally loaded cavities. For our crystal, we determine the one-photon absorption coefficient at 846 nm to be (0.0034 \pm 0.0022) per m and the two-photon absorption coefficient at 846 nm to be (3.2 \pm 0.5) \times 10^{-11} m/W and the one-photon absorption coefficient at 423 nm to be (13 \pm 2) per m. We also address the issue of blue-light-induced-infrared-absorption (BLIIRA), and determine a coefficient for this excited state absorption process. Our method is particularly well suited to bulk absorption measurements where absorption is small compared to scattering. We also report new measurements of the temperature dependence of the index of refraction at 846 nm, and compare to values in the literature.
physics.optics:We review and extend the analogies between Gaussian pulse propagation and Gaussian beam diffraction. In addition to the well-known parallels between pulse dispersion in optical fiber and CW beam diffraction in free space, we review temporal lenses as a way to describe nonlinearities in the propagation equations, and then introduce further concepts that permit the description of pulse evolution in more complicated systems. These include the temporal equivalent of a spherical dielectric interface, which is used by way of example to derive design parameters used in a recent dispersion-mapped soliton transmission experiment. Our formalism offers a quick, concise and powerful approach to analyzing a variety of linear and nonlinear pulse propagation phenomena in optical fibers.
physics.optics:We have measured the frequency of the $6s^2S_{1/2} - 5d^2D_{3/2}$ electric-quadrupole transition of $^{171}$Yb$^+$ with a relative uncertainty of $1\times 10^{-14}$, $\nu_{Yb}$ = 688 358 979 309 312 Hz $\pm$ 6 Hz. A femtosecond frequency comb generator was used to phase-coherently link the optical frequency derived from a single trapped ion to a cesium fountain controlled hydrogen maser. This measurement is one of the most accurate measurements of optical frequencies ever reported, and it represents a contribution to the development of optical clocks based on an $^{171}$Yb$^+$ ion standard.
physics.optics:The time behaviour of microwaves undergoing partial reflection by photonic barriers was measured in the time and in the frequency domain. It was observed that unlike the duration of partial reflection by dielectric layers, the measured reflection duration of barriers is independent of their length. The experimental results point to a nonlocal behaviour of evanescent modes at least over a distance of some ten wavelengths. Evanescent modes correspond to photonic tunnelling in quantum mechanics.
physics.optics:We study the conditions for soliton-like wave propagation in the Photorefractive (PR) and electro-optic (i.e., Pockels) material, by using Nonlinear Schrodinger (NLS) equation. The complete NLS equation is solved analytically and numerically by transforming it into the phase space. Our results clearly show the existence of both the dark and bright solitary solutions for the PR medium. Interestingly, however, we find only one bright solitary solution in the Pockels case and there is no evidence of any dark solitary solution.
physics.optics:In the theory of optical gap solitons, slowly-moving finite-amplitude Lorentzian solutions are found to mediate the transition from bright to coexistent dark-antidark solitary wave pairs when the laser frequency is detuned out of the proper edge of a dynamical photonic bandgap. Catastrophe theory is applied to give a geometrical description of this strongly asymmetrical 'morphing' process.
physics.optics:Harmonic and Intermodulation distortions occur when a physical system is excited with a single or several frequencies and when the relationship between the input and output is non-linear. Working with non-linearities in the Frequency domain is not straightforward specially when the relationship between the input and output is not trivial. We outline the complete derivation of the Harmonic and Intermodulation distortions from basic principles to a general physical system. For illustration, the procedure is applied to the Single Mode laser diode where the relationship of input to output is non-trivial. The distortions terms are extracted directly from the Laser Diode rate equations and the method is tested by comparison to many results cited in the literature. This methodology is general enough to be applied to the extraction of distortion terms to any desired order in many physical systems in a general and systematic way.
physics.optics:We reelaborate on the basic properties of lossless multilayers. We show that the transfer matrices for these multilayers have essentially the same algebraic properties as the Lorentz group SO(2,1) in a (2+1)-dimensional spacetime, as well as the group SL(2,R) underlying the structure of the ABCD law in geometrical optics. By resorting to the Iwasawa decomposition, we represent the action of any multilayer as the product of three matrices of simple interpretation. This group-theoretical structure allows us to introduce bilinear transformations in the complex plane. The concept of multilayer transfer function naturally emerges and its corresponding properties in the unit disc are studied. We show that the Iwasawa decomposition reflects at this geometrical level in three simple actions that can be considered the basic pieces for a deeper undestanding of the multilayer behavior. We use the method to analyze in detail a simple practical example.
physics.optics:A method is presented to investigate diffraction of an electromagnetic plane wave by an infinitely thin infinitely conducting circular cylinder with longitudinal slots. It is based on the use of the combined boundary conditions method that consists on expressing the continuity of the tangential components of both the electric and the magnetic fields in a single equation. This method proves to be very efficient for this kind of problems and leads to fast numerical codes.
physics.optics:We present a reliable, narrow linewidth (100 kHz) continuous-wave optical parametric oscillator (OPO) suitable for high-resolution spectroscopy applications. The OPO is based on a periodically-poled lithium-niobate crystal and features a specially designed intracavity etalon which permits its continuous tuning and stable operation at any desired wavelength in a wide operation range. We demonstrate Doppler-free spectroscopy on a rovibrational transition of methane at 3.39 um.
physics.optics:We describe the action of a plane interface between two semi-infinite media in terms of a transfer matrix. We find a remarkably simple factorization of this matrix, which enables us to express the Fresnel coefficients as a hyperbolic rotation.
physics.optics:We report on a methodology for the evaluation of the DC characteristics, small-signal frequency response and large-signal dynamic response of carrier and photon density responses in semiconductor laser diodes. A single mode laser is considered and described with a pair of rate equations containing a novel non-linear gain compensation term depending on a single parameter that can be chosen arbitrarily. This approach can be applied to any type of solid-state laser as long as it is described by a set of rate equations.
physics.optics:We report the discovery of a "dark area theorem," a new quantum optical relation for propagation of unmatched pulses in thick three-level $\Lambda$-type media. We define dark area and derive the dark area theorem for a coherently prepared and inhomogeneously broadened lambda medium. We also obtain the first equation for the spatial evolution of the dark state amplitude prior to pulse-matching.
physics.optics:We propose experimentally simplified schemes of an optically dispersive interface region between two coupled free electron lasers (FELs), aimed at achieving a much broader gain bandwidth than in a conventional FEL or a conventional optical klystron composed of two separated FELs. The proposed schemes can {\it universally} enhance the gain of FELs, regardless of their design when operated in the short pulsed regime.
physics.optics:As a light beam is produced by an amplification of modes of the zero point field in its source, this field cannot be distinguished; consequently a nonlinear optical effect is a function of the total field. However, we generally prefer to use a conventional field which excludes the zero point field; for a low conventional field, the total field may be developed to the first order, so that the effect appears linear.   This nearly trivial remark allows a correct computation of the signal of a photocell used for photon counting and shows that the "impulsive stimulated Raman scattering" (ISRS), a nonlinear, without threshold effect, which shifts the frequencies, becomes linear at low light levels, so that the shifted spectra are not distorted.
physics.optics:The effect of thermal fluctuations in the resonance fluorescence of a three-level system is studied. The damped three-level system is driven by two strong incident classical fields near resonances frequencies. The simulation of a thermal bath is obtained with a large system of harmonic oscillators that represent the normal modes of the thermal radiation field. The time evolution of the fluorescent light intensities are obtained solving by a iterative method the Heisenberg equations of motion in the integral form. The results show that the time development of the intensity of the fluorescence light is strongly affected by the interaction of the system with the thermal bath.
physics.optics:The dynamical response of a relativistic bunch of electrons injected in a planar magnetic undulator and interacting with a counterpropagating electromagnetic wave is studied. We demonstrate a resonance condition for which the free electron laser (FEL) dynamics is strongly influenced by the presence of the external field. It opens up the possibility of control of short wavelength FEL emission characteristics by changing the parameters of the microwave field without requiring change in the undulator's geometry or configuration. Numerical examples, assuming realistic parameter values analogous to those of the TTF-FEL, currently under development at DESY, are given for possible control of the amplitude or the polarization of the emitted radiation.
physics.optics:We have operated a CW triply resonant OPO using a PPLN crystal pumped by a Nd:YAG laser at 1.06 micron and generating signal and idler modes in the 2-2.3 micron range. The OPO was operated stably in single mode operation over large periods of time with a pump threshold as low as 500 microwatts.
physics.optics:We extend a modal theory of diffraction by a set of parallel fibers to deal with the case of a hard boundary: that is a structure made for instance of air-holes inside a dielectric matrix. Numerical examples are given concerning some resonant phenomena.
physics.optics:We report observation of lasing in the scarred modes in an asymmetrically deformed microcavity made of liquid jet. The observed scarred modes correspond to morphology-dependent resonance of radial mode order 3 with their Q values in the range of 10^6. Emission directionality is also observed, corresponding to a hexagonal unstable periodic orbit.
physics.optics:We have demonstrated an ultrahigh-Q whispering-gallery-mode (WGM) microsphere laser based on the evanescent-wave-coupled gain. Dye molecules outside the sphere near the equator were excited, resulting in WGM lasing in the lowest radial mode order. The loaded quality factor of the lasing WGM was 8(2)\times 10^9, the highest ever achieved in the microlaser.
physics.optics:An extended cavity diode laser operating in the Littrow configuration emitting near 657 nm is stabilized via its injection current to a reference cavity with a finesse of more than 10^5 and a corresponding resonance linewidth of 14 kHz. The laser linewidth is reduced from a few MHz to a value below 30 Hz. The compact and robust setup appears ideal for a portable optical frequency standard using the Calcium intercombination line.
physics.optics:We introduce a novel concept for optical frequency measurement and division which employs a Kerr-lens mode-locked laser as a transfer oscillator whose noise properties do not enter the measurement process. We experimentally demonstrate, that this method opens up the route to phase-link signals with arbitrary frequencies in the optical or microwave range while their frequency stability is preserved.
physics.optics:We investigate the self-phase modulation of intense femtosecond laser pulses propagating in an ionizing gas and its effects on collective properties of high-order harmonics generated in the medium. Plasmas produced in the medium are shown to induce a positive frequency chirp on the leading edge of the propagating laser pulse, which subsequently drives high harmonics to become positively chirped. In certain parameter regimes, the plasma-induced positive chirp can help to generate sharply peaked high harmonics, by compensating for the dynamically-induced negative chirp that is caused by the steep intensity profile of intense short laser pulses.
physics.optics:We developed a novel technique for frequency measurement and synthesis, based on the operation of a femtosecond comb generator as transfer oscillator. The technique can be used to measure frequency ratios of any optical signals throughout the visible and near-infrared part of the spectrum. Relative uncertainties of $10^{-18}$ for averaging times of 100 s are possible. Using a Nd:YAG laser in combination with a nonlinear crystal we measured the frequency ratio of the second harmonic $\nu_{SH}$ at 532 nm to the fundamental $\nu_0$ at 1064 nm, $\nu_{SH}/\nu_0 = 2.000 000 000 000 000 001 \times (1 \pm 7 \times 10^{-19})$.
physics.optics:The mixed crystal of a para-dibromobenzene with a para-chloronitrobenzene is investigated at concentration of components from 0% up to 60% of a para-chloronitrobenzene by the method of Low-Frequency Raman spectroscopy. It is shown, that in range of concentrations from 25% up to 50% of a para-chloronitrobenzene the spectrum of the mixed crystal would consist of the sum of spectrums a and b phases which relation of intensities depends on concentration of components. It is also found, that the single crystal in this range has rod frame.
physics.optics:The stability of polarization, areas, and number of self-induced transparency (SIT)-solitons at the output from the LaF_3:Pr^{3+} crystal is theoretically studied versus the polarization direction and the area of the input linearly polarized laser pulse. For this purpose the Vector Area Theorem is rederived and two-dimensional Vector Area Theorem map is obtained. The map is governed by the crystal symmetry and takes into account directions of the dipole matrix element vectors of the different site subgroups of optically excited ions. The Vector Area Theorem mapping of the time evolution of the laser pulse allows one to highlight soliton polarization properties.
physics.optics:The dynamics of light in Fabry-Perot cavities with varying length and input laser frequency are analyzed and the exact condition for resonance is derived. This dynamic resonance depends on the light transit time in the cavity and the Doppler effect due to the mirror motions. The response of the cavity to length variations is very different from its response to laser frequency variations. If the frequency of these variations is equal to multiples of the cavity free spectral range, the response to length is maximized while the response to the laser frequency is zero. Implications of these results for the detection of gravitational waves using kilometer-scale Fabry-Perot cavities are discussed.
physics.optics:Numerical simulation of the National Ignition Facility (NIF) laser performance and automated control of the laser setup process are crucial to the project's success. These functions will be performed by two closely coupled computer code: the virtual beamline (VBL) and the laser performance operations model (LPOM).
physics.optics:Since its birth, the laser has been extraordinarily effective in the study and applications of laser-matter interaction at the atomic and molecular level and in the nonlinear optics of the bound electron. In its early life, the laser was associated with the physics of electron volts and of the chemical bond. Over the past fifteen years, however, we have seen a surge in our ability to produce high intensities, five to six orders of magnitude higher than was possible before. At these intensities, particles, electrons and protons, acquire kinetic energy in the mega-electron-volt range through interaction with intense laser fields. This opens a new age for the laser, the age of nonlinear relativistic optics coupling even with nuclear physics. We suggest a path to reach an extremely high-intensity level $10^{26-28} $W/cm$^2$ in the coming decade, much beyond the current and near future intensity regime $10^{23} $W/cm$^2$, taking advantage of the megajoule laser facilities. Such a laser at extreme high intensity could accelerate particles to frontiers of high energy, tera-electron-volt and peta-electron-volt, and would become a tool of fundamental physics encompassing particle physics, gravitational physics, nonlinear field theory, ultrahigh-pressure physics, astrophysics, and cosmology. We focus our attention on high-energy applications in particular and the possibility of merged reinforcement of high-energy physics and ultraintense laser.
physics.optics:A simple and intuitive geometical method to analyze Fresnel formulas is presented. It applies to transparent media and is valid for perpendicular and parallel polarizations. The approach gives a graphical characterization particularly simple of the critical and Brewster angles. It also provides an interpretation of the relation between the reflection coefficients for both basic polarizations as a symmetry in the plane.
physics.optics:The tunnel effect is considered here within the framework of electromagnetic propagation. The classical problem of a plane gap of dielectric, surrounded on both sides by a medium with larger refraction index, is studied in the case in which an electromagnetic plane wave impinges into the gap with an incidence angle larger than the critical angle. In this condition (total reflection), the gap acts as a classically forbidden region and behaves like a tunnel. The field inside the forbidden gap consists of two evanescent waves, each one having its wavefronts normal to the interface. In the present paper we study the total field derived as a superposition of two such evanescent waves, its wavefronts, and the directions of propagation of both phase and energy.
physics.optics:The motion of an electromagnetic wave, through a classically-forbidden region, has recently attracted renewed interest because of its implication with regard to the theoretical and experimental problems of superluminality. From an experimental point of view, many papers provide an evidence of superluminality in different physical systems. Theoretically, the problem of a passage through a forbidden gap has been treated by considering plane waves at oblique incidence into a plane parallel layer of a medium with a refractive index smaller than the index of the surrounding medium, and also confined (Gaussian) beams, still at oblique incidence. In the present paper the case of a Bessel beam is examined, at normal incidence into the layer (Secs. II and III), in the scalar approximation (Sec. IV) and by developing also a vectorial treatment (Sec. V). Conclusions are reported in Sic. VI.
physics.optics:The tunneling time is here investigated by means of an electromagnetic model, for a system where a gap, between two parallel planes, acts as a classically-forbidden region for an impinging pulse with incidence angle larger than the critical angle. In all cases of frustrated total reflection we obtain a superluminal behavior both for phase and group delays.
physics.optics:We report an injection-locked cw titanium:sapphire ring laser at 846 nm. It produces 1.00 W in a single frequency when pumped with 5.5 W. Single frequency operation requires only a few milliwatts of injected power.
physics.optics:Accurate knowledge of absorption coefficient of a sample is a prerequisite for measuring the third order optical nonlinearity of materials, which could become a serious limitation for unknown samples. We introduce a new method, which measures both the absorption coefficient and the third order optical nonlinearity of materials with high sensitivity in a single experimental setup. We use a dual-beam pump-probe experiment under different conditions to achieve this goal. We also demonstrate a counterintuitive coupling of the non-interacting probe-beam with the pump-beam in pump-probe z-scan experiment.
physics.optics:We obtain gain of the probe field at multiple frequencies in a closed three-level V-type system using frequency modulated pump field. There is no associated population inversion among the atomic states of the probe transition. We describe both the steady-state and transient dynamics of this system. Under suitable conditions, the system exhibits large gain simultaneously at series of frequencies far removed from resonance. Moreover, the system can be tailored to exhibit multiple frequency regimes where the probe experiences anomalous dispersion accompanied by negligible gain-absorption over a large bandwidth, a desirable feature for obtaining superluminal propagation of pulses with negligible distortion.
physics.optics:An undoped double quantum well (DQW) was driven with a terahertz (THz) electric field of frequency \omega_{THz} polarized in the growth direction, while simultaneously illuminated with a near-infrared (NIR) laser at frequency \omega_{NIR}. The intensity of NIR upconverted sidebands \omega_{sideband}=\omega_{NIR} + \omega_{THz} was maximized when a dc voltage applied in the growth direction tuned the excitonic states into resonance with both the THz and NIR fields. There was no detectable upconversion far from resonance. The results demonstrate the possibility of using gated DQW devices for all-optical wavelength shifting between optical communication channels separated by up to a few THz.
physics.optics:Driving a double-quantum-well excitonic intersubband resonance with a terahertz (THz) electric field of frequency \omega_{THz} generated terahertz optical sidebands \omega=\omega_{THz}+\omega_{NIR} on a weak NIR probe. At high THz intensities, the intersubband dipole energy which coupled two excitons was comparable to the THz photon energy. In this strong-field regime the sideband intensity displayed a non-monotonic dependence on the THz field strength. The oscillating refractive index which gives rise to the sidebands may be understood by the formation of Floquet states, which oscillate with the same periodicity as the driving THz field.
physics.optics:We elaborate on the consequences of the factorization of the transfer matrix of any lossless multilayer in terms of three basic matrices of simple interpretation. By considering the bilinear transformation that this transfer matrix induces in the complex plane, we introduce the concept of multilayer transfer function and study its properties in the unit disk. In this geometrical setting, our factorization translates into three actions that can be viewed as the basic pieces for understanding the multilayer behavior. Additionally, we introduce a simple trace criterion that allows us to classify multilayers in three types with properties closely related to one (and only one) of these three basic matrices. We apply this approach to analyze some practical examples that are representative of these types of matrices.
physics.optics:We consider the problem of radiation into free space from the end-facet of a single-mode photonic crystal fiber (PCF). We calculate the numerical aperture NA=sin theta from the half-divergence angle theta ~ tan^{-1}(lambda/pi w) with pi w^2 being the effective area of the mode in the PCF. For the fiber first presented by Knight et al. we find a numerical aperture NA ~ 0.07 which compares to standard fiber technology. We also study the effect of different hole sizes and demonstrate that the PCF technology provides a large freedom for NA-engineering. Comparing to experiments we find good agreement.
physics.optics:Polarized and azimuthal dependencies of optical second harmonics generation (SHG) at the surface of noncentrosymmetric semiconductor crystals have been measured on polished surfaces of ZnSe(100), using a fundamental wavelength of 1.06$\mu m$. The SHG intensity patterns were analyzed for all four combination of p- and s-polarized incidence and output, considering both the bulk and surface optical nonlinearities in the electric dipole approximation. We found that the measurement using $S_{in}-S_{out}$ is particularly useful in determining the symmetry of the oxdized layer interface, which would lower the effective symmetry of the surface from $C_{4v}$ to $C_{2v}.$ We also have shown that the [011] and [0$\bar{1}$1] directions can be distinguished through the analysis of p-incident and p-output confugration.
physics.optics:Fundamental rules and definitions of Fractional Differintegrals are outlined. Factorizing 1-D and 2-D Helmholtz equations four fractional eigenfunctions are determined. The functions exhibit incident and reflected plane waves as well as diffracted incident and reflected waves of the half-plane edge. They allow to construct the Sommerfeld half-plane diffraction solutions. Parabolic-Wave Equation (PWE, Leontovich-Fock) for paraxial propagation is factorized and differetial fractional solutions of Fresnel-integral type are derived. We arrived at two solutions, which are the mothers of known and new solutions.
physics.optics:In the classical theory, an electromagnetic field obeying Maxwell's equations cannot be absorbed quickly by matter, so that it remains a zero point field. Splitting the total, genuine electromagnetic field into the sum of a conventional field and a zero point field is physically meaningless until a receiver attenuates the genuine field down to the zero point field, or studying the amplification of the zero point field by a source.   In classical optics all optical effects must be written using the genuine field, so that at low light levels the nonlinear effects become linear in relation to the conventional field. The result of the interpretation of all observations, even at low light levels, is exactly the same in quantum electrodynamics and in the semi- classical theory.   The zero point field is stochastic only far from the sources and the receivers; elsewhere, it is shaped by matter, it may be studied through fields visible before an absorption or after an amplification.   A classical study of the reduction of the wave packet extends the domain of equivalence of the classical and quantum zero point field; using both interpretations of this field makes the results more reliable, because the traps are different.
physics.optics:The smaller the size of a light-emitting microcavity, the more important it becomes to understand the effects of the cavity boundary on the optical mode profile. Conventional methods of laser physics, such as the paraxial approximation, become inapplicable in many of the more exotic cavity designs to be discussed here. Cavities in the shape of microdisks, pillars and rings can yield low lasing thresholds in a wide variety of gain media: quantum wells, wires and even dots, as well as quantum cascade superlattices and GaN. An overview of the experimental and theoretical status is provided, with special emphasis on the light extraction problem.
physics.optics:The stationary states of a microlaser are related to the decaying quasibound states of the corresponding passive cavity. These are interpreted classically as originating from sequential escape attempts of an ensemble of rays obeying a curvature-corrected Fresnel formula. Polarization-dependent predictions of this model, and its limitations for stable orbits in partially chaotic systems are discussed.
physics.optics:We measured and calculated transmission spectra of two-dimensional quasiperiodic photonic crystals (PCs) based on a 5-fold (Penrose) or 8-fold (octagonal) symmetric quasiperiodic pattern. The photonic crystal consisted of dielectric cylindrical rods in air placed normal to the basal plane on vertices of tiles composing the quasiperiodic pattern. An isotropic photonic band gap (PBG) appeared in the TM mode, where electric fields were parallel to the rods, even when the real part of a dielectric constant of the rod was as small as 2.4. An isotropic PBG-like dip was seen in tiny Penrose and octagonal PCs with only 6 and 9 rods, respectively. These results indicate that local multiple light scattering within the tiny PC plays an important role in the PBG formation. Besides the isotropic PBG, we found dips depending on the incident angle of the light. This is the first report of anisotropic structures clearly observed in transmission spectra of quasiperiodic PCs. Based on rod-number and rod-arrangement dependence, it is thought that the shapes and positions of the anisotropic dips are determined by global multiple light scattering covering the whole system. In contrast to the isotropic PBG due to local light scattering, we could not find any PBGs due to global light scattering even though we studied transmission spectra of a huge Penrose PC with 466 rods.
physics.optics:A perfect focus telescope is one in which all rays parallel to the axis meet at a point and give equal magnification there. It is shown that these two conditions define the shapes of both primary and secondary mirrors. Apart from scale, the solution depends upon two parameters, $s$, which gives the mirror separation in terms of the effective focal length, and $K$, which gives the relative position of the final focus in that unit. The two conditions ensure that the optical systems have neither spherical aberration nor coma, no matter how fast the $f$ ratio. All known coma--free systems emerge as approximate special cases. In his classical paper, K. Schwarzschild studied all two mirror systems whose profiles were conic sections. We make no such a priori shape conditions but demand a perfect focus and solve for the mirrors' shapes.
physics.optics:The results of experimental testing the existence of intense Lorentzian--like wings with FWHM $\sim 4.5 cm^{-1}$ in the absorption spectra of polyatomic molecules in a gas phase are presented. Two independent experimental methods were used for evaluating the integral intensity of the line wings for a number of substances. In the first case, the cross--section of the far wings of absorption bands in a gas phase spectrum were measured. Then, these band wings were extrapolated inside the contour of absorption band. In the second case, the saturation degree of the linear spectrum of molecules was determined. Radiation of a pulsed $CO_2$--laser was used at low gas pressure ($\sim 16$ mtorr) and averaged excitation level of molecules ${<n>}\sim 0.1$ quanta/molecule. The values obtained by these two independent methods coincide for a variety of molecules. The average relative integral intensity of the line wings varied from $\sim 0.6%$ for $SF_6$ and $SiF_4$ to $\sim 90%$ for $(CF_3)_2O$ and $(CF_3)_2CO$.
physics.optics:It is shown that the direct Fourier synthesization of light beams allows one to create polarity-asymmetric waves, which are able, in the process of nonlinear interaction with a medium, to break its inversion symmetry. As a result, these "polar" waves may show the effect of optical rectification in nonlinear centrosymmetric media by generating light-induced dc electric polarization. At the same time, the waves of this type, due to their unusual symmetry properties, can be used for detecting the direction and sign of a dc electric field applied to the medium. The prospects of application of polar waves to data recording and processing are discussed.
physics.optics:Presented is an analysis of general scaling perturbations in a transmitting fiber. For elliptical perturbations, under some conditions an intermode dispersion parameter characterizing modal PMD is shown to be directly proportional to the mode dispersion.
physics.optics:Extensive Bose-Einstein condensation research activities have recently led to studies of fermionic atoms and optical confinements. Here we present a case of micro-optical fermionic electron phase transition. Optically confined ordering and phase transitions of a fermionic cloud in dynamic steady state are associated with Rayleigh emissions from photonic quantum ring manifold which are generated by nature without any ring lithography. The whispering gallery modes, produced in a semiconductor Rayleigh-Fabry-Perot toroidal cavity at room temperature, exhibit novel properties of ultralow thresholds open to nano-ampere regime, thermal stabilities from square-root-T-dependent spectral shift, and angularly varying intermode spacings. The photonic quantum ring phenomena are associated with a photonic field-driven phase transition of quantum-well-to-quantum-wire and hence the photonic (non-de Broglie) quantum corral effect on the Rayleigh cavity-confined carriers in dynamic steady state. Based upon the intra-cavity fermionic condensation we also offer a prospect for an electrically driven few-quantum dot single photon source from the photonic quantum ring laser for quantum information processors.
physics.optics:Nonlinear optical media that are normally dispersive, support a new type of localized (nondiffractive and nondispersive) wavepackets that are X-shaped in space and time and have slower than exponential decay. High-intensity X-waves, unlike linear ones, can be formed spontaneously through a trigger mechanism of conical emission, thus playing an important role in experiments.
physics.optics:We report three-dimensional laser microfabrication, which enables microstructuring of materials on the scale of 0.2-1 micrometers. The two different types of microfabrication demonstrated and discussed in this work are based on holographic recording, and light-induced damage in transparent dielectric materials. Both techniques use nonlinear optical excitation of materials by ultrashort laser pulses (duration < 1 ps).
physics.optics:We propose a concept for production of high power coherent attosecond pulses in X-ray range. An approach is based on generation of 8th harmonic of radiation in a multistage HGHG FEL (high gain high harmonic free electron laser) configuration starting from shot noise. Single-spike phenomena occurs when electron bunch is passed through the sequence of four relatively short undulators. The first stage is a conventional "long" wavelength (0.8 nm) SASE FEL which operates in the high-gain linear regime. The 0.1 nm wavelength range is reached by successive multiplication (0.8 nm $\to$ 0.4 nm $\to$ 0.2 nm $\to$ 0.1 nm) in a stage sequence. Our study shows that the statistical properties of the high-harmonic radiation from the SASE FEL, operating in linear regime, can be used for selection of radiation pulses with a single spike in time domain. The duration of the spikes is in attosecond range. Selection of single-spike high-harmonic pulses is achieved by using a special trigger in data acquisition system. The potential of X-ray SASE FEL at TESLA at DESY for generating attosecond pulses is demonstrated. Since the design of XFEL laboratory at TESLA is based on the use of long SASE undulators with tunable gap, no special place nor additional FEL undulators are required for attophysics experiments. The use of a 10 GW-level attosecond X-ray pulses at X-ray SASE FEL facility will enable us to track processes inside atoms.
physics.optics:We present an algorithm for the maximization of photonic bandgaps in two-dimensional crystals. Once the translational symmetries of the underlying structure have been imposed, our algorithm finds a global maximal (and complete, if one exists) bandgap. Additionally, we prove two remarkable results related to maximal bandgaps: the so-called `maximum contrast' rule, and about the location in the Brillouin zone of band edges.
physics.optics:We investigate the propagation of electromagnetic waves in finite photonic band gap structures. We analyze the phenomenon of conduction and forbidden bands and we show that two regimes are to be distinguished with respect to the existence of a strong field near the interfaces. We precise the domain for which an effective medium theory is sounded.
physics.optics:The maximum bit-rate of a slab waveguide is ultimately determined by the waveguide dispersion. We show that while the maximum bit rate in a waveguide is inversely proportional to the waveguide's width, bit rate per unit width (i.e., spatial capacity) decreases, and in the limit of a zero-width waveguide it converges to a value, which is independent of the waveguide's refractive indices. This value is qualitatively equivalent to the transmission rate per unit of width in free space. We also show that in a 3D waveguide (e.g., fibers), unlike free space, the spatial capacity vanishes in the same limit.
physics.optics:The photonic band dispersion and density of states (DOS) are calculated for the three-dimensional (3D) hexagonal structure corresponding to a distributed Bragg reflector patterned with a 2D triangular lattice of circular holes. Results for the Si/SiO$_2$ and GaAs/AlGaAs systems determine the optimal parameters for which a gap in the 2D plane occurs and overlaps the 1D gap of the multilayer. The DOS is considerably reduced in correspondence with the overlap of 2D and 1D gaps. Also, the local density of states (i.e., the DOS weighted with the squared electric field at a given point) has strong variations depending on the position. Both results imply substantial changes of spontaneous emission rates and patterns for a local emitter embedded in the structure and make this system attractive for the fabrication of a 3D photonic crystal with controlled radiative properties.
physics.optics:We present a Fourier transform methodology for all-order polarization mode dispersion (PMD) analysis, based on the first Born approximation to the coupled-mode equation solution. Our method predicts wavelength-dependent PMD effects and allows design of filters for their mitigation.
physics.optics:We demonstrate the combination of a hemispherical solid immersion lens with a micro-photoluminescence setup. Two advantages introduced by the SIL, an improved resolution of 0.4 times the wavelength in vacuum and a 5 times enhancement of the collection efficiency, make it an ideal system for spatially resolved spectroscopy applications. The influence of the air gap between the SIL and the sample surface is investigated in detail. We confirm the tolerance of the set--up to an air gap of several micrometers. Such a system is proven to be ideal system in the studies of exciton transport and polarization dependent single quantum dot spectroscopy.
physics.optics:It is assumed, that the clumps of lines do not connected with states mixing and IVR, but they are the result of breaking (destruction) of the process of averaging of momentum of inertia of molecules during the vibration motion of atoms. Rough estimates of the widths of clumps of lines in absorption spectra of some acetylenic derivatives were made with this model. Obtained results are in a satisfactory agreement with the available experimental data. This idea allows also in principle to explain the origin of intensive wings of lines, the existence of which was discussed earlier.
physics.optics:The origin of the Kerr type nonlinearity of the medium as a result of the interaction between photons via the Dirac delta-potential is presented in the formalism adopted from the photon wave function approach. In the view of the result the optical soliton may be treated as a bound state (cluster) of many photons.
physics.optics:The propagation of photon in a dielectric may be described with the help of the scalar and vector potentials of the medium. The main novelty of the paper is that the concept of the vector potential (which is connected with the velocity of the medium) can be extended to relativistic velocities of the medium. The position-dependent photon wave function was used to describe the propagation of the photon. The new concepts of the velocity of photon as particle and the photon mass in the dielectric medium were proposed.
physics.optics:Mathematical aspects of the SU(1,1) group parameter x dynamics governed by Hamiltonians exhibiting some special types of time dependence has been presented on an elementary level from the point of view of Moebius transformation of complex plane. The trajectories of x in continuous and mappings in discrete dynamics are considered. Some simple examples have been examined. Analytical considerations and numerical results have been given.
physics.optics:Propagation of the TE electromagnetic waves in self-focusing medium is governed by the nonlinear Schroedinger equation. In this paper the stationary solutions of this equation have been systematically presented. The phase-plane method, qualitative analysis, and mechanical interpretation of the differential equations are widely used. It is well known that TE waves can be guided by the single interface between two semi-infinite media, providing that one of the media has a self-focusing (Kerr type) nonlinearity. This special solution is called a spatial soliton. In this paper our interests are not restricted to the soliton solutions. In the context of the nonlinear substrate and cladding we have found solutions which could be useful to describe also the incident light in nonlinear medium. This result is the main point of the paper. Some of the presented stationary solutions were already used in similar optical context in literature but we show a little wider class of solutions. In the last section we review and illustrate some results concerning the spatial soliton solution.
physics.optics:We present angle- and polarization-resolved measurements of the optical transmission of a subwavelength hole array. These results give a (far-field) visualization of the corresponding (near-field) propagation of the excited surface plasmons and allow for a simple analysis of their polarization properties.
physics.optics:A monochromatic linear source of light is rotated with certain angular frequency and when such light is analysed after reflection then a change of frequency or wavelength may be observed depending on the location of the observer. This change of frequency or wavelength is different from the classical Doppler effect [1] or relativistic Doppler effect [2]. The reason behind this shift in wavelength is that a certain time interval observed by an observer in the rotating frame is different from that of a stationary observer.
physics.optics:We investigate the spectral response of a Brillouin amplifier in the frequency regime within the SBS bandwidth. This is done by amplitude modulating the pump with a low frequency, and therefore, unlike previous studies, the spectrum of the modulated pump is, in all cases, smaller than the SBS bandwidth. We show both theoretically and experimentally that unlike phase modulation, which was reported in the literature, the amplitude modulation increases the Brillouin amplifier gain, and that this effect has a very narrow bandwidth. Only modulation frequencies that are lower than a certain cut-off frequency increase the gain. This cut-off frequency is inversely proportional to the fiber's length, and can therefore be arbitrarily small.
physics.optics:The Phase Diverse Speckle (PDS) problem is formulated mathematically as Multi Frame Blind Deconvolution (MFBD) together with a set of Linear Equality Constraints (LECs) on the wavefront expansion parameters. This MFBD-LEC formulation is quite general and, in addition to PDS, it allows the same code to handle a variety of different data collection schemes specified as data, the LECs, rather than in the code. It also relieves us from having to derive new expressions for the gradient of the wavefront parameter vector for each type of data set. The idea is first presented with a simple formulation that accommodates Phase Diversity, Phase Diverse Speckle, and Shack-Hartmann wavefront sensing. Then various generalizations are discussed, that allows many other types of data sets to be handled.
physics.optics:A Monte Carlo simulation has been performed to track light rays in cylindrical fibres by ray optics. The trapping efficiencies for skew and meridional rays in active fibres and distributions of characteristic quantities for all trapped light rays have been calculated. The simulation provides new results for curved fibres, where the analytical expressions are too complex to be solved. The light losses due to sharp bending of fibres are presented as a function of the ratio of curvature to fibre radius and bending angle. It is shown that a radius of curvature to fibre radius ratio of greater than 65 results in a loss of less than 10% with the loss occuring in the initial stage of the bend (at bending angles Phi circa pi/8 rad).
physics.optics:We have measured the photonic bandgap in the transmission of microwaves through a two-dimensional photonic crystal slab. The structure was constructed by cementing acrylic rods in a hexagonal closed-packed array to form rectangular stacks. We find a bandgap centered at approximately 11 GHz, whose depth, width and center frequency vary with the number of layers in the slab, angle of incidence and microwave polarization.
physics.optics:We study forward stimulated Raman emission from weakly fluorescent dye 4'-diethylamino-N-methyl-4-stilbazolium tosylate (DEST) in 1,2,dichloroethane solution excited by a 28 ps, 532 nm Nd: YAG laser. Neat 1, 2, dichloroethane emits the first Stokes line at 631 nm with a spectral width of 1.6 nm corresponding to a Raman shift of 2956 per cm. We observe reduction of spectral width with the addition of DEST in 1, 2, dichloroethane solution. The single pass conversion efficiency for forward Raman emission is as high as 20 percent in a 1 cm path length sample. The pulse duration of forward stimulated Raman emission measured by a third order autocorrelation technique is 10 ps in neat 1, 2, dichloroethane, whereas it is nearly 3 ps for 0.04 mM of DEST solution.
physics.optics:Distribution of centrosymmetrical molecules of an impurity (p-diclorobenzene) in monocrystals of solid solutions in two different matrixes with centrosymmetrical (p-dibrombenzene) and noncentrosymmetrical (p-bromchlorbenzene) molecules by the method of a Raman Effect is determined.
physics.optics:We demonstrate that twisting one part of a chiral photonic structure about its helical axis produces a single circularly polarized localized mode that gives rise to an anomalous crossover in propagation. Up to a crossover thickness, this defect results in a peak in transmission and exponential scaling of the linewidth for a circularly polarized wave with the same handedness as structure. Above the crossover, however, the linewidth saturates and the defect mode can be excited only by the oppositely polarized wave, resulting in a peak in reflection instead of transmission.
physics.optics:We study experimentally and theoretically the polarization alternation during the switch-on transient of a quasi-isotropic CO$_2$ laser emitting on the fundamental mode. The observed transient dynamics is well reproduced by means of a model which provides a quantitative discrimination between the intrinsic asymmetry due to the kinetic coupling of molecules with different angular momenta, and the extrinsic anisotropies, due to a tilted intracavity window. Furthermore, the experiment provides a numerical assignment for the decay rate of the coherence term for a CO$_2$ laser.
physics.optics:In this paper we present an analysis of information transfer time based on holomorphism, causality and the classical principle of stationary phase. We also make a preliminary study of the effect of noise on information transfer time, and find that noise tends to increase transfer times. Noise and information signals are both essentially acausal, such that analytic continuation (i.e. prediction) is impossible, which also implies that their frequency spectra cannot be holomorphic. This leads to the paradox of a non-holomorphic information-bearing light signal, yet whose underlying Maxwell equations governing the propagation of the EM wave describe a holomorphic function in spacetime. We find that application of stationary phase and entropy arguments circumvents this difficulty, with stationary phase only suggesting the most likely transfer times of an information signal in the presence of noise. Faster transit times are not excluded, but are highly improbable. Stationary phase solutions, by definition, do not include signal forerunners, whose detection in the presence of noise is also unreliable. Hence a finite information capacity ensues, as expected from Shannon's law, and information cannot be transferred faster than c. We also find that the method of stationary phase implies complex transfer times. However, by considering spacetime to be isomorphic with the complex temporal plane, we find that an imaginary time is equivalent to a real distance, and can be interpreted as the uncertainty in the spatial position of the information pulse. Finally, we apply our theory to a photonic band gap crystal, and find that information transfer speed and tunneling is always subluminal.
physics.optics:Enhancement of optical Kerr nonlinearity for self-action by electro-magnetically induced transparency in a four-level atomic system including dephasing between the ground states is studied in detail by solving the density matrix equations for the atomic levels. We discern three major contributions, from energy shifts of the ground states induced by the probe light, to the third-order susceptibility in the four-level system. In this four-level system with the frequency-degenerate probes, quantum interference amongst the three contributions can, not only enhance the third-order susceptibility more effectively than in the three-level system with the same characteristic parameters, but also make the ratio between its real and imaginary part controllable. Due to dephasing between the two ground states and constructive quantum interference, the most effective enhancement generally occurs at an offset that is determined by the atomic transition frequency difference and the coupling Rabi frequency.
physics.optics:We numerically study supercontinuum (SC) generation in photonic crystal fibers pumped with low-power 30-ps pulses close to the zero dispersion wavelength 647nm. We show how the efficiency is significantly improved by designing the dispersion to allow widely separated spectral lines generated by degenerate four-wave-mixing (FWM) directly from the pump to broaden and merge. By proper modification of the dispersion profile the generation of additional FWM Stokes and anti-Stokes lines results in efficient generation of an 800nm wide SC. Simulations show that the predicted efficient SC generation is more robust and can survive fiber imperfections modelled as random fluctuations of the dispersion coefficients along the fiber length.
physics.optics:We numerically study the possibilities for improved large-mode area endlessly single mode photonic crystal fibers for use in high-power delivery applications. By carefully choosing the optimal hole diameter we find that a triangular core formed by three missing neighboring air holes considerably improves the mode area and loss properties compared to the case with a core formed by one missing air hole. In a realized fiber we demonstrate an enhancement of the mode area by ~30 % without a corresponding increase in the attenuation.
physics.optics:A new type of perturbative expansion is built in order to give a rigorous derivation and to clarify the range of validity of some commonly used model equations.   This model describes the evolution of the modulation of two short and localized pulses, fundamental and second harmonic, propagating together in a bulk uniaxial crystal with non-vanishing second order susceptibility $\chi^(2)$ and interacting through the nonlinear effect known as ``cascading'' in nonlinear optics.   The perturbative method mixes a multi-scale expansion with a power series expansion of the susceptibility, and must be carefully adapted to the physical situation. It allows the determination of the physical conditions under which the model is valid: the order of magnitude of the walk-off, phase-mismatch,and anisotropy must have determined values.
physics.optics:Nonlinear phase noise, often called the Gordon-Mollenauer effect, can be compensated electronically by subtracting from the received phase a correction proportional to the received intensity. The optimal scaling factor is derived analytically and found to be approximately equal to half of the ratio of mean nonlinear phase noise and the mean received intensity. Using optimal compensation, the standard deviation of residual phase noise is halved, doubling the transmission distance in systems limited by nonlinear phase noise.
physics.optics:On the basis of the data given in the works of different authors a criterion of phase-photometric method of measurement of energy angle of divergence has been formulated. Validity of application of the obtained relations for a ray beam with an arbitrary diameter and an arbitrary shape of the wave front has been proved. Advantages of the proposed phase-photometric method in comparison with the focal-spot method have been confirmed. Necessity and possibility of building a standard solid angle has been proved.
physics.optics:This document contains my detailed calculation of the Generalised Few-cycle Envelope Approximation (GFEA) propagation equation reported and used in Phys. Rev. A (submitted) and its associated longer version at arXiv.org. This GFEA propagation equation is intended to be applicable to optical pulses only a few cycles long, a regime where the standard Slowly Varying Envelope Approximation (SVEA) fails.
physics.optics:We present a comprehensive framework for treating the nonlinear interaction of few-cycle pulses using an envelope description that goes beyond the traditional SVEA method. This is applied to a range of simulations that demonstrate how the effect of a $\chi^{(2)}$ nonlinearity differs between the many-cycle and few-cycle cases. Our approach, which includes diffraction, dispersion, multiple fields, and a wide range of nonlinearities, builds upon the work of Brabec and Krausz[1] and Porras[2]. No approximations are made until the final stage when a particular problem is considered.   The original version (v1) of this arXiv paper is close to the published Phys.Rev.A. version, and much smaller in size.
physics.optics:Broadband noise on supercontinuum spectra generated in microstructure fiber is shown to lead to amplitude fluctuations as large as 50 % for certain input laser pulse parameters. We study this noise using both experimental measurements and numerical simulations with a generalized stochastic nonlinear Schroedinger equation, finding good quantitative agreement over a range of input pulse energies and chirp values. This noise is shown to arise from nonlinear amplification of two quantum noise inputs: the input pulse shot noise and the spontaneous Raman scattering down the fiber.
physics.optics:The probability density function of Kerr effect phase noise, often called the Gordon-Mollenauer effect, is derived analytically. The Kerr effect phase noise can be accurately modeled as the summation of a Gaussian random variable and a noncentral chi-square random variable with two degrees of freedom. Using the received intensity to correct for the phase noise, the residual Kerr effect phase noise can be modeled as the summation of a Gaussian random variable and the difference of two noncentral chi-square random variables with two degrees of freedom. The residual phase noise can be approximated by Gaussian distribution better than the Kerr effect phase noise without correction.
physics.optics:Steady-state and dynamics of the self-phase-locked (3\omega ==> 2\omega, \omega) subharmonic optical parametric oscillator are analyzed in the pump-and-signal resonant configuration, using an approximate analytical model and a full propagation model. The upper branch solutions are found always stable, regardless of the degree of pump enhancement. The domain of existence of stationary states is found to critically depend on the phase-mismatch of the competing second-harmonic process.
physics.optics:In the present paper we investigate the transmission and reflection band behavior for a plane electromagnetic wave falling obliquely on an ideal layered structure. The dependence of this behavior on the problem parameters and wave incident angle is considered. It is shown, that in general case the band width is a non-monotonous function of the problem parameters. A condition is found, which defines the possibility of the contact of the transmission bands. This condition has the same form for s and p waves. It is also shown that irrespective of the wave polarization, the transmission coefficient equals to the unit at the contact points.
physics.optics:The problem of determination of the maximum of second harmonic generation in the potential well containing a rectangular barrier is considered. It is shown that, in general, the problem of finding the ensemble of structures with equidistant first three levels has two types of solutions.   For the first type the second and third energy levels are located above a rectangular barrier, and for the second type the third level is located above the barrier only. It is also shown, that generation corresponding to the second type of solution always is less than generation for the first one. Taking into account the effective mass changes the problem of finding the generation maximum for a finite depth well is exactly solved.
physics.optics:We investigate numerically optical properties of novel two-dimensional photonic materials where parallel dielectric rods are randomly placed with the restriction that the distance between rods is larger than a certain value. A large complete photonic gap (PG) is found when rods have sufficient density and dielectric contrast. Our result shows that neither long-range nor short-range order is an essential prerequisite to the formation of PGs. A universal principle is proposed for designing arbitrarily shaped waveguides, where waveguides are fenced with side walls of periodic rods and surrounded by the novel photonic materials. We observe highly efficient transmission of light for various waveguides. Due to structural uniformity, the novel photonic materials are best suited for filling up the outer region of waveguides of arbitrary shape and dimension comparable with the wavelength.
physics.optics:We suggest an effective method for controlling nonlinear switching in arrays of weakly coupled optical waveguides. We demonstrate the digitized switching of a narrow input beam for up to eleven waveguides in the engineered waveguide arrays.
physics.optics:Plane waves in Kerr media spontaneously generate paraxial X-waves (i.e. non-dispersive and non-diffractive pulsed beams) that get amplified along propagation. This effect can be considered a form of conical emission (i.e. spatio-temporal modulational instability), and can be used as a key for the interpretation of the out of axis energy emission in the splitting process of focused pulses in normally dispersive materials. A new class of spatio-temporal localized wave patterns is identified. X-waves instability, and nonlinear X-waves, are also expected in periodical Bose condensed gases.
physics.optics:The Dicke superradiance on vibronic transitions of impurity crystals is considered. It is shown that parameters of the superradiance (duration and intensity of the superradiance pulse and delay times) on each vibronic transition depend on the strength of coupling of electronic states with the intramolecular impurity vibration (responsible for the vibronic structure of the optical spectrum in the form of vibrational replicas of the pure electronic line) and on the crystal temperature through the Debye-Waller factor of the lattice vibrations. Theoretical estimates of the ratios of the time delays, as well as of the superradiance pulse intensities for different vibronic transitions well agree with the results of experimental observations of two-color superradiance in the polar dielectric KCl:O2-. In addition, the theory describes qualitatively correctly the critical temperature dependence of the superradiance effect.
physics.optics:This work is concerned with the propagation of electromagnetic waves in isotropic chiral media and with the effects produced by a plane boundary between two such media. In analogy with the phenomena of reflection and refraction of plane electromagnetic waves in ordinary dielectrics, the kinematical and dynamical aspects of these phenomena are studied, such as the intensity of the various wave components and the change in the polarization of the wave as it crosses the boundary. As a prerequisite of this, we show that the plane wave solution must be written as a suitable superposition of the circularly amplitudes on both sides of the interface, we elucidate which is the appropriate set of conditions that the solution must satisfy at the boundary, and we set down the minimal, and complete, set of equations that must be solved for the coefficient amplitudes in order to satisfy the boundary conditions. The equations are solved explicitly for some particular cases and configurations (e.g., normal incidence), the salient features of those solutions are analyzed in some detail, and the general solution to the equations is given as well.
physics.optics:We study the class of endlessly single-mode all-silica photonic crystal fibers with a triangular air-hole cladding. We consider the sensibility to longitudinal nonuniformities and the consequences and limitations for realizing low-loss large-mode area photonic crystal fibers. We also discuss the dominating scattering mechanism and experimentally we confirm that both macro and micro-bending can be the limiting factor.
physics.optics:Some aspects of lasing at vibronic transitions in impurity crystals are theoretically studied. The threshold conditions for a vibronic laser are shown to be dependent on the strength of interaction of optical centers with a local vibration, which forms the vibronic spectrum, and the crystal lattice temperature. The theory can be easily generalized to the spectrum containing a structureless phonon sideband and well agrees with the experimental temperature dependence of the output power of a Mg2SiO4:Cr4+ forsterite laser.
physics.optics:We investigate the characteristics of guided wave modes in planar coupled waveguides. In particular, we calculate the dispersion relations for TM modes in which one or both of the guiding layers consists of negative index media (NIM)-where the permittivity and permeability are both negative. We find that the Poynting vector within the NIM waveguide axis can change sign and magnitude, a feature that is reflected in the dispersion curves.
physics.optics:It has recently been shown that periodic layered media can reflect strongly for all incident angles and polarizations in a given frequency range. The standard treatment gets these band gaps from an eigenvalue equation for the Bloch factor in an infinite periodic structure. We argue that such a procedure may become meaningless when dealing with structures with not very many periods. We propose an alternative approach based on a factorization of the multilayer transfer matrix in terms of three fundamental matrices of simple interpretation. We show that the trace of the transfer matrix sorts the periodic structures into three types with properties closely related to one (and only one) of the three fundamental matrices. We present the reflectance associated to each one of these types, which can be considered as universal features of the reflection in these media.
physics.optics:We study effects of finite height and surrounding material on photonic crystal slabs of one- and two-dimensional photonic crystals with a pseudo-spectral method and finite difference time domain simulation methods. The band gap is shown to be strongly modified by the boundary material. As an application we suggest reflection and guiding of light by patterning the material on top/below the slab.
physics.optics:The characteristics of an imaging system formed by a slab of a lossy left-handed material (LHM) are studied. The transfer function of the LHM imaging system is written in an appropriate product form with each term having a clear physical interpretation. A tiny loss of the LHM may suppress the transmission of evanescent waves through the LHM slab and this is explained physically. An analytical expression for the resolution of the imaging system is derived. It is shown that it is impossible to make a subwavelength imaging by using a realistic LHM imaging system unless the LHM slab is much thinner than the wavelength.
physics.optics:We observe the formation of an intense optical wavepacket fully localized in all dimensions, i.e. both longitudinally (in time) and in the transverse plane, with an extension of a few tens of fsec and microns, respectively. Our measurements show that the self-trapped wave is a X-shaped light bullet spontaneously generated from a standard laser wavepacket via the nonlinear material response (i.e., second-harmonic generation), which extend the soliton concept to a new realm, where the main hump coexists with conical tails which reflect the symmetry of linear dispersion relationship.
physics.optics:The statistical properties of nonlinear phase noise, often called the Gordon-Mollenauer effect, is studied analytically when the number of fiber spans is very large. The joint characteristic functions of the nonlinear phase noise with electric field, received intensity, and the phase of amplifier noise are all derived analytically. Based on the joint characteristic function of nonlinear phase noise with the phase of amplifier noise, the error probability of signal having nonlinear phase noise is calculated using the Fourier series expansion of the probability density function. The error probability is increased due to the dependence between nonlinear phase noise and the phase of amplifier noise. When the received intensity is used to compensate the nonlinear phase noise, the optimal linear and nonlinear minimum mean-square error compensators are derived analytically using the joint characteristic function of nonlinear phase noise and received intensity. Using the joint probability density of received amplitude and phase, the optimal maximum a posteriori probability detector is derived analytically. The nonlinear compensator always performs better than linear compensator.
physics.optics:The exact Green function for the scalar wave equation in a plane with any set of perfectly reflecting straight mirrors, which may be joined to form corners, is given as a diffraction scattering series. Instances would be slit diffraction in optics, or the Schrodinger equation inside (or outside) a general polygonal enclosure ('quantum polygon billiards'). The method is based on the seminal 1896 Riemann helicoid surface solution by Sommerfeld for optical diffraction by a single corner. It is generalised to account for multiple scatter by adapting the analysis of Stovicek for a closely related problem: a collection of magnetic flux lines (points) in a plane, the multi-flux Aharonov-Bohm effect. The short wavelength limit is shown to yield the 'geometrical theory of diffraction'. For slit diffraction the exact series is shown to coincide with that of Schwarzschild in 1902.
physics.optics:We experimentally demonstrate for the first time that a linearly polarized beam is focussed to an asymmetric spot when using a high-numerical aperture focussing system. This asymmetry was predicted by Richards and Wolf [Proc.R.Soc.London A, 253, 358 (1959)] and can only be measured when a polarization insensitive sensor is placed in the focal region. We used a specially modified photodiode in a knife edge type set up to obtain highly resolved images of the total electric energy density distribution at the focus. The results are in good agreement with the predictions of a vectorial focussing theory.
physics.optics:A simple model is used to estimate the Q factor in numerical simulations of differential phase shift keying (DPSK) with optical delay demodulation and balanced detection. It is found that an alternative definition of Q is needed for DPSK in order to have a more accurate prediction of the bit error ratio (BER).
physics.optics:With using of point-dipole model the theoretical calculations of main refractive indices and orientation of indicatrix of 18 minerals are performed. The feature of studied minerals is the statistically disordered arrangement of CO3, SO4, SO2, PO4 groups and also separate ions. The optical characters of uniaxial minerals and orientation of indicatrix of orthorhombic and monoclinic minerals, obtained by results of calculations, agree with experimental definitions.
physics.optics:The features of a compact, single pass, multi-pixel optical parametric generator are discussed. Several hundreds of independent high spatial-quality tunable ultrashort pulses were produced by pumping a bulk lithium triborate crystal with an array of tightly focussed intense beams. The array of beams was produced by shining a microlenses array with a large pump beam. Overall conversion efficiency to signal and idler up to 30% of the pump beam has been reported. Shot-to-shot energy fluctuation down to 3% was achieved for the generated radiation.
physics.optics:We use a spatially resolved cavity ring-down technique to show that the 2D eigenmode of an unstable optical cavity has a fractal pattern, i.e. it looks the same at different length scales. In agreement with theory, we find that this pattern has the maximum conceivable roughness, i.e., its fractal dimension is 3.01 plus\minus 0.04. This insight in the nature of unstable cavity eigenmodes may lead to better understanding of wave dynamics in open systems, for both light and matter waves.
physics.optics:Numerical Calculations are employed to study the modulation of light by surface acoustic waves (SAWs) in photonic band gap (PBG) structures. The on/off contrast ratio in PBG switch based on optical cavity is determined as a function of the SAW induced dielectric modulation. We show that these structures exhibit high contrast ratios even for moderate acousto-optic coupling
physics.optics:By combining the definition of the Wigner distribution function (WDF) and the matrix method of optical system modeling, we can evaluate the transformation of the former in centered systems with great complexity. The effect of stops and lens diameter are also considered and are shown to be responsible for non-linear clipping of the resulting WDF in the case of coherent illumination and non-linear modulation of the WDF when the illumination is incoherent. As an example, the study of a single lens imaging systems illustrates the applicability of the method.
physics.optics:Free-space propagation can be described as a shearing of the Wigner distribution function in the spatial coordinate; this shearing is linear in paraxial approximation but assumes a more complex shape for wide-angle propagation. Integration in the frequency domain allows the determination of near-field diffraction, leading to the well known Fresnel diffraction when small angles are considered and allowing exact prediction of wide-angle diffraction. The authors use this technique to demonstrate evanescent wave formation and diffraction elimination for very small apertures.
physics.optics:We reelaborate on the basic properties of lossless multilayers by using bilinear transformations. We study some interesting properties of the multilayer transfer function in the unit disk, showing that hyperbolic geometry turns out to be an essential tool for understanding multilayer action. We use a simple trace criterion to classify multilayers into three classes that represent rotations, translations, or parallel displacements. Moreover, we show that these three actions can be decomposed as a product of two reflections in hyperbolic lines. Therefore, we conclude that hyperbolic reflections can be considered as the basic pieces for a deeper understanding of multilayer optics.
physics.optics:In a coherent monoenergetic beam of non-interacting particles, the phase velocity and the particle transport velocity are functions of position, with the strongest variation being in the focal region. These velocities are everywhere parallel to each other, and their product is constant in space. For a coherent monochromatic electromagnetic beam, the energy transport velocity is never greater than the speed of light, and can even be zero. The phase velocities (one each for the non-zero components of the electric and magnetic fields, in general) can be different from each other and from the energy transport velocity, both in direction and in magnitude. The phase velocities at a given point are independent of time, for both particle and electromagnetic beams. The energy velocity is independent of time for the particle beam, but in general oscillates (with angular frequency 2w) in magnitude and direction about its mean value at a given point in the electromagnetic beam. However, there exist electromagnetic steady beams, within which the energy flux, energy density and energy velocity are all independent of time.
physics.optics:The polarization properties of monochromatic light beams are studied. In contrast to the idealization of an electromagnetic plane wave, finite beams which are everywhere linearly polarized in the same direction do not exist. Neither do beams which are everywhere circularly polarized in a fixed plane. It is also shown that transversely finite beams cannot be purely transverse in both their electric and magnetic vectors, and that their electromagnetic energy travels at less than c. The electric and magnetic fields in an electromagnetic beam have different polarization properties in general, but there exists a class of steady beams in which the electric and magnetic polarizations are the same (and in which energy density and energy flux are independent of time). Examples are given of exactly and approximately linearly polarized beams, and of approximately circularly polarized beams.
physics.optics:We suggest a geometrical framework to discuss periodic layered structures in the unit disk. The band gaps appear when the point representing the system approaches the unit circle. We show that the trace of the matrix describing the basic period allows for a classification in three families of orbits with quite different properties. The laws of convergence of the iterates to the unit circle can be then considered as universal features of the reflection.
physics.optics:The effect of the Kerr nonlinearity on linear non-diffractive Bessel beams is investigated analytically and numerically using the nonlinear Schr\"odinger equation. The nonlinearity is shown to primarily affect the central parts of the Bessel beam, giving rise to radial compression or decompression depending on whether the nonlinearity is focusing or defocusing, respectively. The dynamical properties of Gaussian-truncated Bessel beams are also analysed in the presence of a Kerr nonlinearity. It is found that although a condition for width balance in the root-mean-square sense exists, the beam profile becomes strongly deformed during propagation and may exhibit the phenomena of global and partial collapse.
physics.optics:We describe an optical technique based on the statistical analysis of the random intensity distribution due to the interference of the near-field scattered light with the strong transmitted beam. It is shown that, from the study of the two-dimensional power spectrum of the intensity, one derives the scattered intensity as a function of the scattering wave vector. Near-field conditions are specified and discussed. The substantial advantages over traditional scattering technique are pointed out, and is indicated that the technique could be of interest for wave lengths other than visible light.
physics.optics:The usual computation of the spontaneous emission uses a mixture of classical and quantum postulates. A purely classical computation shows that a source of electromagnetic field absorbs light in the eigenmode it is able to emit. Thus in an excitation by an other mode, the component of this mode on the eigenmode is absorbed, while the remainder is scattered. This loss of energy does not apply to the zero point field which has its regular energy in the eigenmode, so that the zero point field seems more effective than the other fields for the stimulation of light emission.
physics.optics:We perform numerical studies of the effect of sidewall imperfections on the resonant state broadening of the optical microdisk cavities for lasing applications. We demonstrate that even small edge roughness causes a drastic degradation of high-Q whispering gallery (WG) mode resonances reducing their Q-values by many orders of magnitude. At the same time, low-Q WG resonances are rather insensitive to the surface roughness. The results of numerical simulation obtained using the scattering matrix technique, are analyzed and explained in terms of wave reflection at a curved dielectric interface combined with the examination of Poincare surface of sections in the classical ray picture.
physics.optics:We consider plane waves propagating in quadratic nonlinear slab waveguides with nonlinear quasi-phase-matching gratings. We predict analytically and verify numerically the complete gain spectrum for transverse modulational instability, including hitherto undescribed higher order gain bands.
physics.optics:Optical near field has been generated by Laguarre-Gaussian doughnut beam on inner surface of "atom funnel". The resulting optical near field has been measured with the help of fiber probe and a consequent effect on cold atoms- released from MOT, has been estimated. Atoms with temperature less than 10 micro_kelvin can be reflected by the optical near field.
physics.optics:We report on an attempt to generate highly stable continuous terahertz (THz) wave by using optical frequency comb (OFC). About 10-nm wide OFC has been generated through a deep phase modulation of a 852 nm laser line in lithium niobate crystal cavity. The multiple optical modes (side bands) of the OFC, which are equally separated from each other by the modulation frequency (=6 GHz) are taken as the frequency reference. When another semiconductor laser is frequency locked, the stability of the difference frequency between the master laser and the second laser is improved on the same order of the RF modulator. An ultra-narrow line and tunable THz radiation source can be achieved by photomixing of this stable difference-frequency optical beat in a photoconductive antenna.
physics.optics:Doughnut shaped light beam has been generated from Gaussian mode ($TEM_{00}$) cw-Ti sapphire laser. After splitting the pump beam into two equal intensity components and introducing unequal convergence and phase delay while they are recombined it results in doughnut mode. Such a beam is tunable and have long propagation length. The evanescent field generated by 360 mW (at 780 nm wavelength) of such a beam creates optical field of 600 nm decay length with a 5.75 neV repulsive dipole potential. Thus cold Rb atoms (at 10{$\mu$}K or less temperature) released from MOT can be reflected by the surface so that the atoms are collected ultimately at the bottom of the prism. By focussing such doughnut beam with 8 cm focal length converging lens, the dark radius reduces to 22{$\mu$}. We also observe such beam to contain azimuthal phase as well as radial phase distribution.
physics.optics:Ferroelectric ordering, the electroclinic effect and chiral smectic C (SmC*) - smectic A (SmA*) phase transitions in thin planar ferroelectric liquid crystal (FLC) cells are studied by means of linear electrooptic and second harmonic generation techniques. The ferroelectric switching is detected in biased FLC cells by measuring azimuthal dependences of linear and nonlinear responses. The applied DC-electric field rotates the FLC symmetry axis with initial and final orientations in the cell plane. Comparative studies of the switching behavior in reflection and transmission allows to distinguish the contributions from the bulk and the sub-surface layers of the cell. The analysis of temperature dependence shows the existence of a strong surface coupling. The temperature dependent nonlinear polarization shows a critical behavior corresponding to the superfluid model.
physics.optics:We have generated high power doughnut beam suitable for atom funnel experiment with the conversion efficiency of about 50 %.
physics.optics:We consider large-mode area photonic crystal fibers for visible applications where micro-deformation induced attenuation becomes a potential problem when the effective area A_eff is sufficiently large compared to lambda^2. We argue how a slight increase in fiber diameter D can be used in screening the high-frequency components of the micro-deformation spectrum mechanically and we confirm this experimentally for both 15 and 20 micron core fibers. For typical bending-radii (R~16 cm) the operating band-width increases by ~3-400 nm to the low-wavelength side.
physics.optics:We investigate general properties of spatial 1-dimensional bright photorefractive solitons and suggest various analytical approximations for the soliton profile and the half width, both depending on an intensity parameter r.
physics.optics:A model for a non-Kerr cylindrical nematic fiber is presented. We use the multiple scales method to show the possibility of constructing different kinds of wavepackets of transverse magnetic (TM) modes propagating through the fiber. This procedure allows us to generate different hierarchies of nonlinear partial differential equations (PDEs) which describe the propagation of optical pulses along the fiber. We go beyond the usual weakly nonlinear limit of a Kerr medium and derive an extended Nonlinear Schrodinger equation (eNLS) with a third order derivative nonlinearity, governing the dynamics for the amplitude of the wavepacket. In this derivation the dispersion, self-focussing and diffraction in the nematic are taken into account. Although the resulting nonlinear $PDE$ may be reduced to the modified Korteweg de Vries equation (mKdV), it also has additional complex solutions which include two-parameter families of bright and dark complex solitons. We show analytically that under certain conditions, the bright solitons are actually double embedded solitons. We explain why these solitons do not radiate at all, even though their wavenumbers are contained in the linear spectrum of the system. Finally, we close the paper by making comments on the advantages as well as the limitations of our approach, and on further generalizations of the model and method presented.
physics.optics:The modal cut-off is investigated experimentally in a series of high quality non-linear photonic crystal fibers. We demonstrate a suitable measurement technique to determine the cut-off wavelength and verify it by inspecting the near field of the modes that may be excited below and above the cut-off. We observe a double peak structure in the cut-off spectra, which is attributed to a splitting of the higher order modes. The cut-off is measured for seven different fiber geometries with different pitches and relative hole size, and a very good agreement with recent theoretical work is found.
physics.optics:We address the long-standing unresolved problem concerning the V-parameter in a photonic crystal fiber (PCF). Formulate the parameter appropriate for a core-defect in a periodic structure we argue that the multi-mode cut-off occurs at a wavelength lambda* which satisfies V_PCF(lambda*)=pi. Comparing to numerics and recent cut-off calculations we confirm this result.
physics.optics:We propose in this article an unambiguous definition of the local density of electromagnetic states (LDOS) in a vacuum near an interface in an equilibrium situation at temperature $T$. We show that the LDOS depends only on the electric field Green function of the system but does not reduce in general to the trace of its imaginary part as often used in the literature. We illustrate this result by a study of the LDOS variations with the distance to an interface and point out deviations from the standard definition. We show nevertheless that this definition remains correct at frequencies close to the material resonances such as surface polaritons. We also study the feasability of detecting such a LDOS with apetureless SNOM techniques. We first show that a thermal near-field emission spectrum above a sample should be detectable and that this measurement could give access to the electromagnetic LDOS. It is further shown that the apertureless SNOM is the optical analog of the scanning tunneling microscope which is known to detect the electronic LDOS. We also discuss some recent SNOM experiments aimed at detecting the electromagnetic LDOS.
physics.optics:The nonlinearity of a transmission fiber may be compensated by a specialty fiber and an optical phase conjugator. Such combination may be used to pre-distort signals before each fiber span so to linearize an entire transmission line.
physics.optics:Two fiber lines may compensate each other for nonlinearity with the help of optical phase conjugation. The pair of fiber lines and the optical signals in them may be either mirror-symmetric or translationally symmetric about the conjugator.
physics.optics:We have developed a scattering-matrix approach for numerical calculation of resonant states and Q-values of a nonideal optical disk cavity of an arbitrary shape and of an arbitrary varying refraction index. The developed method has been applied to study the effect of surface roughness and inhomogeneity of the refraction index on Q-values of microdisk cavities for lasing applications. We demonstrate that even small surface roughness can lead to a drastic degradation of high-Q cavity modes by many orders of magnitude. The results of numerical simulation are analyzed and explained in terms of wave reflection at a curved dielectric interface combined with the examination of Poincare surfaces of section and Husimi distributions.
physics.optics:We analyse theoretically for the first time to our knowledge the perfect phase matching of guided TE and TM modes with a multilayer waveguide composed of linear isotropic dielectric materials. Alongside strict investigation into dispersion relations for multilayer systems, we give an explicit qualitative explanation for the phenomenon of mode matching on the basis of the standard one-dimensional homogenization technique, and discuss the minimum number of layers and the refractive index profile for the proposed device scheme. Direct applications of the scheme include polarization-insensitive, intermodal dispersion-free planar propagation, efficient fibre-to-planar waveguide coupling and, potentially, mode filtering. As a self-sufficient result, we present compact analytical expressions for the mode dispersion in a finite, N-period, three-layer dielectric superlattice.
physics.optics:The characteristic function of soliton phase jitter is found analytically when the soliton is perturbed by amplifier noise. In additional to that from amplitude jitter, the nonlinear phase noise due to frequency and timing jitter is also analyzed. Because the nonlinear phase noise is not Gaussian distributed, the overall phase jitter is also non-Gaussian. For a fixed mean nonlinear phase shift, the contribution of nonlinear phase noise from frequency and timing jitter decreases with distance and signal-to-noise ratio.
physics.optics:The field energy distributions and effective mode areas of silica-based photonic bandgap fibers with a honeycomb airhole structure in the cladding and an extra airhole defining the core are investigated. We present a generalization of the common effective area definition, suitable for the problem at hand, and compare the results for the photonic bandgap fibers with those of index-guiding microstructured fibers. While the majority of the field energy in the honeycomb photonic bandgap fibers is found to reside in the silica, a substantial fraction (up to ~30%) can be located in the airholes. This property may show such fibers particularly interesting for sensor applications, especially those based on nonlinear effects or interaction with other structures (e.g. Bragg gratings) in the glass.
physics.optics:The waveguiding properties of two silica-based airguiding photonic bandgap fiber designs are investigated with special emphasis on material effects. The nonlinear coefficients are found to be 1-2 orders of magnitude smaller than those obtained in index-guiding microstructured fibers with large mode areas. The material dispersion of silica makes a significant contribution to the total chromatic dispersion although less than 10% of the field energy is located in the silica regions of the fibers. These findings suggest that dispersion engineering through the choice of base material may be a possibility in this type of fibers.
physics.optics:Lithium thioindate (LiInS$_{2}$) is a new nonlinear chalcogenide biaxial material transparent from 0.4 to 12 $\mu$m, that has been successfully grown in large sizes and good optical quality. We report on new physical properties that are relevant for laser and nonlinear optics applications. With respect to AgGaS(e)$_2$ ternary chalcopyrite materials, LiInS$_{2}$ displays a nearly-isotropic thermal expansion behavior, a 5-times larger thermal conductivity associated with high optical damage thresholds, and an extremely low intensity-dependent absorption allowing direct high-power downconversion from the near-IR to the deep mid-IR. Continuous-wave difference-frequency generation (5-11$ \mu$m) of Ti:sapphire laser sources is reported for the first time.
physics.optics:We find that the function that describes the surface of spherical aberration free lenses can be used for both positive and negative refractive index media. With the inclusion of negative index, this function assumes the form of all the conic sections and expands the theory of aplanatic optical surfaces. There are two different symmetry centers with respect to the index that create an asymmetric relationship between positive and negative index lens profiles. In the thin lens limit the familiar formulas for image position and magnification hold for any index.
physics.optics:We report the surprising observation of directional tunneling escape from nearly spherical fused-silica optical resonators, in which most of the phase space is filled with nonchaotic regular trajectories. Experimental and theoretical studies of the dependence of the far-field emission pattern on both the degree of deformation and the excitation condition show that nonperturbative phase-space structures in the internal ray dynamics profoundly affect tunneling leakage of the whispering-gallery modes.
physics.optics:Intermodal interactions displayed through the phenomena of mode coupling and conversion in optical systems are treated by means of the Lindstedt-Poincare perturbation method of strained parameters more widely known in classical quantum mechanics and quantum chemistry as the stationary perturbation technique. The focus here is on the mode conversion at the points of virtual phase matching (otherwise called anticrossings or avoided crossings) associated with the maximum conversion efficiency. The method is shown to provide a convenient tool to deal with intermodal interactions at anticrossings -- interactions induced by any kind of perturbation in dielectric index profile of the waveguide, embracing optical inhomogeneity, magnetization of arbitrary orientation, and nonlinearity. Closed-form analytic expressions are derived for the minimum value of mode mismatch and for the length of complete mode conversion (the coupling length, or the beat length) in generic waveguiding systems exhibiting anticrossings. Demonstrating the effectiveness of the method, these general expressions are further applied to the case of TE -- TM mode conversion in (i) a multilayer gyrotropic waveguide under piecewise-constant, arbitrarily oriented magnetization, and (ii) an optically-inhomogeneous planar dielectric waveguide -- an example which the standard coupled-mode theory fails to describe.
physics.optics:We exploit a slightly noncollinear second-harmonic cross-correlation scheme to map the 3D space-time intensity distribution of an unknown complex-shaped ultrashort optical pulse. We show the capability of the technique to reconstruct both the amplitude and the phase of the field through the coherence of the nonlinear interaction down to a resolution of 10 $\mu$m in space and 200 fs in time. This implies that the concept of second-harmonic holography can be employed down to the sub-ps time scale, and used to discuss the features of the technique in terms of the reconstructed fields.
physics.optics:Nonlinear mode coupling in a coaxial waveguide filled with Faraday material has been considered. The picture of mode interaction is shown to resemble Coulomb interaction of charges: higher modes with nonzero angular momentum interact like effective charges via exchange of zero angular momentum quanta of the fundamental mode. Thus, at large distances this interaction becomes the dominant mechanism of mode coupling. The developed model may be used in designing coaxial photonic crystal fibers with strong tailored mode interaction.
physics.optics:We develop a general theory of spatial solitons in a liquid crystalline medium exhibiting a nonlinearity with an arbitrary degree of effective nonlocality. The model accounts the observability of "accessible solitons" and establishes an important link with parametric solitons.
physics.optics:Theoretical analysis is presented on quantum state evolution of polarization light waves at frequencies $\omega_{o}$ and $\omega_{e}$ in a periodically poled nonlinear crystal (PPNC). It is shown that the variances of all the four Stokes parameters can be squeezed.
physics.optics:Counter-propagating light fields have the ability to create self-organized one-dimensional optically bound arrays of microscopic particles, where the light fields adapt to the particle locations and vice versa. We develop a theoretical model to describe this situation and show good agreement with recent experimental data (Phys. Rev. Lett. 89, 128301 (2002)) for two and three particles, if the scattering force is assumed to dominate the axial trapping of the particles. The extension of these ideas to two and three dimensional optically bound states is also discussed.
physics.optics:The inversion of a diffraction pattern offers aberration-free diffraction-limited 3D images without the resolution and depth-of-field limitations of lens-based tomographic systems, the only limitation being radiation damage. We review our experimental results, discuss the fundamental limits of this technique and future plans.
physics.optics:The stability of two-dimensional bright vortex solitons in a media with focusing cubic and defocusing quintic nonlinearities is investigated analytically and numerically. It is proved that above some critical beam powers not only one- and two-charged but also multiple-charged stable vortex solitons do exist. A vortex soliton occurs robust with respect to symmetry-breaking modulational instability in the self-defocusing regime provided that its radial profile becomes flattened, so that a self-trapped wave beam gets a pronounced surface. It is demonstrated that the dynamics of a slightly perturbed stable vortex soliton resembles an oscillation of a liquid stream having a surface tension. Using the idea of sustaining effective surface tension for spatial vortex soliton in a media with competing nonlinearities the explanation of a suppression of the modulational instability is proposed.
physics.optics:Quasi error-free 10 Gbit/s data transmission is demonstrated over a novel type of 50 micron core diameter photonic crystal fiber with as much as 100 m length. Combined with 850$ nm VCSEL sources, this fiber is an attractive alternative to graded-index multi-mode fibers for datacom applications. A comparison to numerical simulations suggests that the high bit-rate may be partly explained by inter-modal diffusion.
physics.optics:The Casimir force between metallic plates made of realistic materials is evaluated for distances in the nanometer range. A spectrum over real frequencies is introduced and shows narrow peaks due to surface resonances (plasmon polaritons or phonon polaritons) that are coupled across the vacuum gap. We demonstrate that the Casimir force originates from the attraction (repulsion) due to the corresponding symmetric (antisymmetric) eigenmodes, respectively. This picture is used to derive a simple analytical estimate of the Casimir force at short distances. We recover the result known for Drude metals without absorption and compute the correction for weakly absorbing materials.
physics.optics:In recent years there has been an explosive development of interest in the measurement of forces at the microscopic level, such as within living cells, as well as the properties of fluids and suspensions on this scale, using optically trapped particles as probes. The next step would be to measure torques and associated rotational motion. This would allow measurement on very small scales since no translational motion is needed. It could also provide an absolute measurement of the forces holding a stationary non-rotating particle in place. The laser-induced torque acting on an optically trapped microscopic birefringent particle can be used for these measurements. Here we present a new method for simple, robust, accurate, simultaneous measurement of the rotation speed of a laser trapped birefringent particle, and the optical torque acting on it, by measuring the change in angular momentum of the light from passing through the particle. This method does not depend on the size or shape of the particle or the laser beam geometry, nor does it depend on the properties of the surrounding medium. This could allow accurate measurement of viscosity on a microscopic scale.
physics.optics:Optical tweezers are widely used for the manipulation of cells and their internal structures. However, the degree of manipulation possible is limited by poor control over the orientation of trapped cells. We show that it is possible to controllably align or rotate disc shaped cells - chloroplasts of Spinacia oleracea - in a plane polarised Gaussian beam trap, using optical torques resulting predominantly from circular polarisation induced in the transmitted beam by the non-spherical shape of the cells.
physics.optics:Optical trapping is a widely used technique, with many important applications in biology and metrology. Complete modelling of trapping requires calculation of optical forces, primarily a scattering problem, and non-optical forces. The T-matrix method is used to calculate forces acting on spheroidal and cylindrical particles.
physics.optics:Optical trapping, where microscopic particles are trapped and manipulated by light is a powerful and widespread technique, with the single-beam gradient trap (also known as optical tweezers) in use for a large number of biological and other applications.   The forces and torques acting on a trapped particle result from the transfer of momentum and angular momentum from the trapping beam to the particle.   Despite the apparent simplicity of a laser trap, with a single particle in a single beam, exact calculation of the optical forces and torques acting on particles is difficult. Calculations can be performed using approximate methods, but are only applicable within their ranges of validity, such as for particles much larger than, or much smaller than, the trapping wavelength, and for spherical isotropic particles.   This leaves unfortunate gaps, since wavelength-scale particles are of great practical interest because they are readily and strongly trapped and are used to probe interesting microscopic and macroscopic phenomena, and non-spherical or anisotropic particles, biological, crystalline, or other, due to their frequent occurance in nature, and the possibility of rotating such objects or controlling or sensing their orientation.   The systematic application of electromagnetic scattering theory can provide a general theory of laser trapping, and render results missing from existing theory. We present here calculations of force and torque on a trapped particle obtained from this theory and discuss the possible applications, including the optical measurement of the force and torque.
physics.optics:Multipole expansion of an incident radiation field - that is, representation of the fields as sums of vector spherical wavefunctions - is essential for theoretical light scattering methods such as the T-matrix method and generalised Lorenz-Mie theory (GLMT). In general, it is theoretically straightforward to find a vector spherical wavefunction representation of an arbitrary radiation field. For example, a simple formula results in the useful case of an incident plane wave. Laser beams present some difficulties. These problems are not a result of any deficiency in the basic process of spherical wavefunction expansion, but are due to the fact that laser beams, in their standard representations, are not radiation fields, but only approximations of radiation fields. This results from the standard laser beam representations being solutions to the paraxial scalar wave equation. We present an efficient method for determining the multipole representation of an arbitrary focussed beam.
physics.optics:The T-matrix method is widely used for the calculation of scattering by particles of sizes on the order of the illuminating wavelength. Although the extended boundary condition method (EBCM) is the most commonly used technique for calculating the T-matrix, a variety of methods can be used.   We consider some general principles of calculating T-matrices, and apply the point-matching method to calculate the T-matrix for particles devoid of symmetry. This method avoids the time-consuming surface integrals required by the EBCM.
physics.optics:Light-induced rotation of absorbing microscopic particles by transfer of angular momentum from light to the material raises the possibility of optically driven micromachines. The phenomenon has been observed using elliptically polarized laser beams or beams with helical phase structure. But it is difficult to develop high power in such experiments because of overheating and unwanted axial forces, limiting the achievable rotation rates to a few hertz. This problem can in principle be overcome by using transparent particles, transferring angular momentum by a mechanism first observed by Beth in 1936, when he reported a tiny torque developed in a quartz waveplate due to the change in polarization of transmitted light. Here we show that an optical torque can be induced on microscopic birefringent particles of calcite held by optical tweezers. Depending on the polarization of the incident beam, the particles either become aligned with the plane of polarization (and thus can be rotated through specified angles) or spin with constant rotation frequency. Because these microscopic particles are transparent, they can be held in three-dimensional optical traps at very high power without heating. We have observed rotation rates in excess of 350 Hz.
physics.optics:This report contains a tutorial introduction to the method of importance sampling. The use of this method is illustrated for simulations of the noise-induced energy jitter of return-to-zero pulses in optical communication systems.
physics.optics:The 3-dimensional coherence matrix is interpreted by emphasising its invariance with respect to spatial rotations. Under these transformations, it naturally decomposes into a real symmetric positive definite matrix, interpreted as the moment of inertia of the ensemble (and the corresponding ellipsoid), and a real axial vector, corresponding to the mean angular momentum of the ensemble. This vector and tensor are related by several inequalities, and the interpretation is compared to those in which unitary invariants of the coherence matrix are studied.
physics.optics:We propose novel multi-phase-matched process that starts with generation of a pair of symmetric second-harmonic waves. Each of them interacts again with the fundamental wave to produce two constructively interfering third harmonic waves collinear to the fundamental input wave.
physics.optics:We numerically calculate the equivalent mode-field radius of the fundamental mode in a photonic crystal fiber (PCF) and show that this is a function of the V-parameter only and not the relative hole size. This dependency is similar to what is found for graded-index standard fibers and we furthermore show that the relation for the PCF can be excellently approximated with the same general mathematical expression. This is to our knowledge the first semi-analytical description of the mode-field radius of a PCF.
physics.optics:The output spectrum of both gas and semiconductor lasers usually contains more than one frequency. Multimode operation in gas versus semiconductor lasers arises from different physics. In gas lasers, slow equilibration of the electron populations at different energies makes each frequency an independent single-mode laser. The slow electron diffusion in semiconductor lasers, combined with the spatially varying optical intensity patterns of the modes, makes each region of space an independent single-mode laser. We develop a rate equation model for the photon number in each mode which captures all these effects. Plotting the photon number versus pumping rate for the competing modes, in both subthreshold and above threshold operation, illustrates the changes in the laser output spectrum due to either slow equilibration or slow diffusion of electrons.
physics.optics:A cascaded iterative Fourier transform (CIFT) algorithm is presented for optical security applications. Two phase-masks are designed and located in the input and the Fourier domains of a 4-f correlator respectively, in order to implement the optical encryption or authenticity verification. Compared with previous methods, the proposed algorithm employs an improved searching strategy: modifying the phase-distributions of both masks synchronously as well as enlarging the searching space. Computer simulations show that the algorithm results in much faster convergence and better image quality for the recovered image. Each of these masks is assigned to different person. Therefore, the decrypted image can be obtained only when all these masks are under authorization. This key-assignment strategy may reduce the risk of being intruded.
physics.optics:Generic wave dislocations (phase singularities, optical vortices) in three dimensions have anisotropic local structure, which is analysed, with emphasis on the twist of surfaces of equal phase along the singular line, and the rotation of the local anisotropy ellipse (twirl). Various measures of twist and twirl are compared in specific examples, and a theorem is found relating the (quantised) topological twist and twirl for a closed dislocation loop with the anisotropy C line index threading the loop.
physics.optics:Diffraction is a fundamental property of light propagation. Owing to this phenomenon,light diffracts out in all directions when it passes through a subwavelength slit.This imposes a fundamental limit on the transverse size of a light beam at a given distance from the aperture. We show that a subwavelength-sized beam propagating without diffractive broadening can be produced in free space by the constructive interference of multiple beams of a Fresnel source of the respective high-refraction-index waveguide. Moreover, it is shown that such a source can be constructed not only for continuous waves, but also for ultra-short (near single-cycle) pulses. The results theoretically demonstrate the feasibility of completely diffraction-free subwavelength-beam optics, for both continuous waves and ultra-short pulses. The approach extends operation of the near-field subwavelength-beam optics, such as near-field scanning optical microscopy and spectroscopy,to the "not-too-distant" field regime (0.5 to about 10 wavelengths).
physics.optics:In recent years the topic of localized wave solutions of the homogeneous scalar wave equation, i.e., the wave fields that propagate without any appreciable spread or drop in intensity, has been discussed in many aspects in numerous publications. In this review the main results of this rather disperse theoretical material are presented in a single mathematical representation - the Fourier decomposition by means of angular spectrum of plane waves. This unified description is shown to lead to a transparent physical understanding of the phenomenon as such and yield the means of optical generation of such wave fields.
physics.optics:In recent experiments, localized and stationary pulses have been generated in second-order nonlinear processes with femtosecond pulses, whose asymptotic features relate with those of nondiffracting and nondispersing polychromatic Bessel beams in linear dispersive media. We investigate on the nature of these linear waves, and show that they can be identified with the X-shaped (O-shaped) modes of the hyperbolic (elliptic) wave equation in media with normal (anomalous) dispersion. Depending on the relative strengths of mode phase mismatch, group velocity mismatch with respect to a plane pulse, and of the defeated group velocity dispersion, these modes can adopt the form of pulsed Bessel beams, focus wave modes, and X-waves (O-waves), respectively.
physics.optics:We explain the main concepts centered around Sharafutdinov's ray transform, its kernel, and the extent to which it can be inverted. It is shown how the ray transform emerges naturally in any attempt to reconstruct optical and stress tensors within a photoelastic medium from measurements on the state of polarization of light beams passing through the strained medium. The problem of reconstruction of stress tensors is crucially related to the fact that the ray transform has a nontrivial kernel; the latter is described by a theorem for which we provide a new proof which is simpler and shorter as in Sharafutdinov's original work, as we limit our scope to tensors which are relevant to Photoelasticity. We explain how the kernel of the ray transform is related to the decomposition of tensor fields into longitudinal and transverse components. The merits of the ray transform as a tool for tensor reconstruction are studied by walking through an explicit example of reconstructing the $\sigma_{33}$-component of the stress tensor in a cylindrical photoelastic specimen. In order to make the paper self-contained we provide a derivation of the basic equations of Integrated Photoelasticity which describe how the presence of stress within a photoelastic medium influences the passage of polarized light through the material.
physics.optics:The controversial term "nondiffracting beam" was introduced into optics by Durnin in 1987. Discussions related to that term revived interest in problems of the light diffraction and resulted in an appearance of the new research direction of the classical optics dealing with the localized transfer of electromagnetic energy. In the paper, the physical concept of the nondiffracting propagation is presented and the basic properties of the nondiffracting beams are reviewed. Attention is also focused to the experimental realization and to applications of the nondiffracting beams.
physics.optics:Theory of the optical parametric amplification at high-frequency pumping in crystals with a regular space modulation of the sign of nonlinear coupling coefficient of interacting waves is developed. By applying the matrix method, the theory is based on a step-by-step approach. It is shown that, in the case where the pumping intensity is less than some critical value, the spatial dynamics of the signal intensity inside a separate layer with the constant nonlinear coefficient has an oscillatory behavior and the change of the signal intensity from layer to layer is defined, in general, by the power function. The same law is valid for the change of variance of signal's quadrature components. At large number of layers, these dependences can be reduced to the well-known ones for homogeneous nonlinear optical crystals.
physics.optics:We show how it is possible to controllably rotate or align microscopic particles of isotropic nonabsorbing material in a TEM00 Gaussian beam trap, with simultaneous measurement of the applied torque using purely optical means. This is a simple and general method of rotation, requiring only that the particle is elongated along one direction. Thus, this method can be used to rotate or align a wide range of naturally occurring particles. The ability to measure the applied torque enables the use of this method as a quantitative tool--the rotational equivalent of optical tweezers based force measurement. As well as being of particular value for the rotation of biological specimens, this method is also suitable for the development of optically-driven micromachines.
physics.optics:The near-field diffraction of fs and sub-fs light pulses by nm-size slit-type apertures and its implication for near-field scanning optical microscopy (NSOM) is analyzed. The amplitude distributions of the diffracted wave-packets having the central wavelengths in the visible spectral region are found by using the Neerhoff and Mur coupled integral equations, which are solved numerically for each Fourier's component of the wave-packet. In the case of fs pulses, the duration and transverse dimensions of the diffracted pulse remain practically the same as that of the input pulse. This demonstrates feasibility of the NSOM in which a fs pulse is used to provide the fs temporal resolution together with nm-scale spatial resolution. In the sub-fs domain, the Fourier spectrum of the transmitted pulse experiences a considerable narrowing that leads to the increase of the pulse duration in a few times. This imposes a limit on the simultaneous resolutions in time and space.
physics.optics:We show theoretically and demonstrate experimentally that highly absorbing particles can be trapped and manipulated in a single highly focused Gaussian beam. Our studies of the effects of polarized light on such particles show that they can be set into rotation by elliptically polarized light and that both the sense and the speed of their rotation can be smoothly controlled.
physics.optics:Wolf discovered how the spatial coherence characteristics of the source affect the spectrum of the radiation in the far zone. In particular the spatial coherence of the source can result either in red or blue shifts in the measured spectrum.His predictions have been verified in a large number of different classes of systems. Wolf and coworkers usually assume a given form of source correlations and study its consequence. In this paper we consider microscopic origin of spatial coherence and radiation from a system of atoms. We discuss how the radiation is different from that produced from an independent system of atoms. We show that the process of radiation itself is responsible for the creation of spatial correlations within the source. We present different features of the spectrum and other statistical properties of the radiation, which show strong dependence on the spatial correlations. We show the existence of a new type of two-photon resonance that arises as a result of such spatial correlations. We further show how the spatial coherence of the field can be used in the context of radiation generated by nonlinear optical processes. We conclude by demonstrating the universality of Wolf shifts and its application in the context of pulse propagation in a dispersive medium.
physics.optics:We experimentally demonstrate for the first time that a radially polarized field can be focussed to a spot size significantly smaller (0.16(1) lambda^2) than for linear polarization (0.26 lambda^2). The effect of the vector properties of light is shown by a comparison of the focal intensity distribution for radially and azimuthally polarized input fields. For strong focusing a radially polarized field leads to a longitudinal electric field component at the focus which is sharp and centered at the optical axis. The relative contribution of this component is enhanced by using an annular aperture.
physics.optics:Two strong simultaneous resonances of scattering--double-resonant extremely asymmetrical scattering (DEAS)--are predicted in two parallel, oblique, periodic Bragg arrays separated by a gap, when the scattered wave propagates parallel to the arrays. One of these resonances is with respect to frequency (which is common to all types of Bragg scattering), and another is with respect to phase variation between the arrays. The diffractional divergence of the scattered wave is shown to be the main physical reason for DEAS in the considered structure. Although the arrays are separated, they are shown to interact by means of the diffractional divergence of the scattered wave across the gap from one array into the other. It is also shown that increasing separation between the two arrays results in a broader and weaker resonance with respect to phase shift. The analysis is based on a recently developed new approach allowing for the diffractional divergence of the scattered wave inside and outside the arrays. Physical interpretations of the predicted features of DEAS in separated arrays are also presented. Applicability conditions for the developed theory are derived.
physics.optics:Radiation pressure forces in a focussed laser beam can be used to trap microscopic absorbing particles against a substrate. Calculations based on momentum transfer considerations show that stable trapping occurs before the beam waist, and that trapping is more effective with doughnut beams. Such doughnut beams can transfer angular momentum leading to rotation of the trapped particles. Energy is also transferred, which can result in heating of the particles to temperatures above the boiling point of the surrounding medium.
physics.optics:Extremely asymmetrical scattering (EAS) is a highly resonant type of Bragg scattering with a strong resonant increase of the scattered wave amplitude inside and outside the grating. EAS is realized when the scattered wave propagates parallel to the grating boundaries. We present a rigorous algorithm for the analysis of non-steady-state EAS, and investigate the relaxation of the incident and scattered wave amplitudes to their steady-state values. Non-steady-state EAS of bulk TE electromagnetic waves is analyzed in narrow and wide, slanted, holographic gratings. Typical relaxation times are determined and compared with previous rough estimations. Physical explanation of the predicted effects is presented.
physics.optics:We demonstrate generation and frequency doubling of unit charge vortices in a linear astigmatic resonator. Topological instability of the double charge harmonic vortices leads to well separated vortex cores that are shown to rotate, and become anisotropic, as the resonator is tuned across resonance.
physics.optics:We have developed a new method based on two cavities containing $\chi^{(2)}$ media to reshape optical pulses by an all-optical technique. The system is entirely passive \emph{i.e.}, all the energy is brought by the incoming pulse and uses two successive optical cavities with independent thresholds. The output pulse is close to a rectangular shape. We show that this technique could be extended to high bit rates and telecommunication wavelength using very small cavities containing current nonlinear materials.
physics.optics:We show that useful non-instantaneous nonlinear phase shifts can be obtained from cascaded quadratic processes in the presence of group velocity mismatch. The two-field nature of the process permits responses that can be effectively advanced or retarded in time with respect to one of the fields. There is an analogy to a generalized Raman-scattering effect, permitting both red and blue shifts of short pulses. We expect this capability to have many applications in short-pulse generation and propagation, such as the compensation of Raman-induced effects and high-quality pulse compression, which we discuss.
physics.optics:A method of formation of the tightly confined distortion-free fs pulses with the step-like decreasing of intensity under the finite-length propagation in free space is described. Such pulses are formed by the Fresnel source of a high refraction-index waveguide. The source reproduces in free space a propagation-invariant (distortion-free) pulse confined by the waveguide. Converse to the case of material waveguides, when the pulse goes out from the Fresnel (virtual) waveguide its shape is not changed, but the intensity immediately drops down to the near-zero level.
physics.optics:Based on a recent formulation of the V-parameter of a photonic crystal fiber we provide numerically based empirical expressions for this quantity only dependent on the two structural parameters - the air hole diameter and the hole-to-hole center spacing. Based on the unique relation between the V-parameter and the equivalent mode field radius we identify how the parameter space for these fibers is restricted in order for the fibers to remain single mode while still having a guided mode confined to the core region.
physics.optics:The alternative to dynamic alignment explanation of experimental results on spatial-asymmetric dissociation of molecules in a laser field is proposed. The concept of geometrical alignment is sufficient for explanation of these results. In this case the spatial anisotropy of interaction of molecules with laser radiation is transferred from one field to another through the ordinary mechanism of nonlinear optical interactions. Thus laser radiation does not create alignment, but only registers it. A physical basis of such nonlinear processes is inequality of forward and reversed optical transitions that corresponds to a concept of time invariance violation in electromagnetic interactions. Directions of the further researches in the field of alignment spectroscopy are discussed.
physics.optics:Periodic layered media can reflect strongly for all incident angles and polarizations in a given frequency range. Quarter-wave stacks at normal incidence are commonplace in the design of such omnidirectional reflectors. We discuss alternative design criteria to optimize these systems.
physics.optics:We study propagation of a pair of oppositely charged and mutually incoherent vortices in anisotropic nonlinear optical media. Mutual interactions retard the delocalization of the vortex core observed for isolated vortices.
physics.optics:The efficiency of evanescent coupling between a silica optical fiber taper and a silicon photonic crystal waveguide is studied. A high reflectivity mirror on the end of the photonic crystal waveguide is used to recollect, in the backwards propagating fiber mode, the optical power that is initially coupled into the photonic crystal waveguide. An outcoupled power in the backward propagating fiber mode of 88% of the input power is measured, corresponding to a lower bound on the coupler efficiency of 94%.
physics.optics:The reversible phase transition induced by femtosecond laser excitation of Gallium has been studied by measuring the dielectric function at 775 nm with ~ 200 fs temporal resolution. The real and imaginary parts of the transient dielectric function were calculated from absolute reflectivity of Gallium layer measured at two different angles of incidence, using Fresnel formulas. The time-dependent electron-phonon effective collision frequency, the heat conduction coefficient and the volume fraction of a new phase were restored directly from the experimental data, and the time and space dependent electron and lattice temperatures in the layer undergoing phase transition were reconstructed without ad hoc assumptions. We converted the temporal dependence of the electron-phonon collision rate into the temperature dependence, and demonstrated, for the first time, that the electron-phonon collision rate has a non-linear character. This temperature dependence converges into the known equilibrium function during the cooling stage. The maximum fraction of a new phase in the laser-excited Gallium layer reached only 60% even when the deposited energy was two times the equilibrium enthalpy of melting. We have also demonstrated that the phase transition pace and a fraction of the transformed material depended strongly on the thickness of the laser-excited Gallium layer, which was of the order of several tens of nanometers for the whole range of the pump laser fluencies up to the damage threshold. The kinetics of the phase transformation after the laser excitation can be understood on the basis of the classical theory of the first-order phase transition while the duration of non-thermal stage appears to be comparable to the sub-picosecond pulse length.
physics.optics:The derivation of a new condition for characterizing isotropic dielectric-magnetic materials exhibiting negative phase velocity, and the equivalence of that condition with previously derived conditions, are presented.
physics.optics:Linear and nonlinear directional couplers are currently used in fiber optics communications. They may also play a role in multiphoton approaches to quantum information processing if accurate control is obtained over the phases and polarizations of the signals at the output of the coupler. With this motivation, the constants of motion of the coupler equation are used to obtain an explicit analytical solution for the nonlinear coupler.
physics.optics:A single-mode all-silica photonic crystal fiber with an effective area of 600 square-micron and low bending loss is demonstrated. The fiber is characterized in terms of attenuation, chromatic dispersion and modal properties.
physics.optics:Based on the Wigner distribution approach, an analysis of the effect of partial incoherence on the transverse instability of soliton structures in nonlinear Kerr media is presented. It is explicitly shown, that for a Lorentzian incoherence spectrum the partial incoherence gives rise to a damping which counteracts, and tends to suppress, the transverse instability growth. However, the general picture is more complicated and it is shown that the effect of the partial incoherence depends crucially on the form of the incoherence spectrum. In fact, for spectra with finite rms-width, the partial incoherence may even increase both the growth rate and the range of unstable, transverse wave numbers.
physics.optics:We study theoretically and experimentally the modulational instability of broad optical beams in photorefractive nonlinear media. We demonstrate the impact of the anisotropy of the nonlinearity on the growth rate of periodic perturbations. Our findings are confirmed by experimental measurements in a strontium barium niobate photorefractive crystal.
physics.optics:Coherent Anti-Stokes Raman Scattering (CARS) processes are ``coherent,'' but the phase of the anti-Stokes radiation is usually lost by most incoherent spectroscopic CARS measurements. We propose a novel Raman microscopy imaging method called Nonlinear Interferometric Vibrational Imaging, which measures Raman spectra by obtaining the temporal anti-Stokes signal through nonlinear interferometry. With a more complete knowledge of the anti-Stokes signal, we show through simulations that a high-resolution Raman spectrum can be obtained of a molecule in a single pulse using broadband radiation. This could be useful for identifying the three-dimensional spatial distribution of molecular species in tissue.
physics.optics:An examination of the propagation of intense 200 fs pulses in water reveals light filaments not sustained by the balance between Kerr-induced self-focusing and plasma-induced defocusing. Their appearance is interpreted as the consequence of a spontaneous reshaping of the wave packet form a gaussian into a conical wave, driven by the requirement of maximum localization, minimum losses and stationarity in the presence of non-linear absorption.
physics.optics:In positive phase-mismatched SHG and normal dispersion, a gaussian spatio-temporal pulse transforms spontaneously into a X-pulse, underlies spatio-temporal compression and eventually leads to stationary 3-D propagation. Experimental and numerical data are provided
physics.optics:It is shown that a system of two coupled planar material sheets possessing surface mode (polariton) resonances can be used for the purpose of evanescent field restoration and, thus, for the sub-wavelength near-field imaging. The sheets are placed in free space so that they are parallel and separated by a certain distance. Due to interaction of the resonating surface modes (polaritons) of the sheets an exponential growth in the amplitude of an evanescent plane wave coming through the system can be achieved. This effect was predicted earlier for backward-wave (double-negative or Veselago) slab lenses. The alternative system considered here is proved to be realizable at microwaves by grids or arrays of resonant particles. The necessary electromagnetic properties of the resonating grids and the particles are investigated and established. Theoretical results are supported by microwave experiments that demonstrate amplification of evanescent modes.
physics.optics:Motivated by recent experimental work by Folkenberg et al. we consider the effect of weak disorder in the air-hole lattice of small-core photonic crystal fibers. We find that the broken symmetry leads to higher-order modes which have generic intensity distributions resembling those found in standard fibers with elliptical cores. This explains why recently reported experimental higher-order mode profiles appear very different from those calculated numerically for ideal photonic crystal fibers with inversion and six-fold rotational symmetry. The splitting of the four higher-order modes into two groups fully correlates with the observation that these modes have different cut-offs.
physics.optics:We present a numerical investigation of the ray dynamics in a paraxial optical cavity when a ray splitting mechanism is present. The cavity is a conventional two-mirror stable resonator and the ray splitting is achieved by inserting an optical beam splitter perpendicular to the cavity axis. We show that depending on the position of the beam splitter the optical resonator can become unstable and the ray dynamics displays a positive Lyapunov exponent.
physics.optics:This paper analyses theoretically and numerically the effect of varying grating amplitude on the extremely asymmetrical scattering (EAS) of bulk and guided optical modes in non-uniform strip-like periodic Bragg arrays with stepwise and gradual variations in the grating amplitude across the array. A recently developed new approach based on allowance for the diffractional divergence of the scattered wave is used for this analysis. It is demonstrated that gradual variations in magnitude of the grating amplitude may change the pattern of EAS noticeably but not radically. On the other hand, phase variations in the grating may result in a radically new type of Bragg scattering - double-resonant EAS (DEAS). In this case, a combination of two strong simultaneous resonances (one with respect to frequency, and another with respect to the phase variation) is predicted to take place in non-uniform arrays with a step-like phase and gradual magnitude variations of the grating amplitude. The tolerances of EAS and DEAS to small gradual variations in the grating amplitude are determined. The main features of these types of scattering in non-uniform arrays are explained by the diffractional divergence of the scattered wave inside and outside the array.
physics.optics:We present a symmetry-based theory of the depolarization induced by subwavelength metal hole arrays. We derive the Mueller matrices of hole arrays with various symmetries (in particular square and hexagonal) when illuminated by a finite-diameter (e.g. gaussian) beam. The depolarization is due to a combination of two factors: (i) propagation of surface plasmons along the surface of the array, (ii) a spread of wave vectors in the incident beam.
physics.optics:We investigate the ray dynamics in an optical cavity when a ray splitting mechanism is present. The cavity is a conventional two-mirror stable resonator and the ray splitting is achieved by inserting an optical beam splitter perpendicular to the cavity axis. Using Hamiltonian optics, we show that such a simple device presents a surprisingly rich chaotic ray dynamics.
physics.optics:We concentrate on the forces and torques exerted on transparent and absorbing particles trapped in laser beams containing optical vortices. We review previous theoretical and experimental work and then present new calculations of the effect of vortex beams on absorbing particles.
physics.optics:We have monitored the space-time transformation of 150-fs pulse, undergoing self-focusing and filamentation in water, by means of the nonlinear gating tech- nique. We have observed that pulse splitting and subsequent recombination apply to axial temporal intensity only, whereas space-integrated pulse profile preserves its original shape.
physics.optics:It is shown that three-dimensional nonparaxial beams are described by the oblate spheroidal exact solutions of the Helmholtz equation. For the first time, their beam behaviour is investigated and their corresponding parameters are defined. Using the fact that the beam width of the family of paraxial Gaussian beams is described by an hyperbola, the connection between the physical parameters of nonparaxial spheroidal beam solutions and those of paraxial beams is formally stablished. These results are also helpful to investigate the exact vector nonparaxial beams.
physics.optics:The images of the silicon test object has been carried out. An image for in-line hard X-ray hologram is presented. The transmission of a hologram image for hard X-ray radiation using Fresnel phase zone plate has been investigated.
physics.optics:We develop a theory of light transmission through an aperture-type near-field optical probe with a dissipative matter in its semiconducting core described by a complex frequency-dependent dielectric function. We evaluate the near-field transmission coefficient of a metallized silicon probe with a large taper angle of in the visible and near-infrared wavelength range. It is shown that in this spectral range the use of a short silicon probe instead of a glass one allows to achieve a strong (up to 10$^2-10^{3}$) enhancement in the transmission efficiency.
physics.optics:A metal nanoparticle plasmon waveguide for electromagnetic energy transport utilizing dispersion engineering to dramatically increase lateral energy confinement via a two-dimensional pattern of Au dots on an optically thin Si membrane is described. Using finite-difference time-domain simulations and coupled-mode theory, we show that phase-matched evanescent excitation from conventional fiber tapers is possible with efficiencies > 90 % for realistic geometries. Energy loss in this waveguide is mainly due to material absorption, allowing for 1/e energy decay distances of about 2 mm for excitation at telecommunication frequencies. This concept can be extended to the visible regime and promises applications in optical energy guiding, optical sensing, and switching.
physics.optics:A two-dimensional photonic crystal microcavity design supporting a wavelength-scale volume resonant mode with a calculated quality factor (Q) insensitive to deviations in the cavity geometry at the level of Q~2x10^4 is presented. The robustness of the cavity design is confirmed by optical fiber-based measurements of passive cavities fabricated in silicon. For microcavities operating in the lambda = 1500 nm wavelength band, quality factors between 1.3-4.0x10^4 are measured for significant variations in cavity geometry and for resonant mode normalized frequencies shifted by as much as 10% of the nominal value.
physics.optics:e investigate both experimentally and theoretically the waveguiding properties of a novel double trench waveguide where a conventional single-mode strip waveguide is embedded in a two dimensional photonic crystal (PhC) slab formed in silicon on insulator (SOI) wafers. We demonstrate that the bandwidth for relatively low-loss (50dB/cm) waveguiding is significantly expanded to 250nm covering almost all the photonic band gap owing to nearly linear dispersion of the TE-like waveguiding mode. The flat transmission spectrum however is interrupted by numerous narrow stop bands. We found that these stop bands can be attributed to anti-crossing between TE-like (positive parity) and TM-like (negative parity) modes. This effect is a direct result of the strong asymmetry of the waveguides that have an upper cladding of air and lower cladding of oxide. To our knowledge this is the first demonstration of the effects of cladding asymmetry on the transmission characteristics of the PhC slab waveguides.
physics.optics:In this paper, we present an approximate expression for determining the effective permittivity describing the coherent propagation of an electromagnetic wave in random media. Under the Quasicrystalline Coherent Potential Approximation (QC-CPA), it is known that multiple scattering theory provided an expression for this effective permittivity. The numerical evaluation of this one is, however, a challenging problem. To find a tractable expression, we add some new approximations to the (QC-CPA) approach. As a result, we obtained an expression for the effective permittivity which contained at the same time the Maxwell-Garnett formula in the low frequency limit, and the Keller formula, which has been recently proved to be in good agreement for particles exceeding the wavelength.
physics.optics:We investigate the electromagnetic propagation in two-dimensional photonic crystals, formed by parallel dielectric cylinders embedded a uniform medium. The frequency band structure is computed using the standard plane-wave expansion method, while the propagation and scattering of the electromagnetic waves are calculated by the multiple scattering theory. It is shown that within partial bandgaps, the waves tend to bend away from the forbidden directions. Such a property may render novel applications in manipulating optical flows. In addition, the relevance with the imaging by flat photonic crystal slabs will also be discussed.
physics.optics:This paper is the result of setting up GRENOUILLE in the Nonlinear Dynamics Laboratory at the University of Maryland at College Park. With the experience acquired in the process of setting up GRENOUILLE, this manual was compiled from literature and from hand-on experience to serve as a quick guide, a step-by-step help to construct GRENOUILLE and to understand some of its basic principles.
physics.optics:Accurate knowledge of absorption coefficient of a sample is a prerequisite for measuring the third order optical nonlinearity of materials, which can be a serious limitation for unknown samples. We introduce a method, which measures both the absorption coefficient and the third order optical nonlinearity of materials with high sensitivity in a single experimental arrangement. We use a dual-beam pump-probe experiment and conventional single-beam z-scan under different conditions to achieve this goal. We also demonstrate a counterintuitive coupling of the non-interacting probe-beam with the pump-beam in pump-probe z-scan experiment.
physics.optics:The concept of a plane scatterer that was developed earlier for scalar waves is generalized so that polarization of light is included. Starting from a Lippmann-Schwinger formalism for vector waves, we show that the Green function has to be regularized before T-matrices can be defined in a consistent way. After the regularization, optical modes and Green functions are determined exactly for finite structures built up of an arbitrary number of parallel planes, at arbitrary positions, and where each plane can have different optical properties. The model is applied to the special case of finite crystals consisting of regularly spaced identical planes, where analytical methods can be taken further and only light numerical tasks remain. The formalism is used to calculate position- and orientation-dependent spontaneous-emission rates inside and near the finite photonic crystals. The results show that emission rates and reflection properties can differ strongly for scalar and for vector waves. The finite size of the crystal influences the emission rates. For parallel dipoles close to a plane, emission into guided modes gives rise to a peak in the frequency-dependent emission rate.
physics.optics:Single-shot ultrafast absorbance spectroscopy based on the frequency encoding of the kinetics is analyzed theoretically and implemented experimentally. The kinetics are sampled in the frequency domain using linearly chirped, amplified 33 fs FWHM pulses derived from a Ti:sapphire laser. A variable length grating pair compressor is used to achieve the time resolution of 500-1000 channels per a 2-to-160 ps window with sensitivity > 5x10-4. In terms of the acquisition time, FDSS has an advantage over the pump-probe spectroscopy in a situation when the "noise" is dominated by amplitude variations of the signal, due to the pump and flow instabilities. The possibilities of FDSS are illustrated with the kinetics obtained in multiphoton ionization of water and aqueous iodide and one-photon excitation of polycrystalline ZnSe and thin-film amorphous Si:H. Unlike other "single-shot" techniques, FDSS can be implemented for fluid samples flowing in a high-speed jet and for thin solid samples that exhibit interference fringes; no a priori knowledge of the excitation profile of the pump across the beam is needed. Another advantage is that due to the interference of quasimonochromatic components of the chirped probe pulse, an oscillation pattern near the origin of the FDSS kinetics emerges. This pattern is unique and can be used to determine the complex dielectric function of the photogenerated species.
physics.optics:Single-shot ultrafast absorbance spectroscopy based on the frequency encoding of the kinetics is analyzed theoretically and implemented experimentally. In Part II of the series, arbitrary thickness sample is analysed theroretically. The model is then used to simulate the results for a-Si:H films.
physics.optics:We present a unifying point of view which allows to understand spectral features reported in recent experiments with two-dimensional arrays of subwavelength holes in metal films. We develop a Fano analysis of the related scattering problem by distinguishing two interfering contributions to the transmission process, namely a non-resonant contribution (direct scattering) and a resonant contribution (surface plasmon excitation). The introduction of a coupling strength between these two contributions naturally induces resonance shifts and asymmetry of profiles which satisfy simple scaling relations. We also report an experiment to confirm this analysis.
physics.optics:We study the dispersion and leakage properties for the recently reported low-loss photonic band-gap fiber by Smith et al. [Nature 424, 657 (2003)]. We find that surface modes have a significant impact on both the dispersion and leakage properties of the fundamental mode. Our dispersion results are in qualitative agreement with the dispersion profile reported recently by Ouzounov et al. [Science 301, 1702 (2003)] though our results suggest that the observed long-wavelength anomalous dispersion is due to an avoided crossing (with surface modes) rather than band-bending caused by the photonic band-gap boundary of the cladding.
physics.optics:Micron-scale optical cavities are produced using a combination of template sphere self-assembly and electrochemical growth. Transmission measurements of the tunable microcavities show sharp resonant modes with a Q-factor>300, and 25-fold local enhancement of light intensity. The presence of transverse optical modes confirms the lateral confinement of photons. Calculations show sub-micron mode volumes are feasible. The small mode volume of these microcavities promises to lead to a wide range of applications in microlasers, atom optics, quantum information, biophotonics and single molecule detection.
physics.optics:We experimentally compare the optical bandwidth of a conventional single-mode fiber (SMF) with 3 different photonic crystal fibers (PCF) all optimized for visible applications. The spectral attenuation, single-turn bend loss, and mode-field diameters (MFD) are measured and the PCF is found to have a significantly larger bandwidth than the SMF for an identical MFD. It is shown how this advantage can be utilized for realizing a larger MFD for the PCF while maintaining a bending resistant fiber.
physics.optics:We consider an air-silica honeycomb lattice and demonstrate a new approach to the formation of a core defect. Typically, a high or low-index core is formed by adding a high-index region or an additional air-hole (or other low-index material) to the lattice, but here we discuss how a core defect can be formed by manipulating the cladding region rather than the core region itself. Germanium-doping of the honeycomb lattice has recently been suggested for the formation of a photonic band-gap guiding silica-core and here we experimentally demonstrate how an index-guiding silica-core can be formed by fluorine-doping of the honeycomb lattice.
physics.optics:Self-similar propagation of ultrashort, parabolic pulses in a laser resonator is observed theoretically and experimentally. This constitutes a new type of pulse-shaping in modelocked lasers: in contrast to the well-known static (soliton-like) and breathing (dispersion-managed soliton) pulse evolutions, asymptotic solutions to the nonlinear wave equation that governs pulse propagation in most of the laser cavity are observed. Stable self-similar pulses exist with energies much greater than can be tolerated in soliton-like pulse shaping, and this will have implications for practical lasers.
physics.optics:The existence of resonant enhanced transmission and collimation of light waves by subwavelength slits in metal films [for example, see T.W. Ebbesen et al., Nature (London) 391, 667 (1998) and H.J. Lezec et al., Science, 297, 820 (2002)] leads to the basic question: Can a light be enhanced and simultaneously localized in space and time by a subwavelength slit? To address this question, the spatial distribution of the energy flux of an ultrashort (femtosecond) wave-packet diffracted by a subwavelength (nanometer-size) slit was analyzed by using the conventional approach based on the Neerhoff and Mur solution of Maxwell's equations. The results show that a light can be enhanced by orders of magnitude and simultaneously localized in the near-field diffraction zone at the nm- and fs-scales. Possible applications in nanophotonics are discussed.
physics.optics:We demonstrate an optical system that can apply and accurately measure the torque exerted by the trapping beam on a rotating birefringent probe particle. This allows the viscosity and surface effects within liquid media to be measured quantitatively on a micron-size scale using a trapped rotating spherical probe particle. We use the system to measure the viscosity inside a prototype cellular structure.
physics.optics:The core theorem on which the above paper is centred - that a perfectly conducting body of revolution absorbs no angular momentum from an axisymmetric electromagnetic wave field - is in fact a special case of a more general result in electromagnetic scattering theory. In addition, the scaling of the efficiency of transfer of angular momentum to an object with the wavelength and object size merits further discussion. Finally, some comments are made on the choice of terminology and the erroneous statement that a circularly polarized plane wave does not carry angular momentum.
physics.optics:The propagation of plane waves in a Faraday chiral medium is investigated. Conditions for the phase velocity to be directed opposite to the direction of power flow are derived for propagation in an arbitrary direction; simplified conditions which apply to propagation parallel to the distinguished axis are also established. These negative phase-velocity conditions are explored numerically using a representative Faraday chiral medium, arising from the homogenization of an isotropic chiral medium and a magnetically biased ferrite. It is demonstrated that the phase velocity may be directed opposite to power flow, provided that the gyrotropic parameter of the ferrite component medium is sufficiently large compared with the corresponding nongyrotropic permeability parameters.
physics.optics:Second harmonic optical coherence tomography, which uses coherence gating of second-order nonlinear optical response of biological tissues for imaging, is described and demonstrated. Femtosecond laser pulses were used to excite second harmonic waves from collagen harvested from rat tail tendon and a reference nonlinear crystal. Second harmonic interference fringe signals were detected and used for image construction. Because of the strong dependence of second harmonic generation on molecular and tissue structures, this technique offers contrast and resolution enhancement to conventional optical coherence tomography.
physics.optics:Considering the diffraction of a plane wave by a periodically corrugated half-space, we show that the transformation of the refracting medium from positive/negative phase-velocity to negative/positive phase-velocity type has an influence on the diffraction efficiencies. This effect increases with increasing corrugation depth, owing to the presence of evanescent waves in the troughs of the corrugated interface.
physics.optics:We have developed a scheme to measure the optical torque, exerted by a laser beam on a phase object, by measuring the orbital angular momentum of the transmitted beam. The experiment is a macroscopic simulation of a situation in optical tweezers, as orbital angular momentum has been widely used to apply torque to microscopic objects. A hologram designed to generate LG02 modes and a CCD camera are used to detect the orbital component of the beam. Experimental results agree with theoretical numerical calculations, and the strength of the orbital component suggest its usefulness in optical tweezers for micromanipulation.
physics.optics:We investigate optical parametric oscillations through four-wave mixing in resonant cavities and photonic crystals. The theoretical analysis underlines the relevant features of the phenomenon and the role of the density of states. Using fully vectorial 3D time-domain simulations, including both dispersion and nonlinear polarization, for the first time we address this process in a face centered cubic lattice and in a photonic crystal slab. The results lead the way to the development of novel parametric sources in isotropic media.
physics.optics:We present a study of orbital angular momentum transfer from pump to down-converted beams in a type-II Optical Parametric Oscillator. Cavity and anisotropy effects are investigated and demostrated to play a central role in the transverse mode dynamics. While the idler beam can oscillate in a Laguerre-Gauss mode, the crystal birefringence induces an astigmatic effect in the signal beam that prevents the resonance of such mode.
physics.optics:We introduce a prototype model for globally-coupled oscillators in which each element is given an oscillation frequency and a preferential oscillation direction (polarization), both randomly distributed. We found two collective transitions: to phase synchronization and to polarization ordering. Introducing a global-phase and a polarization order parameters, we show that the transition to global-phase synchrony is found when the coupling overcomes a critical value and that polarization order enhancement can not take place before global-phase synchrony. We develop a self-consistent theory to determine both order parameters in good agreement with numerical results.
physics.optics:We report on a polarization maintaining large mode area photonic crystal fiber. Unlike, previous work on polarization maintaining photonic crystal fibers, birefringence is introduced using stress applying parts. This has allowed us to realize fibers, which are both single mode at any wavelength and have a practically constant birefringence for any wavelength. The fibers presented in this work have mode field diameters from about 4 to 6.5 micron, and exhibit a typical birefringence of 1.5e-4.
physics.optics:Speden is a computer program that reconstructs the electron density of single particles from their x-ray diffraction patterns, using a single-particle adaptation of the Holographic Method in crystallography. (Szoke, A., Szoke, H., and Somoza, J.R., 1997. Acta Cryst. A53, 291-313.) The method, like its parent, is unique that it does not rely on ``back'' transformation from the diffraction pattern into real space and on interpolation within measured data. It is designed to deal successfully with sparse, irregular, incomplete and noisy data. It is also designed to use prior information for ensuring sensible results and for reliable convergence. This article describes the theoretical basis for the reconstruction algorithm, its implementation and quantitative results of tests on synthetic and experimentally obtained data. The program could be used for determining the structure of radiation tolerant samples and, eventually, of large biological molecular structures without the need for crystallization.
physics.optics:We detect the vortex evolution from the increase of the fractional phase step by interfering two beams of opposite but equal fractional step increment.The interference pattern generated shows evidence of the birth of an additional single extra charge as the fractional phase step increase extends above a half-integer value
physics.optics:We report on a single-mode photonic crystal fiber with attenuation and effective area at 1550 nm of 0.48 dB/km and 130 square-micron, respectively. This is, to our knowledge, the lowest loss reported for a PCF not made from VAD prepared silica and at the same time the largest effective area for a low-loss (< 1 dB/km) PCF. We briefly discuss the future applications of PCFs for data transmission and show for the first time, both numerically and experimentally, how the group velocity dispersion is related to the mode field diameter
physics.optics:We resort to the concept of turns to provide a geometrical representation of the action of any lossless multilayer, which can be considered as the analogous in the unit disk to the sliding vectors in Euclidean geometry. This construction clearly shows the peculiar effects arising in the composition of multilayers. A simple optical experiment revealing the appearance of the Wigner angle is analyzed in this framework.
physics.optics:We examine the Seidel aberrations of thin spherical lenses composed of media with refractive index not restricted to be positive. We find that consideration of this expanded parameter space allows reduction or elimination of more aberrations than is possible with only positive index media. In particular we find that spherical lenses possessing real aplanatic focal points are possible only with negative index. We perform ray tracing, using custom code that relies only on Maxwell's equations and conservation of energy, that confirms the results of the aberration calculations.
physics.optics:We study coupling and decoupling of parallel waveguides in two-dimensional square-lattice photonic crystals. We show that the waveguide coupling is prohibited at some wavelengths when there is an odd number of rows between the waveguides. In contrast, decoupling does not take place when there is even number of rows between the waveguides. Decoupling can be used to avoid cross talk between adjacent waveguides.
physics.optics:We report on an easy-to-evaluate expression for the prediction of the bend-loss for a large mode area photonic crystal fiber (PCF) with a triangular air-hole lattice. The expression is based on a recently proposed formulation of the V-parameter for a PCF and contains no free parameters. The validity of the expression is verified experimentally for varying fiber parameters as well as bend radius. The typical deviation between the position of the measured and the predicted bend loss edge is within measurement uncertainty.
physics.optics:We proposed and realized a two-dimensional (2D) photonic bandedge laser surrounded by the photonic bandgap. The heterogeneous photonic crystal structure consists of two triangular lattices of the same lattice constant with different air hole radii. The photonic crystal laser was realized by room-temperature optical pumping of air-bridge slabs of InGaAsP quantum wells emitting at 1.55 micrometer. The lasing mode was identified from its spectral positions and polarization directions. A low threshold incident pump power of 0.24mW was achieved. The measured characteristics of the photonic crystal lasers closely agree with the results of real space and Fourier space calculations based on the finite-difference time-domain method.
physics.optics:The effect of lattice termination on the surface states in a two-dimensional truncated photonic crystal slab is experimentally studied in a high index contrast silicon-on-insulator system. A single-mode silicon strip waveguide that is separated from the photonic crystal by a trench of variable width is used to evanescently couple to surface states in the surrounding lattice. It is demonstrated that the dispersion of the surface states depends strongly on the specific termination of the lattice.
physics.optics:A new phasing algorithm has been used to determine the phases of diffuse elastic X-ray scattering from a non-periodic array of gold balls of 50 nm diameter. Two-dimensional real-space images, showing the charge-density distribution of the balls, have been reconstructed at 50 nm resolution from transmission diffraction patterns recorded at 550 eV energy. The reconstructed image fits well with scanning electron microscope (SEM) image of the same sample. The algorithm, which uses only the density modification portion of the SIR2002 program, is compared with the results obtained via the Gerchberg-Saxton-Fienup HIO algorithm. In this way the relationship between density modification in crystallography and the HiO algorithm used in signal and image processing is elucidated.
physics.optics:Iterative projection algorithms for phase retrieval are tested on two simple toy models. The result provides useful insights in the behavior of these algorithms.
physics.optics:We demonstrate a technique for shaping current inputs for the direct modulation of a semiconductor laser for digital communication. The introduction of shaped current inputs allows for the suppression of relaxation oscillations and the avoidance of dynamical memory in the physical laser device, i.e., the output will not be influenced by previously communicated information. On the example of time-optimized bits, the possible performance enhancement for high data rate communications is shown numerically.
physics.optics:Phase-stabilized 12-fs, 1-nJ pulses from a commercial Ti:sapphire oscillator are directly amplified in a chirped-pulse optical parametric amplifier and recompressed to yield near-transform-limited 17.3-fs pulses. The amplification process is demonstrated to be phase preserving and leads to 85-uJ, carrier-envelope-offset phase-locked pulses at 1 kHz for 0.9 mJ of pump, corresponding to a single-pass gain of 8.5 x 10^4.
physics.optics:We have observed for the first time a new photonic quantum ring emission of anti-whispering gallery modes from a negative mesa-type toroid cavity due to semiconductor photonic corrals.
physics.optics:We predict that nonlinear left-handed metamaterials can support both TE- and TM-polarized self-trapped localized beams, spatial electromagnetic solitons. Such solitons appear as single- and multi-hump beams, being either symmetric or antisymmetric, and they can exist due to the hysteresis-type magnetic nonlinearity and the effective domains of negative magnetic permeability.
physics.optics:The use of one or more gold nanoballs as reference objects for Fourier Transform holography (FTH) is analysed using experimental soft X-ray diffraction from objects consisting of separated clusters of these balls. The holograms are deconvoluted against ball reference objects to invert to images, in combination with a Wiener filter to control noise. A resolution of ~30nm, smaller than one ball, is obtained even if a large cluster of balls is used as the reference, giving the best resolution yet obtained by X-ray FTH. Methods of dealing with missing data due to a beamstop are discussed. Practical prepared objects which satisfy the FTH condition are suggested, and methods of forming them described.
physics.optics:We study the transmission properties of a nonlinear periodic structure containing alternating slabs of a nonlinear right handed material and a linear left handed material. We find that the transmission associated with the zero averaged- refractive- index gap exhibits a bistable characteristic that is relatively insensitive to incident angle. This is in contrast to the nonlinear behavior of the usual Bragg gap
physics.optics:By use of an imaging spectrometer we map the far-field ($\theta-\lambda$) spectra of 200 fs optical pulses that have undergone beam collapse and filamentation in a Kerr medium. By studying the evolution of the spectra with increasing input power and using a model based on stationary linear asymptotic wave modes, we are able to trace a consistent model of optical beam collapse high-lighting the interplay between conical emission, multiple pulse splitting and other effects such as spatial chirp.
physics.optics:Periodic structures consisting of alternating layers of positive index and negative index materials possess a novel band gap at the frequency at which the average refractive index is zero. We show that in the presence of a Kerr nonlinearity, this zero-n gap can switch from low transmission to a perfectly transmitting state, forming a nonlinear resonance or gap soliton in the process. This zero-n gap soliton is omnidirectional in contrast to the usual Bragg gap soliton of positive index periodic structures
physics.optics:Experimental evidence of mode-selective evanescent power coupling at telecommunication frequencies with efficiencies up to 75 % from a tapered optical fiber to a carefully designed metal nanoparticle plasmon waveguide is presented. The waveguide consists of a two-dimensional square lattice of lithographically defined Au nanoparticles on an optically thin silicon membrane. The dispersion and attenuation properties of the waveguide are analyzed using the fiber taper. The high efficiency of power transfer into these waveguides solves the coupling problem between conventional optics and plasmonic devices and could lead to the development of highly efficient plasmonic sensors and optical switches.
physics.optics:In optical second harmonic generation with normal dispersion, the virtually infinite bandwidth of the unbounded, hyperbolic, modulational instability leads to quenching of spatial multi-soliton formation and to the occurrence of a catastrophic spatio-temporal break-up when an extended beam is let to interact with an extremely weak external noise with coherence time much shorter than that of the pump.
physics.optics:Interfering liquid surface waves are generated by electrically driven vertical oscillations of two or more equispaced pins immersed in a liquid (water). The corresponding intensity distribution, resulting from diffraction of monochromatic light by the reflection phase grating formed on the liquid surface, is calculated theoretically and found to tally with experiments. The curious features of the diffraction pattern and its relation to the interference of waves on the liquid surface are used to measure the amplitude and wavelength of the resultant surface wave along the line joining the two sources of oscillation. Finally, a sample diffraction pattern obtained by optically probing surface regions where interference produces a lattice--like structure is demonstrated and qualitatively explained.
physics.optics:We report polarization tomography experiments on metallic nanohole arrays with square and hexagonal symmetry. As a main result, we find that a fully polarized input beam is partly depolarized after transmission through a nanohole array. This loss of polarization coherence is found to be anisotropic, i.e. it depends on the polarization state of the input beam. The depolarization is ascribed to a combination of two factors: i) the nonlocal response of the array due to surface plasmon propagation, ii) the non-plane wave nature of a practical input beam.
physics.optics:Using analytical modeling and detailed numerical simulations, we investigate properties of hybrid systems of Photonic Crystal micro-cavities which incorporate a highly non-linear Ultra Slow Light medium. We demonstrate that such systems, while being miniature in size (order wavelength), and integrable, could enable ultra-fast non-linear all-optical switching at single photon energy levels.
physics.optics:We fabricated two dimensional photonic crystal structures in zinc oxide films with focused ion beam etching. Lasing is realized in the near ultraviolet frequency at room temperature under optical pumping. From the measurement of lasing frequency and spatial profile of the lasing modes, as well as the photonic band structure calculation, we conclude that lasing occurs in the strongly localized defect modes near the edges of photonic band gap. These defect modes originate from the structure disorder unintentionally introduced during the fabrication process.
physics.optics:One dimensional rectangular metallic gratings enable enhanced transmission of light for specific resonance frequencies. Two kinds of modes participating to enhanced transmission have already been demonstrated : (i) waveguide modes and (ii) surface plasmon polaritons (SPP). Since the original paper of Hessel and Oliner \cite{hessel} pointing out the existence of (i), no progress was made in their understanding. We present here a carefull analysis, and show that the coupling between the light and such resonances can be tremendously improved using an {\it evanescent} wave. This leads to enhanced localisation of light in cavities, yielding, in particular, to a very selective light transmission through these gratings.
physics.optics:We describe an experiment showing a spontaneous symmetry breaking phenomenon between the intensities of the ordinary and extraordinary components of the fundamental field in intracavity type-II harmonic generation. It is based on a triply resonant dual cavity containing a type II phase matched $\chi^{(2)}$ crystal pumped at the fundamental frequency $\omega_0$. The pump beam generates in the cavity a second harmonic mode at frequency $2\omega_0$ which acts as a pump for frequency degenerate type II parametric down conversion. Under operating conditions which are precisely symmetric with respect to the ordinary and extraordinary components of the fundamental wave, we have observed a breaking of the symmetry on the intensities of these two waves in agreement with the theoretical predictions.
physics.optics:Unavoidable variations in size and position of the building blocks of photonic crystals cause light scattering and extinction of coherent beams. We present a new model for both 2 and 3-dimensional photonic crystals that relates the extinction length to the magnitude of the variations. The predicted lengths agree well with our new experiments on high-quality opals and inverse opals, and with literature data analyzed by us. As a result, control over photons is limited to distances up to 50 lattice parameters ($\sim 15 \mu$m) in state-of-the-art structures, thereby impeding large-scale applications such as integrated circuits. Conversely, scattering in photonic crystals may lead to novel physics such as Anderson localization and non-classical diffusion.
physics.optics:A semi-analytical method evaluates the error probability of DPSK signals with intrachannel four-wave-mixing (IFWM) in a highly dispersive fiber link with strong pulse overlap. Depending on initial pulse width, the mean nonlinear phase shift of the system can be from 1 to 2 rad for signal-to-noise ratio (SNR) penalty less than 1 dB. An approximated empirical formula, valid for penalty less than 2 dB, uses the variance of the differential phase of the ghost pulses to estimate the penalty.
physics.optics:The major sources causing deterioration of optical quality in extremely large optical telescopes are misadjustments of the mirrors, deformations of monolithic mirrors, and misalignments of segments in segmented mirrors. For active optics corrections, all three errors, which can partially compensate each other, are measured simultaneously. It is therefore of interest to understand the similarities and differences between the three corresponding types of modes which describe these errors. The first two types are best represented by Zernike polynomials and elastic modes respectively, both of them being continuous and smooth functions. The segment misaligment modes, which are derived by singular value decomposition, are by their nature not smooth and in general discontinuous. However, for mirrors with a large number of segments, the lowest modes become effectively both smooth and continuous. This paper derives analytical expressions for these modes, using differential operators and their adjoints, for the limit case of infinitesimally small segments. For segmented mirrors with approximately 1000 segments, it is shown that these modes agree well with the corresponding lowest singular value decomposition modes. Furthermore, the analytical expressions reveal the nature of the segment misalignment modes and allow for a detailed comparison with the elastic modes of monolithic mirrors. Some mathematical features emerge as identical in the two cases.
physics.optics:We report on remote delivery of 25 pJ broadband near-infrared femtosecond light pulses from a Ti:sapphire laser through 150 meters of single-mode optical fiber. Pulse distortion due to dispersion is overcome with pre-compensation using adaptive pulse shaping techniques, while nonlinearities are mitigated using an SF10 rod for the final stage of pulse compression. Near transform limited pulse duration of 130 fs is measured after the final compression.
physics.optics:High refractive index contrast optical microdisk resonators fabricated from silicon-on-insulator wafers are studied using an external silica fiber taper waveguide as a wafer-scale optical probe. Measurements performed in the 1500 nm wavelength band show that these silicon microdisks can support whispering-gallery modes with quality factors as high as 5.2 x 10^5, limited by Rayleigh scattering from fabrication induced surface roughness. Microdisks with radii as small as 2.5 microns are studied, with measured quality factors as high as 4.7 x 10^5 for an optical mode volume of 5.3 cubic wavelengths in the material.
physics.optics:We develop and demonstrate two numerical methods for solving the class of open cavity problems which involve a curved, cylindrically symmetric conducting mirror facing a planar dielectric stack. Such dome-shaped cavities are useful due to their tight focusing of light onto the flat surface. The first method uses the Bessel wave basis. From this method evolves a two-basis method, which ultimately uses a multipole basis. Each method is developed for both the scalar field and the electromagnetic vector field and explicit ``end user'' formulas are given. All of these methods characterize the arbitrary dielectric stack mirror entirely by its 2\times2 transfer matrices for s- and p-polarization. We explain both theoretical and practical limitations to our method. Non-trivial demonstrations are given, including one of a stack-induced effect (the mixing of near-degenerate Laguerre-Gaussian modes) that may persist arbitrarily far into the paraxial limit. Cavities as large as 50 \lambda are treated, far exceeding any vectorial solutions previously reported.
physics.optics:We recently proposed two-dimensional coupled photonic crystal microcavity arrays as a route to achieve a slow-group velocity of light (flat band) in all crystal directions. In this paper we present the first experimental demonstration of such structures with a measured group velocity below 0.008c and discuss the feasibility of applications such as low-threshold photonic crystal lasers with increased output powers, optical delay components and sensors.
physics.optics:We present the design and fabrication of photonic crystal structures exhibiting electromagnetic bands that are flattened in all crystal directions, i.e., whose frequency variation with wavevector is minimized. Such bands can be used to reduce group velocity of light propagating in arbitrary crystal direction, which is of importance for construction of miniaturized tunable optical delay components, low-threshold photonic crystal lasers, and study of nonlinear optics phenomena.
physics.optics:By direct numerical simulations of the kinoform refractive lens within the quazioptical approach the effects of shape misalinement were investigated. The quazioptical approach was based on numerical integration of parabolic equation for complex wave amplitude by spep-by-step method with "splitting" procedure. The effect of 2pi- shift compensation was calculated for different orders and imperfections. The performance of kinoform lens was compared with the compound refractive lens and thin lens approximation.
physics.optics:We review a novel method for characterizing both the spectral and spatial properties of resonant cavities within two-dimensional photonic crystals (PCs). An optical fiber taper serves as an external waveguide probe whose micron-scale field is used to source and couple light from the cavity modes, which appear as resonant features in the taper's wavelength-dependent transmission spectrum when it is placed within the cavity's near field. Studying the linewidth and depth of these resonances as a function of the taper's position with respect to the resonator produces quantitative measurements of the quality factor Q and modal volume Veff of the resonant cavity modes. Polarization information about the cavity modes can be obtained by studying their depths of coupling when the cavity is probed along different axes by the taper. This fiber-based technique has been used to measure Q ~ 40,000 and Veff ~ 0.9 cubic wavelengths in a graded square lattice PC microcavity fabricated in silicon. The speed and versatility of this fiber-based probe is highlighted, and a discussion of its applicability to other wavelength-scale resonant elements is given.
physics.optics:Micro-domes based on a combination of metallic and dielectric multilayer mirrors are studied using a fully vectorial numerical basis-expansion method that accurately accounts for the effects of an arbitrary Bragg stack and can efficiently cover a large range of dome shapes and sizes. Results are examined from three different viewpoints: (i) the ray-optics limit, (ii) the (semi-) confocal limit for which exact wave solutions are known, and (iii) the paraxial approximation using vectorial Gaussian beams.
physics.optics:An overview is provided over the physics of dielectric microcavities with non-paraxial mode structure; examples are microdroplets and edge-emitting semiconductor microlasers. Particular attention is given to cavities in which two spatial degrees of freedom are coupled via the boundary geometry. This generally necessitates numerical computations to obtain the electromagnetic cavity fields, and hence intuitive understanding becomes difficult. However, as in paraxial optics, the ray picture shows explanatory and predictive strength that can guide the design of microcavities. To understand the ray-wave connection in such asymmetric resonant cavities, methods from chaotic dynamics are required.
physics.optics:We analyze theoretically the propagation of surface plasmon polaritons about a metallic corner with a finite bend radius, using a one-dimensional model analogous to the scattering from a finite-depth potential well. We obtain expressions for the energy reflection and transmission coefficients in the short wavelength limit, as well as an upper bound for the transmittance. In certain cases we find that propagation on non-planar interfaces may result in lower losses than on flat surfaces, contrary to expectation. In addition, we also find that the maximum transmittance depends non-monotonously on the bend radius, allowing increased transmission with decreasing radius.
physics.optics:This book chapter is the first part of a review of nanoporous materials for optical applications. Whereas the second part [J.Sauer, F. Marlow and F.Schueth, pp. 153-172 of the same volume] discusses material properties, this part gives a self-contained discussion of fluorescence and lasing in dielectric microresonators, with special emphasis on the hexagonal morphology found in molecular-sieve-dye compounds.
physics.optics:We address the formation and propagation of multi-spot soliton packets in saturable Kerr nonlinear media with an imprinted harmonic transverse modulation of the refractive index. We show that, in sharp contrast to homogeneous media where stable multi-peaked solitons do not exist, the photonic lattices support stable higher-order structures in the form of soliton packets, or soliton trains. Intuitively, such trains can be viewed as made of several lowest order solitons bound together with appropriate relative phases and their existence as stable objects puts forward the concept of compact manipulation of several solitons as a single entity.
physics.optics:The formation, deformation, and break-up of liquid interfaces are ubiquitous phenomena in nature. In the present article we discuss the deformation of a liquid interface produced by optical radiation forces. Usually, the bending of such an interface by the radiation pressure of a c.w. laser beam is weak. However, the effect can be enhanced significantly if one works with a near-critical phase-separated liquid mixture, whereby the surface tension becomes weak. The bending may in this way become as large as several tenths of micrometers, even with the use of only moderate laser power. This near-criticality is a key element in our experimental investigations as reviewed in the article. The effect is achieved by working with a micellar phase of microemulsions, at room temperature. We give a brief survey of the theory of electromagnetic forces on continuous matter, and survey earlier experiments in this area, such as the Ashkin-Dziedzic optical radiation force experiment on a water/air surface (1973), the Zhang-Chang experiment on the laser-induced deformation of a micrometer-sized spherical water droplet (1988), and the experiment of Sakai et al. measuring surface tensions of interfaces in a non-contact manner (2001). Thereafter, we survey results we obtained in recent years by performing experiments on near-critical interfaces, such as interface bending in the linear regime, stationary large deformations of liquid interfaces, asymmetric pressure effects on interfaces under intense illumination, nonlinear deformations, and laser-sustained liquid columns.
physics.optics:We introduce solitons supported by Bessel photonic lattices in cubic nonlinear media. We show that the cylindrical geometry of the lattice, with several concentric rings, affords unique soliton properties and dynamics. In particular, besides the lowest-order solitons trapped in the center of the lattice, we find soliton families trapped at different lattice rings. Such solitons can be set into controlled rotation inside each ring, thus featuring novel types of in-ring and inter-ring soliton interactions.
physics.optics:We present a novel general framework to deal with forward and backward components of the electromagnetic field in axially-invariant nonlinear optical systems, which include those having any type of linear or nonlinear transverse inhomogeneities. With a minimum amount of approximations, we obtain a system of two first-order equations for forward and backward components explicitly showing the nonlinear couplings among them. The modal approach used allows for an effective reduction of the dimensionality of the original problem from 3+1 (three spatial dimensions plus one time dimension) to 1+1 (one spatial dimension plus one frequency dimension). The new equations can be written in a spinor Dirac-like form, out of which conserved quantities can be calculated in an elegant manner. Finally, these new equations inherently incorporate spatio-temporal couplings, so that they can be easily particularized to deal with purely temporal or purely spatial effects. Nonlinear forward pulse propagation and non-paraxial evolution of spatial structures are analyzed as examples.
physics.optics:Metamaterials--artificially structured materials with tailored electromagnetic response--can be designed to have properties difficult to achieve with existing materials. Here we present a structured metamaterial, based on conducting split ring resonators (SRRs), which has an effective index-of-refraction with a constant spatial gradient. We experimentally confirm the gradient by measuring the deflection of a microwave beam by a planar slab of the composite metamaterial over a broad range of frequencies. The gradient index metamaterial represents an alternative approach to the development of gradient index lenses and similar optics that may be advantageous, especially at higher frequencies. In particular, the gradient index material we propose may be suited for terahertz applications, where the magnetic resonant response of SRRs has recently been demonstrated.
physics.optics:A recent advance in optical coherence tomography (OCT), termed swept-source OCT, is generalized into a new technique, Fourier-domain OCT. It represents a realization of a full-field OCT system in place of the conventional serial image acquisition in transverse directions typically implemented in "flying-spot" mode. To realize the full-field image acquisition, a Fourier holography system illuminated with a swept-source is employed instead of a Michelson interferometer commonly used in OCT. Fourier-domain OCT offers a new leap in signal-to-noise ratio improvement, as compared to flying-spot OCT systems. This paper presents experimental evidence that the signal-to-noise ratio of this new technique is indeed improved.
physics.optics:We show that a slab of meta-material (with $\epsilon=\mu=-1+i\Delta$) possesses a vortex-like surface wave with no ability to transport energy, whose nature is completely different from a localized mode or a standing wave. Through computations based on a rigorous time-dependent Green's function approach, we demonstrate that such a mode inevitably generates characteristic image oscillations in two dimensional focusing with even a monochromatic source, which were observed in many numerical simulations, but such oscillations are weak in three dimensional focusing.
physics.optics:The holographic imaging of rigid objects with diode lasers emitting in many wavelengths in a sillenite Bi12TiO20 photorefractive crystal is both theoretically and experimentally investigated. It is shown that, due to the multi-wavelength emission and the typically large free spectral range of this light source, contour fringes appear on the holographic image corresponding to the surface relief, even in single-exposure recordings. The influence of the number of emitted modes on the fringe width is analysed, and the possible applications of the contour fringes in the field of optical metrology are pointed out.
physics.optics:We develop a point-scattering approach to the plane-wave optical transmission of subwavelength metal hole arrays. We present a real space description instead of the more conventional reciprocal space description; this naturally produces interfering resonant features in the transmission spectra and makes explicit the tensorial properties of the transmission matrix. We give transmission spectra simulations for both square and hexagonal arrays; these can be evaluated at arbitrary angles and polarizations.
physics.optics:We derive phase-matching conditions for four-wave mixing between solitons and linear waves in optical fibres with arbitrary dispersion and demonstrate resonant excitation of new spectral components via this process.
physics.optics:We have experimentally studied polarization properties of the two-dimensional coupled photonic crystal microcavity arrays, and observed a strong polarization dependence of the transmission and reflection of light from the structures - the effects that can be employed in building miniaturized polarizing optical components. Moreover, by combining these properties with a strong sensitivity of the coupled bands on the surrounding refractive index, we have demonstrated a detection of small refractive index changes in the environment, which is useful for construction of bio-chemical sensors.
physics.optics:We demonstrate a new class of hollow-core Bragg fibers that are composed of concentric cylindrical silica rings separated by nanoscale support bridges. We theoretically predict and experimentally observe hollow-core confinement over an octave frequency range. The bandwidth of bandgap guiding in this new class of Bragg fibers exceeds that of other hollow-core fibers reported in the literature. With only three rings of silica cladding layers, these Bragg fibers achieve propagation loss of the order of 1 dB/m.
physics.optics:We analyze, by the finite-difference time-domain numerical methods, several ways to enhance the directional emission from photonic crystal waveguides through the beaming effect recently predicted by Moreno et al. [Phys. Rev. E 69, 121402(R) (2004)], by engineering the surface modes and corrugation of the photonic crystal surface. We demonstrate that the substantial enhancement of the light emission can be achieved by increasing the refractive index of the surface layer. We also measure power of surface modes and reflected power and confirm that the enhancement of the directional emission is related to the manipulation of the photonic crystal surface modes.
physics.optics:It is shown that the monochromatic optical wave propagating through the medium with linear birefringence in presence of a signal electromagnetic wave (whose wavelength is equal to the polarization beats length), displays Faraday rotation having the frequency of the signal wave and unsuppressed by linear birefringence. The effect is resonant with respect to the frequency of a signal wave. The "sharpness" of the resonance is defined by length of the birefringent medium.
physics.optics:Second harmonic generation in a two dimensional nonlinear quasi-crystal is demonstrated for the first time. Temperature and wavelength tuning of the crystal reveal the uniformity of the pattern while angle tuning reveals the dense nature of the crystal's Fourier spectrum. These results compare well with theoretical predictions showing the excellent uniformity of the crystal and suggest that more complicated ``nonlinear holograms'' should be possible.
physics.optics:We show analytically, and numerically that highly-dispersive media can be used to drastically increase lifetimes of high-Q microresonators. In such a resonator, lifetime is limited either by undesired coupling to radiation, or by intrinsic absorption of the constituent materials. The presence of dispersion weakens coupling to the undesired radiation modes and also effectively reduces the material absorption.
physics.optics:The Lorentz transformations for the optical constants (electric permittivity, magnetic permeability and index of refraction) of moving media are considered.
physics.optics:The existence of resonant enhanced transmission and collimation of light waves by subwavelength slits in metal films [for example, see T.W. Ebbesen et al., Nature (London) 391, 667 (1998) and H.J. Lezec et al., Science, 297, 820 (2002)] leads to the basic question: Can a light pulse be enhanced and simultaneously localized in space and time by a subwavelength slit? To address this question, the spatial distribution of the energy flux of an ultrashort (femtosecond) wave-packet diffracted by a subwavelength (nanometer-size) slit was analyzed by using the conventional approach based on the Neerhoff and Mur solution of Maxwell's equations. The results show that a light pulse can be enhanced by orders of magnitude and simultaneously localized in the near-field diffraction zone at the nm- and fs-scales. Possible applications in nanophotonics are discussed.
physics.optics:We address the dynamics of higher-order solitons in optical lattices, and predict their self-splitting into the set of their single-soliton constituents. The splitting is induced by the potential introduced by the lattice, together with the imprinting of a phase tilt onto the initial multisoliton states. The phenomenon allows the controllable generation of several coherent solitons linked via their Zakharov-Shabat eigenvalues. Application of the scheme to the generation of correlated matter waves in Bose-Einstein condensates is discussed.
physics.optics:We report on a high-efficiency 461 nm blue light conversion from an external cavity-enhanced second-harmonic generation of a 922 nm diode laser with a quasi-phase-matched KTP crystal (PPKTP). By choosing a long crystal (LC=20 mm) and twice looser focusing (w0=43 $\mu$m) than the "optimal" one, thermal lensing effects due to the blue power absorption are minimized while still maintaining near-optimal conversion efficiency. A stable blue power of 234 mW with a net conversion efficiency of eta=75% at an input mode-matched power of 310 mW is obtained. The intra-cavity measurements of the conversion efficiency and temperature tuning bandwidth yield an accurate value d33(461 nm)=15 pm/V for KTP and provide a stringent validation of some recently published linear and thermo-optic dispersion data of KTP.
physics.optics:We consider an anisotropic homogenized composite medium (HCM) arising from isotropic particulate component phases based on ellipsoidal geometries. For cubically nonlinear component phases, the corresponding zeroth-order strong-permittivity-fluctuation theory (SPFT) (which is equivalent to the Bruggeman homogenization formalism) and second-order SPFT are established and used to estimate the constitutive properties of the HCM. The relationship between the component phase particulate geometry and the HCM constitutive properties is explored. Significant differences are highlighted between the estimates of the Bruggeman homogenization formalism and the second-order SPFT estimates. The prospects for nonlinearity enhancement are investigated.
physics.optics:Under certain circumstances, Voigt waves can propagate in a biaxial composite medium even though the component material phases individually do not support Voigt wave propagation. This phenomenon is considered within the context of the strong--permittivity--fluctuation theory. A generalized implementation of the theory is developed in order to explore the propagation of Voigt waves in any direction. It is shown that the correlation length--a parameter characterizing the distributional statistics of the component material phases--plays a crucial role in facilitating the propagation of Voigt waves in the homogenized composite medium.
physics.optics:In conventional approaches to the homogenization of random particulate composites, both the distribution and size of the component phase particles are often inadequately taken into account. Commonly, the spatial distributions are characterized by volume fraction alone, while the electromagnetic response of each component particle is represented as a vanishingly small depolarization volume. The strong-permittivity-fluctuation theory (SPFT) provides an alternative approach to homogenization wherein a comprehensive description of distributional statistics of the component phases is accommodated. The bilocally-approximated SPFT is presented here for the anisotropic homogenized composite which arises from component phases comprising ellipsoidal particles. The distribution of the component phases is characterized by a two-point correlation function and its associated correlation length. Each component phase particle is represented as an ellipsoidal depolarization region of nonzero volume. The effects of depolarization volume and correlation length are investigated through considering representative numerical examples. It is demonstrated that both the spatial extent of the component phase particles and their spatial distributions are important factors in estimating coherent scattering losses of the macroscopic field.
physics.optics:The polarization matrix ($2\times2$) obtained from two component eigen-spinors of spherical harmonics help us to evaluate the differential matrix $N$ of the anisotropic optical medium. The geometric phase is realized through {\it helicity} of photon, assuming the transmission of polarized light through the crystal which has been twisted about the normal to its surface over a closed path.
physics.optics:A circularly polarized rotationally symmetric paraxial laser beams carries hbar angular momentum per photon as spin. Focussing the beam with a rotationally symmetric lens cannot change this angular momentum flux, yet the focussed beam must have spin less than hbar per photon. The remainder of the original spin is converted to orbital angular momentum, manifesting itself as a longitudinal optical vortex at the focus. This demonstrates that optical orbital angular momentum can be generated by a rotationally symmetric optical system which preserves the total angular momentum of the beam.
physics.optics:The sign of the refractive index of any medium is soley determined by the requirement that the propagation of an electromagnetic wave obeys Einstein causality. Our analysis shows that this requirement predicts that the real part of the refractive index may be negative in an isotropic medium even if the electric permittivity and the magnetic permeability are both positive. Such a system may be a route to negative index media at optical frequencies. We also demonstrate that the refractive index may be positive in left-handed media that contain two molecular species where one is in its excited state.
physics.optics:This paper presents a novel approach to wave propagation inside the Fabry-Perot framework. It states that the time-averaged Poynting vector modulus could be nonequivalent with the squared-field amplitude modulus. This fact permits the introduction of a new kind of nonlinear medium whose nonlinearity is proportional to the time-averaged Poynting vector modulus. Its transmittance is calculated and found to differ with that obtained for the Kerr medium, whose nonlinearity is proportional to the squared-field amplitude modulus. The latter emphasizes the nonequivalence of these magnitudes. A space-time symmetry analysis shows that the Poynting nonlinearity should be only possible in noncentrosymmetric materials.
physics.optics:The resonant optical modes of a high permittivity dielectric prism with an equilateral triangular cross section are discussed. Eigenmode solutions of the scalar Helmholtz equation with Dirichlet boundary conditions, appropriate to a conducting boundary, are applied for this purpose. The particular plane wave components present in these modes are analyzed for their total internal reflection behavior and implied mode confinement when the conducting boundary is replaced by a sharp dielectric mismatch. Improvement in TIR confinement by adjusting the longitudinal wavevector $k_z$ is also discussed. For two-dimensional electromagnetic solutions ($k_z=0$), TE polarization leads to longer lifetime than TM polarization, assuming that escape of evanescent boundary waves at the corners is the primary decay process.
physics.optics:We present a simple polarizing Mach-Zehnder interferometer that can be used for optimal minimal ellipsometry: Only four intensities are measured to determine the three Stokes parameters, and an optimal choice for the four polarization projections can be achieved for any sufficiently small wavelength range of interest.
physics.optics:Gold micro-mirrors have been formed in silicon in an inverted pyramidal shape. The pyramidal structures are created in the (100) surface of a silicon wafer by anisotropic etching in potassium hydroxide. High quality micro-mirrors are then formed by sputtering gold onto the smooth silicon (111) faces of the pyramids. These mirrors show great promise as high quality optical devices suitable for integration into MOEMS systems.
physics.optics:We demonstrate low-threshold random lasing in random amplifying layered medium via photon localization. Lasing is facilitated by resonant excitation of localized modes at the pump laser wavelength, which are peaked deep within the sample with greatly enhanced intensity. Emission occurs into long-lived localized modes overlapping the localized gain region. This mechanism overcomes a fundamental barrier to reducing lasing thresholds in diffusive random lasers, in which multiple scattering restricts the excitation region to the proximity of the sample surface.
physics.optics:The rate of linear collisionless damping (Landau damping) in a classical electron gas confined to a heated ionized thin film is calculated. The general expression for the imaginary part of the dielectric tensor in terms of the parameters of the single-particle self-consistent electron potential is obtained. For the case of a deep rectangular well, it is explicitly calculated as a function of the electron temperature in the two limiting cases of specular and diffuse reflection of the electrons from the boundary of the self-consistent potential. For realistic experimental parameters, the contribution of Landau damping to the heating of the electron subsystem is estimated. It is shown that for films with a thickness below about 100 nm and for moderate laser intensities it may be comparable with or even dominate over electron-ion collisions and inner ionization.
physics.optics:We propose and analyze a new type of a resonator in an annular geometry which is based on a single defect surrounded by radial Bragg reflectors on both sides. We show that the conditions for efficient mode confinement are different from those of the conventional Bragg waveguiding in a rectangular geometry. A simple and intuitive approach to the design of optimal radial Bragg reflectors is proposed and employed, yielding chirped gratings. Small bending radii and strong control over the resonator dispersion are possible by the Bragg confinement. A design compromise between large Free Spectral Range (FSR) requirements and fabrication tolerances is suggested.
physics.optics:Lasing at telecommunication wavelengths from annular resonators employing radial Bragg reflectors is demonstrated at room temperature under pulsed optical pumping. Sub milliwatt pump threshold levels are observed for resonators with 0.5-1.5 wavelengths wide defects of radii 7-8 mm. The quality factors of the resonator modal fields are estimated to be on the order of a few thousands. The electromagnetic field is shown to be guided by the defect. Good agreement is found between the measured and calculated spectrum.
physics.optics:We address Bessel photonic lattices of radial symmetry imprinted in cubic Kerr-type nonlinear media and show that they support families of stable dipole-mode solitons featuring two out-of-phase light spots located in different lattice rings. We show that the radial symmetry of the Bessel lattices afford a variety of unique soliton dynamics including controlled radiation-free rotation of the dipole-mode solitons.
astro-ph.GA:The magnetic fields of our Milky Way galaxy are the main agent for cosmic rays to transport. In the last decade, much new knowledge has been gained from measurements of the Galactic magnetic fields. In the Galactic disk, from the RMs of a large number of newly discovered pulsars, the large-scale magnetic fields along the spiral arms have been delineated in a much larger region than ever before, with alternating directions in the arm and interarm regions. The toroidal fields in the Galactic halo were revealed to have opposite directions below and above the Galactic plane, which is an indication of an A0 mode dynamo operating in the halo. The strength of large-scale fields obtained from pulsar RM data has been found to increase exponentially towards the Galactic center. Compared to the steep Kolmogorov spectrum of magnetic energy at small scales, the large-scale magnetic fields show a shallow broken spatial magnetic energy spectrum.
astro-ph.GA:We present a list of interstellar absorption lines in the direction of HD 37061 in the M 43 nebula. Some of the absorption lines arise from atomic excited levels that are uncommon in interstellar clouds. The excited levels of Fe II are populated by fluorescence. We found a large number of H2 molecular absorption lines arising from vibrationally excited levels. The ortho/para H2 ratio is equal to 2.7. The H2 rotational temperature of vibrational levels 1 - 5 exceeds 2000 K.
astro-ph.GA:We present a new multi-fluid, grid MHD code PIERNIK, which is based on the Relaxing TVD scheme (Jin & Xin, 1995). The original scheme (see Trac & Pen (2003) and Pen et al. (2003)) has been extended by an addition of dynamically independent, but interacting fluids: dust and a diffusive cosmic ray gas, described within the fluid approximation, with an option to add other fluids in an easy way. The code has been equipped with shearing-box boundary conditions, and a selfgravity module, Ohmic resistivity module, as well as other facilities which are useful in astrophysical fluid-dynamical simulations. The code is parallelized by means of the MPI library. In this paper we present an extension of PIERNIK, which is designed for simulations of diffusive propagation of the Cosmic-Ray (CR) component in the magnetized ISM.
astro-ph.GA:Aims. High angular resolution N-band imaging is used to discern the torus of active galactic nuclei (AGN) from its environment in order to allow a comparison of its mid-infrared properties to the expectations of the unified scenario for AGN. Methods. We present VLT-VISIR images of 25 low-redshift AGN of different Seyfert types, as well as N-band SEDs of 20 of them. In addition, we compare our results for 19 of them to Spitzer IRS spectra. Results. We find that at a resolution of ~ 0.35", all the nuclei of our observed sources are point-like, except for 2 objects whose extension is likely of instrumental origin. For 3 objects, however, we observed additional extended circumnuclear emission, even though our observational strategy was not designed to detect it. Comparison of the VISIR photometry and Spitzer spectrophotometry indicates that the latter is affected by extended emission in at least 7 out of 19 objects and the level of contamination is (0.20 ~ 0.85) * F_IRS. In particular, the 10 um silicate emission feature seen in the Spitzer spectra of 6 type I AGN, possibly 1 type II AGN and 2 LINERs, also probably originates not solely in the torus but also in extended regions. Conclusions. Our results generally agree with the expectations from the unified scenario, while the relative weakness of the silicate feature supports clumpy torus models. Our VISIR data indicate that, for low-redshift AGN, a large fraction of Spitzer IRS spectra are contaminated by extended emission close to the AGN.
astro-ph.GA:The dark cloud Lynds 1622 is one of a few specific sites in the Galaxy where, relative to observed free-free and vibrational dust emission, there is a clear excess of microwave emission. In order to constrain models for this microwave emission, and to better establish the contribution which it might make to ongoing and near-future microwave background polarization experiments, we have used the Green Bank Telescope to search for linear polarization at 9.65 Ghz towards Lynds 1622. We place a 95.4% upper limit of 88 micro-Kelvin (123 micro-Kelvin at 99.7 confidence) on the total linear polarization of this source averaged over a 1'.3 FWHM beam. Relative to the observed level of anomalous emission in Stokes I these limits correspond to fractional linear polarizations of 2.7% and 3.5%.
astro-ph.GA:Alignment of dust by radiative torques (RATs) has proven to be the most promising mechanism to explain alignment in various astrophysical environments, from comet atmospheres to accretion disks, molecular clouds, and diffuse interstellar gas. We discuss some of the major advances, which include, first of all, formulating of the analytical model of RATs. This model was shown to reproduce well the torques acting on actual irregular dust grains and allowed studies of the parameter space for which the alignment happens with long axes perpendicular and parallel to the magnetic field. Such a study resulted in an important conclusion that, without any paramagnetic relaxation, the RAT alignment always happens for interstellar grains with long axes perpendicular to the magnetic field. We show that the gaseous bombardment in some cases increases the degree of alignment by knocking out grains from the positions of imperfect alignment when the grains rotate slowly to more stable positions of perfect alignment where grains rotate fast. In terms of pinwheel torques, important revisions have been made in the Lazarian and Draine model of grain flipping and thermal trapping. Those, however, do not change the major conclusion that very small grains (i.e. grain size smaller than ~0.03 micron) should be marginally aligned. Recent work made the RAT alignment a predictive theory which is ready for quantitative modeling of astrophysical polarization. We predict that the microwave emission from the Zodiacal dust presents an important contaminant, which should be included into foreground polarization templates.
astro-ph.GA:Bulges are of different types, morphologies and kinematics, from pseudo-bulges, close to disk properties (Sersic index, rotation fraction, flatenning), to classical de Vaucouleurs bulges, close to elliptical galaxies. Secular evolution and bar development can give rise to pseudo-bulges. To ensure prolonged secular evolution, gas flows are required along the galaxy life-time. There is growing evidence for cold gas accretion around spiral galaxies. This can explain the bar cycle of destruction and reformation, together with pseudo-bulge formation. However, bulges can also be formed through major mergers, minor mergers, and massive clumps early in the galaxy evolution. Bulge formation is so efficient that it is difficult to explain the presence of bulgeless galaxies today.
astro-ph.GA:Outward radiation pressure can exceed the inward gravitational pull on gas clouds in the neighbourhood of a luminous Active Galactic Nucleus (AGN). This creates a forbidden region for long-lived dusty clouds in the observed columnn density - Eddington fraction plane. (The Eddington fraction lambda_Edd is the ratio of the bolometric luminosity of an AGN to the Eddington limit for its black hole mass.) The Swift/BAT catalogue is the most complete hard X-ray selected sample of AGN and has 97 low redshift AGN with measured column densities N_H and inferred black hole masses. Eddington fractions for the sources have been obtained using recent bolometric corrections and the sources have been plotted on the N_H - lambda_Edd plane. Only one source lies in the forbidden region and it has a large value of N_H due to an ionized warm absorber, for which radiation pressure is reduced. The effective Eddington limit for the source population indicates that the high column density clouds in the more luminous objects lie within the inner few pc, where the central black hole provides at least half the mass. Our result shows that radiation pressure does affect the presence of gas clouds in the inner galaxy bulge. We discuss briefly how the N_H - lambda_Edd plane may evolve to higher redshift, when feedback due to radiation pressure may have been strong.
astro-ph.GA:We numerically evolve turbulence driven by the magnetorotational instability (MRI) in a 3D, unstratified shearing box and study its structure using two-point correlation functions. We confirm Fromang and Papaloizou's result that shearing box models with zero net magnetic flux are not converged; the dimensionless shear stress $\alpha$ is proportional to the grid scale. We find that the two-point correlation of the magnetic field shows that it is composed of narrow filaments that are swept back by differential rotation into a trailing spiral. The correlation lengths along each of the correlation function principal axes decrease monotonically with the grid scale. For mean azimuthal field models, which we argue are more relevant to astrophysical disks than the zero net field models, we find that: $\alpha$ increases weakly with increasing resolution at fixed box size; $\alpha$ increases slightly as the box size is increased; $\alpha$ increases linearly with net field strength, confirming earlier results; the two-point correlation function of the magnetic field is resolved and converged, and is composed of narrow filaments swept back by the shear; the major axis of the two-point increases slightly as the box size is increased; these results are code independent, based on a comparison of ATHENA and ZEUS runs. The velocity, density, and magnetic fields decorrelate over scales larger than $\sim H$, as do the dynamical terms in the magnetic energy evolution equations. We conclude that MHD turbulence in disks is localized, subject to the limitations imposed by the absence of vertical stratification, the use of an isothermal equation of state, finite box size, finite run time, and finite resolution
astro-ph.GA:We present the first Chandra/ACIS imaging study of the circumnuclear region of the nearby Seyfert galaxy NGC 1365. The X-ray emission is resolved into point-like sources and complex, extended emission. The X-ray morphology of the extended emission shows a biconical soft X-ray emission region extending ~5 kpc in projection from the nucleus, coincident with the high excitation outflow cones seen in optical emission lines particularly to the northwest. Harder X-ray emission is detected from a kpc-diameter circumnuclear ring, coincident with the star-forming ring prominent in the Spitzer mid-infrared images; this X-ray emission is partially obscured by the central dust lane of NGC 1365. Spectral fitting of spatially separated components indicates a thermal plasma origin for the soft extended X-ray emission (kT=0.57 keV). Only a small amount of this emission can be due to photoionization by the nuclear source. Detailed comparison with [OIII]5007 observations shows the hot interstellar medium (ISM) is spatially anticorrelated with the [OIII] emitting clouds and has thermal pressures comparable to those of the [OIII] medium, suggesting that the hot ISM acts as a confining medium for the cooler photoionized clouds. The abundance ratios of the hot ISM are fully consistent with the theoretical values for enrichment from Type II supernovae, suggesting that the hot ISM is a wind from the starburst circumnuclear ring. X-ray emission from a ~450 pc long nuclear radio jet is also detected to the southeast.
astro-ph.GA:A gap in phase-space, the loss cone (LC), is opened up by a supermassive black hole (MBH) as it disrupts or accretes stars in a galactic centre. If a star enters the LC then, depending on its properties, its interaction with the MBH will either generate a luminous electromagnetic flare or give rise to gravitational radiation, both of which are expected to have directly observable consequences. A thorough understanding of loss-cone refilling mechanisms is important for the prediction of astrophysical quantities, such as rates of tidal disrupting main-sequence stars, rates of capturing compact stellar remnants and timescales of merging binary MBHs. In this thesis, we use N-body simulations to investigate how noise from accreted satellites and other substructures in a galaxy's halo can affect the LC refilling rate.   Any N-body model suffers from Poisson noise which is similar to, but much stronger than, the two-body diffusion occurring in real galaxies. To lessen this spurious Poisson noise, we apply the idea of importance sampling to develop a new scheme for constructing N-body realizations of a galaxy model, in which interesting regions of phase-space are sampled by many low-mass particles. We use multimass N-body models of galaxies with centrally-embedded MBHs to study the effects of satellite flybys on LC refilling rates. We find that although the flux of stars into the initially emptied LC is enhanced, but the fuelling rate averaged over the entire subhalos is increased by only a factor 3 over the rate one expects from the Poisson noise due the discreteness of the stellar distribution.
astro-ph.GA:The structure and potential of a complex gravitational lens is reconstructed using the perturbative method presented in Alard 2007, MNRAS, 382L, 58; Alard 2008, MNRAS, 388, 375. This lens is composed of 6 galaxies belonging to a small group. The lens inversion is reduced to the problem of reconstructing non-degenerate quantities: the 2 fields of the perturbative theory of strong gravitational lenses. Since in the perturbative theory the circular source solution is analytical, the general properties of the perturbative solution can be inferred directly from the data. As a consequence, the reconstruction of the perturbative fields is not affected by degeneracy, and finding the best solution is only a matter of numerical refinement. The local shape of the potential and density of the lens are inferred from the perturbative solution, revealing the existence of an independent dark component that does not follow light. The most likely explanation is that the particular shape of the dark halo is due to the merging of cold dark matter halos. This is a new result illustrating the structure of dark halos at the scale of galaxies.
astro-ph.GA:We present kinematic simulations of a galactic dynamo model based on the large scale differential rotation and the small scale helical fluctuations due to supernova explosions. We report for the first time direct numerical simulations of the full galactic dynamo using an unparameterized global approach. We argue that the scale of helicity injection is large enough to be directly resolved rather than parameterized. While the actual superbubble characteristics can only be approached, we show that numerical simulations yield magnetic structures which are close both to the observations and to the previous parameterized mean field models. In particular, the quadrupolar symmetry and the spiraling properties of the field are reproduced. Moreover, our simulations show that the presence of a vertical inflow plays an essential role to increase the magnetic growth rate. This observation could indicate an important role of the downward flow (possibly linked with galactic fountains) in sustaining galactic magnetic fields.
astro-ph.GA:Strong gravitational lensing is a unique tool to model with great accuracy the inner mass distribution of massive galaxy clusters. In particular, clusters with large Einstein radii provide a wealth of multiply imaged systems in the cluster core allowing to determine precisely the shape of the central dark matter profile. This paper presents a spectroscopic survey in the massive cluster Abell 1703, displaying a large Einstein radius (28" at z=2.8) and a high number of strongly-lensed systems including a central ring-like configuration. We used LRIS on Keck to target multiple images and lensed galaxy candidates, and use the measured redshifts to constrain the mass distribution of the cluster using a parametric model. The data enable us to measure accurate redshifts in good agreement with their photometric redshifts, and to update the identification of multiply imaged systems by discovering 3 new systems and a radial counter image. We also report the discovery of a remarkably bright ~3.6 L* i-band dropout at z=5.827 in our mask which is only moderately magnified by the cluster (~3.0+/-0.08). The improved parametric mass model, including 16 multiple systems with 10 spectroscopic redshifts, further constrains the cluster-scale mass distribution with a generalized NFW profile of best-fit logarithmic slope alpha=0.92+/-0.04, concentration c200=4.72+/-0.40 and scale radius rs=476+/-45 kpc. Our strong-lensing model predicts a large scale shear signal consistent with Subaru weak-lensing measurements out to 4 Mpc h^-1. Together with the fact that the strong-lensing modeling requires a single dark matter clump, this suggests that Abell 1703 is a relaxed, unimodal cluster. This unique cluster could be probed further using deep X-ray, SZ and dynamics analysis, for a detailed study of the physics in a relaxed cluster. (abridged)
astro-ph.GA:Newborn neutron stars surrounded by hyperaccreting and neutrino-cooled disks may exist in some gamma-ray bursts (GRBs) and/or supernovae (SNe). In this paper we further study the structure of such a neutron-star disk based on the two-region (i.e., inner & outer) disk scenario following our previous work, and calculate the neutrino annihilation luminosity from the disk in various cases. We investigate the effects of the viscosity parameter, energy parameter (measuring the neutrino cooling efficiency of the inner disk) and outflow strength on the structure of the entire disk as well as the effect of emission from the neutron star surface boundary emission on the total neutrino annihilation rate. The inner disk satisfies the entropy-conservation or the advection-dominated self-similar structure depending on the energy parameter. An outflow from the disk decreases the density and pressure but increases the thickness of the disk. Moreover, compared with the black-hole disk, the neutrino annihilation luminosity above the neutron-star disk is higher, and the neutrino emission from the boundary layer could increase the neutrino annihilation luminosity by about one order of magnitude higher than the disk without boundary emission. The neutron-star disk with the advection-dominated inner disk could produce the highest neutrino luminosity while the disk with an outflow has the lowest. Although a heavily mass-loaded outflow from the neutron star surface at early times of neutron star formation prevents the outflow material from being accelerated to a high bulk Lorentz factor, an energetic ultrarelativistic jet via neutrino annihilation can be produced above the stellar polar region at late times if the disk accretion rate and the neutrino emission luminosity from the surface boundary layer are sufficiently high.
astro-ph.GA:Gas can be used to trace the formation and evolution of galaxies as well as the impact that the nuclear activity has on the surrounding medium. For nearby compact radio sources, we have used observations of neutral hydrogen - that we detected in emission distributed over very large scales - combined with the study of the stellar population and deep optical images to investigate the history of the formation of their host galaxy and the triggering of the activity. For more distant and more powerful compact radio sources, we have used optical spectra and HI - in absorption - to investigate the presence of fast outflows that support the idea that compact radio sources are young radio loud AGN observed during the early stages of their evolution and currently shredding their natal cocoons through extreme circumnuclear outflows. We will review the most recent results obtained from these projects.
astro-ph.GA:In the paradigm of hierarchical galaxy formation, luminous radio galaxies mark mass assembly peaks that should contain clusters of galaxies. Observations of the z=1.53 quasar 3C270.1 with the Spitzer Space Telescope at 3.6-24 micron and with the 6.5-m MMT in the z'- and Y-bands allow detection of potential cluster members via photometric redshifts. Compared with nearby control fields, there is an excess of 11 extremely red objects (EROs) at 1.33 < z_phot < 1.73, consistent with a proto-cluster around the quasar. The spectral energy distributions (SEDs) of 3/4 of the EROs are better fitted with passive elliptical galaxies than withdust-reddened starbursts, and of four sources well-detected on an archival HST snapshot image, all have undisturbed morphologies. However, one ERO, not covered by the HST image, is a double source with 0.8" separation on the z' image and a marginal (2sigma) 24 micron detection indicating a dust-enshrouded starburst. The EROs are more luminous than L* (H = -23.6 AB mag at z=1.5).
astro-ph.GA:We present a newly observed relation between galaxy mass and radial metallicity gradients of early-type galaxies. Our sample of 51 early-type galaxies encompasses a comprehensive mass range from dwarf to brightest cluster galaxies. The metallicity gradients are measured out to one effective radius by comparing nearly all of the Lick absorption-line indices to recent models of single stellar populations. The relation shows very different behaviour at low and high masses, with a sharp transition being seen at a mass of ~ 3.5 x 10^10 M_sun (velocity dispersion of ~140 km/s, M_B ~ -19). Low-mass galaxies form a tight relation with mass, such that metallicity gradients become shallower with decreasing mass and positive at the very low-mass end. Above the mass transition point several massive galaxies have steeper gradients, but a clear downturn is visible marked by a broad scatter. The results are interpreted in comparison with competing model predictions. We find that an early star-forming collapse could have acted as the main mechanism for the formation of low-mass galaxies, with star formation efficiency increasing with galactic mass. The high-mass downturn could be a consequence of merging and the observed larger scatter a natural result of different merger properties. These results suggest that galaxies above the mass threshold of ~ 3.5 x 10^10 M_sun might have formed initially by mergers of gas-rich disc galaxies and then subsequently evolved via dry merger events. The varying efficiency of the dissipative merger-induced starburst and feedback processes have shaped the radial metallicity gradients in these high-mass systems.
astro-ph.GA:We present the results of Spitzer IRS infrared 5-35 micron low-resolution spectroscopic energy diagnostics of ultraluminous infrared galaxies (ULIRGs) at z > 0.15, classified optically as non-Seyferts. Based on the equivalent widths of polycyclic aromatic hydrocarbon emission and the optical depths of silicate dust absorption features, we searched for signatures of intrinsically luminous, but optically elusive, buried AGNs in these optically non-Seyfert ULIRGs. We then combined the results with those of non-Seyfert ULIRGs at z < 0.15 and non-Seyfert galaxies with infrared luminosities L(IR) < 10^12Lsun. We found that the energetic importance of buried AGNs clearly increases with galaxy infrared luminosity, becoming suddenly discernible in ULIRGs with L(IR) > 10{12}Lsun. For ULIRGs with buried AGN signatures, a significant fraction of infrared luminosities can be accounted for by detected buried AGN and modestly-obscured (Av < 20 mag) starburst activity. The implied masses of spheroidal stellar components in galaxies for which buried AGNs become important roughly correspond to the value separating red massive and blue, less-massive galaxies in the local universe. Our results may support the widely-proposed AGN-feedback scenario as the origin of galaxy downsizing phenomena, where galaxies with currently larger stellar masses previously had higher AGN energetic contributions and star-formation-originating infrared luminosities, and have finished their major star-formation more quickly, due to stronger AGN feedback.
astro-ph.GA:We use absolutely calibrated data from the ARCADE 2 flight in July 2006 to model Galactic emission at frequencies 3, 8, and 10 GHz. The spatial structure in the data is consistent with a superposition of free-free and synchrotron emission. Emission with spatial morphology traced by the Haslam 408 MHz survey has spectral index beta_synch = -2.5 +/- 0.1, with free-free emission contributing 0.10 +/- 0.01 of the total Galactic plane emission in the lowest ARCADE 2 band at 3.15 GHz. We estimate the total Galactic emission toward the polar caps using either a simple plane-parallel model with csc|b| dependence or a model of high-latitude radio emission traced by the COBE/FIRAS map of CII emission. Both methods are consistent with a single power-law over the frequency range 22 MHz to 10 GHz, with total Galactic emission towards the north polar cap T_Gal = 0.498 +/- 0.028 K and spectral index beta = -2.55 +/- 0.03 at reference frequency 1 GHz. The well calibrated ARCADE 2 maps provide a new test for spinning dust emission, based on the integrated intensity of emission from the Galactic plane instead of cross-correlations with the thermal dust spatial morphology. The Galactic plane intensity measured by ARCADE 2 is fainter than predicted by models without spinning dust, and is consistent with spinning dust contributing 0.4 +/- 0.1 of the Galactic plane emission at 22 GHz.
astro-ph.GA:We present imaging and spectroscopic observations for six quasars at z>5.9 discovered by the Canada-France High-z Quasar Survey (CFHQS). The CFHQS contains sub-surveys with a range of flux and area combinations to sample a wide range of quasar luminosities at z~6. The new quasars have luminosities 10 to 75 times lower than the most luminous SDSS quasars at this redshift. The least luminous quasar, CFHQS J0216-0455 at z=6.01, has absolute magnitude M_1450=-22.21, well below the likely break in the luminosity function. This quasar is not detected in a deep XMM-Newton survey showing that optical selection is still a very efficient tool for finding high redshift quasars.
astro-ph.GA:We report a search for H2O megamasers in 274 SDSS type-2 AGNs (0.3 < z < 0.83), half of which can be classified as type-2 QSOs from their [OIII] 5007 luminosity, using the Robert C. Byrd Green Bank Telescope (GBT) and the Effelsberg 100-m radio telescope. Apart from the detection of the extremely luminous water vapor megamaser SDSS J080430.99+360718.1, already reported by Barvainis & Antonucci (2005), we do not find any additional line emission. This high rate of non-detections is compared to the water maser luminosity function created from the 78 water maser galaxies known to date and its extrapolation towards the higher luminosities of "gigamasers" that we would have been able to detect given the sensitivity of our survey. The properties of the known water masers are summarized and discussed with respect to the nature of high-z type-2 AGNs and megamasers in general. In the appendix, we list 173 additional objects (mainly radio galaxies, but also QSOs and galaxies) that were observed with the GBT, the Effelsberg 100-m radio telescope, or Arecibo Observatory without leading to the detection of water maser emission.
astro-ph.GA:Above redshift 6, the dominant source of neutral hydrogen in the Universe shifts from localized clumps in and around galaxies and filaments to a pervasive, diffuse component of the intergalactic medium (IGM). This transition tracks the global neutral fraction of hydrogen in the IGM and can be studied, in principle, through the redshifted 21 cm hyperfine transition line. During the last half of the reionization epoch, the mean (global) brightness temperature of the redshifted 21 cm emission is proportional to the neutral fraction, but at earlier times (10 < z < 25), the mean brightness temperature should probe the spin temperature of neutral hydrogen in the IGM. Measuring the (of order 10 mK) mean brightness temperature of the redshifted 21 cm line as a function of frequency (and hence redshift) would chart the early evolution of galaxies through the heating and ionizing of the IGM by their stellar populations. Experiments are already underway to accomplish this task or, at least, provide basic constraints on the evolution of the mean brightness temperature. We provide a brief overview of one of these projects, the Experiment to the Detect the Global EOR Signature (EDGES), and discuss prospects for future results.
astro-ph.GA:We exploit the recent observations of extremely metal-poor (EMP) stars in the Galactic halo and investigate the constraints on the IMF of the stellar population that left these low-mass survivors of [Fe/H]<-2.5 and the chemical evolution that they took part in. A high-mass IMF with the typical mass~10Msun and the overwhelming contribution of low-mass members of binaries to the EMP survivors are derived from the statistics of carbon-enriched EMP stars with and without the enhancement of s-process elements (Komiya et al. 2007). We first examine the analysis to confirm their results for various assumptions on the mass-ratio distribution function. As compared with the uniform distribution, the increase or decrease function of the mass ratio gives a higher- or lower-mass IMF, and a lower-mass IMF results for the independent distribution with the both members in the same IMF, but the derived ranges of typical mass differ less than by a factor of two and overlap for the extreme cases. Furthermore, we prove that the same constraints are placed on the IMF from the surface density of EMP stars estimated from the surveys and the chemical evolution consistent with the metal yields of theoretical supernova models. We then apply the derived high-mass IMF with the binary contribution to show that the observed MDF of EMP stars can be reproduced not only for the shape but also for the number of EMP stars. In particular, the scarcity of stars below [Fe/H]<-4 is naturally explained in terms of the hierarchical structure formation, and there is no indication of significant changes in the IMF for the EMP Population. The present study indicates that 3 HMP stars of [Fe/H]<-4 are the primordial stars that were born as the low-mass members of binaries before the host clouds were polluted by their own supernovae.
astro-ph.GA:The origin of S0 galaxies is discussed in the framework of early mergers in a Cold Dark Matter cosmology, and in a scenario where S0s are assumed to be former spirals stripped of gas. From an analysis of 127 early-type disk galaxies (S0-Sa), we find a clear correlation between the scale parameters of the bulge (r_eff) and the disk (h_R), a correlation which is difficult to explain if these galaxies were formed in mergers of disk galaxies. However, the stripping hypothesis, including quiescent star formation, is not sufficient to explain the origin of S0s either, because it is not compatible with our finding that S0s have a significantly smaller fraction of bars (46$\pm$6 %) than their assumed progenitors, S0/a galaxies (93$\pm$5 %) or spirals (64-69 %). Our conclusion is that even if a large majority of S0s were descendants of spiral galaxies, bars and ovals must play an important role in their evolution. The smaller fraction particularly of strong bars in S0 galaxies is compensated by a larger fraction of ovals/lenses (97$\pm$2 % compared to 82-83 % in spirals), many of which might be weakened bars. We also found massive disk-like bulges in nine of the S0 galaxies, bulges which might have formed at an early gas-rich stage of galaxy evolution.
astro-ph.GA:Statistics of the weak lensing of galaxies can be used to constrain cosmology if the galaxy shear can be estimated accurately. In general this requires accurate modelling of unlensed galaxy shapes and the point spread function (PSF). I discuss suboptimal but potentially robust methods for estimating galaxy shear by stacking images such that the stacked image distribution is closely Gaussian by the central limit theorem. The shear can then be determined by radial fitting, requiring only an accurate model of the PSF rather than also needing to model each galaxy accurately. When noise is significant asymmetric errors in the centroid must be corrected, but the method may ultimately be able to give accurate un-biased results when there is a high galaxy density with constant shear. It provides a useful baseline for more optimal methods, and a test-case for estimating biases, though the method is not directly applicable to realistic data. I test stacking methods on the simple toy simulations with constant PSF and shear provided by the GREAT08 project, on which most other existing methods perform significantly more poorly, and briefly discuss generalizations to more realistic cases. In the appendix I discuss a simple analytic galaxy population model where stacking gives optimal errors in a perfect ideal case.
astro-ph.GA:The analysis of the broad iron line profile in the X-ray spectra of active galactic nuclei and black hole X-ray binaries allows us to constrain the spin parameter of the black hole. We compare the constraints on the spin value for two X-ray sources, MCG-6-30-15 and GX 339-4, with a broad iron line using present relativistic line models in XSPEC - LAOR and KYRLINE. The LAOR model has the spin value set to the extremal value a=0.9982, while the KYRLINE model enables direct fitting of the spin parameter. The spin value is constrained mainly by the lower boundary of the broad line, which depends on the inner boundary of the disc emission where the gravitational redshift is maximal. The position of the inner disc boundary is usually identified with the marginally stable orbit which is related to the spin value. In this way the LAOR model can be used to estimate the spin value. We investigate the consistency of the LAOR and KYRLINE models. We find that the spin values evaluated by both models agree within the general uncertainties when applied on the current data. However, the results are apparently distinguishable for higher quality data, such as those simulated for the International X-ray Observatory (IXO) mission. We find that the LAOR model tends to overestimate the spin value and furthermore, it has insufficient resolution which affects the correct determination of the high-energy edge of the broad line.
astro-ph.GA:We report the results of interferometric HCN(1-0) and HCO+(1-0) observations of four luminous infrared galaxies (LIRGs), NGC 2623, Mrk 266, Arp 193, and NGC 1377, as a final sample of our systematic survey using the Nobeyama Millimeter Array. Our survey contains the most systematic interferometric, spatially-resolved, simultaneous HCN(1-0) and HCO+(1-0) observations of LIRGs. Ground-based infrared spectra of these LIRGs are also presented to elucidate the nature of the energy sources at the nuclei. We derive the HCN(1-0)/HCO+(1-0) brightness-temperature ratios of these LIRGs and confirm the previously discovered trend that LIRG nuclei with luminous buried AGN signatures in infrared spectra tend to show high HCN(1-0)/HCO+(1-0) brightness-temperature ratios, as seen in AGNs, while starburst-classified LIRG nuclei in infrared spectra display small ratios, as observed in starburst-dominated galaxies. Our new results further support the argument that the HCN(1-0)/HCO+(1-0) brightness-temperature ratio can be used to observationally separate AGN-important and starburst-dominant galaxy nuclei.
astro-ph.GA:We present WHAM observations of Halpha, [N II], and [S II] in the Smith Cloud. A map of Halpha emission from the cloud shows ionized gas coincident with the brightest H I emission, but nearly-as-bright Halpha in some regions with faint H I. The ionized mass of the cloud is at least as large as the neutral mass, > 10^6 M_sun. Ionized gas in the core of the Smith Cloud has an electron temperature 6000 K < T < 16000 K. The observed ratio [N II] / Halpha = 0.39 \pm 0.09 shows that the cloud has a non-primordial nitrogen abundance, 0.1 - 1 times solar.
astro-ph.GA:We model the large kinematic data sets for the four Milky Way dwarf spheroidal (dSph) satellites: Carina, Fornax, Sculptor and Sextans, recently published by Walker et al. The member stars are selected using a reliable dynamical interloper removal scheme tested on simulated data. Our member selection is more restrictive than the one based on metallicity indicators as it removes not only contamination due to Milky Way stars but also the unbound stars from the tidal tails. We model the cleaned data sets by adjusting the solutions of the Jeans equations to the profiles of the projected velocity dispersion and kurtosis. The data are well reproduced by models where mass follows light and the best-fitting stellar orbits are isotropic to weakly tangential, as expected from the tidal stirring scenario. The Fornax dwarf, with more than 2400 member stars, is a dSph galaxy with the most accurately determined mass to date: its 1 sigma error following from the sampling errors of the velocity moments is below 5 percent. With mass-to-light ratio of 97 solar units, Sextans seems to be the most dark matter dominated of the four dSph galaxies.
astro-ph.GA:Abreg: By combining HST/UDF imagery with kinematics from VLT/GIRAFFE we derive a physical model of distant galaxy J033245.11-274724.0 in a way similar to what can be done in the nearby Universe. Here we study the properties of a distant compact LIRGs galaxy. Given the photometric and spectro photometric accuracies, we can decompose the galaxy in sub components and correct them for reddening. The galaxy is dominated by a dust enshrouded disk revealed by UDF imagery. The disk radius is half that of the Milky Way and the galaxy have a SFR=20Mo/yr. Morphology and kinematics show that gas and stars together spiral inwards rapidly to feed the disk and the central regions. A combined system of a bar and two non rotating spiral arms regulates the material accretion, induces large sigma, with sigma larger than 100 km/s and redistributes the angular momentum (AM). The detailed physical properties resemble to the expectations from modeling a merger of two equal mass, gaseous rich galaxies, 0.5 Gyr after the merger. In its later evolution, this galaxy could become a late type galaxy which falls on the T-F relation, with an AM mostly induced by the orbital AM of the merger.
astro-ph.GA:We analyse new deep g and i-band imaging with the CFHT of 16 QSOs in the redshift range 0.9 to 1.3. The principal points of interest are the symmetry and signs of tidal effects in the QSO hosts and nearby (`companion') galaxies. The sample measures are compared with similar measures on randomly selected field galaxy samples. Asymmetry measures are made for all objects to g ~22, and magnitudes of all galaxies 2 magnitudes fainter. The QSOs are found in denser environments than the field, and are somewhat offset from the centroid of their surrounding galaxies. The QSO hosts appear more disturbed than other galaxies. While the QSO companions and field galaxies have the same average asymmetry, the distribution of asymmetry values is different. QSO companions within 15 arcsec are fainter than average field galaxies. We discuss scenarios that are consistent with these and other measured quantities.
astro-ph.GA:We present an analysis of far-infrared dust emission from diffuse cirrus clouds. This study is based on serendipitous observations at 160 microns at high galactic latitude with the Multiband Imaging Photometer (MIPS) onboard the Spitzer Space Telescope by the Spitzer Infrared Nearby Galaxies Survey (SINGS). These observations are complemented with IRIS data at 100 and 60 microns and constitute one of the most sensitive and unbiased samples of far infrared observations at small scale of diffuse interstellar clouds. Outside regions dominated by the cosmic infrared background fluctuations, we observe a substantial scatter in the 160/100 colors from cirrus emission. We compared the 160/100 color variations to 60/100 colors in the same fields and find a trend of decreasing 60/100 with increasing 160/100. This trend can not be accounted for by current dust models by changing solely the interstellar radiation field. It requires a significant change of dust properties such as grain size distribution or emissivity or a mixing of clouds in different physical conditions along the line of sight. These variations are important as a potential confusing foreground for extragalactic studies.
astro-ph.GA:Several recent studies have shown that the star cluster initial mass function (CIMF) can be well approximated by a power law, with indications for a steepening or truncation at high masses. This contribution considers the evolution of such a mass function due to cluster disruption, with emphasis on the part of the mass function that is observable in the first ~Gyr. A Schechter type function is used for the CIMF, with a power law index of -2 at low masses and an exponential truncation at M*. Cluster disruption due to the tidal field of the host galaxy and encounters with giant molecular clouds flattens the low-mass end of the mass function, but there is always a part of the `evolved Schechter function' that can be approximated by a power law with index -2. The mass range for which this holds depends on age, t, and shifts to higher masses roughly as t^0.6. Mean cluster masses derived from luminosity limited samples increase with age very similarly due to the evolutionary fading of clusters. Empirical mass functions are, therefore, approximately power laws with index -2, or slightly steeper, at all ages. The results are illustrated by an application to the star cluster population of the interacting galaxy M51, which can be well described by a model with M*=(1.9+/-0.5)x10^5 M_sun and a short (mass-dependent) disruption time destroying M* clusters in roughly a Gyr.
astro-ph.GA:Polarization carries information about the magnetic fields in interstellar clouds. The observations of polarized dust emission are used to study the role of magnetic fields in the evolution of molecular clouds and the initial phases of star-formation. We study the grain alignment with realistic simulations, assuming the radiative torques to be the main mechanism that spins the grains up. The aim is to study the efficiency of the grain alignment as a function of cloud position and to study the observable consequences of these spatial variations. Our results are based on the analysis of model clouds derived from MHD simulations. The continuum radiative transfer problem is solved with Monte Carlo methods to estimate the 3D distribution of dust emission and the radiation field strength affecting the grain alignment. We also examine the effect of grain growth in cores. We are able to reproduce the results of Cho & Lazarian using their assumptions. However, the anisotropy factor even in the 1D case is lower than their assumption of $\gamma = 0.7$, and thus we get less efficient radiative torques. Compared with our previous paper, the polarization degree vs. intensity relation is steeper because of less efficient grain alignment within dense cores. Without grain growth, the magnetic field of the cores is poorly recovered above a few $A_{\rm V}$. If grain size is doubled in the cores, the polarization of dust emission can trace the magnetic field lines possibly up to $A_{\rm V} \sim 10$ magnitudes. However, many of the prestellar cores may be too young for grain coagulation to play a major role. The inclusion of direction dependent radiative torque efficiency weakens the alignment. Even with doubled grain size, we would not expect to probe the magnetic field past a few magnitudes in $A_{\rm V}$.
astro-ph.GA:The very young open cluster (OC) NGC 2244 in the Rosette Nebula was studied with field-star-decontaminated 2MASS photometry, which shows the main-sequence (MS) stars and an abundant pre-MS (PMS) population. Fundamental and structural parameters were derived with colour-magnitude diagrams (CMDs), stellar radial density profiles (RDPs) and mass functions (MFs). Most previous studies centred NGC 2244 close to the bright K0V star 12 Monocerotis, which is not a cluster member. Instead, the near-IR RDP indicates a pronounced core near the O5 star HD 46150. We derive an age within 1--6 Myr, an absorption $\aV=1.7\pm0.2$, a distance from the Sun $\ds=1.6\pm0.2$ kpc ($\approx1.5$ kpc outside the Solar circle), an MF slope $\chi=0.91\pm0.13$ and a total (MS+PMS) stellar mass of $\sim625 \ms$. Its RDP is characterised by the core and cluster radii $\rc\approx5.6\arcmin$ ($\approx2.6$ pc) and $\rl\approx10\arcmin$ ($\approx4.7$ pc), respectively. Departure from dynamical equilibrium is suggested by the abnormally large core radius and the marked central stellar excess. We also investigate the elusive neighbouring OC NGC 2239, which is low-mass ($m_{MS+PMS}\approx301 \ms$), young ($5\pm4$ Myr) rather absorbed ($\aV=3.4\pm0.2$), and located in the background of NGC 2244 at $\ds=3.9\pm0.4$ kpc. Its RDP follows a King-like function of $\rc\approx0.5\arcmin\approx0.5$ pc and $\rl\approx5.0\arcmin\approx5.6$ pc. The MF slope, $\chi=1.24\pm0.06$, is essentially Salpeter's IMF. NGC 2244 is probably doomed to dissolution in a few $10^7$ yr. Wide-field extractions and field-star decontamination increase the stellar statistics and enhance both CMDs and RDPs, which is essential for faint and bright star clusters.
astro-ph.GA:From our radio observations of the magnetic field strength and large-scale pattern of spiral galaxies of different Hubble types and star formation rates (SFR) we conclude that - though a high SFR in the disk increases the total magnetic field strength in the disk and the halo - the SFR does not change the global field configuration nor influence the global scale heights of the radio emission. The similar scale heights indicate that the total magnetic field regulates the galactic wind velocities. The galactic wind itself may be essential for an effective dynamo action.
astro-ph.GA:We follow numerically the nonlinear evolution of the Parker instability in the presence of phase transitions from a warm to a cold HI interstellar medium in two spatial dimensions. The nonlinear evolution of the system favors modes that allow the magnetic field lines to cross the galactic plane. Cold HI clouds form with typical masses ~= 10^5 M_sun, mean densities ~= 20 cm^-3, mean magnetic field strengths ~= 4.3 muG (rms field strengths ~= 6.4 muG), mass-to-flux ratios ~= 0.1 - 0.3 relative to critical, temperatures ~= 50 K, (two-dimensional) turbulent velocity dispersions ~= 1.6 km s^-1, and separations ~= 500 pc, in agreement with observations. The maximum density and magnetic field strength are ~= 10^3 cm^-3 and ~= 20 muG, respectively. Approximately 60% of all HI mass is in the warm neutral medium. The cold neutral medium is arranged into sheet-like structures both perpendicular and parallel to the galactic plane, but it is also found almost everywhere in the galactic plane, with the density being highest in valleys of the magnetic field lines. `Cloudlets' also form whose physical properties are in quantitative agreement with those observed for such objects by Heiles (1967). The nonlinear phase of the evolution takes ~< 30 Myr, so that, if the instability is triggered by a nonlinear perturbation such as a spiral density shock wave, interstellar clouds can form within a time suggested by observations.
astro-ph.GA:It has been shown recently that the dynamical V-band mass-to-light ratios of compact stellar systems with masses from 10^6 to 10^8 Solar masses are not consistent with the predictions from simple stellar population (SSP) models. Top-heavy stellar initial mass functions (IMFs) in these so-called ultra compact dwarf galaxies (UCDs) offer an attractive explanation for this finding, the stellar remnants and retained stellar envelopes providing the unseen mass. We therefore construct a model which quantifies by how much the IMFs of UCDs would have to deviate in the intermediate-mass and high-mass range from the canonical IMF in order to account for the enhanced M/L_V ratio of the UCDs. The deduced high-mass IMF in the UCDs depends on the age of the UCDs and the number of faint products of stellar evolution retained by them. Assuming that the IMF in the UCDs is a three-part power-law equal to the canonical IMF in the low-mass range and taking 20% as a plausible choice for the fraction of the remnants of high-mass stars retained by UCDs, the model suggests the exponent of the high-mass IMF to be approximately 1.6 if the UCDs are 13 Gyr old (i.e. almost as old as the Universe) or approximately 1.0 if the UCDs are 7 Gyr old, in contrast to 2.3 for the Salpeter-Massey IMF. If the IMF was as top-heavy as suggested here, the stability of the UCDs might have been threatened by heavy mass loss induced by the radiation and evolution of massive stars. The central densities of UCDs must have been in the range 10^6 to 10^7 Solar masses per cubic parsec when they formed with star formation rates of 10 to 100 Solar masses per year.
astro-ph.GA:H-alpha emission from neutral halo clouds probes the radiation and hydrodynamic conditions in the halo. Armed with such measurements, we can explore how radiation escapes from the Galactic plane and how infalling gas can survive a trip through the halo. The Wisconsin H-Alpha Mapper (WHAM) is one of the most sensitive instruments for detecting and mapping optical emission from the ISM. Here, we present recent results exploring the ionization of two infallling high-velocity complexes. First, we report on our progress mapping H-alpha emission covering the full extent of Complex A. Intensities are faint (<100 mR; EM <0.2 pc cm^-6 but correlate on the sky and in velocity with 21-cm emission. Second, we explore the ionized component of some Anti-Center Complex clouds studied by Peek et al. (2007) that show dynamic shaping from interaction with the Galactic halo.
astro-ph.GA:This article reviews observations and models of the diffuse ionized gas that permeates the disk and halo of our Galaxy and others. It was inspired by a series of invited talks presented during an afternoon scientific session of the 65th birthday celebration for Professor Carl Heiles held at Arecibo Observatory in August 2004. This review is in recognition of Carl's long standing interest in and advocacy for studies of the ionized as well as the neutral components of the interstellar medium.
astro-ph.GA:Three recent surveys of 21-cm line emission in the Galactic plane, combining single dish and interferometer observations to achieve resolution of 1 arcmin to 2 arcmin, 1 km/s, and good brightness sensitivity, have provided some 650 absorption spectra with corresponding emission spectra for study of the distribution of warm and cool phase H I in the interstellar medium. These emission-absorption spectrum pairs are used to study the temperature of the interstellar neutral hydrogen in the outer disk of the Milky Way, outside the solar circle, to a radius of 25 kpc.   The cool neutral medium is distributed in radius and height above the plane with very similar parameters to the warm neutral medium. In particular, the ratio of the emission to the absorption, which gives the mean spin temperature of the gas, stays nearly constant with radius to 25 kpc radius. This suggests that the mixture of cool and warm phases is a robust quantity, and that the changes in the interstellar environment do not force the H I into a regime where there is only one temperature allowed. The mixture of atomic gas phases in the outer disk is roughly 15% to 20% cool (40 K to 60 K), the rest warm, corresponding to mean spin temperature 250 to 400 K.   The Galactic warp appears clearly in the absorption data, and other features on the familiar longitude-velocity diagram have analogs in absorption with even higher contrast than for 21-cm emission. In the third and fourth Galactic quadrants the plane is quite flat, in absorption as in emission, in contrast to the strong warp in the first and second quadrants. The scale height of the cool gas is similar to that of the warm gas, and both increase with Galactic radius in the outer disk.
astro-ph.GA:We have examined the physical conditions in the narrow-line region (NLR) of the Seyfert 2 galaxy Markarian 3, using long-slit spectra obtained with the Hubble Space Telescope/Space Telescope Imaging Spectrograph and photoionization models. We find three components of photoionized gas in the NLR. Two of these components, characterized by emission lines such as [NeV] 3426 and [OIII] 5007, lie within the envelope of the bi-conical region described in our previous kinematic study. A component of lower ionization gas, in which lines such as [OII] 3727 arise, is found to lie outside the bi-cone. Each of these components is irradiated by a power-law continuum which is attenuated by intervening gas, presumably closer to the central source. The radiation incident upon the low ionization gas, external to the bi-cone, is much more heavily absorbed. These absorbers are similar to the intrinsic UV and X-ray absorbers detected in many Seyfert 1 galaxies, which suggests that the collimation of the ionizing radiation occurs in a circumnuclear wind, rather than a thick, molecular torus. We estimate the mass for the observed NLR emitting gas to be 2 million solar-masses. It is likely that Markarian 3 acquired this gas through an on-going interaction with the spiral galaxy UGC 3422.
astro-ph.GA:We present the results of the EROS2 search for the hidden galactic matter of the halo through the gravitational microlensing of stars in the Magellanic clouds. Microlensing was also searched for and found in the Milky-Way plane, where foreground faint stars are expected to lens background stars. A total of 67 million of stars were monitored over a period of about 7 years. Hundreds of microlensing candidates have been found in the galactic plane, but only one was found towards the subsample of bright --well measured-- Magellanic stars. This result implies that massive compact halo objects (machos) in the mass range $10^{-7}M_\odot<M<5M_{\odot}$ are ruled out as a major component of the Milky Way Halo.
astro-ph.GA:Near-infrared spectroscopic data for the five Seyfert galaxies with jet-gas interaction Mrk 348, Mrk 573, Mrk 1066, NGC 7212, and NGC 7465, taken with the LIRIS near-infrared camera/spectrometer at the William Herschel Telescope (WHT) are reported. The long-slit spectra reveal the characteristic strong emission lines of this type of objects. Many forbidden transitions and hydrogen recombination lines are employed here to study the excitation and ionization mechanisms that are dominating the narrow-line region emission of these objects, that is affected by the radio-jet interaction. Several absorption features are also detected in the H and K bands of these galaxies, allowing us to identify the spectral types that are producing them. We find that the continuum can be reproduced by a combination of late-type stellar templates plus a Blackbody component associated to host dust, mainly contributing to the K band emission. The detection of the permitted O I and Fe II lines and broad components of the hydrogen recombination lines in the spectra of Mrk 573 and NGC 7465 allows the reclassification of these two galaxies that are not canonical Type-2 Seyferts: Mrk 573 is confirmed to be an obscured Narrow-line Seyfert 1 and NGC 7465 is revealed for the first time as a Type-1 LINER through its near-infrared spectrum.
astro-ph.GA:Context: An unexpectedly complex polyatomic chemistry exists in diffuse clouds, allowing detection of species such as C2H, C3H2, H2CO and NH3 which have relative abundances that are strikingly similar to those inferred toward the dark cloud TMC-1   Aims: We probe the limits of complexity of diffuse cloud polyatomic chemistry.   Methods: We used the IRAM Plateau de Bure Interferometer to search for galactic absorption from low-lying J=2-1 rotational transitions of A- and E-CH3OH near 96.740 GHz and used the VLA to search for the J=8-7 transition of HC5N at 21.3 GHz.   Results: Neither CH3OH nor HC5N were detected at column densities well below those of all polyatomics known in diffuse clouds and somewhat below the levels expected from comparison with TMC-1. The HCN/HC5N ratio is at least 3-10 times higher in diffuse gas than toward TMC-1.   Conclusions: It is possible to go to the well once (or more) too often
astro-ph.GA:Recent observations of astrophysical jets emanating from various galactic nuclei strongly suggest that a double layered structure, or a spine-sheath structure, is likely to be their common feature. We propose that such a sheath jet structure can be formed magnetohydrodynamically within a valley of the magnetic pressures, which is formed between the peaks due to the poloidal and toroidal components, with the centrifugal force acting on the rotating sheath plasma is balanced by the hoop stress of the toroidal field. The poloidal field concentrated near the polar axis is maintained by a converging plasma flow toward the jet region, and the toroidal field is developed outside the jet cone owing to the poloidal current circulating through the jet. Under such situations, the set of magnetohydrodynamic (MHD) equations allows two main types of solutions, at least, in the region far from the footpoint. The first type solution describes the jets of marginally bound nature. This type is realized when the jet temperature decreases like viral one, and neither the pressure-gradient nor the MHD forces, which are both determined consistently, cannot completely overcome the gravity even at infinity. The second type is realized under an isothermal situation, and the gravity is cancelled exactly by the pressure-gradient force. Hence, the jets of this type are accelerated purely by the MHD force. It is suggested also that these two types correspond, respectively, to the jets from type I and II radio galaxies in the Fanaroff-Riley classification.
astro-ph.GA:We describe a new sample of 226 GPS (GHz-Peaked Spectrum) source candidates selected using simultaneous 1-22 GHz multi-frequency observations with the RATAN-600 radio telescope. Sixty objects in our sample are identified as GPS source candidates for the first time. The candidates were selected on the basis of their broad-band radio spectra only. We discuss the spectral and variability properties of selected objects of different optical classes.
astro-ph.GA:We describe Monte Carlo models for the dynamical evolution of the nearby globular cluster NGC 6397. The code includes treatments of two-body relaxation, most kinds of three- and four-body interactions involving primordial binaries and those formed dynamically, the Galactic tide, and the internal evolution of both single and binary stars. We arrive at a set of initial parameters for the cluster which, after 12Gyr of evolution, gives a model with a fairly satisfactory match to the surface brightness profile, the velocity dispersion profile, and the luminosity function in two fields. We describe in particular those aspects of the evolution which distinguish this cluster from M4, which has a roughly similar mass and Galactocentric distance, but a qualitatively different surface brightness profile. Within the limitations of our modelling, we conclude that the most plausible explanation for the difference is fluctuations: both clusters are post-collapse objects, but sometimes have resolvable cores and sometimes not.
astro-ph.GA:The importance of the radiative feedback from SMBHs at the centers of elliptical galaxies is not in doubt, given the well established relations among electromagnetic output, black hole mass and galaxy optical luminosity. In addition, feedback due to mechanical and thermal deposition of energy from jets and winds emitted by the accretion disk around the central SMBH is also expected to occur. In this paper we improve and extend the accretion and feedback physics explored in our previous papers to include also a physically motivated mechanical feedback. We study the evolution of an isolated elliptical galaxy with the aid of a high-resolution 1-D hydrodynamical code, where the cooling and heating functions include photoionization and Compton effects, and restricting to models which include only radiative or only mechanical feedback. We confirm that for Eddington ratios above 0.01 both the accretion and radiative output are forced by feedback effects to be in burst mode, so that strong intermittencies are expected at early times, while at low redshift the explored models are characterized by smooth, very sub-Eddington mass accretion rates punctuated by rare outbursts. However, the explored models always fail some observational tests. If we assume the high mechanical efficiency of 10^{-2.3}, we find that most of the gas is ejected from the galaxy, the resulting X-ray luminosity is far less than is typically observed and little SMBH growth occurs. But models with low enough mechanical efficiency to accomodate satisfactory SMBH growth tend to allow too strong cooling flows and leave galaxies at z=0 with E+A spectra more frequently than is observed. We conclude that both types of feedback are required. Models with combined feedback are explored in a forthcoming paper [abridged]
astro-ph.GA:The colour-magnitude diagrams of resolved stellar populations are the best tool to study the star formation histories of the host galactic regions. In this review the method to derive star formation histories by means of synthetic colour-magnitude diagrams is briefly outlined, and the results of its application to resolved galaxies of various morphological types are summarized. It is shown that all the galaxies studied so far were already forming stars at the lookback time reached by the observational data, independently of morphological type and metallicity. Early-type galaxies have formed stars predominantly, but in several cases not exclusively, at the earliest epochs. All the other galaxies appear to have experienced rather continuous star formation activities throughout their lifetimes, although with significant rate variations and, sometimes, short quiescent phases.
astro-ph.GA:We present an analysis of late-O/early-B-powered, parsec-sized bubbles and associated star-formation using 2MASS, GLIMPSE, MIPSGAL and MAGPIS surveys. Three bubbles were selected from the Churchwell et al. (2007) catalog. We confirm that the structure identified in Watson et al. (2008) holds in less energetic bubbles, i.e. a PDR, identified by 8 um emission due to PAHs surrounds hot dust, identified by 24 um emission and ionized gas, identified by 20 cm continuum. We estimate the dynamical age of two bubbles by comparing bubble sizes to numerical models of Hosokawa & Inutsuka (2006). We also identify and analyze candidate young stellar objects (YSOs) using SED fitting and identify sites of possible triggered star-formation. Lastly, we identify likely ionizing sources for two sources based on SED fitting.
astro-ph.GA:Methods: 12CO emission is imaged in position and position-velocity space analyzed statistically, and then compared with maps of total reddening and with models of the C+ - CO transition in H2-bearing diffuse clouds. Results: Around Zeta Oph, 12CO emission appears in two distinct intervals of reddening centered near EBV = 0.4 and 0.65 mag, of which < 0.2 mag is background material. Within either interval, the integrated 12CO intensity varies up to 6-12 K-km/s compared to 1.5 K-km/s toward Zeta Oph. Nearly 80% of the individual profiles have velocity dispersions < 0.6 km/s, which are subsonic at the kinetic temperature derived from H2 toward Zeta Oph, 55 K. Partly as a result, 12CO emission exposes the internal, turbulent, supersonic (1-3 km/s) gas flows with especial clarity in the cores of strong lines. The flows are manifested as resolved velocity gradients in narrow, subsonically-broadened line cores. Conclusions: The scatter between N(CO) and EBV in global, CO absorption line surveys toward bright stars is present in the gas seen around Zeta Oph, reflecting the extreme sensitivity of N(12CO) to ambient conditions. The two-component nature of the optical absorption toward Zeta Oph is coincidental and the star is occulted by a single body of gas with a complex internal structure, not by two distinct clouds. The very bright 12CO lines in diffuse gas arise at N(H2) ~ 10^21/cm^2 in regions of modest density n(H) ~ 200-500/cc and somewhat more complete C+-CO conversion. Given the variety of structure in the foreground gas, it is apparent that only large surveys of absorption sightlines can hope to capture the intrinsic behavior of diffuse gas.
astro-ph.GA:Aims: We show the existence of a small family of inner-galaxy dust lanes and dust lane standing shocks beyond the two major ones that were previously known to exist Methods: We analyze images of CO emission in the inner regions of the Galaxy Results: The peculiar kinematics of the major dust lane features are repeated in several other distinct instances at l > 0deg, in one case at a contrary location 100 pc above the galactic equator at l > 3degr at the upper extremity of Clump 2. Like the previously-known dust lanes, these new examples are alsoassociated with localized, exceptionally broad line profiles believed to be characteristic of the shredding of neutral gas at the standing dust lane shocks. Conclusions: There may be secondary dust lane and standing shocks in the Milky Way bulge. The vertical structure provides a temporal sequence for understanding the secular evolution of gas flow in the bar.
astro-ph.GA:Context: Over the past thirty years a wealth of observations of CO and other molecules in optical/uv absorption in diffuse clouds has accumulated for which no comparable CO emission line data exist. Aims: To acquire mm-wave J=1-0 CO emission line profiles toward a substantial sample of commonly-studied optical/uv absorption line targets and to compare with the properties of the absorbing gas, especially the predicted emission line strengths. Methods: Using the ARO 12m telescope we observed mm-wavelength J=1-0 CO emission with spectral resolution R ~ 3x10^6 and spatial resolution 1' toward a sample of 110 lines of sight previously studied in optical/uv absorption lines of CO, \HH, CH, etc. Results: Interstellar CO emission was detected along 65 of the 110 lines of sight surveyed and there is a general superabundance of CO emission given the distribution of galactic latitudes in the survey sample. Much of the emission is optically thick or very intense and must emanate from dark clouds or warm dense gas near HII regions. Conclusions: Judging from the statistical superabundance of CO emission, seen also in the total line of sight reddening, the OB star optical/uv absorption line targets must be physically associated with the large quantities of neutral gas whose CO emission was detected, in which case they are probably influencing the absorbing gas by heating and/or photoionizing it. This explains why CO/H2 and 12CO/13CO ratios differ somewhat between $uv$ and mm-wave absorption line studies. Because the lines of sight have been preselected to have AV < 1 mag, relatively little of the associated material actually occults the targets, making it difficult for CO emission line observations to isolate the foreground gas contribution.
astro-ph.GA:We have obtained deep multi-object optical spectra of 49 HII regions in the outer disk of the spiral galaxy M83 (=NGC 5236) with the FORS2 spectrograph at the Very Large Telescope. The targets span the range in galactocentric distance between 0.64 and 2.64 times the R25 isophotal radius (5.4-22.3 kpc), and 31 of them are located at R>R25, thus belonging to the extreme outer disk of the galaxy, populated by UV complexes revealed recently by the GALEX satellite. In order to derive the nebular chemical abundances, we apply several diagnostics of the oxygen abundance, including R23, [NII]/[OII] and the [OIII]4363 auroral line, which was detected in four HII regions. We find that, while inwards of the optical edge the O/H ratio follows the radial gradient known from previous investigations, the outer abundance trend flattens out to an approximately constant value. The latter varies, according to the adopted diagnostic, between 12+log(O/H)=8.2 and 12+log(O/H)=8.6 (i.e. from approximately 1/3 the solar oxygen abundance to nearly the solar value). An abrupt discontinuity in the radial oxygen abundance trend is also detected near the optical edge of the disk. These results are tentatively linked to the flat gas surface density in the outskirts of the galaxy, the relatively unevolved state of the extended disk of M83, and the redistribution of chemically enriched gas following a past galaxy encounter.
astro-ph.GA:Methods: The microscopic equations of H2-formation and protonation are integrated numerically over time in such a manner that the overall structures evolve self-consistently under benign conditions. Results: The equilibrium H2 formation timescale in an H I cloud with N(H) ~ 4x10^{20}/cm^2 is 1-3 x 10^7 yr, nearly independent of the assumed density or H2 formation rate constant on grains, etc. Attempts to speed up the evolution of the H2-fraction would require densities well beyond the range usually considered typical of diffuse gas. The calculations suggest that, under benign, quiescent conditions, formation of H2 is favored in larger regions having moderate density, consistent with the rather high mean kinetic temperatures measured in H2, 70-80 K. Formation of H3+ is essentially complete when H2-formation equilibrates but the final abundance of H3+ appears more nearly at the very last instant. Chemistry in a weakly-molecular gas has particular properties so that the abundance patterns change appreciably as gas becomes more fully molecular, either in model sequences or with time in a single model. One manifestation of this is that the predicted abundance of H3+ is much more weakly dependent on the cosmic-ray ionization rate when n(H2)/n(H) < 0.05. In general, high abundances of H3+ do not enhance the abundances of other species (e.g. HCO+) but late-time OH formation proceeds most vigourously in more diffuse regions having modest density, extinction and H2 fraction and somewhat higher fractional ionization, suggesting that atypically high OH/H2 abundance ratios might be found optically in diffuse clouds having modest extinction.
astro-ph.GA:The Parkes Galactic All-Sky Survey (GASS) is a survey of Galactic atomic hydrogen (HI) emission in the Southern sky covering declinations $\delta \leq 1^{\circ}$ using the Parkes Radio Telescope. The survey covers $2\pi$ steradians with an effective angular resolution of ~16', at a velocity resolution of 1.0 km/s, and with an rms brightness temperature noise of 57 mK. GASS is the most sensitive, highest angular resolution survey of Galactic HI emission ever made in the Southern sky. In this paper we outline the survey goals, describe the observations and data analysis, and present the first-stage data release. The data product is a single cube at full resolution, not corrected for stray radiation. Spectra from the survey and other data products are publicly available online.
astro-ph.GA:The magnetic structure in the Galactic disk, the Galactic center and the Galactic halo can be delineated more clearly than ever before. In the Galactic disk, the magnetic structure has been revealed by starlight polarization within 2 or 3 kpc of the Solar vicinity, by the distribution of the Zeeman splitting of OH masers in two or three nearby spiral arms, and by pulsar dispersion measures and rotation measures in nearly half of the disk. The polarized thermal dust emission of clouds at infrared, mm and submm wavelengths and the diffuse synchrotron emission are also related to the large-scale magnetic field in the disk. The rotation measures of extragalactic radio sources at low Galactic latitudes can be modeled by electron distributions and large-scale magnetic fields. The statistical properties of the magnetized interstellar medium at various scales have been studied using rotation measure data and polarization data. In the Galactic center, the non-thermal filaments indicate poloidal fields. There is no consensus on the field strength, maybe mG, maybe tens of uG. The polarized dust emission and much enhanced rotation measures of background radio sources are probably related to toroidal fields. In the Galactic halo, the antisymmetric RM sky reveals large-scale toroidal fields with reversed directions above and below the Galactic plane. Magnetic fields from all parts of our Galaxy are connected to form a global field structure. More observations are needed to explore the untouched regions and delineate how fields in different parts are connected.
astro-ph.GA:The source J 1128+5925 was found recently to show strong intraday variability at radio wavelengths and its radio variability may come from interstellar scintillation. In optical, the object was quiet in our 2007 monitoring session. Here we report the results of our new optical monitoring of this source in 2008. In addition to confirm our 2007 results, that the object did not display any clear variation on timescales from hour--day to month, we provide evidence that the object does not vary on timescale of one year, and it is probably intrinsically quiet in optical domain. Its very different behaviors in optical and radio regimes can be naturally explained if its strong radio variability comes from interstellar scintillation.
astro-ph.GA:The high redshift GPS quasar PKS 0858-279 exhibits the following properties which make the source unusual. Our RATAN-600 monitoring of 1-22 GHz spectrum has detected broad-band radio variability with high amplitude and relatively short time scale. In the same time, the milliarcsecond scale structure observed in a snapshot VLBA survey turned out to be very resolved which is not expected from the fast flux density variations. We performed 1.4-22 GHz VLBA observations of this quasar in 2005-2007. It has revealed a core-jet morphology. A high Doppler factor delta is suggested for the jet, its nature is discussed in this report on the basis of the multi-frequency VLBA and RATAN data collected. Synchrotron self-absorption was confirmed to be dominating at low frequencies, the magnetic field strength of the dominating jet feature is estimated of an order of 0.1*delta mG.
astro-ph.GA:We present photometric evolution models of galaxies, in which, in addition to the stellar component, the effects of an evolving dusty interstellar medium have been included with particular care. Starting from the work of Calura, Pipino & Matteucci (2008), in which chemical evolution models have been used to study the evolution of both the gas and dust components of the interstellar medium in the solar neighbourhood, elliptical and irregular galaxies, it has been possible to combine these models with a spectrophotometric stellar code that includes dust reprocessing (GRASIL) (Silva et al. 1998) to analyse the evolution of the spectral energy distributions (SED) of these galaxies. We test our models against observed SEDs both in the local universe and at high redshift and use them to predict how the percentage of reprocessed starlight evolves for each type of galaxy. The importance of following the dust evolution is investigated by comparing our results with those obtained by adopting simple assumptions to treat this component.
astro-ph.GA:Infrared photometry and later infrared spectroscopy provided powerful diagnostics to distinguish between the main emission mechanisms in galaxies: AGN and Starburst. After the pioneering work on infrared photometry with IRAS in the far-IR and the S.Pedro Martir and ESO ground-based work in the near-IR, ISO photometry extended up to 200um the coverage of the galaxies energy distributions. Then Spitzer collected accurate mid-infrared spectroscopy on different samples of galaxies. We will review the work done on the 12um galaxy sample since the times of IRAS photometry to the new Spitzer spectroscopy. The main results on the multifrequency data of 12um selected Seyfert galaxies are presented and discussed in the light of unification and evolution models. The spectroscopic work of Spitzer will soon be complemented at longer wavelengths by the Herschel spectrometers and in the future by SPICA at higher redshift.
astro-ph.GA:We investigate the sample of 213 GPS sources selected from simultaneous multi-frequency 1-22 GHz observations obtained with RATAN-600 radio telescope. We use publicly available data to characterize parsec-scale structure of the selected sources. Among them we found 121 core dominated sources, 76 Compact Symmetric Object (CSO) candidates (24 of them are highly probable), 16 sources have complex parsec-scale morphology. Most of GPS galaxies are characterized by CSO-type morphology and lower observed peak frequency (~1.8 GHz). Most of GPS quasars are characterized by "core-jet"-type morphology and higher observed peak frequency (~3.6 GHz). This is in good agreement with previous results. However, we found a number of sources for which the general relation CSO - galaxy, core-jet - quasar does not hold. These sources deserve detailed investigation. Assuming simple synchrotron model of a homogeneous cloud we estimate characteristic magnetic field in parsec-scale components of GPS sources to be B ~ 10 mG.
astro-ph.GA:Accretion disks in AGN should be subject to the same type of instability as in cataclysmic variables (CVs) or in low-mass X-ray binaries (LMXBs), which leads to dwarf nova and soft X-ray transient outbursts. It has been suggested that this thermal/viscous instability can account for the long term variability of AGNs. We test this assertion by presenting a systematic study of the application of the disk instability model (DIM) to AGNs. We are using the adaptative grid numerical code we have developed in the context of CVs, enabling us to fully resolve the radial structure of the disk. We show that, because in AGN disks the Mach numbers are very large, the heating and cooling fronts are so narrow that they cannot be resolved by the numerical codes that have been used until now. In addition, these fronts propagate on time scales much shorter than the viscous time. As a result, a sequence of heating and cooling fronts propagate back and forth in the disk, leading only to small variations of the accretion rate onto the black hole, with short quiescent states occurring for very low mass transfer rates only. Truncation of the inner part of the disk by e.g. an ADAF does not alter this result, but enables longer quiescent states. Finally we discuss the effects of irradiation by the central X-ray source, and show that, even for extremely high irradiation efficiencies, outbursts are not a natural outcome of the model.
astro-ph.GA:We outline a method for fitting binary-lens caustic-crossing microlensing events based on the alternative model parameterisation proposed and detailed in Cassan (2008). As an illustration of our methodology, we present an analysis of OGLE-2007-BLG-472, a double-peaked Galactic microlensing event with a source crossing the whole caustic structure in less than three days. In order to identify all possible models we conduct an extensive search of the parameter space, followed by a refinement of the parameters with a Markov Chain-Monte Carlo algorithm. We find a number of low-chi2 regions in the parameter space, which lead to several distinct competitive best models. We examine the parameters for each of them, and estimate their physical properties. We find that our fitting strategy locates several minima that are difficult to find with other modelling strategies and is therefore a more appropriate method to fit this type of events.
astro-ph.GA:We present new interferometric data obtained with MIDI (MID infrared Interferometric instrument) for the Seyfert II galaxy NGC 1068, with an extensive coverage of sixteen uv points. These observations resolve the nuclear mid-infrared emission from NGC 1068 in unprecedented detail with a maximum resolution of 7 mas. For the first time, sufficient uv points have been obtained, allowing us to generate an image of the source using maximum entropy image reconstruction. The features of the image are similar to those obtained by modelling. We find that the mid-infrared emission can be represented by two components, each with a Gaussian brightness distribution. The first, identified as the inner funnel of the obscuring torus, is hot (800K), 1.35 parsec long, and 0.45 parsec thick in FWHM at a PA=-42 degrees (from north to east). It has an absorption profile different than standard interstellar dust and with evidence for clumpiness. The second component is 3 by 4 pc in FWHM with T=300K, and we identify it with the cooler body of the torus. The compact component is tilted by 45 degrees with respect to the radio jet and has similar size and orientation to the observed water maser distribution. We show how the dust distribution relates to other observables within a few parsecs of the core of the galaxy such as the nuclear masers, the radio jet, and the ionization cone. We compare our findings to a similar study of the Circinus galaxy and other relevant studies. Our findings shed new light on the relation between the different parsec-scale components in NGC 1068 and the obscuring torus.
astro-ph.GA:Blue hook (BHk) stars are a rare class of horizontal branch stars that so far have been found in only very few Galactic globular clusters (GCs). The dominant mechanism for producing these objects is currently still unclear. In order to test if the presence of BHk populations in a given GC is linked to specific physical or structural cluster properties, we have constructed a parent sample of GCs for which existing data is sufficient to establish the presence or absence of BHk populations with confidence. We then compare the properties of those clusters in our parent sample that do contain a BHk population to those that do not. We find that there is only one compelling difference between BHk and non-BHk clusters: all known BHk clusters are unusually massive. However, we also find that the BHk clusters are consistent with being uniformly distributed within the cumulative mass distribution of the parent sample. Thus, while it is attractive to suggest there is is a lower mass cut-off for clusters capable of forming BHk stars, the data do not require this. Instead, the apparent preference for massive clusters could still be a purely statistical effect: intrinsically rare objects can only be found by searching a sufficiently large number of stars.
astro-ph.GA:The goal of this paper is to provide a numerically fast and stable description for the microlensing amplification of an extended source (either uniform or limb-darkened) that holds in any amplification regime. We show that our method of evaluating the amplification can be implemented into a light-curve fitting routine using the Levenberg-Marquardt algorithm. We compare the accuracy and computation times to previous methods that either work in the high-amplification regime only, or require special treatments due to the singularity of elliptic integrals.   In addition, we also provide the equations including finite lens effects in microlensing light curves. We apply our methods to the MACHO-1995-BLG-30 and the OGLE-2003-BLG-262 events and obtain results consistent to former studies. We derive an upper limit for the OGLE-2003-BLG-262 event lens size.   We conclude that our method allows to simultaneously search for point-source and finite-source microlensing events in future large area microlensing surveys in a fast manner.
astro-ph.GA:The EROS-2 project has been designed to search for microlensing events towards any dense stellar field. The densest parts of the Galactic spiral arms have been monitored to maximize the microlensing signal expected from the stars of the Galactic disk and bulge. 12.9 million stars have been monitored during 7 seasons towards 4 directions in the Galactic plane, away from the Galactic center. A total of 27 microlensing event candidates have been found. Estimates of the optical depths from the 22 best events are provided. A first order interpretation shows that simple Galactic models with a standard disk and an elongated bulge are in agreement with our observations. We find that the average microlensing optical depth towards the complete EROS-cataloged stars of the spiral arms is $\bar{\tau} =0.51\pm .13\times 10^{-6}$, a number that is stable when the selection criteria are moderately varied. As the EROS catalog is almost complete up to $I_C=18.5$, the optical depth estimated for the sub-sample of bright target stars with $I_C<18.5$ ($\bar{\tau}=0.39\pm >.11\times 10^{-6}$) is easier to interpret. The set of microlensing events that we have observed is consistent with a simple Galactic model. A more precise interpretation would require either a better knowledge of the distance distribution of the target stars, or a simulation based on a Galactic model. For this purpose, we define and discuss the concept of optical depth for a given catalog or for a limiting magnitude.
astro-ph.GA:The HII complex N44 in the Large Magellanic Cloud (LMC) provides an excellent site to perform a detailed study of star formation in a mild starburst, as it hosts three regions of star formation at different evolutionary stages and it is not as complicated and confusing as the 30 Doradus giant HII region. We have obtained Spitzer Space Telescope observations and complementary ground-based 4m uBVIJK observations of N44 to identify candidate massive young stellar objects (YSOs). We further classify the YSOs into Types I, II, and III, according to their spectral energy distributions (SEDs). In our sample of 60 YSO candidates, ~65% of them are resolved into multiple components or extended sources in high-resolution ground-based images. We have modeled the SEDs of 36 YSOs that appear single or dominant within a group. We find good fits for Types I and I/II YSOs,but Types II and II/III YSOs show deviations between their observed SEDs and models that do not include PAH emission. We have also found that some Type III YSOs have central holes in their disk components. YSO counterparts are found in four ultracompact HII regions and their stellar masses determined from SED model fits agree well with those estimated from the ionization requirements of the HII regions. The distribution of YSOs is compared with those of the underlying stellar population and interstellar gas conditions to illustrate a correlation between the current formation of O-type stars and previous formation of massive stars. Evidence of triggered star formation is also presented.
astro-ph.GA:This is the initial paper in a series presenting the first optical detections and subsequent follow-up spectroscopy of known Southern Galactic supernova remnants (SNRs) previously discovered in the radio. These new detections come from the AAO/UKST HAlpha survey of the Southern Galactic plane which has opened up fresh opportunities to study Galactic remnants. Here we present the first optical imaging and follow-up spectra of Galactic SNR G279.0+1.1 where a series of 14 small-scale fragmented groups of HAlpha filaments have been discovered in a ~2.3 deg. area centred on G279.0+1.1. Individually they are somewhat inconspicuous but collectively they are completely enclosed within the overall radio contours of this known SNR. Three of these filamentary groupings are particularly prominent and optical spectra have been obtained across two of them. Their morphological structure and spectral characteristics are typical of optically detected SNR filaments. Very strong [S II] emission relative to H has been detected with [S II]/HAlpha 0.7 and 1.1, confirming strong, shock heated emission. This is sufficient to classify these filaments in the likely SNR domain and therefore indicating a direct connection with the radio remnant. Other typical SNR emission lines such as [O II] at 3727A, HBeta, [O III] at 4959 and 5007A, HAlpha and [N II] at 6548 and 6584A were also detected, lending strong support to an SNR origin of these optical filaments. The value and insights that these optical data can provide for known remnants are discussed along with their relevance to the Galactic nitrogen abundance. A serendipitous discovery of an adjacent H II region is also briefly described.
astro-ph.GA:We demonstrate for the first time that gaseous halos of disk galaxies can play a vital role in recycling metal-rich gas ejected from the bulges and thus in promoting chemical evolution of disks. Our numerical simulations show that metal-rich stellar winds from bulges in disk galaxies can be accreted onto the thin disks owing to hydrodynamical interaction between the gaseous ejecta and the gaseous halos, if the mean densities of the halos (rho_ hg) are as high as 10^{-5} cm^{-3}. The total amount of gas that is ejected from a bulge through a stellar wind and then accreted onto the disk depends mainly on rho_ hg and the initial velocity of the stellar wind. About ~ 1% of gaseous ejecta from bulges in disk galaxies of scale length a_d can be accreted onto disks around R ~ 2.5 a_ d for a reasonable set of model parameters. We discuss these results in the context of the origin of the surprisingly high metallicities of the solar neighborhood disk stars in the Galaxy. We also discuss some implications of the present results in terms of chemical evolution of disk galaxies with possibly different rho_ hg in different galaxy environments.
astro-ph.GA:Using high-resolution data of the linearly polarized intensity and polarization angle at 3.6, 6.2, and 20 cm together with a 3-D model of the regular magnetic field, we study variations of the structure, strength, and energy density of the magnetic field in the Scd galaxy M33. The regular magnetic field consists of a horizontal component (represented by an axisymmetric mode from 1 to 3 kpc radius and a superposition of axisymmetric and bisymmetric modes from 3 to 5 kpc radius) and a vertical component. However, the inferred `vertical field' may be partly due to a galactic warp. We estimate the average total and regular magnetic field strengths as ~ 6.4 and 2.5 $\mu$G, respectively. Generation of interstellar magnetic fields by turbulent gas motion in M33 is indicated as the turbulent and magnetic energy densities are about equal.
astro-ph.GA:Black hole mass determination in active galaxies is a key issue in understanding various luminosity states. In the present paper we try to generalise the mass determination method based on the X-ray excess variance, successfully used for typical broad line Seyfert 1 galaxies (BLS1) to Narrow Line Seyfert 1 (NLS1) galaxies. NLS1 galaxies differ from BLS1 with respect to several properties. They are generally more variable in 2-10 keV energy band so the natural expectation is the need to use a different scaling coefficient between the mass and the variance in these two types of sources. However, we find that such a simple approach is not enough. Although for majority of the 21 NLS1 galaxies in our sample a single scaling coefficient (larger by a factor 20) provided us with a satisfactory method of mass determination, in a small subset of NLS1 galaxies this approach failed. Variability of those objects appeared to be at the intermediate level between NLS1 and BLS1 galaxies. These exceptional NLS1 galaxies have much harder soft X-ray spectra than majority of NLS1 galaxies. We thus postulate that the division of Seyfert 1 galaxies into BLS1 and NLS1 according to the widths of the Hbeta line is less generic than according to the soft X-ray slope.
astro-ph.GA:The Galactic Center lobe is a degree-tall shell seen in radio continuum images of the Galactic center (GC) region. If it is actually located in the GC region, formation models would require massive energy input (e.g., starburst or jet) to create it. At present, observations have not strongly constrained the location or physical conditions of the GC lobe. This paper describes the analysis of new and archival single-dish observations of radio recombination lines toward this enigmatic object. The observations find that the ionized gas has a morphology similar to the radio continuum emission, suggesting that they are associated. We study averages of several transitions from H106alpha to H191epsilon and find that the line ratios are most consistent with gas in local thermodynamic equilibrium. The radio recombination line widths are remarkably narrow, constraining the typical electron temperature to be less than about 4000 K. These observations also find evidence of pressure broadening in the higher electronic states, implying a gas density of n_e=910^{+310}_{-450} cm^{-3}. The electron temperature, gas pressure, and morphology are all consistent with the idea that the GC lobe is located in the GC region. If so, the ionized gas appears to form a shell surrounding the central 100 parsecs of the galaxy with a mass of roughly 10^5 Msun, similar to ionized outflows seen in dwarf starbursts.
astro-ph.GA:In February 1997, the Japanese radio astronomy satellite HALCA was launched to provide the space-bourne element for the VLBI Space Observatory Programme (VSOP) mission. A significant fraction of the mission time was to be dedicated to the VSOP Survey of bright compact Active Galactic Nuclei (AGN) at 5 GHz, which was lead by ISAS. The VSOP Survey Sources are an unbiased dataset of 294 targets, of which 82% were successfully observed. These are now undergoing statistical analysis to tease out the characteristics of typical AGN sources. We present here the summary of the imaging and conclusions we have reached.
astro-ph.GA:We test the reliability of infrared (IR) emission to trace star formation in individual star-forming sites of M33, and outline a new method for testing the distribution function of massive stars in newly formed clusters. We select IR sources from the Spitzer survey of M33 and show that the IR and Halpha luminosities are not correlated. Complementing the infrared photometry with GALEX-UV data, we estimate the source bolometric luminosities. For a given stellar IMF we simulate a theoretical curve for the expected bolometric-to-Halpha luminosity ratio, along which stellar clusters are born. We call this the cluster birthline in the Lbol--Lbol/LHal plane. The birthline is flat for Lbol>3x10^{39}erg/s because all clusters fully sample the IMF and it increases toward lower luminosities as the upper end of the IMF becomes incompletely sampled. The observations of M33 show that young isolated clusters lie close to the theoretical birthline for a wide range of Lbol. The luminosity is not proportional to Halpha emission for low mass clusters and aging moves clusters above the birthline. The best fit to the birthline is for a randomly sampled IMF, in which the mass of most massive star in a cluster is not strictly limited by the cluster's mass. We also find that the IR luminosity of young stellar clusters in M33 is not proportional to their bolometric luminosity. This irregularity could be the result of low and patchy dust abundance in M33.
astro-ph.GA:We present results of three-dimensional, fully nonlinear MHD simulations of a large-scale magnetic field evolution in a barred galaxy. The model does not take into consideration the dynamo process. We find that the obtained magnetic field configurations are highly similar to the observed maps of the polarized intensity of barred galaxies, because the modeled vectors form coherent structures along the bar and spiral arms. Due to the dynamical influence of the bar the gas forms spiral waves which go radially outward. Each spiral arm forms the magnetic arm which stays much longer in the disk, than the gaseous spiral structure. Additionally the modeled total energy of magnetic field grows due to strong compression and shear of non-axisymmetrical bar flows and differential rotation, respectively.
astro-ph.GA:The interstellar medium (ISM) is a key ingredient in galaxy formation and evolution as it provides the molecular gas reservoir which fuels star formation and supermassive black hole accretion. Yet the ISM is one of the least studied aspects of distant galaxies. Molecular and atomic transitions at (sub)millimetre wavelengths hold great promise in measuring macroscopic properties (e.g. masses, morphologies, star formation laws), as well as microscopic properties (e.g. gas densities, temperatures, cooling) of high-z galaxies. In this overview I summarize the growing number of high-z molecular line detections, highlighting some of the most intriguing results along the way. I end by discussing a few areas where future facilities (e.g. ALMA, EVLA, CCAT, LMT) will drastically improve on the current state of affairs.
astro-ph.GA:In this second of a series of papers on spatially resolved star formation, we investigate the impact of the density-morphology relation of galaxies on the spatial variation of star formation (SF) and its dependence on environment. We find that while a density-morphology relation is present for the sample, it cannot solely explain the observed suppression of SF in galaxies in high-density environments. We also find that early-type and late-type galaxies exhibit distinct radial star formation rate (SFR) distributions, with early-types having a SFR distribution that extends further relative to the galaxy scale length, compared to late-types at all densities. We find that a suppression of SF in the highest density environments is found in the highest star forming galaxies for both galaxy types. This suppression occurs in the innermost regions in late-types (r <= 0.125 Petrosian radii), and further out in radius in early-types (0.125< r <= 0.25 Petrosian radii). When the full sample is considered no clear suppression of SF is detected, indicating that the environmental trends are driven only by the highest SF galaxies. We demonstrate that the density-morphology relation alone cannot account for the suppression of SF in the highest density environments. This points to an environmentally-governed evolutionary mechanism that affects the SF in the innermost regions in both early and late-type galaxies. We suggest that this is a natural consequence of the "downsizing" of SF in galaxies.
astro-ph.GA:To date the onset of large-scale star formation in galaxies and its link to gravitational stability of the galactic disk have not been fully understood. The nearby face-on spiral galaxy M51 is an ideal target for studying this subject. This paper combines CO, dust, HI, and stellar maps of M51 and its companion galaxy to study the H2/HI transition, the gas-to-dust ratios, and the stability of the disk against gravitational collapse. We combine maps of the molecular gas using 12CO 2--1 map HERA/IRAM-30m data and HI VLA data to study the total gas surface density and the phase transition of atomic to molecular gas. The total gas surface density is compared to the dust surface density from 850 micron SCUBA data. Taking into account the velocity dispersions of the molecular and atomic gas, and the stellar surface densities derived from the 2MASS K-band survey, we derive the total Toomre Q parameter of the disk. The gas surface density in the spiral arms is approximately 2-3 higher compared to that of the interarm regions. The ratio of molecular to atomic surface density shows a nearly power-law dependence on the hydrostatic pressure P_hydro. The gas surface density distribution in M51 shows an underlying exponential distribution with a scale length of h_gas=7.6 kpc representing 55% of the total gas mass, comparable to the properties of the exponential dust disk. In contrast to the velocity widths observed in HI, the CO velocity dispersion shows enhanced line widths in the spiral arms compared to the interarm regions. The contribution of the stellar component in the Toomre Q-parameter analysis is significant and lowers the combined Q-parameter Q_tot by up to 70% towards the threshold for gravitational instability. The value of Q_tot varies from 1.5-3 in radial averages. A map of Q_tot shows values around 1 on the spiral arms.
astro-ph.GA:We present high resolution images of the 12CO(2-1) emission in the central 1' (1 kpc) of NGC 5128 (Centaurus A), observed using the SMA. We elucidate for the first time the distribution and kinematics of the molecular gas in this region with a resolution of 6'.0 x 2'.4 (100 pc x 40 pc). We spatially resolve the circumnuclear molecular gas in the inner 24'' x 12'' (400 pc x 200 pc), which is elongated along a position angle P.A. = 155 deg and perpendicular to the radio/X-ray jet. The SE and NW components of the circumnuclear gas are connected to molecular gas found at larger radii. This gas appears as two parallel filaments at P.A. = 120 deg, which are coextensive with the long sides of the 3 kiloparsec parallelogram shape of the previously observed dust continuum, as well as ionized and pure rotational H2 lines. Spatial and kinematical asymmetries are apparent in both the circumnuclear and outer gas, suggesting non-coplanar and/or non-circular motions. We extend to inner radii (r < 200 pc) previously studied warped disk models built to reproduce the central parallelogram-shaped structure. Adopting the warped disk model we would confirm a gap in emission between the radii r = 200 - 800 pc (12'' - 50''), as has been suggested previously. Although this model explains this prominent feature, however, our 12CO(2-1) observations show relevant deviations from this model. Namely, the physical connection between the circumnuclear gas and that at larger radii, brighter SE and NW sides on the parallelogram-shaped feature, and an outer curvature of its long sides. Overall it resembles more closely an S-shaped morphology, a trend that is also found in other molecular species. Hence, we explore qualitatively the possible contribution of a weak bi-symmetric potential which would naturally explain these peculiarities.
astro-ph.GA:The spatial distributions of the most recently discovered ultra faint dwarf satellites around the Milky Way and the Andromeda galaxy are compared to the previously reported discs-of-satellites (DoS) of their host galaxies. In our investigation we pay special attention to the selection bias introduced due to the limited sky coverage of SDSS. We find that the new Milky Way satellite galaxies follow closely the DoS defined by the more luminous dwarfs, thereby further emphasizing the statistical significance of this feature in the Galactic halo. We also notice a deficit of satellite galaxies with Galactocentric distances larger than 100 kpc that are away from the disc-of-satellites of the Milky Way. In the case of Andromeda, we obtain similar results, naturally complementing our previous finding and strengthening the notion that the discs-of-satellites are optical manifestations of a phase-space correlation of satellite galaxies.
astro-ph.GA:Observations of the Galactic Centre show evidence of disc-like structures of very young stars orbiting the central super-massive black hole within a distance of a few 0.1 pc. While it is widely accepted that about half of the stars form a relatively flat disc rotating clockwise on the sky, there is a substantial ongoing debate on whether there is a second, counter-clockwise disc of stars.   By means of N-body simulations using our bhint code, we show that two highly inclined stellar discs with the observed properties cannot be recognised as two flat circular discs after 5 Myr of mutual interaction. Instead, our calculations predict a significant warping of the two discs, which we show to be apparent among the structures observed in the Galactic Centre. While the high eccentricities of the observed counter-clockwise orbits suggest an eccentric origin of this system, we show the eccentricity distribution in the inner part of the more massive clockwise disc to be perfectly consistent with an initially circular disc in which stellar eccentricities increase due to both non-resonant and resonant relaxation.   We conclude that the relevant question to ask is therefore not whether there are two discs of young stars, but whether there were two such discs to begin with.
astro-ph.GA:The growth of supermassive black holes and their host galaxies are thought to be linked, but the precise nature of this symbiotic relationship is still poorly understood. Both observations and simulations of galaxy formation suggest that the energy input from active galactic nuclei (AGN), as the central supermassive black hole accretes material and grows, heats the interstellar material and suppresses star formation. In this Letter, we show that most host galaxies of moderate-luminosity supermassive black holes in the local universe have intermediate optical colors that imply the host galaxies are transitioning from star formation to quiescence, the first time this has been shown to be true for all AGN independent of obscuration. The intermediate colors suggest that star formation in the host galaxies ceased roughly 100 Myr ago. This result indicates that either the AGN are very long-lived, accreting for more than 1 Gyr beyond the end of star formation, or there is a ~100 Myr time delay between the shutdown of star formation and detectable black hole growth. The first explanation is unlikely given current estimates for AGN lifetimes, so low-lumiosity AGN must shut down star formation before substantial black hole accretion activity is detected. The scarcity of AGN host galaxies in the blue cloud reported here challenges scenarios where significant star formation and black hole growth are coeval. Lastly, these observations also strongly support the `Unified Model' of AGN as the host galaxy colors are independent of obscuration towards the central engine.
astro-ph.GA:We investigated the kinematic and excitation structure of the NGC 1068 narrow-line region (NLR). We obtained profiles of several emission lines, [OIII]$\lambda$5007, H$\beta$, [OI]$\lambda$6300 and [FeVII]$\lambda$6087 at high-velocity resolution (R ~ 7500 - 11000), and confirmed that they showed different profiles. These profiles are useful for understanding the NLR structure, as they cover a wide ionization potential range. By comparing the results with a photoionization model, we found that 1) blueshifted components at the center are very dense, 2) those in the northeast region have slightly lower densities than those in the center, and 3) ionization parameters of the blueshifted components increase with increasing velocity with respect to the systemic velocity. We investigated the NLR structure in NGC 1068 based on these results. We show that both the observed velocity dependence of the ionization parameter and the gradually increasing velocity field can be reproduced by varying the ionizing continuum attenuation, assuming a hollowed biconical geometry and varying the column densities of outflowing clouds.
astro-ph.GA:Microlensing observations towards M31 are a powerful tool for the study of the dark matter population in the form of MACHOs both in the Galaxy and the M31 halos, a still unresolved issue, as well as for the analysis of the characteristics of the M31 luminous populations. In this work we present the second year results of our pixel lensing campaign carried out towards M31 using the 152 cm Cassini telescope in Loiano. We have established an automatic pipeline for the detection and the characterisation of microlensing variations. We have carried out a complete simulation of the experiment and evaluated the expected signal, including an analysis of the efficiency of our pipeline. As a result, we select 1-2 candidate microlensing events (according to different selection criteria). This output is in agreement with the expected rate of M31 self-lensing events. However, the statistics are still too low to draw definitive conclusions on MACHO lensing.
astro-ph.GA:In this paper we present extinction properties of interstellar dust in a prominent dust lane galaxy NGC 4370 based on the optical broad band (BVRI) imaging observations taken from the Himalaya Chandra Telescope (HCT), Hanle and the near-IR (J,H,K$_s$) images taken from the 2MASS archive. NGC 4370 belongs to the Virgo cluster (VCC 0758) and form a non-interactive pair with NGC 4365 at 10$\arcmin$. NGC 4370 hosts a prominent dust lane running parallel to its optical major axis and is extended almost up to 1\arcmin. The extinction curve derived for NGC 4370 is found to run parallel to Galactic extinction curve, implying that the properties of dust in NGC 4370 are identical to those of the canonical grains in the Milky Way. The $R_V$ value is found to be equal to 2.85$\pm$0.05 and is consitent with the values reported for the dust lane galaxies. The total dust content of NGC 4370 estimated using optical extinction and IRAS flux densities are found to be equal to $4.4\times 10^4$ \msol and $2.0\times 10^5$ \msol, respectively. As regard to the origin of dust and ISM in this galaxy, the accumulated dust by this galaxy over its life-time is insufficient to account for the detected mass by optical means, which in turn imply that the ISM might have been acquired by the NGC 4370 through a merger like event. An attempt is also made to study the apparent spatial correspondence between the multiple phases of ISM, i.e., hot gas, warm gas and dust in this galaxy by obtaining optical emission maps from narrow band imaging and diffuse X-ray emission map obtained from the analysis of \emph{Chandra} archival data. This analysis implies a physical connection between the dust and warm gas in terms of their physical co-existence and common origin too.
astro-ph.GA:We present a homogeneous and 92 % complete dataset of optical nuclear spectra for the 113 3CR radio sources with redshifts < 0.3, obtained with the Telescopio Nazionale Galileo. For these sources we could obtain uniform and uninterrupted coverage of the key spectroscopic optical diagnostics. The observed sample, including powerful classical FR II radio-galaxies and FR I, together spanning four orders of magnitude in radio-luminosity, provides a broad representation of the spectroscopic properties of radio galaxies. In this first paper we present an atlas of the spectra obtained, provide measurements of the diagnostic emission line ratios, and identify active nuclei with broad line emission. These data will be used in follow-up papers to address the connection between the optical spectral characteristics and the multiwavelength properties of the sample.
astro-ph.GA:We present the first results of the expected variations of the molecular line emission arising from material recently affected by C-shocks (shock precursors). Our parametric model of the structure of C-shocks has been coupled with a radiative transfer code to calculate the molecular excitation and line profiles of shock tracers such as SiO, and of ion and neutral molecules such as H13CO+ and HN13C, as the shock propagates through the unperturbed medium. Our results show that the SiO emission arising from the early stage of the magnetic precursor typically has very narrow line profiles slightly shifted in velocity with respect to the ambient cloud. This narrow emission is generated in the region where the bulk of the ion fluid has already slipped to larger velocities in the precursor as observed toward the young L1448-mm outflow. This strongly suggests that the detection of narrow SiO emission and of an ion enhancement in young shocks, is produced by the magnetic precursor of C-shocks. In addition, our model shows that the different velocity components observed toward this outflow can be explained by the coexistence of different shocks at different evolutionary stages, within the same beam of the single-dish observations.
astro-ph.GA:We review the use of velocity centroids statistics to recover information of interstellar turbulence from observations. Velocity centroids have been used for a long time now to retrieve information about the scaling properties of the turbulent velocity field in the interstellar medium. We show that, while they are useful to study subsonic turbulence, they do not trace the statistics of velocity in supersonic turbulence, because they are highly influenced by fluctuations of density. We show also that for sub-Alfv\'enic turbulence (both supersonic and subsonic) two-point statistics (e.g. correlation functions or power-spectra) are anisotropic. This anisotropy can be used to determine the direction of the mean magnetic field projected in the plane of the sky.
astro-ph.GA:We present the results of a Suzaku monitoring campaign of the Seyfert 2 galaxy, NGC7582. The source is characterized by very rapid (on timescales even lower than a day) changes of the column density of an inner absorber, together with the presence of constant components arising as reprocessing from a Compton-thick material. The best fitting scenario implies important modifications to the zeroth order view of Unified Models. While the existence of a pc-scale torus is needed in order to produce a constant Compton reflection component and an iron K$\alpha$ emission line, in this Seyfert 2 galaxy this is not viewed along the line of sight. On the other hand, the absorption of the primary continuum is due to another material, much closer to the BH, roughly at the distance of the BLR, which can produce the observed rapid spectral variability. On top of that, the constant presence of a $10^{22}$ cm$^{-2}$ column density can be ascribed to the presence of a dust lane, extended on a galactic scale, as previously confirmed by Chandra. There is now mounting evidence that complexity in the obscuration of AGN may be the rule rather than the exception. We therefore propose to modify the Unification Model, adding to the torus the presence of two further absorbers/emitters. Their combination along the line of sight can reproduce all the observed phenomenology.
astro-ph.GA:Observations show that magnetic fields in the interstellar medium (ISM) often do not respond to increases in gas density as would be naively expected for a frozen-in field. This may suggest that the magnetic field in the diffuse gas becomes detached from dense clouds as they form. We have investigated this possibility using theoretical estimates, a simple magneto-hydrodynamic model of a flow without mass conservation and numerical simulations of a thermally unstable flow. Our results show that significant magnetic flux can be shed from dense clouds as they form in the diffuse ISM, leaving behind a magnetically dominated diffuse gas.
astro-ph.GA:Galactic winds in dwarf galaxies are driven by the energy released by supernova explosions and stellar winds following an intense episode of star formation, which create an over-pressured cavity of hot gas. Although the luminosity of the star formation episode and the mass of the galaxy play a key role in determining the occurrence of the galactic winds and the fate of the freshly produced metals, other parameters play an equally important role. In this contribution we address the following questions (i) What is the late evolution of superbubbles and what is the final fate of the superbubble cavities? (ii) How does the multi-phase nature of the ISM, in particular the coexistence of hot gas with embedded clouds, affect the development of galactic winds? (iii) What is the relation between the flattening of a galaxy and the development of bipolar galactic winds?
astro-ph.GA:Using deep J, H and Ks-band observations, we have studied the near-infrared (nIR) extinction of the Nuclear Bulge (NB) and we find significant, complex variations on small physical scales. We have applied a new variable nIR colour excess method, V-NICE, to measure the extinction; this method allows for variation in both the extinction law parameter alpha and the degree of absolute extinction on very small physical scales. We see significant variation in both these parameters on scales of 5 arcsec. In our observed fields, representing a random sample of sight lines to the NB, we measure alpha to be 2.64 +- 0.52, compared to the canonical "universal" value of 2. Our measured levels of A_Ks are similar to previously measured results (1 < A_Ks < 4.5); however, the steeper extinction law results in higher values for A_J (4.5 < A_J < 10) and A_H (1.5 < A_H < 6.5). Only when the extinction law is allowed to vary on the smallest scales can we recover self-consistent measures of the absolute extinction at each wavelength, allowing accurate reddening corrections for field star photometry in the NB. The steeper extinction law slope also suggests that previous conversions of nIR extinction to A_V may need to be reconsidered. Finally, we find that the measured values of extinction are significantly dependent on the filter transmission functions of the instrument used to obtain the data. This effect must be taken into account when combining or comparing data from different instruments.
astro-ph.GA:Although the continua of radio-loud Active Galactic Nuclei (AGN) are typically dominated by synchrotron radiation over virtually the entire spectrum, it is not clear whether the radio and higher-frequency emission originate in the same or different parts of the jet. Several different radio--optical correlations based on polarization data have been found recently, suggesting that the optical and radio polarization may be closely related, and that the corresponding emission regions may be cospatial (Gabuzda et. al2006, Jorstad et al. 2007, D'Arcangelo et al. 2007) Our joint analysis of optical and VLBA polarization data for a sample of about 40 AGNs shows that, after correction for the inferred VLBA core Faraday rotations, most BL Lac objects and some quasars have aligned VLBA-core and optical polarizations, although many quasars also show no obvious relationship between their VLBA-core and optical polarization angles. This may indicate that not all AGNs have cospatial regions of optical and radio emission in their jets. However, another possibility is that some of the 7mm-2cm VLBA cores have Faraday rotations of the order of several tens of thousand of rad/m^2, which were not properly fit by our three-frequency data due to n*pi ambiguities in the observed polarization angles, leading to incorrect subtraction of the effects of the core Faraday rotation, and so incorrect "zero-wavelength" radio polarization angles. The possibility of such high core Faraday rotations is supported by the results of the parsec-scale Faraday-rotation studies of Zavala & Taylor (2004) and Jorstad et al. (2007).
astro-ph.GA:We show a comparison of the rest-frame UV morphologies of a sample of 162 intermediate redshift (median redshift 1.02) galaxies with their rest-frame optical morphologies. We select our sample from the deepest near-UV image obtained with the Hubble Space Telescope (HST) using the WFPC2 (F300W) as part of the parallel observations of the Hubble Ultra Deep Field campaign overlapping with the HST/ACS GOODS dataset. We perform single component Sersic fits in both WFPC2/F300W (rest-frame UV) and ACS/F850LP (rest-frame optical) bands and deduce that the Sersic index $n$ is estimated to be smaller in the rest-frame UV compared to the rest-frame optical, leading to an overestimation of the number of merger candidates by ~40-100% compared to the rest-frame optical depending upon the cutoff in $n$ employed for identifying merger candidates. This effect seems to be dominated by galaxies with low values of n(F300W) <= 0.5 that have a value of n(F850LP) ~ 1.0. We argue that these objects are probably clumpy starforming galaxies or minor mergers, both of which are essentially contaminants, if one is interested in identifying major mergers.   In addition we also find evidence that the axis ratio b/a is lower, i.e. ellipticity (1-b/a) is higher in rest-frame UV compared to the rest-frame optical. Moreover, we find that in the rest-frame UV, the number of high ellipticity (e >= 0.8) objects are higher by a factor of ~2.8 compared to the rest-frame optical. This indicates that the reported dominance of elongated morphologies among high-z LBGs might just be a bias related to the use of rest-frame UV datasets in high-z studies.
astro-ph.GA:We present a new method to detect and quantify mass segregation in star clusters. It compares the minimum spanning tree (MST) of massive stars with that of random stars. If mass segregation is present, the MST length of the most massive stars will be shorter than that of random stars. This difference can be quantified (with an associated significance) to measure the degree of mass segregation. We test the method on simulated clusters in both 2D and 3D and show that the method works as expected.   We apply the method to the Orion Nebula Cluster (ONC) and show that the method is able to detect the mass segregation in the Trapezium with a `mass segregation ratio' \Lambda_{MSR}=8.0 \pm 3.5 (where \Lambda_{MSR}=1 is no mass segregation) down to 16 \Msun, and also that the ONC is mass segregated at a lower level (~2.0 \pm 0.5) down to 5 \Msun. Below 5 \Msun we find no evidence for any further mass segregation in the ONC.
astro-ph.GA:A study of the ionized and neutral gas kinematics near 23 WR stars in the Irr galaxy IC10 are provided. For most of the stars sings of the WR winds impact on the interstellar medium were detected. A rough estimate of the power of wind WR stars is about ~(0.01-0.84) 10^38 erg / sec.
astro-ph.GA:We discuss the results of the first model of the gas dynamics in the Milky Way in the presence of two bars: the large scale primary bar or boxy bulge and a secondary bar in the Galactic center region. We have obtained an accurate potential by modeling 2MASS star counts and we have used this potential to simulate the gas dynamics. As a first approximation we have used one single pattern speed \Omega_p. The models with Omega_p=30-40 \kmskpc and a primary bar orientation of 20-35 deg reproduce successfully many characteristics of the observed longitude-velocity diagrams as the terminal velocity curve or the spiral arm tangent points. The Galactic Molecular Ring is not an actual ring but the inner part of the spiral arms, within corotation. The model reproduces quantitatively the "3-kpc arm" and the recently found far-side counterpart, which are the lateral arms that contour the bar. In the Galactic center region, the model reproduces the 1-kpc HI ring and the Central Molecular Zone (CMZ), which is the gas response to the secondary bar. In order to reproduce the observed parallelogram shape of the CO longitude velocity diagram of the CMZ, the secondary bar should be oriented by and angle of 60-70 deg with respect to the Sun-GC line. The mass of the secondary bar amounts to (2-5.5)10^9 Msun, which is 10-25 % of the mass of the primary bar.
astro-ph.GA:We present the results of the one year long observational campaign of the type II-plateau SN 2005cs, which exploded in the nearby spiral galaxy M51 (the Whirlpool Galaxy). This extensive dataset makes SN 2005cs the best observed low-luminosity, 56Ni-poor type II-plateau event so far and one of the best core-collapse supernovae ever. The optical and near-infrared spectra show narrow P-Cygni lines characteristic of this SN family, which are indicative of a very low expansion velocity (about 1000 km/s) of the ejected material. The optical light curves cover both the plateau phase and the late-time radioactive tail, until about 380 days after core-collapse. Numerous unfiltered observations obtained by amateur astronomers give us the rare opportunity to monitor the fast rise to maximum light, lasting about 2 days. In addition to optical observations, we also present near-infrared light curves that (together with already published UV observations) allow us to construct for the first time a reliable bolometric light curve for an object of this class. Finally, comparing the observed data with those derived from a semi-analytic model, we infer for SN 2005cs a 56Ni mass of about 0.003 solar masses, a total ejected mass of 8-13 solar masses and an explosion energy of about 3 x 10^50 erg.
astro-ph.GA:We present a mid-infrared spectroscopic data cube of the central part of 30 Doradus, observed with Spitzer's IRS and MIPS/SED mode. Aromatic dust emission features and emission lines from molecular and atomic hydrogen are detected but not particularly strong. The dominant spectral features are emission lines from moderately ionized species of argon, neon, and sulphur, which are used to determine the physical conditions in the ionized gas. The ionized gas excitation shows strong variations on parsec scales, some of which can plausibly be associated with individual hot stars. We fit the ionic line strengths with photoionization and shock models, and find that photoionization dominates in the region. The ionization parameter U traces the rim of the central bubble, as well as highlighting isolated sources of ionization, and at least one quiescent clump. The hardness of the ionizing radiation field T_rad reveals several "hot spots" that are either the result of individual very hot stars or trace the propagation of the diffuse ionizing field through the surrounding neutral cloud. Consistent with other measurements of giant molecular hydrogen regions, log(U) ranges between -3 and -0.75, and T_rad between 30000 and 85000K.
astro-ph.GA:Cluster galaxies moving through the intracluster medium (ICM) are expected to lose some of their interstellar medium (ISM) through ISM-ICM interactions. We perform high resolution (40 pc) three-dimensional hydrodynamical simulations of a galaxy undergoing ram pressure stripping including radiative cooling in order to investigate stripping of a multiphase medium. The clumpy, multiphase ISM is self-consistently produced by the inclusion of radiative cooling, and spans six orders of magnitude in gas density. We find no large variations in the amount of gas lost whether or not cooling is involved, although the gas in the multiphase galaxy is stripped more quickly and to a smaller radius. We also see significant differences in the morphology of the stripped disks. This occurs because the multiphase medium naturally includes high density clouds set inside regions of lower density. We find that the lower density gas is stripped quickly from any radius of the galaxy, and the higher density gas can then be ablated. If high density clouds survive, through interaction with the ICM they lose enough angular momentum to drift towards the center of the galaxy where they are no longer stripped. Finally, we find that low ram pressure values compress gas into high density clouds that could lead to enhanced star formation, while high ram pressure leads to a smaller amount of high-density gas.
astro-ph.GA:(Abridged) The formation of massive spheroidal galaxies is studied on a visually classified sample of 910 galaxies extracted from the ACS/HST images of the GOODS North and South fields (0.4<z<.5). Three key observables are considered: comoving number density, internal colour distribution; and the Kormendy relation. The comoving number density of the most massive galaxies is found not to change significantly with redshift. One quarter of the whole sample of early-types are photometrically classified as blue galaxies. On a volume-limited subset out to z<0.7, the average stellar mass of the blue ellipticals is 5E9Msun compared to 4E10Msun for red ellipticals. On a volume-limited subsample of bright galaxies (Mv<-21) out to z=1.4 we find only 4% are blue early-types, in contrast with 26% for the full sample. The intrinsic colour distribution correlates overall bluer colours with **blue cores** (positive radial gradients of colour), suggesting an inside-out process of formation. The redshift evolution of the observed colour gradients is incompatible with a significant variaton in stellar age within each galaxy. The slope of the Kormendy relation in the subsample of massive galaxies does not change between z=0 and z=1.4.
astro-ph.GA:Young radio-loud active galactic nuclei form an important tool to investigate the evolution of extragalactic radio sources. To study the early phases of expanding radio sources, we have constructed CORALZ, a sample of 25 compact ($\theta<2"$) radio sources associated with nearby ($z<0.16$) galaxies. In this paper we determine the morphologies, linear sizes, and put first constraints on the lobe expansion speeds of the sources in the sample. We observed the radio sources from the CORALZ sample with MERLIN at 1.4 GHz or 1.6 GHz, the EVN at 1.6 GHz, and global VLBI at 1.6 GHz and/or 5.0 GHz. Radio maps, morphological classifications, and linear sizes are presented for all sources in the CORALZ sample. We have determined a first upper limit to the expansion velocity of one of the sources, which is remarkably low compared to the brighter GPS sources at higher redshifts, indicating a relation between radio luminosity and expansion speed, in agreement with analytical models. In addition we present further strong evidence that the spectral turnovers in GPS and CSS sources are caused by synchrotron self-absorption (SSA): the CORALZ sources are significantly offset from the well-known correlation between spectral peak frequency and angular size, but this correlation is recovered after correcting for the flux-density dependence, as predicted by SSA theory.
astro-ph.GA:Abridged: We use three-dimensional SPH simulations to investigate the collapse of low-mass prestellar cores and the formation and early evolution of protostellar discs. The initial conditions are slightly supercritical Bonnor-Ebert spheres in rigid rotation. The core mass and initial radius are held fixed at M_O=6.1 M_sun and R_O=17,000 AU, and the only parameter that we vary is the initial angular speed \Omega_O. Protostellar discs forming from cores with \Omega_O<1.35 10d-13 1/s have radii between 100 and 300 AU and are quite centrally concentrated; due to heating by gas infall onto the disc and accretion onto the central object, they are also quite warm, T>100 K, and therefore stable against gravitational fragmentation. In contrast, more rapidly rotating cores form discs which are less concentrated and cooler, and have radii between 400 and 1000 AU; as a consequence they are prone to gravitational fragmentation and the formation of multiple systems. We derive a criterion that predicts whether a rigidly rotating core having given M_O, R_O and \Omega_O will produce a protostellar disc which fragments whilst material is still infalling from the core envelope. We then apply this criterion to core samples for which M_O, R_O and \Omega_O have been estimated observationally. We conclude that the observed cores are stable against fragmentation at this stage, due to their low angular speeds and the heat delivered at the accretion shock where the infalling material hits the disc.
astro-ph.GA:We map the three dimensional extent of the Virgo Over-density by combining distance information from RR Lyrae variables and projected spatial information from SEKBO (Keller et al. 2008) and Sloan Digital Sky Survey (SDSS) DR6 photometry. The Virgo Over-density is seen to comprise two filaments 14.5 x 3 degrees and 10 x 3 degrees and a circular structure 3 degrees in diameter. Together the three features span 38 degrees of right ascension and declinations of +2 to -15 degrees. RR Lyrae variables place the two filamentary features at heliocentric distances of 20 and 17 kpc respectively, with projected dimensions of 5 x 1 kpc and 3 x 1 kpc.
astro-ph.GA:We draw a comparison between AGN and Galactic black hole binaries using a uniform description of spectral energy distribution of these two classes of accreting X-ray sources. We parametrize spectra of GBHs with an alpha_GBH parameter which we define as a slope of a nominal power law function between 3 and 20 keV. We show that this parameter can be treated as an equivalent of the X-ray loudness, alpha_OX, used to describe AGN spectra. We do not find linear correlation between the alpha_GBH and disc flux (similar to that between alpha_OX and optical/UV luminosity found in AGN). Instead, we show that alpha_GBH follows a well defined pattern during a GBH outburst. We find that alpha_GBH tend to cluster around 1, 1.5 and 2, which correspond to a hard, very high/intermediate and soft spectral state, respectively. We conclude that majority of the observed Type 1 radio quiet AGN are in a spectral state corresponding to a very high/intermediate state of GBHs. The same conclusion is valid for radio loud AGN. We also study variations of the spectral slopes (alpha_GBH and the X-ray photon index, Gamma) as a function of disc and Comptonization fluxes. We discuss these dependencies in the context of correlations of alpha_OX and Gamma with the optical/UV and X-ray 2 keV fluxes considered for AGN and quasars.
astro-ph.GA:We have decomposed the broad H-alpha, H-beta and H-gamma lines of 90 Active Galactic Nuclei (AGNs) into a superposition of a very broad and an intermediate Gaussian components (VBGC and IMGC) and discovered that the two Gaussian components evolve with FWHM of the whole emission lines. We suggest that the VBGC and the IMGC are produced in different emission regions, namely, Very Broad Line Region (VBLR) and Intermediate Line Region (IMLR). The details of the two components of H-alpha, H-beta and H-gamma lines indicate that the radius obtained from the emission line reverberation mapping normally corresponds to the radius of the VBLR, but the radius obtained from the infrared reverberation mapping corresponding to IMLR, i.e., the inner boundary of the dusty torus. The existence of the IMGC may affect the measurement of the black hole mass in AGNs. Therefore, the deviation of NLS1s from the M-sigma relation may be explained naturally in this way. The evolution of the two emission line regions may be related to the evolutionary stages of the broad line regions of AGNs from NLS1s to BLS1s. Other evidences for the existence of the IMLR are also presented.
astro-ph.GA:A significant fraction of high redshift starburst galaxies presents strong Ly alpha emission. Understanding the nature of these galaxies is important to assess the role they played in the early Universe and to shed light on the relation between the narrow band selected Lyalpha emitters and the Lyman break galaxies: are the Lyalpha emitters a subset of the general LBG population? or do they represent the youngest galaxies in their early phases of formation? We studied a sample of UV continuum selected galaxies from z~2.5 to z~6 (U, B, V and i-dropouts) from the GOODS-South survey, that have been observed spectroscopically. Using the GOODS-MUSIC catalog we investigated their physical properties, such as total masses, ages, SFRs, extinction etc as determined from a spectrophotometric fit to the multi-wavelength (U band to mid-IR) SEDs, and their dependence on the emission line characteristics. In particular we determined the nature of the LBGs with Lyalpha in emission and compared them to the properties of narrow band selected Lyalpha emitters. For U and B-dropouts we also compared the properties of LBGs with and without the Lyalpha emission line.
astro-ph.GA:IGR J16351-5806 has been associated with the Seyfert 2 galaxy ESO 137-G34, having been first reported as a high energy emitter in the third INTEGRAL/IBIS survey. Using a new diagnostic tool based on X-ray column density measurements vs softness ratios, Malizia et al. (2007) identified this source as a candidate Compton thick AGN. In the present work we have analysed combined XMM-Newton and INTEGRAL data of IGR J16351-5806 in order to study its broad band spectrum and investigate its Compton thick nature. The prominent K_alpha fluorescence line around 6.4 keV (EW > 1 keV) together with a flat 2-10 keV spectrum immediately point to a highly obscured source. The overall spectrum can be interpreted in terms of a transmission scenario where some of the high energy radiation is able to penetrate through the thick absorption but a good fit is also obtained using a pure reflection spectrum. An alternative possibility is that of a complex absorption, where two layers of absorbing matter each partially covering the central nucleus are present in IGR J16351-5806. All three scenarios are compatible from a statistical viewpoint and provide reasonable AGN spectral parameters; more importantly all point to a source with an absorbing column greater than 1.5 x 10^24 cm^-2, i.e. to a Compton thick AGN. Because of this heavy obscuration, some extra components which would otherwise be hidden are able to emerge at low energies and can be studied. By providing strong evidence for the Compton thick nature of IGR J16351-5806, we indirectly confirm the validity of the Malizia et al. diagnostic diagram.
astro-ph.GA:We carried out long-slit spectroscopic observations of the star forming knots along the polar ring of the dwarf galaxy IIZw71 in the spectral range 3500 - 10000 angstroms taken with the William erschel Telescope (WHT). The spectroscopic observations were complemented with available photometry of the galaxy in the narrow Halpha filter. We measured the rotation curve of the ring, from which we infer a ratio M/L_B = 3.9 inside the star forming ring. We measured the auroral [OIII] line in the two brightest knots, allowing us to measure oxygen, sulphur, nitrogen, argon and neon chemical abundances following the direct method. Different empirical calibrators were used to estimate the oxygen abundance in the two faintest knots. The metallicities obtained are very similar for all the knots, but lower than previously reported in the literature from integrated spectra. The N/O abundance, as derived from the N2O2 parameter, is remarkably constant over the ring, indicating that local polution processes are not conspicuous. Using synthetic stellar populations (SSPs) calculated with the code STARLIGHT, we studied the age distribution of the stellar populations in each knot, finding that in all of them there is a combination of a very young population with less than 10 Myr, responsible for the ionisation of the gas, with other populations older than 100 Myr, probably responsible for the chemical evolution of the knots. The small differences in metallicity and the age distributions among the different knots are indicative of a common chemical evolution, probably related to the process of interaction with the companion galaxy IIZw70.
astro-ph.GA:(Abridge) Bars are very common in the centre of the disc galaxies, and they drive the evolution of their structure. A volume-limited sample of 2106 disc galaxies extracted from the Sloan Digital Sky Survey Data Release 5 was studied to derive the bar fraction, length, and strength as a function of the morphology, size, local galaxy density, light concentration, and colour of the host galaxy. The bars were detected using the ellipse fitting method and Fourier analysis method. The ellipse fitting method was found to be more efficient in detecting bars in spiral galaxies. The fraction of barred galaxies turned out to be 45%. A bar was found in 29% of the lenticular galaxies, in 55% and 54% of the early- and late-type spirals, respectively. The bar length (normalised by the galaxy size) of late-type spirals is shorter than in early-type or lenticular ones. A correlation between the bar length and galaxy size was found with longer bars hosted by larger galaxies. The bars of the lenticular galaxies are weaker than those in spirals. Moreover, the unimodal distribution of the bar strength found for all the galaxy types argues against a quick transition between the barred and unbarred statues. There is no difference between the local galaxy density of barred and unbarred galaxies. Besides, neither the length nor strength of the bars are correlated with the local density of the galaxy neighbourhoods. In contrast, a statistical significant difference between the central light concentration and colour of barred and unbarred galaxies was found. Bars are mostly located in less concentrated and bluer galaxies. These results indicate that the properties of bars are strongly related to those of their host galaxies, but do not depend on the local environment.
astro-ph.GA:Using H I absorption spectra taken from the recent surveys of 21-cm line and continuum emission in the Galactic plane, the distribution of cool atomic clouds in the outer disk of the Milky Way is revealed. The warp of the midplane is clearly seen in absorption, as it is in emission, and the cool, neutral medium also shows flaring or increase in scale height with radius similar to that of the warm atomic hydrogen. The mixture of phases, as measured by the fraction of H I in the cool clouds relative to the total atomic hydrogen, stays nearly constant from the solar circle out to about 25 kpc radius. Assuming cool phase temperature ~50 K this indicates a mixing ratio of 15% to 20% cool H I, with the rest warm.
astro-ph.GA:The papers in this volume represent a broad spectrum of observational, theoretical, and computational astrophysics, sharing as a unifying core the Disk-Halo Interaction in the Milky Way and other spiral galaxies. This topic covers a wide range of Galactic and extra-galactic research, built on a foundation of numerous and diverse physical processes. This summary groups the papers according to six themes, with some historical background and finally a look to the future. The final message is that the astrophysical techniques discussed and reviewed at this conference will grow over the next decade to answer even more fundamental questions about galaxy evolution and the history of the universe.
astro-ph.GA:We present mid-IR observations of the Galactic Luminous Blue Variable (LBV) HR Car and its associated nebula carried out with the Spitzer Space Telescope using both IRAC and IRS, as part of a GTO program aimed to study stellar ejecta from evolved stars. Our observations reveal a rich mid-IR spectrum of the inner nebula showing both solid state and atomic gas signatures. Strong low-excitation atomic fine structure lines such as $ 26.0 \mu$m [\ion{Fe}{2}] and $ 34.8 \mu$m [\ion{Si}{2}], indicate, for the first time, the presence of a PDR in this object class. While the physics and chemistry of the low-excitation gas appears to be dominated by photodissociation, a possible contribution due to shocks can be inferred from the evidence of gas phase Fe abundance enhancement. The presence of amorphous silicates, inferred from the observed characteristic broad feature at $10 \mu$m located in the inner nebula, suggests that dust has formed during the LBV outburst. This is in contrast with the detection of crystalline dust in other probably more evolved Galactic LBVs, which is similar to the crystalline dust observed in red supergiants. This has been considered to be evidence of dust production during evolutionary phases prior to the outburst.
astro-ph.GA:We propose a methodology to perform a self-consistent analysis of the physical properties of the emitting gas of HII galaxies adequate to the data that can be obtained with the XXI century technology. This methodology requires the production and calibration of empirical relations between the different line temperatures that should superseed currently used ones based on very simple, and poorly tested, photo-ionization model sequences. Then, these observations are analysed applying a methodology designed to obtain accurate elemental abundances of oxygen, sulphur, nitrogen, neon, argon and iron in the ionsied gas. Four electron temperatures and one electron density are derived from the observed forbidden line ratios using the five-level atom approximation. For our best objects errors of 1% in T([OIII]), 3% in T([OII]) and 5% in T([SIII]) are achieved with a resulting accuracy between 5 and 9% in total oxygen abundances, O/H. These accuracies are expected to improve as better calibrations based on more precise measurements, both on electron temperatures and densities, are produced.
astro-ph.GA:We performed astrometric observations with the VLBA of WB89-437, an H2O maser source in the Outer spiral arm of the Galaxy. We measure an annual parallax of 0.167 +/- 0.006 mas, corresponding to a heliocentric distance of 6.0 +/- 0.2 kpc or a Galactocentric distance of 13.4 +/- 0.2 kpc. This value for the heliocentric distance is considerably smaller than the kinematic distance of 8.6 kpc. This confirms the presence of a faint Outer arm toward l = 135 degrees. We also measured the full space motion of the object and find a large peculiar motion of ~20 km/s toward the Galactic center. This peculiar motion explains the large error in the kinematic distance estimate. We also find that WB89-437 has the same rotation speed as the LSR, providing more evidence for a flat rotation curve and thus the presence of dark matter in the outer Galaxy.
astro-ph.GA:We revisit the mass ratio Rmol between molecular hydrogen (H2) and atomic hydrogen (HI) in different galaxies from a phenomenological and theoretical viewpoint. First, the local H2-mass function (MF) is estimated from the local CO-luminosity function (LF) of the FCRAO Extragalactic CO-Survey, adopting a variable CO-to-H2 conversion fitted to nearby observations. This implies an average H2-density Omega_H2=(6.9+-2.7) 10^5/h and Omega_H2/Omega_HI=0.26+-0.11 in the local Universe. Second, we investigate the correlations between Rmol and global galaxy properties in a sample of 245 local galaxies. Based on these correlations we introduce four phenomenological models for Rmol, which we apply to estimate H2-masses for each HI-galaxy in the HIPASS catalogue. The resulting H2-MFs (one for each model for Rmol) are compared to the reference H2-MF derived from the CO-LF, thus allowing us to determine the Bayesian evidence of each model and to identify a clear best model, in which, for spiral galaxies, Rmol negatively correlates with both galaxy Hubble type and total gas mass. Third, we derive a theoretical model for Rmol for regular galaxies based on an expression for their axially symmetric pressure profile dictating the degree of molecularization. This model is quantitatively similar to the best phenomenological one at redshift z=0, and hence represents a consistent generalization while providing a physical explanation for the dependence of Rmol on global galaxy properties. Applying the best phenomenological model for Rmol to the HIPASS sample, we derive the first integral cold gas-MF (HI+H2+helium) of the local Universe.
astro-ph.GA:Observations of high redshift galaxies have revealed a multitude of large clumpy rapidly star-forming galaxies. Their formation scenario and their link to present day spirals is still unknown. In this Letter we perform adaptive mesh refinement simulations of disk formation in a cosmological context that are unrivalled in terms of mass and spatial resolution. We find that the so called "chain-galaxies" and "clump-clusters" are a natural outcome of early epochs of enhanced gas accretion from cold dense streams as well as tidally and ram-pressured stripped material from minor mergers and satellites. Through interaction with the hot halo gas, this freshly accreted cold gas settles into a large disk-like system, not necessarily aligned to an older stellar component, that undergoes fragmentation and subsequent star formation, forming large clumps in the mass range 10^7-10^9 M_sun. Galaxy formation is a complex process at this important epoch when most of the central baryons are being acquired through a range of different mechanisms - we highlight that a rapid mass loading epoch is required to fuel the fragmentation taking place in the massive arms in the outskirts of extended disks, an accretion mode that occurs naturally in the hierarchical assembly process at early epochs.
astro-ph.GA:We report on the detection of a population of weak metal-line absorbers in the halo or nearby intergalactic environment of the Milky Way. Using high-resolution ultraviolet absorption-line spectra of bright QSOs obtained with the Space Telescope Imaging Spectrograph (STIS), along six sight lines we have observed unsaturated, narrow absorption in OI and SiII together with mildly saturated CII absorption at high radial velocities (|v_LSR|=100-320 km/s). The measured OI column densities are small, implying that these structures represent Lyman-Limit Systems and sub-Lyman-Limit System with HI column densities < 3x10^18 cm^-2, thus below the detection limits of current 21cm all-sky surveys of high-velocity clouds (HVCs). The absorbers apparently are not directly associated with any of the large high-column density HVC complexes, but rather represent isolated, partly neutral gas clumps embedded in a more tenuous, ionized gaseous medium situated in the halo or nearby intergalactic environment of the Galaxy. We speculate that this absorber population represents the local analog of weak MgII systems that are commonly observed in the circumgalactic environment of low- and high-redshift galaxies.
astro-ph.GA:I review the observational constraints on the star formation histories in the spheroids of M33 and M31, the other two spiral galaxies in the Local Group. M33 does not possess a traditional bulge; instead, it has a small nuclear region hosting stars with a wide range of ages. The star formation history of the M33 halo is poorly constrained, but composite spectra of its halo globular clusters imply a wide age spread of 5 - 7 years, while the presence of RR Lyrae stars in the halo implies at least some of the population is ancient. Although it is possible to obtain the detailed star formation history of the M33 halo via deep photometry, this has not been done to date. M31 hosts a traditional bulge that is apparently dominated by stars older than 10 Gyr. Deep photometry of the M31 halo demonstrates that it hosts both a population of ancient metal-poor stars and a significant population extending to younger ages and high metallicity, apparently due to its active merger history.
astro-ph.GA:The complete census of globular clusters formerly belonging to the Sgr dSph and now deposited into the Galactic halo is an important contribution to our comprehension of the evolution and disruption of this dwarf galaxy. We investigate in this study the possibility that the poorly known "old" globular AM 4 might be associated with the Sagittarius dwarf galaxy, and at the same time provide more solid estimate of its basic parameters. New high quality BVI photometry is presented, from which an improved Color Ma gnitude Diagram is constructed, and estimates of age and distance are then derived. The distance and Galactic position are finally investigated in details. AM~4 is found to be a low luminosity (M$_V$=-1.82) cluster undergoing strong tidal stress by the Milky Way and on the verge to be dissolved. Besides, and at odds with previous suggestions, we provide evidences that AM 4 is indeed young, with an age around 9 Gyrs (as Terzan~7), but somewhat more metal poor ([Fe/H=-0.97]). AM~4 is located at 33$_{-4}^{+3}$ kpc from the Sun, in a direction and at distance not totally incompatible with the Sgr dSph stream. Although we significantly improved our knowledge of AM 4, further studies are encouraged to obtain radial velocity and metallicity to d emonstrate more firmly (or deny) the association to Sgr
astro-ph.GA:In this paper, a consistent model of the multifrequency emission of the starburst galaxy M82, from radio to gamma-rays is presented and discussed. Predictions for observations with Fermi, MAGIC II/VERITAS and CTA telescopes are made. The model is also used to self-consistenty compute the (all flavors) emission of neutrinos resulting from this starburst galaxy, what can be used in considerations of the diffuse contributions of such objects.
astro-ph.GA:Ram pressure stripping of the multiphase ISM is studied in the perturbed Virgo cluster spiral galaxy NGC 4438. This galaxy underwent a tidal interaction ~100 Myr ago and is now strongly affected by ram pressure stripping. Deep VLA radio continuum observations at 6 and 20 cm are presented. We detect prominent extraplanar emission to the west of the galactic center, which extends twice as far as the other tracers of extraplanar material. The spectral index of the extraplanar emission does not steepen with increasing distance from the galaxy. This implies in situ re-acceleration of relativistic electrons. The comparison with multiwavelength observations shows that the magnetic field and the warm ionized interstellar medium traced by Halpha emission are closely linked. The kinematics of the northern extraplanar Halpha emission, which is ascribed to star formation, follow those of the extraplanar CO emission. In the western and southern extraplanar regions, the Halpha measured velocities are greater than those of the CO lines. We suggest that the ionized gas of this region is excited by ram pressure. The spatial and velocity offsets are consistent with a scenario where the diffuse ionized gas is more efficiently pushed by ram pressure stripping than the neutral gas. We suggest that the recently found radio-deficient regions compared to 24 mum emission are due to this difference in stripping efficiency.
astro-ph.GA:We present an analysis of the X-ray point source populations in 182 Chandra images of galaxy clusters at z>0.1 with exposure time >10 ksec, as well as 44 non-cluster fields. Analysis of the number and flux of these sources, using a detailed pipeline to predict the distribution of non-cluster sources in each field, reveals an excess of X-ray point sources associated with the galaxy clusters. A sample of 148 galaxy clusters at 0.1<z<0.9, with no other nearby clusters, show an excess of 230 cluster sources in total, an average of ~1.5 sources per cluster. The lack of optical data for these clusters limits the physical interpretation of this result, as we cannot calculate the fraction of cluster galaxies hosting X-ray sources. However, the fluxes of the excess sources indicate that over half of them are very likely to be AGN, and the radial distribution shows that they are quite evenly distributed over the central 1 Mpc of the cluster, with almost no sources found beyond this radius. We also use this pipeline to successfully reproduce the results of previous studies, particularly the higher density of sources in the central 0.5 Mpc of a few cluster fields, but show that these conclusions are not generally valid for this larger sample of clusters. We conclude that some of these differences may be due to the sample properties, such as the size and redshift of the clusters studied, or a lack of publications for cluster fields with no excess sources. This paper also presents the basic X-ray properties of the galaxy clusters, and in subsequent papers in this series the dependence of the AGN population on these cluster properties will be evaluated.   In addition the properties of over 9500 X-ray point sources in the fields of galaxy clusters are tabulated in a separate catalogue available online.
astro-ph.GA:We report spatially-resolved variations in the 3.4micron hydrocarbon absorption feature and the 3.3micron polycyclic aromatic hydrocarbon (PAH) emission band in the Circinus galaxy over the central few arcsec. The absorption is measured towards warm emitting dust associated with Coronal line regions to the east and west of the nucleus. There is an absorption optical depth tau(3.4um) ~0.1 in the core which decreases to the west and increases to the east. This is consistent with increased extinction out to ~40 pc east of the core, supported by the Coronal emission line intensities which are significantly lower to the east than the west. PAH emission is measured to be symmetrically distributed out to +/- 4 arcsec, outside the differential extinction region. The asymmetry in the 3.4micron absorption band reflects that seen in the 9.7micron silicate absorption band reported by Roche et al. (2006) and the ratio of the two absorption depths remains approximately constant across the central regions, with tau(3.4um) / tau(9.7um) ~ 0.06 +/-0.01. This indicates well-mixed hydrocarbon and silicate dust populations, with no evidence for significant changes near the nucleus.
astro-ph.GA:In a programme of observations of local luminous blue compact galaxies (BCGs), we are investigating kinematics by using tracers of both stars and ionized gas. Here we summarise our program and present new data on the local Lyman break galaxy analogue Haro 11. From spatially-resolved spectroscopy around the near-infrared Ca II triplet, we find that its stars and ionized gas have similar velocity fields. Our programme so far indicates however that emission line velocities can differ locally by a few tens of km/s from the Ca II values. Comparing our data to simple stellar population models, we assess which stellar population the Ca II triplet traces and its potential beyond the local universe.
astro-ph.GA:The study of PopI and PopII indicators in galaxies has a profound impact on our understanding of galaxy evolution. Their present (z=0) ratio suggests that the star formation history of galaxies was primarily dictated by their global mass. Since 1989 Luis Carrasco and I spent most of our sleepless nights gathering H_alpha and near infrared surface photometry of galaxies in the local Universe and focused most of our scientific career on these two indicators trying to convince the community that the mass was the key parameter to their evolution. We were unsuccessful, until in 2004 the Sloan team rediscovered this phenomenon and named it "downsizing"
astro-ph.GA:Gamma-ray emission from cocoons of young radio galaxies is predicted. Considering the process of adiabatic injection of the shock dissipation energy and mass of the relativistic jet into the cocoon, we find that the thermal electron temperature of the cocoon is typically predicted to be of the order of $\sim$ MeV, and is determined only by the bulk Lorentz factor of the jet. Together with the time-dependent dynamics of the cocoon expansion, we find that young cocoons can yield thermal Bremsstrahlung emissions at energies $\sim$MeV. Hotter cocoons (i.e., GeV) for younger sources are also discussed.
astro-ph.GA:Coordinates, magnitudes and spectra are presented for 39 cataclysmic variables found in Sloan Digital Sky Survey spectra that were primarily obtained in 2006. Of these, 12 were CVs identified prior to the SDSS spectra (GY Cnc, GO Com, ST LMi, NY Ser, MR Ser, QW Ser, EU UMa, IY UMa, HS1340+1524, RXJ1610.1+0352, Boo 1, Leo 5). Follow-up spectroscopic observations of seven systems (including one from year 2005 and another from year 2004) were obtained, resulting in estimates of the orbital periods for 3 objects. The new CVs include two candidates for high inclination, eclipsing systems, 4 new Polars and three systems whose spectra clearly reveal atmospheric absorption lines from the underlying white dwarf.
astro-ph.GA:Recent developments on the study of mixed morphology supernova remnants (MMSNRs) have revealed the presence of metal rich X-ray emitting plasma inside a fraction of these remnant, a feature not properly addressed by traditional models for these objects. Radial profiles of thermodynamical and chemical parameters are needed for a fruitful comparison of data and model of MMSNRs, but these are available only in a few cases. We analyze XMM-Newton data of two MMSNRs, namely IC443 and G166.0+4.3, previously known to have solar metal abundances, and we perform spatially resolved spectral analysis of the X-ray emission. We detected enhanced abundances of Ne, Mg and Si in the hard X-ray bright peak in the north of IC443, and of S in the outer regions of G166.0+4.3. The metal abundances are not distributed uniformly in both remnants. The evaporating clouds model and the radiative SNR model fail to reproduce consistently all the observational results. We suggest that further deep X-ray observations of MMSNRs may reveal more metal rich objects. More detailed models which include ISM-ejecta mixing are needed to explain the nature of this growing subclass of MMSNRs.
astro-ph.GA:Deep ACS slitless grism observations and identification of stellar sources are presented within the Great Observatories Origins Deep Survey (GOODS) North and South fields which were obtained in the Probing Evolution And Reionization Spectroscopically (PEARS) program. It is demonstrated that even low resolution spectra can be a very powerful means to identify stars in the field, especially low mass stars with stellar types M0 and later. The PEARS fields lay within the larger GOODS fields, and we used new, deeper images to further refine the selection of stars in the PEARS field, down to a magnitude of mz = 25 using a newly developed stellarity parameter. The total number of stars with reliable spectroscopic and morphological identification was 95 and 108 in the north and south fields respectively. The sample of spectroscopically identified stars allows constraints to be set on the thickness of the Galactic thin disk as well as contributions from a thick disk and a halo component. We derive a thin disk scale height, as traced by the population of M4 to M9 dwarfs along two independent lines of sight, of h_thin = 370 +60/-65 pc. When including the more massive M0 to M4 dwarf population, we derive h_thin = 300 +/- 70pc. In both cases, we observe that we must include a combination of thick and halo components in our models in order to account for the observed numbers of faint dwarfs. The required thick disk scale height is typically h_thick=1000 pc and the acceptable relative stellar densities of the thin disk to thick disk and the thin disk to halo components are in the range of 0.00025<f_halo<0.0005 and 0.05<f_thick<0.08 and are somewhat dependent on whether the more massive M0 to M4 dwarfs are included in our sample.
astro-ph.GA:The Large Area Telescope on the recently launched Fermi Gamma-ray Space Telescope (formerly GLAST), with its large field of view and effective area, combined with its excellent timing capabilities, is poised to revolutionize the field of gamma-ray astrophysics. The large improvement in sensitivity over EGRET is expected to result in the discovery of many new gamma-ray pulsars, which in turn should lead to fundamental advances in our understanding of pulsar physics and the role of neutron stars in the Galaxy. Almost immediately after launch, Fermi clearly detected all previously known gamma-ray pulsars and is producing high precision results on these. An extensive radio and X-ray timing campaign of known (primarily radio) pulsars is being carried out in order to facilitate the discovery of new gamma-ray pulsars. In addition, a highly efficient time-differencing technique is being used to conduct blind searches for radio-quiet pulsars, which has already resulted in new discoveries. I present some recent results from searches for pulsars carried out on Fermi data, both blind searches, and using contemporaneous timing of known radio pulsars.
astro-ph.GA:We observed the northern rim of the Cygnus Loop with the \textit{Suzaku} observatory in 5 pointings (P21-P25). From the spatially resolved analysis, all the spectra are well fitted by the single component of the non-equilibrium ionization plasma model. From the best-fit parameters, we found that the abundances of the heavy elements are significantly lower than the solar values except those at the outermost edge in P21 and P22. The origin of the depleted metal abundances is still unclear while such deficiencies have been reported from many other rim observations of the Loop. To explain these depletion at the rim regions, we considered the several possibilities. The effects of the resonance-line-scattering and the grain condensation lower the values of the abundances. However, these are not sufficient to account for the abundance depletion observed.   We found that the abundances at the outermost edge in P21 and P22 are higher than those at the other regions. From the morphological point of view, it is reasonable to consider that this abundance inhomogeneity is derived from the breakout or the thinness of the cavity wall of the Loop.
astro-ph.GA:We analyzed the metal distribution of the Cygnus Loop using 14 and 7 pointings observation data obtained by the \textit{Suzaku} and the \textit{XMM-Newton} observatories. The spectral analysis shows that all the spectra are well fitted by the two-$kT_e$ non-equilibrium ionization plasma model as shown by the earlier observations. From the best-fit parameters of the high-$kT_e$ component, we calculated the emission measures about various elements and showed the metal distribution of the ejecta component. We found that the distributions of Si and Fe are centered at the southwest of the geometric center toward the blow-out region. From the best-fit parameters, we also estimated the progenitor mass of the Cygnus Loop from our field of view and the metal rich region with a radius of 25 arcmin from the metal center. The result from the metal circle is similar to that from our entire FOV, which suggests the mixing of the metal. From the results, we estimated the mass of the progenitor star at 12-15\MO.
astro-ph.GA:Context. The origin, evolution, and ultimate fate of magnetic cataclysmic variables are poorly understood. It is largely the nature of the magnetic fields in these systems that leads to this poor understanding. Fundamental properties, such as the field strength and the axis alignment, are unknown in a majority of these systems. Aims. We undertake to put all the previous circular polarization measurements into context and systematically survey intermediate polars for signs of circular polarization, hence to get an indication of their true magnetic field strengths and try to understand the evolution of magnetic cataclysmic variables. Methods. We used the TurPol instrument at the Nordic Optical Telescope to obtain simultaneous UBVRI photo-polarimetric observations of a set of intermediate polars, during the epoch 2006 July 31 - August 2. Results. Of this set of eight systems two (1RXS J213344.1+510725 and 1RXS J173021.5-055933) were found to show significant levels of circular polarization, varying with spin phase. Five others (V2306 Cyg, AO Psc, DQ Her, FO Aqr, and V1223 Sgr) show some evidence for circular polarization and variation of this with spin phase, whilst AE Aqr shows little evidence for polarized emission. We also report the first simultaneous UBVRI photometry of the newly identified intermediate polar 1RXS J173021.5-055933. Conclusions. Circular polarization may be ubiquitous in intermediate polars, albeit at a low level of one or two percent or less. It is stronger at longer wavelengths in the visible spectrum. Our results lend further support to the possible link between the presence of soft X-ray components and the detectability of circular polarization in intermediate polars.
astro-ph.GA:White dwarf masses in cataclysmic variables are difficult to determine accurately, but are fundamental for understanding binary system parameters, as well as binary evolution. We investigate the X-ray spectral properties of a sample of Intermediate Polars detected above 15 keV to derive the masses of their accreting white dwarfs. We use data from the Swift/BAT instrument which during the first 2.5 yrs of operation has detected 22 known intermediate polars. The X-ray spectra of these sources are used to estimate the mass of the white dwarfs. We are able to produce a mass estimate for 22 out of 29 of the confirmed intermediate polars. Comparison with previous mass measurements shows good agreement. For GK Per, we were able to detect spectral changes due to the changes in the accretion rate. The Swift/BAT detector with its combination of sensitivity and all-sky coverage provides an ideal tool to determine accurate white dwarf masses in intermediate polars.
astro-ph.GA:Supersonic turbulence is a large reservoir of suprathermal energy in the interstellar medium. Its dissipation, because it is intermittent in space and time, can deeply modify the chemistry of the gas. We further explore a hybrid method to compute the chemical and thermal evolution of a magnetized dissipative structure, under the energetic constraints provided by the observed properties of turbulence in the cold neutral medium. For the first time, we model a random line of sight by taking into account the relative duration of the bursts with respect to the thermal and chemical relaxation timescales of the gas. The key parameter is the turbulent rate of strain "a" due to the ambient turbulence. With the gas density, it controls the size of the dissipative structures, therefore the strength of the burst. For a large range of rates of strain and densities, the models of turbulent dissipation regions (TDR) reproduce the CH+ column densities observed in the diffuse medium and their correlation with highly excited H2. They do so without producing an excess of CH. As a natural consequence, they reproduce the abundance ratios of HCO+/OH and HCO+/H2O, and their dynamic range of about one order of magnitude observed in diffuse gas. Large C2H and CO abundances, also related to those of HCO+, are another outcome of the TDR models that compare well with observed values. The abundances and column densities computed for CN, HCN and HNC are one order of magnitude above PDR model predictions, although still significantly smaller than observed values.
astro-ph.GA:The black hole at the Galactic Center, Sgr A*, is the prototype of a galactic nucleus at a very low level of activity. Its radio through submm-wave emission is known to come from a region close to the event horizon, however, the source of the emission is still under debate. A successful theory explaining the emission is based on a relativistic jet model scaled down from powerful quasars. We want to test the predictive power of this established jet model against newly available measurements of wavelength-dependent time lags and the size-wavelength structure in Sgr A*. Using all available closure amplitude VLBI data from different groups, we again derived the intrinsic wavelength-dependent size of Sgr A*. This allowed us to calculate the expected frequency-dependent time lags of radio flares, assuming a range of in- and outflow velocities. Moreover, we calculated the time lags expected in the previously published pressure-driven jet model. The predicted lags are then compared to radio monitoring observations at 22, 43, and 350 GHz. The combination of time lags and size measurements imply a mildly relativistic outflow with bulk outflow speeds of gamma*beta ~ 0.5-2. The newly measured time lags are reproduced well by the jet model without any major fine tuning. The results further strengthen the case for the cm-to-mm wave radio emission in Sgr A* as coming from a mildly relativistic jet-like outflow. The combination of radio time lag and VLBI closure amplitude measurements is a powerful new tool for assessing the flow speed and direction in Sgr A*. Future VLBI and time lag measurements over a range of wavelengths will reveal more information about Sgr A*, such as the existence of a jet nozzle, and measure the detailed velocity structure of a relativistic jet near its launching point for the first time.
astro-ph.GA:High-dynamic-range surface photometry in a companion paper makes possible accurate measurement of the stellar light deficits L_def and mass deficits M_def associated with the cores of elliptical galaxies. We show that L_def correlates with the velocity dispersion sigma of the host galaxy bulge averaged outside the central region that may be affected by a supermassive black hole (BH). We confirm that L_def correlates with BH mass MBH. Also, the fractional light deficit L_def/L correlates with MBH/M, the ratio of BH mass to the galaxy stellar mass. All three correlations have scatter similar to or smaller than the scatter in the well known correlation between MBH and sigma. The new correlations are remarkable in view of the dichotomy between ellipticals with cores and those with central extra light. Core light deficit correlates closely with MBH and sigma, but extra light does not. This supports the suggestion that extra light Es are made in wet mergers with starbursts whereas core Es are made in dry mergers. After dry mergers, cores are believed to be scoured by BH binaries that fling stars away as their orbits decay or by BHs that sink back to the center after recoiling from anisotropic gravitational radiation emitted when they merge. Direct evidence has been elusive. We interpret the new correlations as the "smoking gun" that connects cores with BHs. Together, the MBH - sigma and MBH - L_def correlations give us two independent ways to estimate BH masses in core ellipticals.
astro-ph.GA:We identify SDSS J153636.22+044127.0, a QSO discovered in the Sloan Digital Sky Survey, as a promising candidate for a binary black hole system. This QSO has two broad-line emission systems separated by 3500 km/sec. The redder system at z=0.3889 also has a typical set of narrow forbidden lines. The bluer system (z=0.3727) shows only broad Balmer lines and UV Fe II emission, making it highly unusual in its lack of narrow lines. A third system, which includes only unresolved absorption lines, is seen at a redshift, z=0.3878, intermediate between the two emission-line systems. While the observational signatures of binary nuclear black holes remain unclear, J1536+0441 is unique among all QSOs known in having two broad-line regions, indicative of two separate black holes presently accreting gas. The interpretation of this as a bound binary system of two black holes having masses of 10^8.9 and 10^7.3 solar masses, yields a separation of ~ 0.1 parsec and an orbital period of ~100 years. The separation implies that the two black holes are orbiting within a single narrow-line region, consistent with the characteristics of the spectrum. This object was identified as an extreme outlier of a Karhunen-Loeve Transform of 17,500 z < 0.7 QSO spectra from the SDSS. The probability of the spectrum resulting from a chance superposition of two QSOs with similar redshifts is estimated at 2X10^-7, leading to the expectation of 0.003 such objects in the sample studied; however, even in this case, the spectrum of the lower redshift QSO remains highly unusual.
astro-ph.GA:We use velocity and metallicity information from SDSS and SEGUE stellar spectroscopy to fit an orbit to the narrow $63^\circ$ stellar stream of Grillmair and Dionatos. The stars in the stream have a retrograde orbit with eccentricity $e = 0.33$ (perigalacticon of 14.4 kpc and apogalacticon of 28.7 kpc) and inclination approximately $i \sim 35^\circ$. In the region of the orbit which is detected, it has a distance of about 7 to 11 kpc from the Sun. Assuming a standard disk plus bulge and logarithmic halo potential for the Milky Way stars plus dark matter, the stream stars are moving with a large space velocity of approximately $276 \rm km s^{-1}$ at perigalacticon. Using this stream alone, we are unable to determine if the dark matter halo is oblate or prolate. The metallicity of the stream is [Fe/H] $= -2.1\pm0.1$. Observed proper motions for individual stream members above the main sequence turnoff are consistent with the derived orbit. None of the known globular clusters in the Milky Way have positions, radial velocities, and metallicities that are consistent with being the progenitor of the GD-1 stream.
astro-ph.GA:We study the polarization properties of relativistic reconfinement shocks with chaotic magnetic fields. Using our hydrodynamical model of their structure, we calculate synthetic polarization maps, longitudinal polarization profiles and discuss the spatially averaged polarization degree as a function of jet half-opening angle Theta_j, jet Lorentz factor Gamma_j and observer inclination angle to the jet axis theta_{obs}. We find, that for theta_{obs} <= Theta_j the wave electric vectors are parallel in the vicinity of the structure ends and perpendicular in between, while for theta_{obs} > Theta_j the polarization can only be perpendicular. The spatially averaged polarization degree does not exceed 30%. Parallel average polarization, with polarization degrees lower than 10%, have been found for theta_{obs} < Theta_j under the condition Gamma_j * Theta_j > 1. As earlier works predicted the parallel polarization from relativistic conical shocks, we explain our results by discussing conical shocks with divergent upstream flow.
astro-ph.GA:Two compact HI clouds which seem to belong to the Ophiuchus superbubble were studied at ~30" resolution using the Very Large Array (VLA) in C and D configurations together with the Green Bank Telescope (GBT) providing the short-spacing flux. Here we present preliminary results of the data analysis.
astro-ph.GA:We present Submillimeter Array observations toward the 10^{4.7} Lsun star-forming region G240.31+0.07, in the J=2-1 transition of 12CO and 13CO and at 1.3 mm continuum, as well as the 12CO and 13CO observations from the Caltech Submillimeter Observatory to recover the extended emission filtered out by the interferometer. Maps of the 12CO and 13CO emission show a bipolar, wide-angle, quasi-parabolic molecular outflow, roughly coincident with an IR nebula revealed by the Spitzer 3.6 and 4.5 micron emission. The outflow has ~98 Msun molecular gas, making it one of the most massive molecular outflows known, and resulting in a very high mass-loss rate of 4.1 by 10^{-3} Msun yr^{-1} over a dynamical timescale of 2.4 by 10^4 yr. The 1.3 mm continuum observations with a 4" by 3" beam reveal a flattened dusty envelope of ~150 Msun, which is further resolved with a 1.2" by 1" beam into three dense cores with a total mass of ~40 Msun. The central mm core, showing evidence of active star formation, approximately coincides with the geometric center of the bipolar outflow thus most likely harbors the powering source of the outflow. Overall our observations provide the best case to date of a well-defined wide-angle molecular outflow in a >10^4 Lsun star-forming region. The outflow is morphologically and kinematically similar to low-mass protostellar outflows but has two to three orders of magnitude greater mass, momentum, and energy, and is apparently driven by an underlying wide-angle wind, hence further supports that high-mass stars up to late-O types, even in a crowded clustering environment, can form as a scaled-up version of low-mass star formation.
astro-ph.GA:Thin accretion discs around massive compact objects can support slow pressure modes of oscillations in the linear regime that have azimuthal wavenumber $m=1$. We consider finite, flat discs composed of barotropic fluid for various surface density profiles and demonstrate--through WKB analysis and numerical solution of the eigenvalue problem--that these modes are stable and have spatial scales comparable to the size of the disc. We show that the eigenvalue equation can be mapped to a Schr\"odinger-like equation. Analysis of this equation shows that all eigenmodes have discrete spectra. We find that all the models we have considered support negative frequency eigenmodes; however, the positive eigenfrequency modes are only present in power law discs, albeit for physically uninteresting values of the power law index $\beta$ and barotropic index $\gamma$.
astro-ph.GA:We aim to study the structure, dynamics and physical conditions of Gomez's Hamburger (IRAS 18059-3211; GoHam). We confirm that GoHam essentially consists of a flaring disk in keplerian rotation around a young, probably pre-MS star. We present high resolution SMA maps of 12CO J=2-1, 13CO J=2-1, 12CO J=3-2, and C17O J=3-2, as well as data on 12CO J=6-5 and the continuum flux at these wavelengths. Spatial resolutions up to 1" are obtained. Except for the C17O data, the dynamical ranges are larger than 10. The maps are compared to a numerical model, which simulates the emission of a rotating disk with the expected general properties of such objects; a very satisfactory fitting of our maps is obtained. The meaning and reliability of our results are thoroughly discussed. Our observations allow measurement of the main properties of GoHam at scales between ~ 1" (~ 5 10^15 cm, for the assumed distance, 300 pc) and the total extent of the nebula, 14". We are able to measure the global structure of the gas-rich disk, which is found to be flaring, and its dynamics, which is clearly dominated by keplerian rotation, with a very small degree of turbulence. The combination of different lines, particularly showing different opacities, allows us to reasonably estimate the distributions of the gas temperature and density. We clearly find a significant and sharp increase in temperature at large distances from the equator, accompanied by a decrease in density of the same order. Finally, we identify and study a condensation in the southern part of the disk that has no counterparts in the rest of the nebula. This condensation is quite extended (about 5 10^15 cm), contains a significant amount of mass (roughly, ~ 6 10^-3 Mo), and seems to be associated with a detectable distortion of the global rotation kinematics.
astro-ph.GA:We present a study of the X-ray properties of a sample of six nearby late-type spiral galaxies based on XMM-Newton observations. Since our primary focus is on the linkage between X-ray emission and star formation in extended, extranuclear galactic disks, we have selected galaxies with near face-on aspect and sufficient angular extent so as to be readily amenable to investigation with the moderate spatial resolution afforded by XMM-Newton. After excluding regions in each galaxy dominated by bright point sources, we study both the morphology and spectral properties of the residual X-ray emission, comprised of both diffuse emission and the integrated signal of the fainter discrete source populations. The soft X-ray morphology generally traces the inner spiral arms and shows a strong correlation with the distribution of UV light, indicative of a close connection between the X-ray emission and recent star formation. The soft (0.3-2 keV) X-ray luminosity to star formation rate (SFR) ratio varies from 1-5 x 10^39 erg/s(/Msun/yr), with an indication that the lower range of this ratio relates to regions of lower SFR density. The X-ray spectra are well matched by a two-temperature thermal model with derived temperatures of typically ~0.2 keV and ~0.65 keV, in line with published results for other normal and star-forming galaxies. The hot component contributes a higher fraction of the soft luminosity in the galaxies with highest X-ray/SFR ratio, suggesting a link between plasma temperature and X-ray production efficiency. The physical properties of the gas present in the galactic disks are consistent with a clumpy thin-disk distribution, presumably composed of diffuse structures such as superbubbles together with the integrated emission of unresolved discrete sources including young supernova remnants.
astro-ph.GA:We present preliminary results from the highest available signal-to-noise rest-frame 2-8um spectra of z~2 ULIRGs. Our 10 targets are selected for their deep silicate absorption features based on previous shallower IRS spectra. The goal of this follow-up program is: 1) allow for a more accurate analysis of inner/hot dust continuum, 2) detecting the 3.3um and 6.2um PAH features, and 3) detecting molecular absorption features such as due to water ice and hydrocarbons (HACs). We find that the 3.4um HAC absorption feature is observed in four sources, while the 3.05um water ice feature is observed in three of the sources. The HAC detectability is higher and ice detectability lower than expected from local ULIRGs, but consistent with a more AGN-dominated sample such as this one. Where ice is detected, the ice-to-silicate ratio is somewhat lower than many local ULIRGs implying on average thinner ice mantles. One source shows the, to our knowledge, highest redshift reported detection of the 3.3um PAH feature (along with a previously detected 6.2um feature). The strength of the 3.3um feature is as expected for a starburst-dominated ULIRG.
astro-ph.GA:We compare the metallicities in high-redshift quasars to the star formation rates (SFR) in their host galaxies using measurements of broad emission lines and far-infrared (FIR) luminosities. The FIR emission indicates the level of ongoing massive starbursts in the galaxy, whereas the abundance of metals in the gas surrounding the quasar indicates the amount of star formation which occurred before the visible quasar phase began. The results of this study can be used to constrain the late stages of starburst-quasar evolution. We detect high metallicities throughout the sample, up to several times solar, confirming that star formation must have begun before the visible quasar phase. However, we do not detect a trend in metallicity versus current SFR.
astro-ph.GA:We present results of deep echelle spectrophotometry of the brightest knot of the HH202 in the Orion Nebula --HH202-S-- using the ultraviolet Visual Echelle Spectrograph (UVES). The high spectral resolution has permitted to separate the component associated with the ambient gas from that associated with the gas flow. We derive electron densities and temperatures for both components, as well as the chemical abundances of several ions and elements from collisionally excited lines, including the first determinations of Ca^{+} and Cr^{+} abundances in the Orion Nebula. We also calculate the He^{+}, C^{2+}, O^{+} and O^{2+} abundances from recombination lines. The difference between the O^{2+} abundances determined from collisionally excited and recombination lines --the so-called abundance discrepancy factor-- is 0.35 dex and 0.11 dex for the shock and nebular components, respectively. Assuming that the abundance discrepancy is produced by spatial variations in the electron temperature, we derive values of the temperature fluctuation parameter, t^2, of 0.050 and 0.016, for the shock and nebular components, respectively. Interestingly, we obtain almost coincident t^2 values for both components from the analysis of the intensity ratios of He I lines. We find significant departures from case B predictions in the Balmer and Paschen flux ratios of lines of high principal quantum number n. We analyze the ionization structure of HH202-S, finding enough evidence to conclude that the flow of HH202-S has compressed the ambient gas inside the nebula trapping the ionization front. We measure a strong increase of the total abundances of nickel and iron in the shock component, the abundance pattern and the results of photoionization models for both components are consistent with the partial destruction of dust after the passage of the shock wave in HH202-S.
astro-ph.GA:Although the stellar initial mass function (IMF) has only been directly determined in star clusters it has been manifoldly applied on galaxy-wide scales. But taking the clustered nature of star formation into account the galaxy-wide IMF is constructed by adding all IMFs of all young star clusters leading to an integrated galactic initial mass function (IGIMF). The IGIMF is top-light compared to the canonical IMF in star clusters and steepens with decreasing total star formation rate (SFR). This discrepancy is marginal for large disk galaxies but becomes significant for SMC-type galaxies and less massive ones. We here construct IGIMF-based relations between the total FUV and NUV luminosities of galaxies and the underlying SFR. We make the prediction that the Halpha luminosity of star forming dwarf galaxies decreases faster with decreasing SFR than the UV luminosity. This turn-down of the Halpha-UV flux ratio should be evident below total SFRs of 10^-2 M_sun/yr.
astro-ph.GA:Recent work has produced a wealth of data concerning the chemical evolution of the galactic bulge, both for stars and nebulae. Present theoretical models generally adopt a limited range of such constraints, frequently using a single chemical element (usually iron), which is not enough to describe it unambiguously. In this work, we take into account constraints involving as many chemical elements as possible, basically obtained from bulge nebulae and stars. Our main goal is to show that different scenarios can describe, at least partially, the abundance distribution and several distance-independent correlationss for these objects. Three classes of models were developed. The first is a one-zone, single-infall model, the second is a one-zone, double-infall model and the third is a multizone, double infall model. We show that a one-zone model with a single infall episode is able to reproduce some of the observational data, but the best results are achieved using a multizone, double infall model.
astro-ph.GA:We discuss whether the Gaussian is a reasonable approximation of the velocity distribution of stellar systems that are not spherically distributed. By using a non-Gaussian velocity distribution to describe the sources in the Large Magellanic Cloud (LMC), we reinvestigate the expected microlensing parameters of a lens population isotropically distributed either in the Milky Way halo or in the LMC (self lensing). We compare our estimates with the experimental results of the MACHO collaboration. An interesting result that emerges from our analysis is that, moving from the Gaussian to the non-Gaussian case, we do not observe any change in the form of the distribution curves describing the rate of microlensing events for lenses in the Galactic halo. The corresponding expected timescales and number of expected events also do not vary. Conversely, with respect to the self-lensing case, we observe a moderate increase in the rate and number of expected events. We conclude that the error in the estimate of the most likely value for the MACHO mass and the Galactic halo fraction in form of MACHOs, calculated with a Gaussian velocity distribution for the LMC sources, is not higher than 2%.
astro-ph.GA:In this paper we show results of numerical simulations for the turbulence in the interstellar medium. These results were obtained using a Riemann solver-free numerical scheme for high-Mach number hyperbolic equations. Here we especially concentrate on the physical properties of the ISM. That is, we do not present turbulence simulations trimmed to be applicable to the interstellar medium. The simulations are rather based on physical estimates for the relevant parameters of the interstellar gas.   Applying our code to simulate the turbulent plasma motion within a typical interstellar molecular cloud, we investigate the influence of different equations of state (isothermal and adiabatic) on the statistical properties of the resulting turbulent structures. We find slightly different density power spectra and dispersion maps, while both cases yield qualitatively similar dissipative structures, and exhibit a departure from the classical Kolmogorov case towards a scaling described by the She-Leveque model.   Solving the full energy equation with realistic heating/cooling terms appropriate for the diffuse interstellar gas, we are able to reproduce a realistic two-phase distribution of cold and warm plasma. When extracting maps of polarised intensity from our simulation data, we find encouraging similarity to actual observations. Finally, we compare the actual magnetic field strength of our simulations to its value inferred from the rotation measure. We find these to be systematically different by a factor of about 1.5, thus highlighting the often underestimated influence of varying line-of-sight particle densities on the magnetic field strength derived from observed rotation measures.
astro-ph.GA:Preliminary results are presented about a fully self-consistent N-body simulation of a sample of four massive globular clusters in close interaction within the central region of a galaxy. The N-body representation (with N=1.5x10^6 particles in total) of both the clusters and the galaxy allows to include in a natural and self-consistent way dynamical friction and tidal interactions. The results confirm the decay and merging of globulars as a viable scenario for the formation/accretion of compact nuclear clusters. Specifically: i) the frictional orbital decay is about 2 times faster than that predicted by the generalized Chandrasekhar formula; ii) the progenitor clusters merge in less than 20 galactic core-crossing times; iii) the NC configuration keeps quasi-stable at least within 70 galactic core-crossing times.
astro-ph.GA:We present a study of outflow and feedback in the well-known Seyfert 2 galaxy Markarian 573 using high angular resolution long-slit spectrophotometry obtained with the Hubble Space Telescope Imaging Spectrograph (STIS). Through analysis of the kinematics and ionization state of a biconical outflow region emanating from the nucleus, we find that the outflow does not significantly accelerate the surrounding host-galaxy interstellar gas and is too weak to be a strong ionization mechanism in the extended emission regions. Instead, the excitation of the extended regions is consistent with photoionization by the active nucleus. From energetics arguments we show that the nuclear outflow is slow and heavy and has a mechanical luminosity that is only ~1% of the estimated bolometric luminosity of the system. The energy in the outflow is able to mildly shape the gas in the extended regions but appears to be insufficient to unbind it, or even to plausibly disrupt star formation. These results are at odds with the picture of strong AGN feedback that has been invoked to explain certain aspects of galaxy evolution.
astro-ph.GA:N-body simulations show that "box-shaped bulges" of edge-on galaxies are not bulges at all: they are bars seen side-on. The two components that we readily see in edge-on Sb galaxies like NGC 4565 are a disk and a bar, but face-on SBb galaxies always show a disk, a bar, and a (pseudo)bulge. Where is the (pseudo)bulge in NGC 4565? We use archival Hubble Space Telescope K-band and Spitzer Space Telescope 3.6 um images to penetrate the dust in NGC 4565. We find a high surface brightness, central stellar component, distinct from the boxy bar and from the galaxy's disk. Its minor-axis profile has a Sersic index of 1.33+/-0.12, so it is a pseudobulge. The pseudobulge has the smallest scale height (~90 pc) of any component in the galaxy, in contrast to ~740 pc for the boxy bar plus thin disk. The disky pseudobulge is also much less luminous than the boxy bar, so the true (pseudo)bulge-to-total luminosity ratio of the galaxy is much less than previously thought. We infer that the pseudobulge-to-total luminosity ratios of edge-on galaxies with box-shaped bulges have generally been overestimated. Therefore more galaxies than we have recognized contain little or no evidence of a merger-built classical bulge. This challenges our picture of galaxy formation by hierarchical clustering, because it is difficult to grow big galaxies without also making a big classical bulge. Solving the puzzle of the "missing pseudobulge" in NGC 4565 further increases our confidence that we understand box-shaped bulges correctly as edge-on bars. This supports our developing picture of the formation of pseudobulges -- both edge-on bars and disky central components -- by secular evolution in isolated galaxies.
astro-ph.GA:[Abridged] We present Gemini-N GMOS-IFU observations of the central starburst clumps and inner wind of M82, together with WIYN DensePak IFU observations of the inner 2x0.9kpc of the disk. These cover the emission lines of H$\alpha$, [NII], [SII], and [SIII]. We were able to accurately decompose the emission line profiles into multiple narrow components (FWHM~30-130kms) superimposed on a broad (FWHM 150-350kms) feature. This paper is the first of a series examining the optical structure of M82's disk and inner wind; here we focus on the ionized gaseous and stellar dynamics and present maps of the relevant emission line properties.   Our observations show that ionized gas in the starburst core of M82 is dynamically complex. Localised line splitting of up to 100kms in the narrow component is associated with expanding shells of compressed, cool, photoionized gas. We have been able to associate some of this inner-wind gas with a distinct outflow channel characterised by its dynamics and gas density patterns, and we discuss the consequences of this discovery in terms of the developing wind outflow.   The broad optical emission line component is observed to become increasingly important moving outward along the outflow channel, and in general with increasing height above/below the plane. Following our recent work on the origins of this component, we associate it with turbulent gas in wind-clump interface layers and hence sites of mass loading, meaning that the turbulent mixing of cooler gas into the outflowing hot gas must become increasingly important with height, and provides powerful direct evidence for the existence of mass-loading over a large, spatially extended area.
astro-ph.GA:Adequate modelling of the multiphase interstellar medium requires optically thin radiative cooling, comprising an inherent thermal instability. The size of the occurring condensation and evaporation interfaces is determined by the so-called Field-length, which gives the dimension at which the instability is significantly damped by thermal conduction. Our aim is to study the relevance of conduction scale effects in the numerical modelling of a bistable medium and check the applicability of conventional and alternative adaptive mesh techniques. The low physical value of the thermal conduction within the ISM defines a multiscale problem, hence promoting the use of adaptive meshes. We here introduce a new refinement strategy that applies the Field condition by Koyama & Inutsuka as a refinement criterion. The described method is very similar to the Jeans criterion for gravitational instability by Truelove and efficiently allows to trace the unstable gas situated at the thermal interfaces. We present test computations that demonstrate the greater accuracy of the newly proposed refinement criterion in comparison to refinement based on the local density gradient. Apart from its usefulness as a refinement trigger, we do not find evidence in favour of the Field criterion as a prerequisite for numerical stability.
astro-ph.GA:Stellar feedback in galactic bulges plays an essential role in shaping the evolution of galaxies. To quantify this role and facilitate comparisons with X-ray observations, we conduct 3D hydrodynamical simulations with the adaptive mesh refinement code, FLASH, to investigate the physical properties of hot gas inside a galactic bulge, similar to that of our Galaxy or M31. We assume that the dynamical and thermal properties of the hot gas are dominated by mechanical energy input from SNe, primarily Type Ia, and mass injection from evolved stars as well as iron enrichment from SNe. We study the bulge-wide outflow as well as the SN heating on scales down to ~4 pc. An embedding scheme that is devised to plant individual SNR seeds, allows to examine, for the first time, the effect of sporadic SNe on the density, temperature, and iron ejecta distribution of the hot gas as well as the resultant X-ray morphology and spectrum. We find that the SNe produce a bulge wind with highly filamentary density structures and patchy ejecta. Compared with a 1D spherical wind model, the non-uniformity of simulated gas density, temperature, and metallicity substantially alters the spectral shape and increases the diffuse X-ray luminosity. The differential emission measure as a function of temperature of the simulated gas exhibits a log-normal distribution, with a peak value much lower than that of the corresponding 1D model. The bulk of the X-ray emission comes from the relatively low temperature and low abundance gas shells associated with SN blastwaves. SN ejecta are not well mixed with the ambient medium, at least in the bulge region. These results, at least partly, account for the apparent lack of evidence for iron enrichment in the soft X-ray-emitting gas in galactic bulges and intermediate-mass elliptical galaxies.[...]
astro-ph.GA:During a survey for stars with disks in the Taurus star-forming region using the Spitzer Space Telescope, we have discovered a pair of young brown dwarfs, FU Tau A and B, in the Barnard 215 dark cloud. They have a projected angular separation of 5.7", corresponding to 800 AU at the distance of Taurus. To assess the nature of these two objects, we have obtained spectra of them and have constructed their spectral energy distributions. Both sources are young (~1 Myr) according to their Halpha emission, gravity-sensitive spectral features, and mid-IR excess emission. The proper motion of FU Tau A provides additional evidence of its membership in Taurus. We measure spectral types of M7.25 and M9.25 for FU Tau A and B, respectively, which correspond to masses of ~0.05 and ~0.015 M\cdot according to the evolutionary models of Chabrier and Baraffe. FU Tau A is significantly overluminous relative to an isochrone passing through FU Tau B and relative to other members of Taurus near its spectral type, which may indicate that it is an unresolved binary. FU Tau A and B are likely to be components of a binary system based on the low probability (~3x10^-4) that Taurus would produce two unrelated brown dwarfs with a projected separation of a </- 6". Barnard 215 contains only one other young star and is in a remote area of Taurus, making FU Tau A and B the first spectroscopically-confirmed brown dwarfs discovered forming in isolation rather than in a stellar cluster or aggregate. Because they were born in isolation and comprise a weakly bound binary, dynamical interactions with stars could not have played a role in their formation, and thus are not essential for the birth of brown dwarfs. ERRATUM: The K-band magnitude for FU Tau B in Table 1 is incorrect and should be 13.33. The bolometric luminosity of FU Tau B in Table 3 and Figure 5 is incorrect because of that mistake and a separate arithmetic error. The correct value of the luminosity is 0.0039 Lsun. FU Tau A and B exhibited different isochronal ages in the original Hertzsprung-Russell diagram in Figure 5, which was unexpected for members of a binary system. This discrepancy is reduced in the corrected version of Figure 5 since both objects are now above the isochrone for 1 Myr. Given the large uncertainties in model isochrones at such young ages, the positions of FU Tau A and B in Figure 5 could be roughly consistent with coevality.
astro-ph.GA:Barium is a key element in constraining the evolution of the (not well understood) r-process in the first galactic stars and currently the Ba abundances in these very metal-poor stars were mostly measured under the Local Thermodynamical Equilibrium (LTE) assumption, which may lead in general to an underestimation of Ba. We present here determinations of the barium abundance taking into account the non-LTE (NLTE) effects in a sample of extremely metal-poor stars (EMP stars): 6 turnoff stars and 35 giants. The NLTE profiles of the three unblended Ba II lines (455.4, 585.3, 649.6nm) have been computed. The computations were made with a modified version of the MULTI code, applied to an atomic model of the Ba atom with 31 levels of Ba I, 101 levels of Ba II, and compared to the observations. The ratios of the NLTE abundances of barium relative to Fe are slightly shifted towards the solar ratio. In the plot of [Ba/Fe] versus [Fe/H], the slope of the regression line is slightly reduced as is the scatter. In the interval -3.3 <[Fe/H] < -2.6, [Ba/Fe] decreases with a slope of about 1.4 and a scatter close to 0.44. For [Fe/H] <-3.3 the number of stars is not sufficient to decide whether [Ba/Fe] keeps decreasing (and then CD-38:245 should be considered as a peculiar "barium-rich star") or if a plateau is reached as soon as [Ba/Fe] ~ -1. In both cases the scatter remains quite large, larger than what can be accounted for by the measurement and determination errors, suggesting the influence of a complex process of Ba production, and/or inefficient mixing in the early Galaxy.
astro-ph.GA:Optical studies of starbursts, AGN and their connections usually leave out galaxies whose emission lines are too weak to warrant reliable measurement and classification. Yet, weak line galaxies abound, and deserve a closer look. We show that these galaxies are either massive, metal rich star-forming systems, or, more often, LINERs. From our detailed stellar population analysis, we find that these LINERs have stopped forming stars long ago. Moreover, their ionizing radiation field is amazingly consistent with that expected from their old stellar populations alone. The black-hole in the centers of these massive, early-type galaxies is not active enough to overwhelm stellar ionization, and thus, despite their looks, they should not be called AGN.
astro-ph.GA:Galaxies are usually classified as star forming or active by using diagnostic diagrams, such as [N II]/Halpha vs. [O III]/Hbeta. Active galaxies are further classified into Seyfert or LINER-like sources. We claim that a non-negligible fraction of galaxies classified as LINERs in the Sloan Digital Sky Survey are in fact ionized by hot post-AGB stars and white dwarfs.
astro-ph.GA:The runaway star HD34078, initially selected to investigate small scale structure in a foreground diffuse cloud has been shown to be surrounded by highly excited H2. We first search for an association between the foreground cloud and HD34078. Second, we extend previous investigations of temporal absorption line variations (CH, CH+, H2) in order to better characterize them. We have mapped the CO(2-1) emission at 12 arcsec resolution around HD34078's position, using the 30 m IRAM antenna. The follow-up of CH and CH+ absorption lines has been extended over 5 more years. In parallel, CH absorption towards the reddened star Zeta Per have been monitored to check the homogeneity of our measurements. Three more FUSE spectra have been obtained to search for N(H2) variations. CO observations show a pronounced maximum near HD34078's position, clearly indicating that the star and diffuse cloud are associated. The optical spectra confirm the reality of strong, rapid and correlated CH and CH+ fluctuations. On the other hand, N(H2, J=0) has varied by less than 5 % over 4 years. We also discard N(CH) variations towards Zeta Per at scales less than 20 AU. Observational constraints from this work and from 24 micron dust emission appear to be consistent with H2 excitation but inconsistent with steady-state bow shock models and rather suggest that the shell of compressed gas surrounding HD34078, is seen at an early stage of the interaction. The CH and CH+ time variations as well as their large abundances are likely due to chemical structure in the shocked gas layer located at the stellar wind/ambient cloud interface. Finally, the lack of variations for both N(H2, J=0) towards HD34078 and N(CH) towards Zeta Per suggests that quiescent molecular gas is not subject to pronounced small-scale structure.
astro-ph.GA:Cool subdwarfs of types K and M are the fainter counterparts of cool main sequence dwarfs that dominate the Galactic population. In this paper we present the results of an optical speckle survey of 62 confirmed cool subdwarf systems within 60 pc. We have resolved two new companions and confirmed two previously known companions with separations 0\farcs13 to 3\farcs29. After including previously known wide companions and all known spectroscopic binaries, we determine the multiplicity rate of cool subdwarfs to be 26$\pm$6%, which is somewhat lower than comparable main sequence stars, which have a multiplicity rate of 37$\pm$5%. We find that only 3% of the cool subdwarfs surveyed have companions within 10 AU, 3% have companions between 10 and 100 AU, and 14% have companions beyond 100 AU. The other 6% of cool subdwarfs are spectroscopic binaries. This is very different from K/M dwarfs that have most companions (13%) at separations closer than 10 AU. However, because a search for close binaries among a large sample of nearby cool subdwarfs remains elusive, it is not yet settled whether or not the multiplicity rates are significantly different. Nonetheless, several different observational results and theories pointing to a possible dearth of subdwarf multiples are discussed.
astro-ph.GA:There is a large observational scatter toward low velocities in the stellar mass Tully-Fisher relation if disturbed and compact objects are included. However, this scatter can be eliminated if one replaces rotation velocity with $\rm S_{\rm 0.5}$, a quantity that includes a velocity dispersion term added in quadrature with the rotation velocity. In this work we use a large suite of hydrodynamic N-body galaxy merger simulations to explore a possible mechanism for creating the observed relations. Using mock observations of the simulations, we test for the presence of observational effects and explore the relationship between $\rm S_{\rm 0.5}$ and intrinsic properties of the galaxies. We find that galaxy mergers can explain the scatter in the TF as well as the tight $\rm S_{\rm 0.5}$-stellar mass relation. Furthermore, $\rm S_{\rm 0.5}$ is correlated with the total central mass of a galaxy, including contributions due to dark matter.
astro-ph.GA:We propose a new chemical evolution model aimed at explaining the chemical properties of globular clusters (GC) stars. Our model depends upon the existence of (i) a peculiar pre-enrichment phase in the GC's parent galaxy associated with very low-metallicity Type II supernovae (SNeII), and (ii) localized inhomogeneous enrichment from a single Type Ia supernova (SNeIa) and intermediate-mass (4 7Msun) asymptotic giant branch (AGB) field stars. GC formation is then assumed to take place within this chemically-peculiar region. Thus, in our model the first low-mass GC stars to form are those with peculiar abundances (i.e., O-depleted and Na-enhanced) while ``normal'' stars (i.e., O-rich and Na depleted) are formed in a second stage when self-pollution from SNeII occurs and the peculiar pollution from the previous phase is dispersed. In this study, we focus on three different GCs: NGC6752, NGC6205 (M13) and NGC2808. We demonstrate that, within this framework, a model can be constructed which is consistent with (i) the elemental abundance anti-correlations, (ii) isotopic abundance patterns, and (iii) the extreme [O/Fe] values observed in NGC2808 and M13, without violating the global constraints of approximately unimodal [Fe/H] and C+N+O.
astro-ph.GA:We present high resolution (R = 75,000-100,000) mid-infrared spectra of the high-mass embedded young star IRS 1 in the NGC 7538 star-forming region. Absorption lines from many rotational states of C2H2, 13C12CH2, CH3, CH4, NH3, HCN, HNCO, and CS are seen. The gas temperature, column density, covering factor, line width, and Doppler shift for each molecule are derived. All molecules were fit with two velocity components between -54 and -63 km/s. We find high column densities (~ 10e16 cm^2) for all the observed molecules compared to values previously reported and present new results for CH3 and HNCO. Several physical and chemical models are considered. The favored model involves a nearly edge-on disk around a massive star. Radiation from dust in the inner disk passes through the disk atmosphere, where large molecular column densities can produce the observed absorption line spectrum.
astro-ph.GA:We present accurate trigonometric parallaxes for 20 new members of the 25 pc white dwarf sample as part of the DENSE project (Discovery and Evalution of Nearby Stellar Embers, http://www.DenseProject.com). Previously, there were a total of 112 white dwarf systems with trigonometric parallaxes placing them within 25 pc and of these, 99 have trigonometric parallaxes known to better than 10%. Thus, the 20 new members presented in this work represent a 20% increase in the number of white dwarfs accurately known to be within 25 pc. In addition, we present updated parallaxes for seven known white dwarfs within 10 pc that have been observed as part of the ASPENS initiative (Astrometric Search for Planets Encircling Nearby Stars) to monitor nearby southern red and white dwarfs for astrometric perturbations from unseen companions. Including a few white dwarf companions and white dwarfs beyond 25 pc, we present a total of 33 trigonometric parallaxes. We perform atmospheric modeling for white dwarfs to determine physical parameters (i.e., effective temperature, log g, mass, and white dwarf age). Finally, a new ZZ Ceti pulsating white dwarf was identified and revised constraints are placed on two mixed H/He atmosphere cool white dwarfs that display continuum absorption in the near-infrared.
astro-ph.GA:Polarisation measurements of pulsars and of their pulsar wind nebulae (PWNe) are uniquely able to provide deep insights into the highly magnetised relativistic environment of young, rotation-powered isolated neutron stars (INSs). Besides the radio band, optical observations are primarily suited to providing such insights. The first INS for which optical polarisation observations were performed is the Crab pulsar which is also the brightest one (V=16.5). For this reason, the Crab pulsar is also the only INS for which repeated, phase-resolved polarisation measurements have been performed through the years. Moreover, it is the only case, together with the much fainter and distant PSR B0540-69 in the Large Magellanic Cloud (LMC), of an optical pulsar embedded in an optical PWN. Thus, the Crab is a perfect test case to study the optical polarisation properties of pulsars and of their PWNe. In this paper, we review the polarisation properties of the Crab pulsar and of its PWN in the optical and ultraviolet domains, we summarise the state of the art of the polarisation observations of other INSs, and we outline perspectives for INS polarisation studies with present and future generations of optical telescopes
astro-ph.GA:We investigate whether the formation mechanism of boxy and peanut-shaped (B/PS) bulges could depend on the gas content of the galaxy. We have performed N-body simulations with and without a gaseous component. In the second case star formation/feedback recipes have also been implemented to create new stellar populations. As in many previous studies, in our N-body collisionless simulation, the B/PS is due to the classical break in the z mirror symmetry lasting roughly 200 Myr. When a gaseous component and star formation recipes are added to the simulation, the bulge-growing mechanism is quite different. The young stellar population that is born in the thin gaseous disc rapidly populates vertical resonant orbits triggered by the combined effects of the linear horizontal and vertical ILRs. This leads to a B/PS bulge mainly made of stellar material younger than the surrounding population. The non-linear analysis of the orbital structure shows that the main orbit family responsible for the B/PS is not the same in the two cases. The 2:2:1 orbits prevail in the collisionless simulation whereas additional asymmetrical families contribute to the B/PS if a dissipative component is present and can form new stars. We found that 2:3:1 and 2:5:1 orbits trap a significant fraction of the mass. A flat ringed discy stellar component also appears simultaneously with the thickening of the young population. It is due to the star formation in a nuclear gaseous disc located in the central kpc, inside the ILR, and accumulated there by the torques exerted by the large-scale bar. Remarkably, it remains flat throughout the simulation although it develops a nuclear bar, leading to a double-barred galaxy. We predict that two populations of B/PS bulges could exist and even coexist in the same galaxy.
astro-ph.GA:The interstellar medium (ISM) is subject, on one hand, to heating and cooling processes that tend to segregate it into distinct phases due to thermal instability (TI), and on the other, to turbulence-driving mechanisms that tend to produce strong nonlinear fluctuations in all the thermodynamic variables. In this regime, large-scale turbulent compressions in the stable warm neutral medium (WNM) dominate the clump-formation process rather than the linear developent of TI. Cold clumps formed by this mechanism are often bounded by sharp density and temperature discontinuities, which however are not contact discontinuities as in the classical 2-phase model, but rather "phase transition fronts", across which there is net mass and momentum flux from the WNM into the clumps. The clumps grow mainly by accretion through their boundaries, are in both thermal and ram pressure balance with their surroundings, and are internally turbulent as well, thus also having significant density fluctuations inside. The temperature and density of the cold and warm gas around the phase transition fronts fluctuate with time and location due to fluctuations in the turbulent pressure. Moreover, shock-compressed diffuse unstable gas can remain in the unstable regime for up to a few Myr before it undergoes a phase transition to the cold phase. These processes populate the classically forbidden density and temperature ranges. Since gas at all temperatures appears to be present in bi- or tri-stable turbulence, we conclude that the word "phase" applies only locally, surrounding phase transition sites in the gas. Globally, the word "phase" must relax its meaning to simply denote a certain temperature or density range.
astro-ph.GA:Active galactic nuclei (AGN) in low surface brightness galaxies (LSBGs) have received little attention in previous studies. In this paper, we present detailed spectral analysis of 194 LSBGs from the Impey et al. (1996) APM LSBG sample which have been observed spectroscopically by the Sloan Digital Sky Survey Data Release 5 (SDSS DR5). Our elaborate spectral analysis enables us to carry out, for the first time, reliable spectral classification of nuclear activities in LSBGs based on the standard emission line diagnostic diagrams in a rigorous way. Star-forming galaxies are common, as found in about 52% LSBGs. We find, contrary to some of the previous claims, that the fraction of galaxies containing an AGN is significantly lower than that found in nearby normal galaxies of high surface brightness. This is qualitatively in line with the finding of Impey et al. (2001). This result holds true even within each morphological type from Sa to Sc. LSBGs having larger central stellar velocity dispersions, or larger physical sizes, tend to have a higher chance to harbor an AGN. For three AGNs with broad emission lines, the black hole masses estimated from the emission lines are broadly consistent with the well known M-$\sigma_\ast$ relation established for normal galaxies and AGNs.
astro-ph.GA:We take advantage of the very simple morphology of RCW 120 -- a perfect bubble -- to understand the mechanisms triggering star formation around an HII region and to establish what kind of stars are formed there. We present 870 microns observations of RCW 120, obtained with the APEX-LABOCA camera. These show the distribution of cold dust, and thus of neutral material. We use Spitzer-MIPS observations at 24 and 70 microns to detect the young stellar objects (YSOs) present in this region and to estimate their evolutionary stages.   A layer of dense neutral material surrounds the HII region, having been swept up during the region's expansion. This layer has a mass greater than 2000 solar masses and is fragmented, with massive fragments elongated along the ionization front (IF). We measured the 24 microns flux of 138 sources. Of these, 39 are Class I or flat-spectrum YSOs observed in the direction of the collected layer. We show that several triggering mechanisms are acting simultaneously in the swept-up shell, where they form a second generation of stars. No massive YSOs are detected. However, a massive, compact 870 microns core lies adjacent to the IF. A 70 microns source with no 24 microns counterpart is detected at the same position. This source is a likely candidate for a Class 0 YSO. Also at 24 microns, we detect a chain of about ten regularly spaced Class I or flat spectrum sources, parallel to the IF, in the direction of the most massive fragment. We suggest that the formation of these YSOs is the result of Jeans gravitational instabilities in the collected layer. Finally, the 870 microns emission, the 24 microns emission, and the Halpha emission show the existence of an extended and partially ionized photodissociation region around RCW 120.
astro-ph.GA:We examine the UV and X-ray properties of 256 radio-quiet SDSS quasars (QSOs) observed in X-rays with Chandra and/or XMM-Newton in order to study the relationship between QSOs with broad CIV absorption lines (BALs; width >2000 km/s) and those with CIV mini-BALs (here defined to have widths of 1000--2000 km/s). Our sample includes 42 BAL and 48 mini-BAL QSOs. The relative X-ray brightness and hard spectral slopes of the mini-BAL population are, on average, intermediate between those of BAL and non-BAL QSOs, as might be expected if narrower and broader absorption line outflows are physically related. However, a significant population of mini-BALs has outflow velocities higher than would be expected for BAL QSOs of the same relative X-ray brightness. Consistenly strong X-ray absorption is apparently not required to accelerate at least some mini-BALs to high outflow velocities. Assuming the mini-BAL features are correctly attributed to intrinsic CIV absorption, we suggest that their observed properties may be explained if mini-BALs are "seeds" which can be accelerated to form BALs when sufficient X-ray shielding is present.   We also examine several QSOs with broad CIV absorption that have been recently reported to be unusually X-ray bright. Such cases are frequently mini-BAL QSOs, which as a population are generally brighter in X-rays than BAL QSOs. Pointed XMM-Newton observations also suggest that these sources (or unresolved neighbors) may have been previously observed in a high flux state.
astro-ph.GA:The slopes of interstellar reddening lines in the 2MASS J-H versus H-Ks diagrams for 26 areas in the inner Galaxy (from Vulpecula to Centaurus) are determined. For this aim we use the red-clump giants located inside and behind spiral arms, or behind dense dust clouds of the Local arm. In most of the investigated directions the ratio E(J-H)/E(H-K_s) is found to be between 1.9 and 2.0, taking the stars with the visual extinction less than 12 mag. The stars with larger extinction deviate down from the reddening lines corresponding to less reddened stars. Probably, this is related to the curvature of reddening lines due to the band-width effect. However, some of the deviating stars may be heavily reddened oxygen- and carbon-rich AGB stars (giants of the latest M subclasses or N-type carbon stars), and pre-main-sequence objects (YSOs).
astro-ph.GA:The band-width effect on interstellar reddening lines in the J-H vs. H-K_s diagram of the 2MASS survey is investigated using synthetic color indices and color excesses based on the Kurucz model atmospheres. At large interstellar reddenings (E(H-K_s) larger than 1.0) reddening lines deviate considerably from a straight line. The lines can be approximated by an equation: E(J-H) = r E(H-K_s) + s E(H-K_s)^2, where the slope coefficient, r, and the curvature coefficient, s, depend slightly on the intrinsic energy distribution of the source. The curvature of the reddening lines is confirmed by the J-H vs. H-K_s diagrams plotted by Straizys and Laugalys (2008) from 2MASS observations.
astro-ph.GA:Recent observations of the white dwarf (WD) populations in the Galactic globular cluster NGC 6397 suggest that WDs receive a kick of a few km/s shortly before they are born. Using our Monte Carlo cluster evolution code, which includes accurate treatments of all relevant physical processes operating in globular clusters, we study the effects of the kicks on their host cluster and on the WD population itself. We find that in clusters whose velocity dispersion is comparable to the kick speed, WD kicks are a significant energy source for the cluster, prolonging the initial cluster core contraction phase significantly so that at late times the cluster core to half-mass radius ratio is a factor of up to ~ 10 larger than in the no-kick case. WD kicks thus represent a possible resolution of the large discrepancy between observed and theoretically predicted values of this key structural parameter. Our modeling also reproduces the observed trend for younger WDs to be more extended in their radial distribution in the cluster than older WDs.
astro-ph.GA:The unified model of active galactic nuclei (AGN) predicts silicate emission features at 10 and 18 microns in type 1 AGN, and such features have now been observed in objects ranging from distant QSOs to nearby LINERs. More surprising, however, is the detection of silicate emission in a few type 2 AGN. By combining Gemini and Spitzer mid-infrared imaging and spectroscopy of NGC 2110, the closest known Seyfert 2 galaxy with silicate emission features, we can constrain the location of the silicate emitting region to within 32 pc of the nucleus. This is the strongest constraint yet on the size of the silicate emitting region in a Seyfert galaxy of any type. While this result is consistent with a narrow line region origin for the emission, comparison with clumpy torus models demonstrates that emission from an edge-on torus can also explain the silicate emission features and 2-20 micron spectral energy distribution of this object. In many of the best-fitting models the torus has only a small number of clouds along the line of sight, and does not extend far above the equatorial plane. Extended silicate-emitting regions may well be present in AGN, but this work establishes that emission from the torus itself is also a viable option for the origin of silicate emission features in active galaxies of both type 1 and type 2.
astro-ph.GA:Based on the kernel estimator and wavelet technique, we have identified 22 moving group candidates in the solar neighborhood from a sample which includes around 14,000 dwarfs and 6000 giants. Six of them were previously known as the Hercules stream, the Sirus-UMa stream, the Hyades stream, the Caster group, the Pleiades stream, and the IC 2391; five of them have also been reported by other authors. 11 moving group candidates, not previously reported in the literature, showprominent structures in dwarf or giant samples.Acatalog of moving group candidates in the solar neighborhood is presented in this work.
astro-ph.GA:The role played by protostellar feedback in clustered star formation is still a matter of debate. In particular, protostellar outflows have been proposed as a source of turbulence in cluster-forming clumps, which may provide support against global collapse for several free-fall times.   Here, we seek to test the above hypothesis in the case of the well-documented NGC 2264-C protocluster, byquantifying the amount of turbulence and support injected in the surrounding medium by protostellar outflows.   Using the HERA heterodyne array on the IRAM 30m telescope, we carried out an extensive mapping of NGC 2264-C in the three molecular line transitions 12CO(2-1), 13CO(2-1), and C18O(2-1). We found widespread high-velocity 12CO emission, testifying to the presence of eleven outflow lobes, closely linked to the compact millimeter continuum sources previously detected in the protocluster.   We carried out a detailed analysis of the dynamical parameters of these outflows, including a quantitative evaluation of the overall momentum flux injected in the cluster-forming clump. These dynamical parameters were compared to the gravitational and turbulent properties of the clump.   We show that the population of protostellar outflows identified in NGC 2264-C are likely to contribute a significant fraction of the observed turbulence but cannot efficiently support the protocluster against global collapse. Gravity appears to largely dominate the dynamics of the NGC 2264-C clump at the present time. It is however possible that an increase in the star formation rate during the further evolution of the protocluster will trigger sufficient outflows to finally halt the contraction of the cloud.
astro-ph.GA:OH(1720 MHz) masers are excellent signposts of interaction between supernova remnants(SNRs) and molecular clouds. Using the GBT and VLA we have surveyed 75 SNRs and six candidates for maser emission. Four new interacting SNRs are detected with OH masers: G5.4-1.2, G5.7-0.0, G8.7-0.1 and G9.7-0.0. The newly detected interacting SNRs G5.7-0.0 and G8.7-0.1 have TeV gamma-ray counterparts which may indicate a local cosmic ray enhancement. It has been noted that maser-emitting SNRs are preferentially distributed in the Molecular Ring and Nuclear Disk. We use the present and existing surveys to demonstrate that masers are strongly confined to within 50 degrees Galactic longitude at a rate of 15 percent of the total SNR population. All new detections are within 10 degrees Galactic longitude emphasizing this trend. Additionally, a substantial number of SNR masers have peak fluxes at or below the detection threshold of existing surveys. This calls into question whether maser surveys of Galactic SNRs can be considered complete and how many maser-emitting remnants remain to be detected in the Galaxy.
astro-ph.GA:Photon-dominated regions (PDRs) are expected to show a layered structure in molecular abundances and emerging line emission, which is sensitive to the physical structure of the region as well as the UV radiation illuminating it. We aim to study this layering in the Orion Bar, a prototypical nearby PDR with a favorable edge-on geometry. We present new maps of 2 by 2 arcminute fields at 14-23 arcsecond resolution toward the Orion Bar in the SO 8_8-9_9, H2CO 5_(1,5)-4_(1,4), 13CO 3-2, C2H 4_(9/2)-3_(7/2) and 4_(7/2)-3_(5/2), C18O 2-1 and HCN 3-2 transitions. The data reveal a clear chemical stratification pattern. The C2H emission peaks close to the ionization front, followed by H2CO and SO, while C18O, HCN and 13CO peak deeper into the cloud. A simple PDR model reproduces the observed stratification, although the SO emission is predicted to peak much deeper into the cloud than observed while H2CO is predicted to peak closer to the ionization front than observed. In addition, the predicted SO abundance is higher than observed while the H2CO abundance is lower than observed. The discrepancies between the models and observations indicate that more sophisticated models, including production of H2CO through grain surface chemistry, are needed to quantitatively match the observations of this region.
astro-ph.GA:We measure the Tully-Fisher relations of 14 lenticular galaxies (S0s) and 14 spirals. We use two measures of rotational velocity. One is derived directly from observed spatially-resolved stellar kinematics and the other from the circular velocities of mass models that include a dark halo and whose parameters are constrained by detailed kinematic modelling. Contrary to the naive expectations of theories of S0 formation, we find no significant difference between the Tully-Fisher relations of the two samples when plotted as functions of both brightness and stellar mass.
astro-ph.GA:We analyze the conditions for detection of CO(1-0) emission in the Large Magellanic Cloud (LMC), using the recently completed second NANTEN CO survey. In particular, we investigate correlations between CO integrated intensity and HI integrated intensity, peak brightness temperature, and line width at a resolution of 2.6' (~40 pc). We find that significant HI column density and peak brightness temperature are necessary but not sufficient conditions for CO detection, with many regions of strong HI emission not associated with molecular clouds. The large scatter in CO intensities for a given HI intensity persists even when averaging on scales of >200 pc, indicating that the scatter is not solely due to local conversion of HI into H_2 near GMCs. We focus on two possibilities to account for this scatter: either there exist spatial variations in the I(CO) to N(H_2) conversion factor, or a significant fraction of the atomic gas is not involved in molecular cloud formation. A weak tendency for CO emission to be suppressed for large HI linewidths supports the second hypothesis, insofar as large linewidths may be indicative of warm HI, and calls into question the likelihood of forming molecular clouds from colliding HI flows. We also find that the ratio of molecular to atomic gas shows no significant correlation (or anti-correlation) with the stellar surface density, though a correlation with midplane hydrostatic pressure P_h is found when the data are binned in P_h. The latter correlation largely reflects the increasing likelihood of CO detection at high HI column density.
astro-ph.GA:Recently, controversy has erupted over whether gas-rich spiral-spiral mergers are capable of forming {\it m$^{*}$} ellipticals. Measurements of $\sigma$$_{\circ}$ from the 2.29$\micron$ CO band-head for local LIRG/ULIRGs, suggest they are not. IR-bright mergers are often cited as the best candidates for forming massive ellipticals, so the recent observations have raised doubts about both the Toomre Merger Hypothesis and the fundamental assumptions of $\Lambda$-CDM galaxy formation models. However, kinematics obtained with the Calcium II Triplet at 8500 {\AA} suggest mergers are forming {\it m} $\ge$ {\it m$^{*}$} ellipticals. In this work, we show that kinematics derived from the CO stellar absorption band-head leads to a significant underestimation of the masses of LIRGs/ULIRGs. This is primarily due to the presence of a young population affecting CO band-head measurements.
astro-ph.GA:We present results of high resolution hydrodynamical simulations of the formation and evolution of dwarf galaxies. Our simulations start from cosmological initial conditions at high redshift. They include metal-dependent cooling, star formation, feedback from type II and type Ia supernovae and UV background radiation, with physical recipes identical to those applied in a previous study of Milky Way type galaxies. We find that a combination of feedback and the cosmic UV background results in the formation of galaxies with properties similar to the Local Group dwarf spheroidals, and that their effect is strongly moderated by the depth of the gravitational potential. Taking this into account, our models naturally reproduce the observed luminosities and metallicities. The final objects have halo masses between 2.3x10^8 and 1.1x10^9 solar masses, mean velocity dispersions between 6.5 and 9.7 kms-1, stellar masses ranging from 5x10^5 to 1.2x10^7 solar masses, median metallicities between [Fe/H] = -1.8 and -1.1, and half-light radii of the order of 200 to 300 pc, all comparable with Local Group dwarf spheroidals. Our simulations also indicate that the dwarf spheroidal galaxies observed today lie near a halo mass threshold around 10^9 solar masses, in agreement with stellar kinematic data, where supernova feedback not only suffices to completely expel the interstellar medium and leave the residual gas-free, but where the combination of feedback, UV radiation and self-shielding establishes a dichotomy of age distributions similar to that observed in the Milky Way and M31 satellites.
astro-ph.GA:The SEGUE survey obtained 240,000 moderate resolution (R = 1800) spectra from 3900 - 9000 Angstroms of fainter Milky Way stars (14.0 < g < 20.3) of a wide variety of spectral types, both main sequence and evolved objects, with the goal of studying the kinematics and populations of our Galaxy and its halo. The spectra are clustered in 212 regions spaced over three-quarters of the sky. Radial velocity accuracies for stars are 4 km/s at g < 18, degrading to 15 km/s at g = 20. For stars with S/N > 10 per resolution element, stellar atmospheric parameters are estimated, including metallicity, surface gravity, and effective temperature. SEGUE obtained 3500 square degrees of additional ugriz imaging (primarily at low Galactic latitudes) providing precise multi-color photometry (g,r,i = 2%), (u,z = 3%) and astrometry (0.1 arcsec) for spectroscopic target selection. The stellar spectra, imaging data, and derived parameter catalogs for this survey are publicly available as part of SDSS Data Release 7 (DR7).
astro-ph.GA:We present results from X-ray analysis of a Galactic middle-aged supernova remnant (SNR) G156.2+5.7 which is bright and largely extended in X-ray wavelengths, showing a clear circular shape (radius about 50'). Using the Suzaku satellite, we observed this SNR in three pointings; partially covering the northwestern rim, the eastern rim, and the central portion of this SNR. In the northwestern rim and the central portion, we confirm that the X-ray spectra consist of soft and hard-tail emission, while in the eastern rim we find no significant hard-tail emission. The soft emission is well fitted by non-equilibrium ionization (NEI) model. In the central portion, a two-component (the interstellar medium and the metal-rich ejecta) NEI model fits the soft emission better than a one-component NEI model from a statistical point of view. The relative abundances in the ejecta component suggest that G156.2+5.7 is a remnant from a core-collapse SN explosion whose progenitor mass is less than 15 M_solar. The origin of the hard-tail emission is highly likely non-thermal synchrotron emission from relativistic electrons. In the northwestern rim, the relativistic electrons seem to be accelerated by a forward shock with a slow velocity of about 500 km/sec.
astro-ph.GA:We investigate the mean velocity dispersion and the velocity dispersion profile of stellar systems in MOND, using the N-body code N-MODY, which is a particle-mesh based code with a numerical MOND potential solver developed by Ciotti, Londrillo and Nipoti (2006). We have calculated mean velocity dispersions for stellar systems following Plummer density distributions with masses in the range of $10^4 M_\odot$ to $10^9 M_\odot$ and which are either isolated or immersed in an external field. Our integrations reproduce previous analytic estimates for stellar velocities in systems in the deep MOND regime ($a_i, a_e \ll a_0$), where the motion of stars is either dominated by internal accelerations ($a_i \gg a_e$) or constant external accelerations ($a_e \gg a_i$). In addition, we derive for the first time analytic formulae for the line-of-sight velocity dispersion in the intermediate regime ($a_i \sim a_e \sim a_0$). This allows for a much improved comparison of MOND with observed velocity dispersions of stellar systems. We finally derive the velocity dispersion of the globular cluster Pal 14 as one of the outer Milky Way halo globular clusters that have recently been proposed as a differentiator between Newtonian and MONDian dynamics.
astro-ph.GA:Historical optical data are combined with more recent optical, extreme ultraviolet, and X-ray data to update the spin ephemeris of the cataclysmic variable EX Hya.
astro-ph.GA:(Abridged) We perform dissipationless N-body simulations to elucidate the dynamical response of thin disks to bombardment by cold dark matter (CDM) substructure. Our method combines (1) cosmological simulations of the formation of Milky Way (MW)-sized CDM halos to derive the properties of substructure and (2) controlled numerical experiments of consecutive subhalo impacts onto an initially-thin, fully-formed MW type disk galaxy. The present study is the first to account for the evolution of satellite populations over cosmic time in such an investigation of disk structure. We find that accretions of massive subhalos onto the central regions of host halos, where the galactic disks reside, since z~1 should be common. One host halo accretion history is used to initialize the controlled simulations of satellite-disk encounters. We show that these accretion events severely perturb the thin galactic disk and produce a wealth of distinctive dynamical signatures on its structure and kinematics. These include (1) considerable thickening and heating at all radii, with the disk thickness and velocity ellipsoid nearly doubling at the solar radius; (2) prominent flaring associated with an increase in disk thickness greater than a factor of 4 in the disk outskirts; (3) surface density excesses at large radii, beyond ~5 disk scale lengths, resembling those of observed antitruncated disks; (4) lopsidedness at levels similar to those measured in observational samples of disk galaxies; and (5) substantial tilting. The interaction with the most massive subhalo drives the disk response while subsequent bombardment is much less efficient at disturbing the disk. We conclude that substructure-disk encounters of the kind expected in the LCDM paradigm play a significant role in setting the structure of disk galaxies and driving galaxy evolution.
astro-ph.GA:We present a study of active stellar forming regions in the environs of the HII region Sh2-205. The analysis is based on data obtained from point source catalogues and images extracted from 2MASS, MSX, and IRAS surveys. Complementary data are taken from CO survey. The identification of primary candidates to stellar formation activity is made following colour criteria and the correlation with molecular gas emission.   A number of stellar formation tracer candidates are projected on two substructures of the HII region: SH148.83-0.67 and SH149.25-0.00. However, the lack of molecular gas related to these structures casts doubts on the nature of the sources. Additional infrared sources may be associated with the HI shell centered at (l,b) = (149\degr 0\arcmin, -1\degr 30\arcmin).   The most striking active area was found in connection to the HII region LBN 148.11-0.45, where stellar formation candidates are projected onto molecular gas. The analytical model to the "collect and collapse" process shows that stellar formation activity could have been triggered by the expansion of this HII region.
astro-ph.GA:We report on a timing analysis performed on a 62-ks long XMM-Newton observation of the accreting millisecond pulsar SAX J1808.4-3658 during the latest X-ray outburst that started on September 21, 2008. By connecting the time of arrivals of the pulses observed during the XMM observation, we derived the best-fit orbital solution and a best-fit value of the spin period for the 2008 outburst. Comparing this new set of orbital parameters and, in particular, the value of the time of ascending-node passage with the orbital parameters derived for the previous four X-ray outbursts of SAX J1808.4-3658 observed by the PCA on board RXTE, we find an updated value of the orbital period derivative, which turns out to be $\dot P_{\rm orb} = (3.89 \pm 0.15) \times 10^{-12}$ s/s. This new value of the orbital period derivative agrees with the previously reported value, demonstrating that the orbital period derivative in this source has remained stable over the past ten years. Although this timespan is not sufficient yet for confirming the secular evolution of the system, we again propose an explanation of this behavior in terms of a highly non-conservative mass transfer in this system, where the accreted mass (as derived from the X-ray luminosity during outbursts) accounts for a mere 1% of the mass lost by the companion.
astro-ph.GA:We present a study of the intrinsic UV absorption and emission lines in an historically low-state spectrum of the Seyfert 1 galaxy NGC 5548, which we obtained in 2004 February at high spatial and spectral resolution with the Space Telescope Imaging Spectrograph (STIS) on the Hubble Space Telescope. We isolate a component of emission with a width of 680 km/s (FWHM) that arises from an "intermediate line region" (ILR), similar to the one we discovered in NGC 4151, at a distance of ~1 pc from the central continuum source. From a detailed analysis of the five intrinsic absorption components in NGC 5548 and their behavior over a span of 8 years, we present evidence that most of the UV absorbers only partially cover the ILR and do not cover an extended region of UV continuum emission, most likely from hot stars in the circumnuclear region. We also find that four of the UV absorbers are at much greater distances (>70 pc) than the ILR, and none have sufficient N V or C IV column densities to be the ILR in absorption. At least a portion of the UV absorption component 3, at a radial velocity of -530 km/s, is likely responsible for most of the X-ray absorption, at a distance < 7 pc from the central source. The fact that we see the ILR in absorption in NGC 4151 and not in NGC 5548 suggests that the ILR is located at a relatively large polar angle (~45 degrees) with respect to the narrow-line region outflow axis.
astro-ph.GA:We study the velocity distribution of Milky Way disk stars in a kiloparsec-sized region around the Sun, based on ~ 2 million M-type stars from DR7 of SDSS, which have newly re-calibrated absolute proper motions from combining SDSS positions with the USNO-B catalogue. We estimate photometric distances to all stars, accurate to ~ 20 %, and combine them with the proper motions to derive tangential velocities for this kinematically unbiased sample of stars. Based on a statistical de-projection method we then derive the vertical profiles (to heights of Z = 800 pc above the disk plane) for the first and second moments of the three dimensional stellar velocity distribution. We find that <W> = -7 +/- 1 km/s and <U> = -9 +/- 1 km/s, independent of height above the mid-plane, reflecting the Sun's motion with respect to the local standard of rest. In contrast, <V> changes distinctly from -20 +/- 2 km/s in the mid-plane to <V> = -32 km/s at Z = 800 pc, reflecting an asymmetric drift of the stellar mean velocity that increases with height. All three components of the M-star velocity dispersion show a strong linear rise away from the mid-plane, most notably \sigma_{ZZ}, which grows from 18 km/s (Z = 0) to 40 km/s (at Z = 800 pc). We determine the orientation of the velocity ellipsoid, and find a significant vertex deviation of 20 to 25 degrees, which decreases only slightly to heights of Z = 800 pc. Away from the mid-plane, our sample exhibits a remarkably large tilt of the velocity ellipsoid towards the Galactic plane, which reaches 20 deg. at Z = 800 pc and which is not easily explained. Finally, we determine the ratio \sigma^2_{\phi\phi}/\sigma^2_{RR} near the mid-plane, which in the epicyclic approximation implies an almost perfectly flat rotation curve at the Solar radius.
astro-ph.GA:This work aims at investigating the molecular gas component in the vicinity of two young stellar object (YSO) candidates identified at the border of the HII region G034.8-0.7 that is evolving within a molecular cloud shocked by the SNR W44. The purpose is to explore signatures of star forming activity in this complex region. We performed a near and mid infrared study towards the border of the HII region G034.8-0.7 and observed a 90" X 90" region near 18h 56m 48s, +01d 18' 45" (J2000) using the Atacama Submillimeter Telescope Experiment (ASTE) in the 12CO J=3--2, 13CO J=3--2, HCO+ J=4--3 and CS J=7--6 lines with an angular resolution of 22". Based on the infrared study we propose that the source 2MASS 18564827+0118471 (IR1 in this work) is a YSO candidate. We discovered a bipolar 12CO outflow in the direction of the line of sight and a HCO+ clump towards IR1, confirming that it is a YSO. From the detection of the CS J=7--6 line we infer the presence of high density (>10^7 cm^-3) and warm (>60 K) gas towards IR1, probably belonging to the protostellar envelope where the YSO is forming. We investigated the possible genetic connection of IR1 with the SNR and the HII region. By comparing the dynamical time of the outflows and the age of the SNR W44, we conclude that the possibility of the SNR has triggered the formation of IR1 is unlikely. On the other hand, we suggest that the expansion of the HII region G034.8-0.7 is responsible for the formation of IR1 through the "collect and collapse" process.
astro-ph.GA:We report on Combined Array for Research in Millimeter-Wave Astronomy (CARMA) and James Clerk Maxwell Telescope (JCMT) observations toward the Einstein source 1E 1740.7-2942, a LMXB commonly known as the "Great Annihilator." The Great Annihilator is known to be near a small, bright molecular cloud on the sky in a region largely devoid of emission in 12-CO surveys of the Galactic Center. The region is of interest because it is interior to the dust lanes which may be the shock zones where atomic gas from HI nuclear disk is converted into molecular gas. We find that the region is populated with a number of dense (n ~ 10^5 cm^-3) regions of excited gas with small filling factors, and estimate that up to 1-3 x 10^5 solar masses of gas can be seen in our maps. The detection suggests that a significant amount of mass is transported from the shock zones to the GC star-forming regions in the form of small, dense bundles.
astro-ph.GA:We use N-body/gasdynamical LambdaCDM cosmological simulations to examine the effect of the assembly of a central galaxy on the shape and mass profile of its dark halo. Two series of simulations are compared; one that follows only the evolution of the dark matter component and a second one where a baryonic component is added. These simulations include radiative cooling but neglect star formation and feedback, leading most baryons to collect at the halo center in a disk which is too small and too massive when compared with typical spiral. This unrealistic model allows us, nevertheless, to gauge the maximum effect that galaxies may have in transforming their dark halos. We find that the shape of the halo becomes more axisymmetric: halos are transformed from triaxial into essentially oblate systems, with well-aligned isopotential contours of roughly constant flattening (c/a ~ 0.85). Halos always contract as a result of galaxy assembly, but the effect is substantially less pronounced than predicted by the "adiabatic contraction" hypothesis. The reduced contraction helps to reconcile LambdaCDM halos with constraints on the dark matter content inside the solar circle and should alleviate the long-standing difficulty of matching simultaneously the scaling properties of galaxy disks and the luminosity function. The halo contraction is also less pronounced than found in earlier simulations, a disagreement that suggests that halo contraction is not solely a function of the initial and final distribution of baryons. Not only how much baryonic mass has been deposited at the center of a halo matters, but also the mode of its deposition. It might prove impossible to predict the halo response without a detailed understanding of a galaxy's assembly history. (Abriged)
astro-ph.GA:We have mapped NGC 3718, a nearby bright galaxy in a loose group, and its companion NGC 3729 in the 21cm line of neutral hydrogen. NGC 3718 is a strikingly unusual galaxy with a strong straight dust lane across the center, peculiar diffuse spiral arms, and an extended disk of neutral hydrogen. Earlier work showed the gas disk to be strongly twisted, warping through edge-on where we see the straight dust lane; stars formed in this gas appear to make up the 'spiral arms'. Our improved maps show a twisted but bisymmetric disk of gas extending to 7arcmin or 35kpc, where the orbital period is roughly 1Gyr. It is surrounded by fragmentary spiral features, and a streamer of gas extending to a cloud lying 12arcmin or 60kpc to the north. We use INSPECTOR, a task in GIPSY, to fit a tilted-ring model interactively to slices through the HI data cube. The apparent major axis swings through 100 degrees from the innermost gas orbits at 30arcsec radius to the outer edge. When viewed in the reference frame of the galaxy's stellar disk, the innermost gas orbits are nearly polar, while the outer rings of gas are tilted at 30-40 degrees. The line of nodes, where the gas orbits pass through the plane of the stellar disk, twists by roughly 90 degrees about the pole. We do not see gas orbiting in the plane of the stellar disk. If we assume that the galaxy's dark halo shares the same midplane, then the observed twist can be explained by differential precession in a dynamical model in which the dark halo is fairly round. The run of tilt with radius is close to what is required for the warped gas disk to precess rigidly in the galaxy's gravitational field without changing its shape. This fact probably accounts for the longevity of the twisted structure.
astro-ph.GA:This White Paper to the National Academy of Sciences Astro2010 Decadal Review Committee highlights cross-disciplinary science opportunities over the next decade with cold brown dwarfs, sources defined here as having photospheric temperatures less than ~1000 K.
astro-ph.GA:A random, hydrogen-free, assembly of microscopic sp2 carbon chips, forming a macroscopically homogeneous and isotropic solid, is proposed as a model carrier for the UV interstellar extinction band . The validity of this model is based on the calculation of the Bruggeman average dielectric function of a mixture of the known parallel and perpendicular dielectric functions of graphite. The pi absorption feature of Rayleigh-sized spheres of this mixture falls near 4.6 mu-1 (2175 Angstroms), but its width is 1.5 mu-1, somewhat larger than the astronomically observed average, 1 mu-1. This is confirmed by measurements of the reflectance of an industrial material, polycrystalline graphite. A better fit to the IS feature position and width is obtained with a hypothetical material, having the same dielectric functions as natural graphite, except for less extended wings of the pi resonance. Physically, this could result from changes in the electronic band structure due to previous thermal histories. On this model, the Frolich feature central wavelength depends only on the pi resonance frequency, while its width depends only on the damping constant of the same resonance. This explains the range of observed feature widths at constant feature wavelength.
astro-ph.GA:The ionization fraction plays a key role in the chemistry and dynamics of molecular clouds. We study the H13CO+, DCO+ and HOC+ line emission towards the Horsehead, from the shielded core to the UV irradiated cloud edge, i.e., the Photodissociation Region (PDR), as a template to investigate the ionization fraction gradient in molecular clouds. We analyze a PdBI map of the H13CO+ J=1-0 line, complemented with IRAM-30m H13CO+ and DCO+ higher-J line maps and new HOC+ and CO+ observations. We compare self-consistently the observed spatial distribution and line intensities with detailed depth-dependent predictions of a PDR model coupled with a nonlocal radiative transfer calculation. The chemical network includes deuterated species, 13C fractionation reactions and HCO+/HOC+ isomerization reactions. The role of neutral and charged PAHs in the cloud chemistry and ionization balance is investigated. The detection of HOC+ reactive ion towards the Horsehead PDR proves the high ionization fraction of the outer UV irradiated regions, where we derive a low [HCO+]/[HOC+]~75-200 abundance ratio. In the absence of PAHs, we reproduce the observations with gas-phase metal abundances, [Fe+Mg+...], lower than 4x10(-9) (with respect to H) and a cosmic-rays ionization rate of zeta=(5+/-3)x10(-17) s(-1). The inclusion of PAHs modifies the ionization fraction gradient and increases the required metal abundance. The ionization fraction in the Horsehead edge follows a steep gradient, with a scale length of ~0.05 pc (or ~25''), from [e-]~10(-4) (or n_e ~ 1-5 cm(-3)) in the PDR to a few times ~10(-9) in the core. PAH^- anions play a role in the charge balance of the cold and neutral gas if substantial amounts of free PAHs are present ([PAH] >10(-8)).
astro-ph.GA:We aim at studying the effect of a cosmologically motivated gas infall law for the formation of a massive elliptical galaxy in order to understand its impact on the formation of the spheroids. We replace the empirical infall law of the model by Pipino & Matteucci with a cosmologically derived infall law for the formation of an elliptical galaxy. We constrast our predictions with observations. We also compare the obtained results with those of Pipino & Matteucci. We computed models with and without galactic winds: we found that models without wind predict a too large current SNIa rate. In particular, the cosmological model produces a current SNIa which is about ten times higher than the observed values. Moreover models without wind predict a large current SNII rate, too large even if compared with the recent GALEX data. The predicted SNII rate for the model with wind, on the other hand, is too low if compared with the star formation histories given by GALEX. Last but not least, the mean value for the [Mg/Fe] ratio in the dominant stellar population of the simulated galaxy, as predicted by the cosmological model, is too low if compared to observations. This is, a very important result indicating that the cosmological infall law is in contrast with the chemical evolution. A cosmologically derived infall law for an elliptical galaxy cannot reproduce all the chemical constraints given by the observations. The problem resides in the fact that the cosmologically derived infall law implies a slow gas accretion with consequent star formation rate active for a long period. In this situation low [Mg/Fe] ratios are produced for the dominant stellar population in a typical elliptical, at variance with observations.
astro-ph.GA:High resolution X-ray absorption spectroscopy is a powerful diagnostic tool for probing chemical and physical properties of the interstellar medium (ISM) at various phases. We present detections of K transition absorption lines from the low ionization ions of OI, OII, NeI, NeII, and NeIII, and the high ionization ones of OVI, OVII, OVIII, NeIX, and MgXI, as well as details of neutral absorption edges from Mg, Ne, and O in an unprecedented high quality spectrum of the low mass X-ray binary Cyg X-2. These absorption features trace the intervening interstellar medium which is indicated by the unshifted line centroids with respect to the rest frame wavelengths of the corresponding atomic transitions. We have measured the column densities of each ion. We complement these measurements with the radio HI and optical Halpha observations toward the same sight line and estimate the mean abundances of Ne, O, and Mg in the cool phase to Ne/H=0.84^{+0.13}_{-0.10}\times10^{-4}, O/H=3.83^{+0.48}_{-0.43}\times10^{-4}, and Mg/H=0.35^{+0.09}_{-0.11}\times10^{-4}, and O and Mg in the hot phase to O/H=5.81^{+1.30}_{-1.34}\times10^{-4} and Mg/H=0.33^{+0.09}_{-0.09}\times10^{-4}, respectively. These results indicate a mild depletion of oxygen into dust grains in the cool phase and little or no depletion of magnesium. We also find that absorption from highly ionized ions in the hot Galactic disk gas can account for most of the absorption observed toward the extragalactic sight lines like Mrk 421. The bulk of the observed OVI likely originates from the conductive interfaces between the cool and hot gases, from which a significant amount of NV and CIV emission is predicted.
astro-ph.GA:We present results from a multi-year monitoring campaign of the broad-line radio galaxy 3C 120, using the Rossi X-ray Timing Explorer (RXTE) for nearly five years of observations. Additionally, we present coincident optical monitoring using data from several ground-based observatories. Both the X-ray and optical emission are highly variable and appear to be strongly correlated, with the X-ray emission leading the optical by 28 days. The X-ray power density spectrum is best fit by a broken power law, with a low-frequency slope of -1.2, breaking to a high-frequency slope of -2.1, and a break frequency of log nu_b=-5.75 Hz, or 6.5 days. This value agrees well with the value expected based on 3C 120's mass and accretion rate. We find no evidence for a second break in the power spectrum. Combined with a moderately soft X-ray spectrum (Gamma=1.8) and a moderately high accretion rate (mdot / mdot_Edd ~ 0.3), this indicates that 3C 120 fits in wellwith the high/soft variability state found in most other AGNs. Previous studies have shown that the spectrum has a strong Fe K-alpha line, which may be relativistically broadened. The presence of this line, combined with a power spectrum similar to that seen in Seyfert galaxies, suggests that the majority of the X-ray emission in this object arises in or near the disk, and not in the jet.
astro-ph.GA:We have determined interstellar extinction law toward the Galactic center (GC) at the wavelength from 1.2 to 8.0 micron, using point sources detected in the IRSF/SIRIUS near-infrared survey and those in the 2MASS and Spitzer/IRAC/GLIMPSE II catalogs. The central region |l| < 3deg and |b| < 1deg has been surveyed in the J, H and Ks bands with the IRSF telescope and the SIRIUS camera whose filters are similar to the Mauna Kea Observatories (MKO) near-infrared photometric system. Combined with the GLIMPSE II point source catalog, we made Ks versus (Ks - lambda) color-magnitude diagrams where lambda = 3.6, 4.5, 5.8, and 8.0 micron. The Ks magnitudes of bulge red clump stars and the (Ks - lambda) colors of red giant branches are used as a tracer of the reddening vector in the color-magnitude diagrams. From these magnitudes and colors, we have obtained the ratios of total to selective extinction A(Ks)/E(Ks-lambda) for the four IRAC bands. Combined with A(lambda)/A(Ks) for the J and H bands derived by Nishiyama et al., we obtain A(J):A(H):A(Ks):A([3.6]):A([4.5]):A([5.8]):A([8.0])=3.02:1.73:1:0.50:0.39:0.36:0.43 for the line of sight toward the GC. This confirms the flattening of the extinction curve at lambda > 3 micron from a simple extrapolation of the power-law extinction at shorter wavelengths, in accordance with recent studies. The extinction law in the 2MASS JHKs bands has also been calculated, and a good agreement with that in the MKO system is found. In nearby molecular clouds and diffuse interstellar medium, the lack of reliable measurements of the total to selective extinction ratios hampers unambiguous determination of the extinction law; however, observational results toward these lines of sight cannot be reconciled with a single extinction law.
astro-ph.GA:This paper presents new observations of the AGNs M87 and Hydra A at 90 GHz made with the MUSTANG bolometer array on the Green Bank Telescope at 8.5" resolution. A spectral analysis is performed combining this new data and archival VLA data on these objects at longer wavelengths. This analysis can detect variations in spectral index and curvature expected from energy losses in the radiating particles. M87 shows only weak evidence for steepening of the spectrum along the jet suggesting either re-acceleration of the relativistic particles in the jet or insufficient losses to affect the spectrum at 90 GHz. The jets in Hydra A show strong steepening as they move from the nucleus suggesting unbalanced losses of the higher energy relativistic particles. The difference between these two sources may be accounted for by the different lengths over which the jets are observable, 2 kpc for M87 and 45 kpc for Hydra A.
astro-ph.GA:The giant molecular cloud G216-2.5, also known as Maddalena's cloud or the Maddalena-Thaddeus cloud, is distinguished by an unusual combination of high gas mass (1-6 x 10^5) solar masses, low kinetic temperatures (10 K), and the lack of bright far infrared emission. Although star formation has been detected in neighboring satellite clouds, little evidence for star formation has been found in the main body of this cloud. Using a combination of mid-infrared observations with the IRAC and MIPS instruments onboard the Spitzer space telescope, and near-IR images taken with the Flamingos camera on the KPNO 2.1-meter, we identify a population of 41 young stars with disks and 33 protostars in the center of the cloud. Most of the young stellar objects are coincident with a filamentary structure of dense gas detected in CS (2-1). These observations show that the main body of G216 is actively forming stars, although at a low stellar density comparable to that found in the Taurus cloud.
astro-ph.GA:M17 is one of the youngest and most massive nearby star-formation regions in the Galaxy. It features a bright H II region erupting as a blister from the side of a giant molecular cloud (GMC). Combining photometry from the Spitzer GLIMPSE survey with complementary infrared (IR) surveys, we identify candidate young stellar objects (YSOs) throughout a 1.5 deg x 1 deg field that includes the M17 complex. The long sightline through the Galaxy behind M17 creates significant contamination in our YSO sample from unassociated sources with similar IR colors. Removing contaminants, we produce a highly-reliable catalog of 96 candidate YSOs with a high probability of association with the M17 complex. We fit model spectral energy distributions to these sources and constrain their physical properties. Extrapolating the mass function of 62 intermediate-mass YSOs (M >3 Msun), we estimate that >1000 stars are in the process of forming in the extended outer regions of M17.   From IR survey images from IRAS and GLIMPSE, we find that M17 lies on the rim of a large shell structure ~0.5 deg in diameter (~20 pc at 2.1 kpc). We present new maps of CO and 13CO (J=2-1) emission, which show that the shell is a coherent, kinematic structure associated with M17 at v = 19 km/s. The shell is an extended bubble outlining the photodissociation region of a faint, diffuse H II region several Myr old. We provide evidence that massive star formation has been triggered by the expansion of the bubble. The formation of the massive cluster ionizing the M17 H II region itself may have been similarly triggered. We conclude that the star formation history in the extended environment of M17 has been punctuated by successive waves of massive star formation propagating through a GMC complex.
astro-ph.GA:We present a systematic spectral analysis with Suzaku of six AGNs detected in the Swift/BAT hard X-ray (15--200 keV) survey, Swift J0138.6-4001, J0255.2-0011, J0350.1-5019, J0505.7-2348, J0601.9-8636, and J1628.1-5145. This is considered to be a representative sample of new AGNs without X-ray spectral information before the BAT survey. We find that the 0.5--200 keV spectra of these sources can be uniformly fit with a base model consisting of heavily absorbed (log $N_{\rm{H}} > 23.5 \rm{cm}^{-2}$) transmitted components, scattered lights, a reflection component, and an iron-K emission line. There are two distinct groups, three "new type" AGNs (including the two sources reported by \citealt{Ueda2007}) with an extremely small scattered fraction ($f_{\rm{scat}} < 0.5%$) and strong reflection component ($R = \Omega / 2 \pi \gtrsim 0.8$ where $\Omega$ is the solid angle of the reflector), and three "classical type" ones with $f_{\rm{scat}} > 0.5%$ and $R \lesssim 0.8$. The spectral parameters suggest that the new type has an optically thick torus for Thomson scattering ($N_{\rm{H}} \sim 10^{25} \rm{cm}^{-2}$) with a small opening angle $\theta \sim 20^{\circ}$ viewed in a rather face-on geometry, while the classical type has a thin torus ($N_{\rm{H}} \sim 10^{23-24} \ \rm{cm}^{-2}$) with $\theta \gtrsim 30^{\circ}$. We infer that a significant number of new type AGNs with an edge-on view is missing in the current all-sky hard X-ray surveys.
astro-ph.GA:We present the discovery of two brown dwarfs in the UKIRT Infrared Deep Sky Survey (UKIDSS) Deep Extragalactic Survey (DXS) Data Release 2. Both objects were selected photometrically from six square degrees in DXS for their blue J-K colour and the lack of optical counterparts in the Sloan Digital Sky Survey (SDSS) Stripe 82. Additional optical photometry provided by the Canada-France-Hawaii Telescope Legacy Survey (CFHT-LS) corroborated the possible substellarity of these candidates. Subsequent methane imaging of UDXS J221611.51+003308.1 and UDXS J221903.10+002418.2, has confirmed them as T7$\pm$1 and T6$\pm$1 dwarfs at photometric distances of 81 (52-118 pc) and 60 (44-87 pc; 2 sigma confidence level). A similar search in the second data release of the Ultra Deep Survey over a smaller area (0.77 square degree) and shallower depth didn't return any late-T dwarf candidate. The numbers of late-T dwarfs in our study are broadly in line with a declining mass function when considering the current area and depth of the DXS and UDS. These brown dwarfs are the first discovered in the VIMOS 4 field and among the few T dwarfs found in pencil-beam surveys. They are valuable to investigate the scale height of T dwarfs.
astro-ph.GA:We are studying the column density distribution of all nearby giant molecular clouds. As part of this project we generated several all sky extinction maps. They are calculated using the median near infrared colour excess technique applied to data from the Two Micron All-Sky Survey (2MASS). Our large scale approach allows us to fit spline functions to extinction free regions in order to accurately determine the colour excess values. Two types of maps are presented: i) Maps with a constant noise and variable spatial resolution; ii) Maps with a constant spatial resolution and variable noise. Our standard Av map uses the nearest 49 stars to the centre of each pixel for the determination of the extinction. The one sigma variance is constant at 0.28mag Av in the entire map. The distance to the 49th nearest star varies from below 1arcmin near the Galactic Plane to about 10arcmin at the poles, but is below 5arcmin for all giant molecular clouds (|b|< 30degr). A comparison with existing large scale maps shows that our extinction values are systematically larger by 20% compared to Dobashi et al. and 40% smaller compared to Schlegel et al.. This is most likely caused by the applied star counting technique in Dobashi et al. and systematic uncertainties in the dust temperature and emissivity in Schlegel et al.. Our superior resolution allows us to detect more small scale high extinction cores compared to the other two maps.
astro-ph.GA:Collimated fast winds (CFWs) have been proposed to operate during the post-AGB evolutionary phase (and even earlier during the late AGB phase), responsible for the shaping of pre-planetary nebulae (PPNs) and young planetary nebulae (PNs). This paper is a follow-up to our previous study of CFW models for the well-studied PPN CRL 618. Previously, we compared our CFW models with optical observations of CRL 618 in atomic and ionic lines and found that a CFW with a small opening angle can readily reproduce the highly collimated shape of the northwestern (W1) lobe of CRL 618 and the bow-like structure seen at its tip. In this paper, we compare our CFW models with recent observations of CRL 618 in CO J=2-1, J=6-5, and H2 1-0 S(1). In our models, limb-brightened shell structures are seen in CO and H2 at low velocity arising from the shocked AGB wind in the shell, and can be identified as the low-velocity (LV) components in the observations. However, the shell structure in CO J=2-1 is significantly less extended than that seen in the observations. None of our models can properly reproduce the observed high-velocity (HV) molecular emission near the source along the body of the lobe. In order to reproduce the HV molecular emission in CRL 618, the CFW is required to have a different structure. One possible CFW structure is the cylindrical jet, with the fast wind material confined to a small cross section and collimated to the same direction along the outflow axis.
astro-ph.GA:Planetary nebulae (and in general any photoionized region) can be classified as ionization-bounded or density-bounded. It is important to determine in which case is the planetary nebula studied to be able to estimate from nebular observations, for example, the total rate of ionizing photons produced by the central star. In this paper we present a simple observational criterion that uses radio continuum images and that allows to establish a necessary (but not sufficient) condition for the planetary nebula to be considered as ionization-bounded. We apply the criterion to two planetary nebulae: NGC 7027 is most possibly ionization-bounded, while Hb~4 is density-bounded, at least in some directions.
astro-ph.GA:A combination of observation, theory, modeling, and laboratory plasma experiments provides a multifaceted approach to develop a much greater understanding of how magnetic fields arise in galactic settings and how these magnetic fields mediate important processes that affect the dynamics, distribution, and composition of galactic plasmas. An important emphasis below is the opportunity to connect laboratory experiments to astrophysics. This approach is especially compelling for the galactic neighborhood, where the distribution and character of magnetic fields can be observed with greater detail than what is possible elsewhere in the universe. The ability to produce laboratory plasmas with unparalleled accessibility permits an even greater level of detail to be assessed and exposed. Theory and modeling provide fundamental ways to understand important processes, and they act as the bridge to connect experimental validation to astronomical observations. In many cases the studies that utilize this approach can make use of existing laboratory facilities, resulting in a cost that is quite small compared to the cost of measurements in dedicated space missions.
astro-ph.GA:We consider the scenario of a magnetic field orthogonal to a front separating two media of different temperatures and densities, such as cold and warm interstellar gas, in a 2-D plane-parallel geometry. A linear stability analysis is performed to assess the behavior of both evaporation and condensation fronts when subject to incompressible, corrugational perturbations with wavelengths larger than the thickness of the front. We discuss the behavior of fronts in both super-Alfvenic and sub-Alfvenic flows. Since the propagation speed of fronts is slow in the ISM, it is the sub-Alfvenic regime that is relevant, and magnetic fields are a significant influence on front dynamics. In this case we find that evaporation fronts, which are unstable in the hydrodynamic regime, are stabilized. Condensation fronts are unstable, but for parameters typical of the neutral ISM the growth rates are so slow that steady state fronts are effectively stable. However, the instability may become important if condensation proceeds at a sufficiently fast rate. This paper is the first in a series exploring the linear and nonlinear effects of magnetic field strength and orientation on the corrugational instability, with the ultimate goal of addressing outstanding questions about small-scale ISM structure.
astro-ph.GA:Tests for the intrinsic shape of the luminosity distribution in elliptical galaxies are discussed, with an emphasis on the uncertainties. Recent determinations of the ellipticity frequency function imply a paucity of nearly spherical galaxies, and may be inconsistent with the oblate hypothesis. Statistical tests based on the correlation of surface brightness, isophotal twisting, and minor axis rotation with ellipticity have so far not provided strong evidence in favor of the nearly oblate or nearly prolate hypothesis, but are at least qualitatively consistent with triaxiality. The possibility that the observed deviations of elliptical galaxy isophotes form ellipses are due to projection effects is evaluated. Dynamical instabilities may explain the absence of elliptical galaxies flatter than about E6, and my also play a role in the lack of nearly-spherical galaxies.
astro-ph.GA:In general, HII regions do not show clear signs of self-enrichment in products from massive stars (M > 8 M_sun). In order to explore why, I modeled the contamination with Wolf-Rayet star ejecta of metal-poor (Z=0.001) HII regions, ionised either by a 10^6 M_sun cluster of coeval stars (cluster 1), or a cluster resulting from continuous star formation at a rate of 1 M_sun yr^-1 (cluster 2). The clusters have Z=0.001 and a Salpeter initial mass function (IMF) from 0.1 to 120 M_sun. Independent one dimensional constant density simulations of the emission-line spectra of unenriched HII regions were computed at the discrete ages 1, 2, 3, 4, and 5 Myr, with the photoionisation code CLOUDY, using as input, radiative and mechanical stellar feedbacks predicted by the evolutionary synthesis code STARBURST99. Each HII region was placed at the outer radius of the adiabatically expanding superbubble of Mac Low and McCray (1988). For models with thermal and ionisation balance time-scales of less than 1 Myr, and with oxygen emission-line ratios in agreement with observations, the interior of the superbubble and the HII region were uniformly and instantaneously polluted with stellar ejecta predicted by STARBURST99. I obtained a maximum oxygen abundance enhancement of 0.025 dex, with cluster 1, at 4 Myr. It would be unobservable.
astro-ph.GA:Context. SuperclusterA in the extragalactic HII region NGC2363 is remarkable for the hypersonic gas seen as faint extended broad emission lines with a full width zero intensity of 7000km/s. Aims. We explore the possibility that the observed broad profiles are the result of the interaction of a high velocity cluster wind with dense photoionized clumps. Methods. The geometry considered is that of near static photoionized condensations at the surface of which turbulent mixing layers arise as a result of the interaction with the hot wind. The approximative treatment of turbulence is carried out using the mixing length approach of Canto & Raga. The code mappings Ic is used to derive the mean quantities describing the flow and to compute the line emissivities within the turbulent layers. The velocity projection in three dimensions of the line sources is carried out analytically. Results. A fast entraining wind of up to ~4300km/s appears to be required to reproduce the faint wings of the broad H-alpha and [O III] profiles. A slower wind of 3500km/s, however, can still reproduce the bulk of the broad component and does provide a better fit than an ad hoc Gaussian profile. Conclusions. Radial acceleration in 3D (away from supercluster A) of the emission gas provides a reasonable first order fit to the broad line component. No broad component is predicted for the [N II] and [S II] lines, as observed. The wind velocity required is uncomfortably high and alternative processes that would provide comparable constant acceleration of the emission gas up to 4000km/s might have to be considered.
astro-ph.GA:In a recent outburst which lasted for 260 days, the black hole candidate GRO J1655-40 exhibited a behaviour similar to its last outburst observed almost eight years ago. We analyze a total of 150 observational spells in 122 days of data spreaded over the entire outburst phase of Feb. 2005 to Oct. 2005. From our study, a comprehensive understanding of the detailed behaviour of this black hole candidate has emerged. Based on the degree of importance of the black body and the power-law components we divide the entire episode in four spectral states, namely, hard, soft, very soft and intermediate. Quasi-Periodic oscillations (QPOs) were found in two out of these four states, namely, in the hard and the intermediate states. In the hard state, at the rising phase of the outburst, QPO frequency ranged from 0.034 - 17.78Hz and the spectra was fitted by a disk black body, power-law and iron emission line at 6.2 - 6.5 keV. In the intermediate state, QPOs vary from 13.17Hz to 19.04Hz and the QPO frequency modulation in this state was not significant. The spectra in this state are well fitted by the disk black body and the power-law components. In the hard state of the declining phase of the outburst, we found QPOs of decreasing frequency from 13.14 Hz to 0.034 Hz. The spectra of this state were fitted by a disk black body and power-law components, but in the initial few days a cooler Comptonized component was required for a better fit. In the soft and very soft states, the spectral states are mostly dominated by the strong disk black body component.
astro-ph.GA:Nuclear star clusters (NSCs) are located at the photometric and dynamical centers of the majority of galaxies. They are among the densest star clusters in the Universe. The NSC in the Milky Way is the only object of this class that can be resolved into individual stars. We measured the proper motions of more than 6000 stars within ~1.0 pc of the supermassive black hole Sgr A*. The full data set is provided in this work. We largely exclude the known early-type stars with their peculiar dynamical properties from the dynamical analysis. The cluster is found to rotate parallel to Galactic rotation, while the velocity dispersion appears isotropic (or anisotropy may be masked by the cluster rotation). The Keplerian fall-off of the velocity dispersion due to the point mass of Sgr A* is clearly detectable only at R <~ 0.3 pc. Nonparametric isotropic and anisotropic Jeans models are applied to the data. They imply a best-fit black hole mass of 3.6 (+0.2/-0.4) x 10^6 solar masses. Although this value is slightly lower than the current canonical value of 4.0x10^6 solar masses, this is the first time that a proper motion analysis provides a mass for Sagittarius A* that is consistent with the mass inferred from orbits of individual stars. The point mass of Sagittarius A* is not sufficient to explain the velocity data. In addition to the black hole, the models require the presence of an extended mass of 0.5-1.5x10^6 solar masses in the central parsec. This is the first time that the extended mass of the nuclear star cluster is unambiguously detected. The influence of the extended mass on the gravitational potential becomes notable at distances >~0.4 pc from Sgr A*. Constraints on the distribution of this extended mass are weak. The extended mass can be explained well by the mass of the stars that make up the cluster.
astro-ph.GA:Recent advances in radio astrometry with the VLBA have resulted in near micro-arcsecond accurate trigonometric parallax and proper motion measurements for masers in star forming regions. We are now poised to directly measure the full 3-dimensional locations and motions of every massive star forming region in the Milky Way and for the first time to map its spiral structure. Such measurements would also yield the full kinematics of the Milky Way and determine its fundamental parameters (Ro and To) with 1% accuracy. Coupled with other observations this would yield the distribution of mass among the various components (including dark matter) of the Milky Way.
astro-ph.GA:Classical novae are phenomena caused by explosive hydrogen burning on an accreting white dwarf. So far, only one classical nova has been identified in X-rays before the actual optical outburst occurred (V2487 Oph). The recently discovered nova, V2491 Cyg, is one of the fastest (He/N) novae observed so far. Using archival ROSAT, XMM-Newton and Swift data, we show that V2491 Cyg was a persistent X-ray source during its quiescent time before the optical outburst. We present the X-ray spectral characteristics and derive X-ray fluxes. The pre-outburst X-ray emission is variable, and at least in one observation it shows a very soft X-ray source.
astro-ph.GA:It is generally believed that O stars, confined near the galactic midplane, are somehow able to photoionize a significant fraction of what is termed the "diffuse ionized gas" (DIG) of spiral galaxies, which can extend up to 1-2 kpc above the galactic midplane. The heating of the DIG remains poorly understood, however, as simple photoionization models do not reproduce the observed line ratio correlations well or the DIG temperature. We present turbulent mixing layer models in which warm photoionized condensations are immersed in a hot supersonic wind. Turbulent dissipation and mixing generate an intermediate region where the gas is accelerated, heated and mixed. The emission spectrum of such layers are compared with observations of Rand (ApJ 462, 712) of the DIG in the edge-on spiral NGC2363. We generate two sequence of models that fit the line ratio correlations between [SII]/H-alpha, [OI]/H-alpha, [NII]/[SII] and [OIII]/H-beta reasonably well. In one sequence of models the hot wind velocity increases while in the other the ionization parameter and layer opacity increases. Despite the success of the mixing layer models, the overall efficiency in reprocessing the stellar UV is much too low, much less than 1%, which compels us to reject the TML model in its present form.
astro-ph.GA:We present new optical imaging and spectroscopy and HI spectral line imaging of the dwarf galaxy ADBS 113845+2008 (hereafter ADBS 1138). This metal-poor (Z~30% Z_Sun), "post-starburst" system has one of the most compact stellar distributions known in any galaxy to date (B-band exponential scale length =0.57 kpc). In stark contrast to the compact stellar component, the neutral gas is extremely extended; HI is detected to a radial distance of ~25 kpc at the 10^19 cm^-2 level (>44 B-band scale lengths). Comparing to measurements of similar "giant disk" dwarf galaxies in the literature, ADBS 1138 has the largest known HI-to-optical size ratio. The stellar component is located near the center of a broken ring of HI that is ~15 kpc in diameter; column densities peak in this structure at the ~3.5x10^20 cm^-2 level. At the center of this ring, in a region of comparatively low HI column density, we find ongoing star formation traced by H alpha emission. We sample the rotation curve to the point of turn over; this constrains the size of the dark matter halo of the galaxy, which outweighs the luminous component (stars + gas) by at least a factor of 15. To explain these enigmatic properties, we examine "inside-out" and "outside-in" evolutionary scenarios. Calculations of star formation energetics indicate that "feedback" from concentrated star formation is not capable of producing the ring structure; we posit that this is a system where the large HI disk is evolving in quiescent isolation. In a global sense, this system is exceedingly inefficient at converting neutral gas into stars.
astro-ph.GA:The Ophiuchus clouds, in particular L~1688, are an excellent region to study the embedded phases of star formation, due to the relatively large number of protostars. However, the standard method of finding and characterizing embedded young stellar objects (YSOs) through just their infrared spectral slope does not yield a reliable sample. This may affect the age determinations, often derived from the statistics on the total number of embedded YSOs and pre-main sequence stars within a cloud.Our aim is to characterize the structure of protostellar envelopes on an individual basis and to correctly identify the embedded YSO population of L1688. Spectral maps of the HCO+ J=4--3 and C18O J=3--2 lines using the HARP-B array on the James Clerk Maxwell Telescope and SCUBA 850 micron dust maps are obtained of all sources in the L1688 region with infrared spectral slopes consistent with, or close to, that of embedded YSOs. Selected 350 micron maps obtained with the Caltech Submillimeter Observatory are presented as well. The properties, extent and variation of dense gas, column density and dust on scalesup to 1' are probed at 15" resolution. Using the spatial variation of the gas and dust, together with the intensity of the HCO+ J=4--3 line, we are able to accurately identify the truly embedded YSOs and determine their properties. RESULTS The protostellar envelopes range from 0.05 to 0.5 Msun in mass. The concentration of HCO+ emission (~0.5 to 0.9) is generally higher than that of the dust concentration. Combined with absolute intensities, HCO+ proves to be a better tracer of protostellar envelopes than dust, which can contain disk and cloud contributions. Our total sample of 45 sources, including all previously classified Class I sources, several flat-spectrum sources and some known disks, was re-classified using the ....
astro-ph.GA:We aim to characterise the properties of the stellar clusters in the Milky Way. Utilising an expectation-maximisation method we determined that the cluster FSR0358, originally discovered by J.D.Kirkpatrick, is the most likely real cluster amongst the cluster candidates from Froebrich et al.. Here we present new deep high resolution near infrared imaging of this object obtained with UKIRT. The analysis of the data reveals that FSR0358 (Kirkpatrick1) is a 5+-2Gyr old open cluster in the outer Milky Way. Its age, metallicity of Z=0.008 and distance from the Galactic Centre of 11.2kpc are typical for the known old open galactic clusters. So far six of the FSR cluster candidates have been identified as having an age above 5Gyr. This shows the significance of this catalogue in enhancing our knowledge of the oldest open clusters in the Galaxy.
astro-ph.GA:We present a new large-scale survey of J=3-2 12CO emission covering 4.8 square degrees around the Rosette Nebula. Approximately 2000 compact clumps are identified, with a spatially-invariant power law mass distribution index of -1.8. Most of the inner clumps show velocity gradients of 1-3 km/s/pc, directed away from the exciting nebula. The gradients decrease with distance from the central O stars, and are consistent with a photoionised gas acceleration model, assuming clump lifetimes of a few 10^5 yrs. However, in one clear case, the observed near-constant velocity gradient is difficult to explain with simple models. Most blue-shifted but very few of the red-shifted clumps are associated with dark absorbing optical globules, confirming that the dominant molecular gas motion is expansion away from the central nebula and O stars. Many clumps also lie in a molecular ring, having an expansion velocity of 30 km/s, radius 11pc, and dynamical lifetime of ~1Myr. The J=3-2/1-0 12CO line ratios of the clumps decrease with distance from the O stars, implying a gradient in their surface temperatures; the results are consistent with a simple model of clump surface heating due to the central stars.   Seven high-velocity molecular flows are found in the region, with a close correspondence between these flows and embedded young clusters. These outflows are sufficiently energetic to drive local gas turbulence within each cluster.   We find 14 clear examples of association between embedded young stars seen at 24um and CO clumps; these are thought to be photoevaporating molecular envelopes. The CO clumps without evidence of embedded stars tend to have lower velocity gradients, and it is suggested that the presence of the young star may extend the lifespan of the photoevaporating envelope.
astro-ph.GA:The Carina Nebula is one of the youngest, most active sites of massive star formation in our Galaxy. In this nebula, we have discovered a bright X-ray source that has persisted for ~30 years. The soft X-ray spectrum, consistent with kT ~128 eV blackbody radiation with mild extinction, and no counterpart in the near- and mid-infrared wavelengths indicate that it is a ~1e6-year-old neutron star housed in the Carina Nebula. Current star formation theory does not suggest that the progenitor of the neutron star and massive stars in the Carina Nebula, in particular Eta Carinae, are coeval. This result suggests that the Carina Nebula experienced at least two major episodes of massive star formation. The neutron star may be responsible for remnants of high energy activity seen in multiple wavelengths.
astro-ph.GA:We discuss the outstanding issues of the interstellar medium which will depend on the application of knowledge from plasma physics. We particularly advocate attention to recent developments in experimental plasma physics, and urge that the astronomical community consider support of these experiments in the next decade.
astro-ph.GA:The resolved stellar populations of local galaxies, from which it is possible to derive complete star formation and chemical enrichment histories, provide an important way to study galaxy formation and evolution that is complementary to lookback time studies. We propose to use photometry of resolved stars to measure the star formation histories in a statistical sample of galaxy disks and E/S0 galaxies near their effective radii. These measurements would yield strong evidence to support critical questions regarding the formation of galactic disks and spheroids. The main technological limitation is spatial resolution for photometry in heavily crowded fields, for which we need improvement by a factor of ~10 over what is possible today with filled aperture telescopes.
astro-ph.GA:Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the field of Galactic science. Community-based White Paper to Astro2010 in response to the call for such papers.
astro-ph.GA:We present multi-wavelength observations (from optical to sub-millimeter, including Spitzer and SCUBA) of H2XMMJ 003357.2-120038 (also GD158_19), an X-ray selected, luminous narrow-line (Type 2) quasar at z=1.957 selected from the HELLAS2XMM survey. Its broad-band properties can be reasonably well modeled assuming three components: a stellar component to account for the optical and near-IR emission, an AGN component (i.e., dust heated by an accreting active nucleus), dominant in the mid-IR, with an optical depth at 9.7 micron along the line of sight (close to the equatorial plane of the obscuring matter) of tau(9.7)=1 and a full covering angle of the reprocessing matter (torus) of 140 degrees, and a far-IR starburst component (i.e., dust heated by star formation) to reproduce the wide bump observed longward of 70 micron. The derived star-formation rate is about 1500 solar masses per year. The overall modeling indicates that GD158_19 is a high-redshift X-ray luminous, obscured quasar with coeval powerful AGN activity and intense star formation. It is probably caught before the process of expelling the obscuring gas has started, thus quenching the star formation.
astro-ph.GA:A wide range of recent observations have shown that AGN-driven cavities may provide the energy source that balances the cooling observed in the centres of cool-core galaxy clusters. One tool for better understanding the physics of these cavities is their observed morphological evolution, which is dependent on such poorly-understood properties as the turbulent density field and the impact of magnetic fields. Here we combine numerical simulations that include subgrid turbulence and software that produces synthetic X-ray observations to examine the evolution of X-ray cavities in the absence of magnetic fields. Our results reveal an anisotropic size evolution of that is dramatically different from simplified, analytical predictions. These differences highlight some of the key issues that must be accurately quantified when studying AGN-driven cavities, and help to explain why the inferred pV energy in these regions appears to be correlated with their distance from the cluster center. Interpreting X- ray observations will require detailed modeling of effects including mass-entrainment, distortion by drag forces, and pro jection. Current limitations do not allow a discrimination between purely hydrodynamic and magnetically-dominated models for X-ray cavities.
astro-ph.GA:We have conducted a series of investigations on the geometry of the reddening material in AGNs, which have important implications to the AGN unification and SMBH demography. According to our statistics of partially obscured quasars, we found that SMBHs in partially obscured type/phase (i.e., intermediate type) are at least as abundant as normal quasars in the local Universe; the reddening material in most objects are located in between the BLR and NLR. According to our comparison of narrow lines in type 1 and 2 AGNs, we found that for high-ionization or high-critical density narrow lines (e.g. OIII 5007, Balmer lines and FeII) a significant fraction of the emission arises from the inner dense part of the NLR; this inner NLR is located very close to the central engine and thus can be covered by the torus.
astro-ph.GA:A massive objects such as a globular cluster passing through the disk of a galaxy can trigger star formation. We test the hypothesis that the most massive globular cluster in the Galaxy, $\omega$ Centauri, which crossed the disk approximately $24\pm2$ Myr ago, may have triggered the formation of the open clusters Stephenson 2 and BDSB 122. The orbits of $\omega$ Centauri, Stephenson 2 and BDSB 122 are computed for the three-component model of Johnston, Hernquist & Bolte, which considers the disk, spheroidal and halo gravitational potentials. With the re-constructed orbit of $\omega$ Centauri, we show that the latest impact site is consistent, within important uncertainties, with the birth-site of the young massive open clusters BDSB 122 and Stephenson 2. Within uncertainties, this scenario is consistent with the time-scale of their backwards motion in the disk, shock wave propagation and delay for star formation. Together with open cluster formation associated to density waves in spiral arms, the present results are consistent with the idea that massive globular clusters as additional progenitors of open clusters, the massive ones in particular.
astro-ph.GA:We report on the identification of the highest redshift submm-selected source currently known: LESSJ033229.4-275619. This source was detected in the Large Apex BOlometer CAmera (LABOCA) Extended Chandra Deep Field South (ECDFS) Submillimetre Survey (LESS), a sensitive 870-um survey (~1.2-mJy rms) of the full 30'x30' ECDFS with the LABOCA camera on the Atacama Pathfinder EXperiment (APEX) telescope. The submm emission is identified with a radio counterpart for which optical spectroscopy provides a redshift of z=4.76. We show that the bolometric emission is dominated by a starburst with a star formation rate of ~1000 Msun/yr, although we also identify a moderate luminosity Active Galactic Nucleus (AGN) in this galaxy. Thus it has characteristics similar to those of z~2 submm galaxies (SMGs), with a mix of starburst and obscured AGN signatures. This demonstrates that ultraluminous starburst activity is not just restricted to the hosts of the most luminous (and hence rare) QSOs at z~5, but was also occurring in less extreme galaxies at a time when the Universe was less than 10% of its current age. Assuming that we are seeing the major phase of star formation in this galaxy, then we demonstrate that it would be identified as a luminous distant red galaxy at z~3 and that the current estimate of the space density of z>4 SMGs is only sufficient to produce ~10% of the luminous red galaxy population at these early times. However, this leaves open the possibility that some of these galaxies formed through less intense, but more extended star formation events. If the progenitors of all of the luminous red galaxies at z~3 go through an ultraluminous starburst at z>4 then the required volume density of z>4 SMGs will exceed that predicted by current galaxy formation models by more than an order of magnitude.
astro-ph.GA:We present the spectral analysis of a large set of XMM-Newton observations of EXO 0748-676, a bright dipping LMXB. In particular, we focus on the dipping phenomenon as a result of changes in the properties of the ionised gas close to the source. Using the high-resolution spectra collected with the RGS, we explored two simple geometrical scenarios for which we derived physical quantities of the absorbing material like the density, size, and mass. We find that the continuum is absorbed by a neutral gas, and by both a collisionally (temperature T~70 eV) and photoionised (ionisation parameter log\xi~2.5) absorbers. Emission lines from OVII and OVIII are also detected. This is the first time that evidence of a collisionally ionised absorber has been found in a low-mass X-ray binary. The collisionally ionised absorber may be in the form of dense (n>10^14 cm^-3) filaments, located at a distance r>10^11 cm. During dips, the photoionised absorber significantly increases its column density (factor 2--4) while becoming less ionised. This strengthens the idea that the colder material of the accretion stream impinging the disc is passing on our line of sight during dips. We find that the distance from the neutron star to the impact region (~ 5x10^10 cm) is similar to the size of the neutron star's Roche lobe. The gas observed during the persistent state may have a flattened geometry. Finally, we explore the possibility of the existence of material forming an initial, hotter portion of a circumbinary disc.
astro-ph.GA:We examine the proposal that the HI "high-velocity" clouds (HVCs) surrounding the Milky Way and other disc galaxies form by condensation of the hot galactic corona via thermal instability. Under the assumption that the galactic corona is well represented by a non-rotating, stratified atmosphere, we find that for this formation mechanism to work the corona must have an almost perfectly flat entropy profile. In all other cases the growth of thermal perturbations is suppressed by a combination of buoyancy and thermal conduction. Even if the entropy profile were nearly flat, cold clouds with sizes smaller than 10 kpc could form in the corona of the Milky Way only at radii larger than 100 kpc, in contradiction with the determined distances of the largest HVC complexes. Clouds with sizes of a few kpc can form in the inner halo only in low-mass systems. We conclude that unless even slow rotation qualitatively changes the dynamics of a corona, thermal instability is unlikely to be a viable mechanism for formation of cold clouds around disc galaxies.
astro-ph.GA:We presented CAIXA, a Catalogue of AGN in the XMM-Newton Archive, in Bianchi et al. (2009). It consists of all the radio-quiet X-ray unobscured (N$_\mathrm{H}<2\times10^{22}$ cm$^{-2}$) active galactic nuclei (AGN) observed by XMM-Newton in targeted observations, whose data are public as of March 2007. With its 156 sources, this is the largest catalogue of high signal-to-noise X-ray spectra of AGN. All the EPIC pn spectra of the sources in CAIXA were extracted homogeneously and a baseline model was applied in order to derive their basic X-ray properties. These data are complemented by multiwavelength data found in the literature: Black Hole masses, Full Width Half Maximum (FWHM) of Hbeta, radio and optical fluxes. A systematic search for correlations between the X-ray spectral properties and the multiwavelength data was performed for the sources in CAIXA. We discuss here some of the significant (>99.9 % confidence level) correlations.
astro-ph.GA:Context. IC 1396N is a bright-rimmed cloud associated with an intermediate-mass star-forming region, where a number of Herbig-Haro objects, H2 jet-like features, CO molecular outflows, and millimeter compact sources have been observed. Aims. To study in detail the complex structure of the IC 1396N core and the molecular outflows detected in the region and to reveal the presence of additional YSOs inside this globule. Methods. We carried out a deep survey of the IC 1396N region in the J, H, K' broadband filters and deep high-angular resolution observations in the H2 narrowband filter with NICS at the TNG telescope. The completeness limits in the 2MASS standard are Ks~17.5, H~18.5 and J~19.5. Results. A total of 736 sources have been detected in all three bands within the area where the JHK' images overlap. There are 128 sources detected only in HK', 67 detected only in K', and 79 detected only in H. We found only few objects exhibiting a Near-Infrared excess and no clear signs of clustering of sources towards the southern rim. In case of triggered star formation in the southern rim of the globule, this could be very recent, because it is not evidenced through Near-Infrared imaging alone. The H2 emission is complex and knotty and shows a large number of molecular hydrogen features spread over the region, testifying a recent star-formation activity throughout the whole globule. This emission is resolved into several chains or groups of knots that sometimes show a jet-like morphology. The shocked cloudlet model scenario previously proposed to explain the V-shaped morphology of the CO molecular outflow powered by the intermediate-mass YSO BIMA 2 seems to be confirmed by the presence of H2 emission at the position of the deflecting western clump. New possible flows have been discovered in the globule,
astro-ph.GA:We present mid-infrared (MIR) observations, made with the TIMMI2 camera on the ESO 3.6 m telescope, toward 14 young massive star-forming regions. All regions were imaged in the N band, and nine in the Q band, with an angular resolution of ~ 1 arcsec. Typically, the regions exhibit a single or two compact sources (with sizes in the range 0.008-0.18 pc) plus extended diffuse emission. The Spitzer-Galactic Legacy Infrared Mid-Plane Survey Extraordinaire images of these regions show much more extended emission than that seen by TIMMI2, and this is attributed to polycyclic aromatic hydrocarbon (PAH) bands. For the MIR sources associated with radio continuum radiation (Paper I) there is a close morphological correspondence between the two emissions, suggesting that the ionized gas (radio source) and hot dust (MIR source) coexist inside the H II region. We found five MIR compact sources which are not associated with radio continuum emission, and are thus prime candidates for hosting young massive protostars. In particular, objects IRAS 14593-5852 II (only detected at 17.7 microns) and 17008-4040 I are likely to be genuine O-type protostellar objects. We also present TIMMI2 N-band spectra of eight sources, all of which are dominated by a prominent silicate absorption feature (~ 9.7 microns). From these data we estimate column densities in the range (7-17)x10^22 cm^-2, in good agreement with those derived from the 1.2 mm data (Paper II). Seven sources show bright [Ne II] line emission, as expected from ionized gas regions. Only IRAS 123830-6128 shows detectable PAH emission at 8.6 and 11.3 microns.
astro-ph.GA:We consider the possibility of detecting intermediate-mass ($10^3-10^4 M_{\odot}$) black holes, whose existence at the centers of globular clusters is expected from optical and infrared observations, using precise pulse arrival timing for the millisecond pulsars in globular clusters known to date. For some of these pulsars closest to the cluster centers, we have calculated the expected delay times of pulses as they pass in the gravitational field of the central black hole. The detection of such a time delay by currently available instruments for the known pulsars is shown to be impossible at a black hole mass of $10^3 M_{\odot}$ and very problematic at a black hole mass of $10^4 M_{\odot}$. In addition, the signal delay will have a negligible effect on the pulsar periods and their first derivatives compared to the current accuracy of their measurements.
astro-ph.GA:In recent years, organic molecules of increasing complexity have been found toward the prolific Galactic center source Sagittarius B2. We wish to explore the degree of complexity that the interstellar chemistry can reach in star-forming regions. We carried out a complete line survey of the hot cores Sgr B2(N) and (M) with the IRAM 30 m telescope in the 3 mm range. We analyzed this spectral survey in the LTE approximation. We modeled the emission of all known molecules simultaneously, which allows us to search for less abundant, more complex molecules. We compared the derived column densities with the predictions of a coupled gas-phase and grain-surface chemical code. We report the first detection in space of ethyl formate (C2H5OCHO) and n-propyl cyanide (C3H7CN) toward Sgr B2(N). The abundances of ethyl formate and n-propyl cyanide relative to H2 are estimated to be 3.6e-9 and 1.0e-9, respectively. Our chemical modeling suggests that the sequential, piecewise construction of ethyl and n-propyl cyanide from their constituent functional groups on the grain surfaces is their most likely formation route. Ethyl formate is primarily formed on the grains by adding CH3 to functional-group radicals derived from methyl formate, although ethanol may also be a precursor. The detection in Sgr B2(N) of the next stage of complexity in two classes of complex molecule, esters and alkyl cyanides, suggests that greater complexity in other classes of molecule may be present in the interstellar medium. {Abridged}
astro-ph.GA:We present medium-resolution spectra of 16 radial velocity red-giant members of the low-luminosity Bootes I dwarf spheroidal (dSph) galaxy, that have sufficient S/N for abundance determination, based on the strength of the Ca II K line. Assuming [Ca/Fe] ~ +0.3, the abundance range in the sample is Delta [Fe/H] ~ 1.7 dex, with one star having [Fe/H] = -3.4. The dispersion is sigma([Fe/H]) = 0.45 +/- 0.08 -- similar to those of the Galaxy's more luminous dSph systems and Omega Centauri. This suggests that the large mass (greater than approximately 10 million solar masses) normally assumed to foster self-enrichment and the production of chemical abundance spreads was provided by the non-baryonic material in Bootes I.
astro-ph.GA:We present VLT-SINFONI K-band IFU spectroscopy of the central galaxies in the cool core clusters A1664, A2204 and PKS 0745-191, to probe the Pa-alpha and ro-vibrational H2 line emission. In A1664 the two emission-line velocity systems seen in our previous H-alpha data appear in both Pa-alpha and H2 emission, with notable morphological differences. The recession velocity of the red component of Pa-alpha increases linearly with decreasing radius, particularly along an 8 kpc filament aligned with the major axis of the underlying galaxy and the cluster X-ray emission. These kinematics are modelled as gravitational free-fall as gas cools rapidly out of the hot phase. In A2204 the gas shows 3 or 4 filaments reaching 10 kpc, three of which lie towards `ghost bubbles' seen in X-ray imaging. For PKS 0745-191, we confirm the twin-arm morphology of previous narrow-band images; the Pa-alpha kinematics suggest rotational motion about an axis aligned with the kpc-scale radio jet; on nucleus, we find a broad Pa-alpha component (FWHM 1700 km/s) and a secondary H2 system redshifted by +500 km/s.   The H2 v=1-0 S(3)/Pa-alpha ratio is highest in isolated and extended regions where it matches the levels in the NGC 1275 filaments as modelled by Ferland et al. Regions with lower ratios highlight active star formation and are often kinematically quiescent (FWHM < 200 km/s). Our findings suggest that these clusters may be captured in different stages of the `cold feedback' cycle of Pizzolato & Soker, with A1664 in a brief phase of extreme cooling and star formation prior to an AGN heating event; PKS 0745-191 in outburst with the AGN accreting from a cool gas disk, and A2204 in a later phase where cool gas is dragged out of the galaxy by the buoyant rise of old radio bubbles (abridged).
astro-ph.GA:(Abridged) Bright-rimmed clouds (BRCs) are isolated molecular clouds located on the edges of evolved HII regions where star formation is thought may have been triggered. In this paper we investigate the current level of star formation within a sample of BRCs and evaluate to what extent star formation may have been induced. We present the results of a programme of position-switched CO observations towards 45 southern BRCs. The 12CO, 13CO and C18O (J=1-0) were simultaneously observed using the 22m Mopra telescope. We complement these observations with archival mid-IR submm and radio data. Analysis of the CO, mid-IR and radio data result in the clouds being divided into three distinct groups. We refer to these groups as spontaneous, triggered, and zapped clouds, respectively. Comparing the physical parameters of spontaneous and triggered samples we find striking differences in luminosity, surface temperature and column density with all three quantities significantly enhanced for the clouds considered to have been triggered. Furthermore, we find strong evidence for star formation within the triggered sample by way of methanol and H_2O masers, embedded mid-IR point sources and CO wings, however, we find evidence of ongoing star formation within only two of the spontaneous sample. We have used CO, mid-IR and radio data to identify 24 of the 45 southern BRCs that are undergoing a strong interaction with their HII region. We can therefore exclude ~50% from future studies. 14 of the 24 interacting BRCs are found to be associated with embedded mid-IR point sources and we find strong evidence of that these clouds are forming stars. The absence of mid-infrared sources towards the remaining ten clouds leads us to conclude that these represent an earlier evolutionary stage of star formation.
astro-ph.GA:To better understand the initial conditions of the high-mass star formation process, it is crucial to study at high-angular resolution the morphology, the kinematics, and eventually the interactions of the coldest condensations associated with intermediate-/high-mass star forming regions. The paper studies the cold condensations in the intermediate-/high-mass proto-cluster IRAS 05345+3157, focusing the attention on the interaction with the other objects in the cluster. We have performed millimeter high-angular resolution observations, both in the continuum and several molecular lines, with the PdBI and the SMA. In a recent paper, we have already published part of these data. The main finding of that work was the detection of two cold and dense gaseous condensations, called N and S (masses ~2 and ~9 M_sun), characterised by high values of the deuterium fractionation (~0.1 in both cores). In this paper, we present a full report of the observations, and a complete analysis of the data obtained. The millimeter maps reveal the presence of 3 cores inside the interferometers primary beam, called C1-a, C1-b and C2. None of them are associated with cores N and S. C1-b is very likely associated with a newly formed early-B ZAMS star embedded inside a hot-core, while C1-a is more likely associated with a class 0 intermediate-mass protostar. The nature of C2 is unclear. Both C1-a and C1-b are good candidates as driving sources of a powerful CO outflow, which strongly interacts with N and S, as demonstrated by the velocity gradient across both condensations. Our major conclusion is that the chemical properties of these pre-stellar cores are similar to those observed in low-mass isolated ones, while the kinematics is dominated by the turbulence triggered by the CO outflow and can influece their evolution.
astro-ph.GA:We explore what dominant physical mechanism sets the kinetic energy contained in neutral, atomic (HI) gas. We compare the HI line widths predicted from turbulence driven by supernova (SN) explosions and magneto-rotational instability (MRI) to direct observations in 11 disk galaxies. We use high-quality maps of the HI mass surface density and line width, obtained by the THINGS survey. We show that all sample galaxies exhibit a systematic radial decline in the HI line width, which appears to be a generic property of HI disks and also implies a radial decline in kinetic energy density of HI. At a galactocentric radius of r25 there is a characteristic value of the HI velocity dispersion of $10\pm2$ \kms. Inside this radius, galaxies show HI line widths above the thermal value expected from a warm HI component, implying that turbulence drivers must be responsible for maintaining this line width. Therefore, we compare maps of HI kinetic energy to maps of the star formation rate (SFR) and to predictions for energy generated by MRI. We find a positive correlation between kinetic energy of HI and SFR. For a given turbulence dissipation timescale we can estimate the energy input required to maintain the observed kinetic energy. The SN rate implied by the observed recent SFR is sufficient to maintain the observed velocity dispersion, if the SN feedback efficiency is at least \epsilon_SN\simeq0.1. Beyond r25, this efficiency would have to increase to unrealistic values, $\epsilon>1$, suggesting that mechanical energy from young stars does not supply most energy in outer disks. On the other hand, both thermal broadening and turbulence driven by MRI can produce the velocity dispersions and kinetic energies that we observe in this regime.
astro-ph.GA:Magnetic pressure has long been known to dominate over gas pressure in atomic and molecular regions of the interstellar medium. Here I review several recent observational studies of the relationships between the H^+, H^0 and H_2 regions in M42 (the Orion complex) and M17. A simple picture results. When stars form they push back surrounding material, mainly through the outward momentum of starlight acting on grains, and field lines are dragged with the gas due to flux freezing. The magnetic field is compressed and the magnetic pressure increases until it is able to resist further expansion and the system comes into approximate magnetostatic equilibrium. Magnetic field lines can be preferentially aligned perpendicular to the long axis of quiescent cloud before stars form. After star formation and pushback occurs ionized gas will be constrained to flow along field lines and escape from the system along directions perpendicular to the long axis. The magnetic field may play other roles in the physics of the H II region and associated PDR. Cosmic rays may be enhanced along with the field and provide additional heating of atomic and molecular material. Wave motions may be associated with the field and contribute a component of turbulence to observed line profiles.
astro-ph.GA:It has been argued that the energy content in time varying spacetimes can be obtained by using the approximate Lie symmetries of the geodesics equations in that spacetime. When applied to cylindrical gravitational waves, it gives a self-damping of the waves. According to this proposal the energy of the waves go to zero asymptotically as the radial distance to the two-thirds power. If true, this would mean that the estimates for the sensitivity of the detectors for the various sources would have to be revised
astro-ph.GA:We present intermediate resolution long-slit spectra and narrow-band Halpha, [NII] and [OIII] images of PM1-242, PM318 and PM1-333, three IRAS sources classified as possible planetary nebulae. The spectra show that the three objects are true planetary nebulae and allow us to study their physical properties; the images provide a detailed view of their morphology. PM1-242 is a medium-to-high-excitation (e.g., HeII4686/Hbeta ~0.4; [NII]6584/Halpha ~0.3) planetary nebula with an elliptical shape containing [NII] enhanced point-symmetric arcs. An electron temperature [Te([SIII])] of ~10250 K and an electron density [Ne([SII])] of ~2300 cm-3 are derived for PM1-242. Abundance calculations suggest a large helium abundance (He/H ~0.29) in PM1-242. PM1-318 is a high-excitation (HeII4686/Hbeta ~1) planetary nebula with a ring-like inner shell containing two enhanced opposite regions, surrounded by a fainter round attached shell brighter in the light of [OIII]. PM1-333 is an extended planetary nebula with a high-excitation (HeII4686/Hbeta up to ~0.9) patchy circular main body containing two low-excitation knotty arcs. A low Ne([SII]) of ~450 cm-3 and Te([OIII]) of ~15000 K are derived for this nebula. Abundance calculations suggest that PM1-333 is a type I planetary nebula. The lack of a sharp shell morphology, low electron density, and high-excitation strongly suggest that PM1-333 is an evolved planetary nebula. PM1-333 also shows two low-ionization polar structures whose morphology and emission properties are reminiscent of collimated outflows. We compare PM1-333 with other evolved planetary nebulae with collimated outflows and find that outflows among evolved planetary nebulae exhibit a large variety of properties, in accordance with these observed in younger planetary nebula.
astro-ph.GA:The main objective of this work is to investigate the role played by Lower Centaurus Crux (LCC) and Upper Centaurus Lupus (UCL), both subcomponents of the Scorpio Centaurus OB association (Sco-Cen), in the formation of the groups beta Pictoris, TW Hydrae and the eta Chamaeleontis cluster. The dynamical evolution of all the stellar groups involved and of the bubbles and shells blown by LCC and UCL are calculated and followed from the past to the present. This leads to a formation scenario in which (1) the groups beta Pictoris, TW Hydrae were formed in the wake of the shells created by LCC and UCL, (2) the young cluster eta Chamaeleontis was born as a consequence of the collision of the shells of LCC and UCL, and (3) the formation of Upper Scorpius (US), the other main subcomponent of the Sco-Cen association, may have been started by the same process that created eta Chamaeleontis.
astro-ph.GA:Most stars are born in rich young stellar clusters (YSCs) embedded in giant molecular clouds. The most massive stars live out their short lives there, profoundly influencing their natal environments by ionizing HII regions, inflating wind-blown bubbles, and soon exploding as supernovae. Thousands of lower-mass pre-main sequence stars accompany the massive stars, and the expanding HII regions paradoxically trigger new star formation as they destroy their natal clouds. While this schematic picture is established, our understanding of the complex astrophysical processes involved in clustered star formation have only just begun to be elucidated. The technologies are challenging, requiring both high spatial resolution and wide fields at wavelengths that penetrate obscuring molecular material and remove contaminating Galactic field stars. We outline several important projects for the coming decade: the IMFs and structures of YSCs; triggered star formation around YSC; the fate of OB winds; the stellar populations of Infrared Dark Clouds; the most massive star clusters in the Galaxy; tracing star formation throughout the Galactic Disk; the Galactic Center region and YSCs in the Magellanic Clouds. Programmatic recommendations include: developing a 30m-class adaptive optics infrared telescope; support for high-resolution and wide field X-ray telescopes; large-aperture sub-millimeter and far-infrared telescopes; multi-object infrared spectrographs; and both numerical and analytical theory.
astro-ph.GA:Our multi-epoch survey of ~20 sq. deg. of the Canis Major overdensity has detected only 10 RR Lyrae stars (RRLS). We show that this number is consistent with the number expected from the Galactic halo and thick disk populations alone, leaving no excess that can be attributed to the dwarf spheroidal (dSph) galaxy that some authors have proposed as the origin of the CMa overdensity. If this galaxy resembles the dSph satellites of the Milky Way and of M31 and has the putative Mv~-14.5, our survey should have detected several tens of RRLS. Even if Mv<-12, the expected excess is >10, which is not observed. Either the old stellar population of this galaxy has unique properties or, as others have argued before, the CMa overdensity is produced by the thin and thick disk and spiral arm populations of the Milky Way and not by a collision with a dSph satellite galaxy.
astro-ph.GA:We have constructed an analytical model of AGN feedback and studied its implications for elliptical galaxies and galaxy clusters. The results show that momentum injection above a critical value will eject material from low mass elliptical galaxies, and leads to an X-ray luminosity, $L_{\rm X}$, that is $\propto$ $\sigma^{8-10}$, depending on the AGN fuelling mechanism, where $\sigma$ is the velocity dispersion of the hot gas. This result agrees well with both observations and semi-analytic models. In more massive ellipticals and clusters, AGN outflows quickly become buoyancy-dominated. This necessarily means that heating by a central cluster AGN redistributes the intracluster medium (ICM) such that the mass of hot gas, within the cooling radius, should be $ \propto L_{\rm X}(<r_{\rm cool})/[g(r_{\rm cool})\sigma]$, where $g(r_{\rm cool})$ is the gravitational acceleration at the cooling radius. This prediction is confirmed using observations of seven clusters. The same mechanism also defines a critical ICM cooling time of $\sim 0.5$ Gyr, which is in reasonable agreement with recent observations showing that star formation and AGN activity are triggered below a universal cooling time threshold.
astro-ph.GA:We study the feedback from an AGN on stellar formation within its host galaxy, mainly using one high resolution numerical simulation of the jet propagation within the interstellar medium of an early-type galaxy. In particular, we show that in a realistic simulation where the jet propagates into a two-phase ISM, star formation can initially be slightly enhanced and then, on timescales of few million years, rapidly quenched, as a consequence both of the high temperatures attained and of the reduction of cloud mass (mainly due to Kelvin-Helmholtz instabilities). We then introduce a model of (prevalently) {\em negative} AGN feedback, where an exponentially declining star formation is quenched, on a very short time scale, at a time t_AGN, due to AGN feedback. Using the Bruzual & Charlot (2003) population synthesis model and our star formation history, we predict galaxy colours from this model and match them to a sample of nearby early-type galaxies showing signs of recent episodes of star formation (Kaviraj et al. 2007). We find that the quantity t_gal - t_AGN, where t_gal is the galaxy age, is an excellent indicator of the presence of feedback processes, and peaks significantly around t_gal - t_AGN \approx 0.85 Gyr for our sample, consistent with feedback from recent energy injection by AGNs in relatively bright (M_{B} \lsim -19) and massive nearby early-type galaxies. Galaxies that have experienced this recent feedback show an enhancement of 3 magnitudes in NUV(GALEX)-g, with respect to the unperturbed, no-feedback evolution. Hence they can be easily identified in large combined near UV-optical surveys.
astro-ph.GA:The structure of globular clusters and elliptical galaxies are described in an unified way through a new class of lowered models inspired on the nonextensive kinetic theory. These power law models are specified by a single parameter q which quantifies to what extent they depart from the class of lowered stellar distributions discussed by Michie and King. For q equal to unity, the Michie-King profiles are recovered. However, for q smaller than unity there is a gradual modification in the shape of the density profiles which depends on the degree of tidal damage imposed on the model, thereby also providing a good fit for globular clusters. It is also shown that a subclass of these models, those with a deeper potential and $q$ slightly less than unity, present a distribution resembling the de Vaucoulers $r^{1/4}$ profile which yields a good description of the structure of elliptical galaxies. This subset of models follows this trend, with a slight departure over nearly 10 orders of magnitudes.
astro-ph.GA:We obtained long-slit spectra of high signal-to-noise ratio of the galaxy M32 with the GMOS spectrograph at the GEMINI North telescope. We analysed the integrated spectra by means of full spectral fitting in order to extract the mixture of stellar populations that best represents its composite nature. Three different galactic radii were analysed, from the nuclear region out to 2 arcmin from the centre. This allows us to compare, for the first time, the results of integrated light spectroscopy with those of resolved colour-magnitude diagrams from the literature. As our main result, we propose that an ancient and an intermediate-age population coexist in M32, and that the balance between these two populations change between the nucleus and outside 1 effective radius in the sense that the contribution from the intermediate population is larger at the nuclear region. We retrieve a smaller signal of a young population at all radii whose origin is unclear and may be a contamination from horizontal-branch stars, such as the ones identified by Brown et al. in the nuclear region. We compare our metallicity distribution function for a region 1 to 2 arcmin from the centre to the one obtained with photometric data by Grillmair et al. Both distributions are broad, but our spectroscopically derived distribution has a significant component with $[Z/Z_{\sun}] \leq -1$, which is not found by Grillmair et al.
astro-ph.GA:This is an introduction to the basic elements needed for the measurements and interpretation of data in the millimeter and sub-mm wavelength range. A more complete version will be published in the proceedings of the Saas Fee Winter School 2008.
astro-ph.GA:We present an analysis of results on absorption from Ca II, Ca I, K I, and the molecules CH+, CH, C2, and CN that probes gas interacting with the supernova remnant IC443. The eleven directions sample material across the visible nebula and beyond its eastern edge. Most of the neutral material, including the diatomic molecules, is associated with the ambient cloud detected via H I and CO emission. Analysis of excitation and chemistry yields gas densities that are typical of diffuse molecular gas. The low density gas probed by Ca II extends over a large range in velocities, from -120 to +80 km/s in the most extreme cases. This gas is distributed among several velocity components, unlike the situation for the shocked molecular clumps, whose emission occurs over much the same range but as very broad features. The extent of the high-velocity absorption suggests a shock velocity of 100 km/s for the expanding nebula.
astro-ph.GA:This paper reports dual-epoch, Very Long Baseline Array observations of H I absorption toward 3C 147. One of these epochs (2005) represents new observations while one (1998) represents the reprocessing of previous observations to obtain higher signal-to-noise results. Significant H I opacity and column density variations, both spatially and temporally, are observed with typical variations at the level of \Delta\tau ~ 0.20 and in some cases as large as \Delta\tau ~ 0.70, corresponding to column density fluctuations of order 5 x 10^{19} cm^{-2} for an assumed 50 K spin temperature. The typical angular scale is 15 mas; while the distance to the absorbing gas is highly uncertain, the equivalent linear scale is likely to be about 10 AU. Approximately 10% of the face of the source is covered by these opacity variations, probably implying a volume filling factor for the small-scale absorbing gas of no more than about 1%. Comparing our results with earlier results toward 3C 138 (Brogan et al.), we find numerous similarities, and we conclude that small-scale absorbing gas is a ubiquitous phenomenon, albeit with a low probability of intercept on any given line of sight. Further, we compare the volumes sampled by the line of sight through the Galaxy between our two epochs and conclude that, on the basis of the motion of the Sun alone, these two volumes are likely to be substantially different. In order to place more significant constraints on the various models for the origin of these small-scale structures, more frequent sampling is required in any future observations.
astro-ph.GA:We have conducted a systematic investigation of the origin and underlying physics of the line--line and line--continuum correlations of AGNs, particularly the Baldwin effect. Based on the homogeneous sample of Seyfert 1s and QSOs in the SDSS DR4, we find the origin of all the emission-line regularities is Eddington ratio (L/Ledd). The essential physics is that L/Ledd regulates the distributions of the properties (particularly column density) of the clouds bound in the line-emitting region.
astro-ph.GA:Using 3D hydrodynamical simulations, we studied in detail the fountain flow and its dependence with several factors, such as the Galactic rotation, the distance to the Galactic center, and the presence of a hot gaseous halo. We have considered the observed size-frequency distribution of young stellar clusters within the Galaxy in order to appropriately fuel the multiple fountains in our simulations. The present work confirms the localized nature of the fountain flows: the freshly ejected metals tend to fall back close to the same Galactocentric region where they are delivered. Therefore, the fountains do not change significantly the radial profile of the disk chemical abundance. The multiple fountains simulations also allowed to consistently calculate the feedback of the star formation on the halo gas. Finally, we have also considered the possibility of mass infall from the intergalactic medium and its interaction with the clouds that are formed by the fountains. Though our simulations are not suitable to reproduce the slow rotational pattern that is typically observed in the halos around the disk galaxies, they indicate that the presence of an external gas infall may help to slow down the rotation of the gas in the clouds and thus the amount of angular momentum that they transfer to the coronal gas, as previously suggested in the literature.
astro-ph.GA:The spiral structure of our Milky Way Galaxy is not yet known. HII regions and giant molecular clouds are the most prominent spiral tracers. We collected the spiral tracer data of our Milky Way from the literature, namely, HII regions and giant molecular clouds (GMCs). With weighting factors based on the excitation parameters of HII regions or the masses of GMCs, we fitted the distribution of these tracers with models of two, three, four spiral-arms or polynomial spiral arms. The distances of tracers, if not available from stellar or direct measurements, were estimated kinetically from the standard rotation curve of Brand & Blitz (1993) with $R_0$=8.5 kpc, and $\Theta_0$=220 km s$^{-1}$ or the newly fitted rotation curves with $R_0$=8.0 kpc and $\Theta_0$=220 km s$^{-1}$ or $R_0$=8.4 kpc and $\Theta_0$=254 km s$^{-1}$. We found that the two-arm logarithmic model cannot fit the data in many regions. The three- and the four-arm logarithmic models are able to connect most tracers. However, at least two observed tangential directions cannot be matched by the three- or four-arm model. We composed a polynomial spiral arm model, which can not only fit the tracer distribution but also match observed tangential directions. Using new rotation curves with $R_0$=8.0 kpc and $\Theta_0$=220 km s$^{-1}$ and $R_0$=8.4 kpc and $\Theta_0$=254 km s$^{-1}$ for the estimation of kinematic distances, we found that the distribution of HII regions and GMCs can fit the models well, although the results do not change significantly compared to the parameters with the standard $R_0$ and $\Theta_0$.
astro-ph.GA:Carbon solids are ubiquitous material in the interstellar space. However, the formation pathway of carbonaceous matter in astrophysical environments as well as in terrestrial gas-phase condensation reactions is not yet understood. Laser ablation of graphite in different quenching gas atmospheres such as pure He, He/H$_2$, and He/H$_2$O at varying pressures is used to synthesize very small, fullerene-like carbon nanoparticles. The particles are characterized by very small diameters between 1 and 4 nm and a disturbed onion-like structure. The soot particles extracted from the condensation zone obviously represent a very early stage of particle condensation. The spectral properties have been measured from the far-ultraviolet (FUV) ($\lambda$=120 nm) to the mid-infrared (MIR) ($\lambda$=15 ~$\mu$m). The seed-like soot particles show strong absorption bands in the 3.4 ~$\mu$m range. The profile and the intensity pattern of the 3.4 ~$\mu$m band of the diffuse interstellar medium can be well reproduced by the measured 3.4 ~$\mu$m profile of the condensed particles, however, all the carbon which is left to form solids is needed to fit the intensity of the interstellar bands. In contrast to the assumption that onion-like soot particles could be the carrier of the interstellar ultraviolet (UV) bump, our very small onion-like carbon nanoparticles do not show distinct UV bands due to ($\pi-\pi$*) transitions.
astro-ph.GA:Carbonaceous grains represent a major component of cosmic dust. In order to understand their formation pathways, they have been prepared in the laboratory by gas-phase condensation reactions such as laser pyrolysis and laser ablation. Our studies demonstrate that the temperature in the condensation zone determines the formation pathway of carbonaceous particles. At temperatures lower than 1700 K, the condensation by-products are mainly polycyclic aromatic hydrocarbons (PAHs), that are also the precursors or building blocks for the condensing soot grains. The low-temperature condensates contain PAH mixtures that are mainly composed of volatile 3-5 ring systems. At condensation temperatures higher than 3500 K, fullerene-like carbon grains and fullerene compounds are formed. Fullerene fragments or complete fullerenes equip the nucleating particles. Fullerenes can be identified as soluble components. Consequently, condensation products in cool and hot astrophysical environments such as cool and hot AGB stars or Wolf Rayet stars should be different and should have distinct spectral properties.
astro-ph.GA:We present new radio and X-ray observations of Abell 262. The X-ray residual image provides the first evidence of an X-ray tunnel in this system while the radio data reveal that the central radio source is more than three times larger than previously known. We find that the well-known cluster-center S-shaped radio source B2 0149+35 is surrounded by extended emission to the east and south-west. The south-western extension is co-spatial with the X-ray tunnel seen in our new Chandra images while the eastern extension shows three clumps of emission with the innermost coincident with a faint X-ray cavity. The outer two eastern radio extensions are coincident with a newly detected X-ray depression. We use the projected separation of the emission regions to estimate a lower limit of tau_rep=28 Myr to the outburst repetition timescale of the central AGN. The total energy input into the cluster over multiple outburst episodes is estimated to be 2.2x 10^{58} ergs, more than an order of magnitude larger than previously thought. The total AGN energy output determined from our new observations shows that the source should be capable of offsetting radiative cooling over several outburst episodes.
astro-ph.GA:We present the first large-scale mosaic performed with the Submillimeter Array (SMA) in the Galactic center. We have produced a 25-pointing mosaic, covering a ~2' x 2' area around Sgr A*. We have detected emission from two high-density molecular tracers, HCN(4-3) and CS(7-6), the latter never before reported in this region. The data have an angular resolution of 4.6" x 3.1", and the spectral window coverage is from -180 km/s to 1490 km/s for HCN(4-3) and from -1605 km/s to 129 km/s for CS(7-6). Both molecular tracers present a very clumpy distribution along the circumnuclear disk (CND), and are detected with a high signal-to-noise ratio in the southern part of the CND, while they are weaker towards the northern part. Assuming that the clumps are as close to the Galactic center as their projected distances, they are still dense enough to be gravitationally stable against the tidal shear produced by the supermassive black hole. Therefore, the CND is a non-transient structure. This geometrical distribution of both tracers suggests that the southern part of the CND is denser than the northern part. Also, by comparing the HCN(4-3) results with HCN(1-0) results we can see that the northern and the southern parts of the CND have different excitation levels, with the southern part warmer than the northern. Finally, we compare our results with those obtained with the detection of NH3, which traces the warmer and less dense material detected in the inner cavity of the CND. We suggest that we are detecting the origin point where a portion of the CND becomes destabilized and approaches the dynamical center of the Milky Way, possibly being impacted by the southern streamer and heated on its way inwards.
astro-ph.GA:A new chemical model is presented for the carbon-rich circumstellar envelope of the AGB star IRC+10216. The model includes shells of matter with densities that are enhanced relative to the surrounding circumstellar medium. The chemical model uses an updated reaction network including reactions from the RATE06 database and a more detailed anion chemistry. In particular, new mechanisms are considered for the formation of CN-, C3N- and C2H-, and for the reactions of hydrocarbon anions with atomic nitrogen and with the most abundant cations in the circumstellar envelope. New reactions involving H- are included which result in the production of significant amounts of C2H- and CN- in the inner envelope. The calculated radial molecular abundance profiles for the hydrocarbons C2H, C4H and C6H and the cyanopolyynes HC3N and HC5N show narrow peaks which are in better agreement with observations than previous models. Thus, the narrow rings observed in molecular microwave emission surrounding IRC+10216 are interpreted as arising in regions of the envelope where the gas and dust densities are greater than the surrounding circumstellar medium. Our models show that CN- and C2H- may be detectable in IRC+10216 despite the very low theorised radiative electron attachment rates of their parent neutral species. We also show that magnesium isocyanide (MgNC) can be formed in the outer envelope through radiative association involving Mg+ and the cyanopolyyne species.
astro-ph.GA:High mass star formation and the evolution of HII regions have a substantial impact on the morphology and star formation history of molecular clouds. The HII region Gum 48d, located in the Centaurus Arm at a distance of 3.5 kpc, is an old, well evolved HII region whose ionizing stars have moved off the main sequence. As such, it represents a phase in the evolution of HII regions that is less well studied than the earlier, more energetic, main sequence phase. In this paper we use multi-wavelength archive data from a variety of sources to perform a detailed study of this interesting region. Morphologically, Gum 48d displays a ring-like faint HII region associated with diffuse emission from the associated PDR, and is formed from part of a large, massive molecular cloud complex. There is extensive ongoing star formation in the region, at scales ranging from low to high mass, which is consistent with triggered star formation scenarios. We investigate the dynamical history and evolution of this region, and conclude that the original HII region was once larger and more energetic than the faint region currently seen. The proposed history of this molecular cloud complex is one of multiple, linked generations of star formation, over a period of 10 Myr. Gum 48d differs significantly in morphology and star formation that the other HII regions in the molecular cloud; these differences are likely the result of the advanced age of the region, and its different evolutionary status.
astro-ph.GA:AIMS:The aim of this paper is to study the characteristics of the stellar populations and the metallicity distribution in the Galactic bulge. We study the entire stellar population, but also retrieve information using only the red clump stars. METHODS: To study the characteristics of the stellar populations and the metallicity distribution in the Galactic bulge, we compared the output of the galaxy model TRILEGAL, which implements the Binney et al. (1997) bulge model, with observations from 2MASS and OGLE-II. A minimisation procedure has been set up to retrieve the best fitting model with different stellar populations and metallicity distributions. RESULTS: Using the TRILEGAL code we find that the best model resembling the characteristics of the Galactic bulge is a model with the distance to the Galactic centre $R_0 = 8.7\pm^{0.57}_{0.43}$ kpc, the major axis ratios of the bar $1:\eta:\zeta = 1 : 0.68\pm_{0.19}^{0.05} : 0.31\pm_{0.04}^{0.06}$, and the angle between the Sun-centre line and the bar $\phi = 15\deg\pm_{12.7}^{13.3}$. Using these parameters the best model is found for a burst of 8 Gyr, although it is almost indistinguishable from models with ages of 9 and 10 Gyr. The metallicity distribution found is consistent with metallicity distributions in the literature based on spectroscopic results.
astro-ph.GA:In this chapter we discuss the X-ray radiation from relativistic accretion disks around supermassive black holes, supposed to exist in the centers of Active Galactic Nuclei (AGN). Our focus is on the X-ray radiation, especially in the Fe K$\alpha$ line which originates in the innermost parts of an accretion disk. Moreover, here we discuss some effects which can disturb the Fe K$\alpha$ profile and cause its rapid and irregular variability, observed in the X-ray spectra of some AGN. We will pay attention to three such effects: perturbations in the disk emissivity, absorbtion by warm absorbers and gravitational microlensing. The X-ray emission from accretion disks around non-rotating (Schwarzschild metric), as well as rotating (Kerr metric) supermassive black holes, is discussed. The X-ray radiation of AGN is probably produced in a compact region near their central supermassive black holes, and can provide us some essential information about the plasma conditions and the space-time geometry in these regions. The goal of this chapter is mainly to present a short overview of some important and recent investigations in this field.
astro-ph.GA:The transition from the Asymptotic Giant Branch (AGB) to the planetary nebula (PN) phase is critical in the shaping of PNe. It is suggested that the most asymmetric PNe are the descendant of massive AGB stars. Since these AGB stars are believed to evolve into heavily obscured post-AGB stars and PNe, the compilation of a sample of bona fide obscured post-AGB stars and PNe is important to help understand the formation of asymmetric PNe. We have used 2MASS, Spitzer GLIMPSE, MSX, and IRAS data in search of the near-IR counterparts of a sample of 165 presumably obscured IRAS post-AGB and PN candidates, and DSS red images to identify the optical counterparts among the objects detected in the near-IR. The IR spectral energy distributions (SEDs) in the wavelength range from 1 to 100 microns of the sources with unambiguous near-IR counterparts have been analyzed using appropriate colour-colour diagrams. We have identified the near-IR counterparts of 119 sources out of the 165 IRAS post-AGB and PN candidates in our sample. The improved astrometric coordinates of these sources have allowed us to find optical counterparts for 59 of them, yielding a reduced sample of 60 optically obscured post-AGB star and PN candidates. Among the 119 sources with near-IR counterparts, only 80 have unambiguous identifications in the 2MASS Point Source Catalogue.
astro-ph.GA:The aim of this study is to investigate systematic chemical differentiation of molecules in regions of high mass star formation. We observed five prominent sites of high mass star formation in HCN, HNC, HCO+, their isotopes, C18O, C34S and some other molecular lines, for some sources both at 3 and 1.3 mm and in continuum at 1.3 mm. Taking into account earlier obtained data for N2H+ we derive molecular abundances and physical parameters of the sources (mass, density, ionization fraction, etc.). The kinetic temperature is estimated from CH3C2H observations. Then we analyze correlations between molecular abundances and physical parameters and discuss chemical models applicable to these species. The typical physical parameters for the sources in our sample are the following: kinetic temperature in the range ~ 30-50 K (it is systematically higher than that obtained from ammonia observations and is rather close to dust temperature), masses from tens to hundreds solar masses, gas densities ~ 10^5 cm^{-3}, ionization fraction ~ 10^{-7}. In most cases the ionization fraction slightly (a few times) increases towards the embedded YSOs. The observed clumps are close to gravitational equilibrium. There are systematic differences in distributions of various molecules. The abundances of CO, CS and HCN are more or less constant. There is no sign of CO and/or CS depletion as in cold cores. At the same time the abundances of HCO+, HNC and especially N2H+ strongly vary in these objects. They anti-correlate with the ionization fraction and as a result decrease towards the embedded YSOs. For N2H+ this can be explained by dissociative recombination to be the dominant destroying process. N2H+, HCO+, and HNC are valuable indicators of massive protostars.
astro-ph.GA:Only massive stars contribute to the chemical evolution of the juvenile universe corresponding to [Fe/H]<-1.5. If Type II supernovae (SNe II) are the only relevant sources, then the abundances in the interstellar medium of the juvenile epoch are simply the sum of different SN II contributions. Both low-mass (~8-11M_sun) and normal (~12-25M_sun) SNe II produce neutron stars, which have intense neutrino-driven winds in their nascent stages. These winds produce elements such as Sr, Y, and Zr through charged-particle reactions (CPR). Such elements are often called the light r-process elements, but are considered here as products of CPR and not the r-process. The observed absence of production of the low-A elements (Na through Zn including Fe) when the true r-process elements (Ba and above) are produced requires that only low-mass SNe II be the site if the r-process occurs in SNe II. Normal SNe II produce the CPR elements in addition to the low-A elements. This results in a two-component model that is quantitatively successful in explaining the abundances of all elements relative to hydrogen for -3<[Fe/H]<-1.5. This model explicitly predicts that [Sr/Fe]>-0.32. Recent observations show that there are stars with [Sr/Fe]<-2 and [Fe/H]<-3. This proves that the two-component model is not correct and that a third component is necessary to explain the observations. This leads to a simple three-component model including low-mass and normal SNe II and hypernovae (HNe), which gives a good description of essentially all the data for stars with [Fe/H]<-1.5. We conclude that HNe are more important than normal SNe II in the chemical evolution of the low-A elements, in sharp distinction to earlier models. (Abridged)
astro-ph.GA:(Abridged) Studying continuum emission from interstellar dust is essential to locating and characterizing the highest density regions in the interstellar medium. In particular, the early stages of massive star formation remain poorly understood. Our goal is to produce a large-scale, systematic database of massive pre- and proto-stellar clumps in the Galaxy, to understand how and under what conditions star formation takes place. A well characterized sample of star-forming sites will deliver an evolutionary sequence and a mass function of high-mass, star-forming clumps. This systematic survey at submm wavelengths also represents a preparatory work for Herschel and ALMA. The APEX telescope is ideally located to observe the inner Milky Way. The Large APEX Bolometer Camera (LABOCA) is a 295-element bolometer array observing at 870 microns, with a beam size of 19". Taking advantage of its large field of view (11.4') and excellent sensitivity, we started an unbiased survey of the Galactic Plane, with a noise level of 50-70 mJy/beam: the APEX Telescope Large Area Survey of the Galaxy (ATLASGAL). As a first step, we covered 95 sq. deg. These data reveal 6000 compact sources brighter than 0.25 Jy, as well as extended structures, many of them filamentary. About two thirds of the compact sources have no bright infrared counterpart, and some of them are likely to correspond to the precursors of (high-mass) proto-stars or proto-clusters. Other compact sources harbor hot cores, compact HII regions or young embedded clusters. Assuming a typical distance of 5 kpc, most sources are clumps smaller than 1 pc with masses from a few 10 to a few 100 M_sun. In this introductory paper, we show preliminary results from these ongoing observations, and discuss the perspectives of the survey.
astro-ph.GA:We have used FUSE to obtain thirteen observations of the dwarf nova VW Hyi covering the period from the end of a superoutburst through the following normal outburst of the system. Here, we present the quiescent spectra. They contain at least three components. The dominant component is the white dwarf (WD), which cools following the superoutburst. The amount of cooling depends somewhat on the WD models used. For log g of 8.0, the temperature drops from 24,000K just after the outburst to 20,000 K just before the normal outburst. For this model, and a distance of 65 pc, the WD radius is ~8 x 10**8 cm and v sin(i) is ~420 km/s. The fact that the derived radius is smaller than expected for a WD with log g=8 suggests a higher gravity WD or that VW Hyi is somewhat further than 65 pc. Either is possible given the current distance uncertainty of +-20 pc. Earlier suggestions that the WD photosphere shows evidence of CNO processed material are confirmed, but our analysis also shows that issues remain in terms of analyzing the spectra of WDs in such unusual physical situations. The second component is relatively featureless and shows modulation on the orbital (and just after outburst, the superhump) period. It is likely associated with the hot spot where material from the secondary encounters the disk, rather than the boundary layer region between the inner disk and WD. The second component fades ~10 days after the superoutburst. There is also a third component, clearly visible in broad emission lines of C III 977, N III 991, Lyman Beta and O VI 1032,1038, which appears to be accompanied by a flat continuum. The strength of the emission lines, which are almost surely associated with the accretion disk, appear relatively constant throughout the observations.
astro-ph.GA:We present Spitzer/IRS spectral mapping observations of the luminous infrared galaxy (LIRG) Arp299 (IC694 + NGC3690) covering the central 45arcsec ~ 9kpc. The integrated mid-IR spectrum of Arp299 is similar to that of local starbursts despite its strongly interacting nature and high infrared luminosity, L_IR ~ 6x10^11 Lsun. This is explained because the star formation (probed by e.g. high [NeIII]15.56micron/[NeII]micron line ratios) is spread across at least 6-8kpc. Moreover, a large fraction of this star formation is taking place in young regions of moderate mid-IR optical depths such as the C+C' complex in the overlap region between the two galaxies and in HII regions in the disks of the galaxies. It is only source A, the nuclear region of IC694, that shows the typical mid-IR characteristics of ultraluminous infrared galaxies (ULIRGs, L_IR > 10^12 Lsun), that is, very compact (less than 1kpc) and dust-enshrouded star formation resulting in a deep silicate feature and moderate equivalent widths of the PAHs. The nuclear region of NGC3690, known as source B1, hosts a low-luminosity AGN and is surrounded by regions of star formation. Although the high excitation [NeV]14.32micron line typical of AGN is not detected in B1, its upper limit is consistent with the value expected from the X-ray luminosity. The AGN emission is detected in the form of a strong hot dust component that accounts for 80-90% of the 6micron luminosity of B1. The similarity between the Arp299 integrated mid-IR spectrum and those of high-z ULIRGs suggests that Arp299 may represent a local example, albeit with lower IR luminosity and possibly higher metallicity, of the star-formation processes occurring at high-z.
astro-ph.GA:High-resolution ultraviolet spectra from the Space Telescope Imaging Spectrograph (STIS) were used to search for unidentified interstellar absorption features in the well studied sightline towards X Per (HD 24534). The significance of features detected was determined from Gaussian fits to the data, as well as the features' persistence in multiple observations. Fixed pattern noise characteristics were studied in STIS echelle data to distinguish between interstellar and instrumental features. We report the detection of two unidentified features that stand out from the more common fixed pattern noise features. Both features have depths of > 3% of the continuum level making them very likely of interstellar origin. Lastly, we comment on possible carriers, and discuss future prospects for studying these and perhaps other unidentified lines in larger samples of sightlines.
astro-ph.GA:We present radial velocity measurements of four wide halo binary candidates from the sample in Chaname & Gould (2004; CG04) which, to date, is the only sample containing a large number of such candidates. The four candidates that we have observed have projected separations >0.1 pc, and include the two widest binaries from the sample, with separations of 0.45 and 1.1 pc. We confirm that three of the four CG04 candidates are genuine, including the one with the largest separation. The fourth candidate, however, is spurious at the 5-sigma level. In the light of these measurements we re-examine the implications for MACHO models of the Galactic halo. Our analysis casts doubt on what MACHO constraints can be drawn from the existing sample of wide halo binaries.
astro-ph.GA:Open clusters have long been used to illuminate both stellar evolution and Galactic evolution. The oldest clusters, though rather rare, can reveal the chemical and nucleosynthetic processes early in the history of the Galaxy. We have studied two turn-off stars in the old, metal-rich open cluster, NGC 6791. The Keck + HIRES spectra have a resolution of 45,000 and signal-to-noise ratios of 40 per pixel. We confirm the high value for [Fe/H] finding +0.30 $\pm$0.08, in agreement with earlier results from evolved stars in other parts of the HR diagram. We have also determined abundances for Na, Si, Ca, Ti, Cr, Ni, Y and Ba. These are compared to a sample of old, metal-rich field stars. With the probable exception of enhanced Ni in the cluster stars, the field and cluster stars show similar abundances of the elements. Model predictions show that the Ni enhancement could result from enrichment of the pre-cluster gas by SN Ia. Orbital evidence indicates that NGC 6791 could have originated near the inner regions of the Galaxy where the metallicity is generally higher than it is in the disk or halo. Subsequent perturbations and migrations may have resulted in its current heliocentric distance of 4 kpc and 1 kpc above the Galactic plane.
astro-ph.GA:The QSO HE0450-2958 was brought to the front scene by the non-detection of its host galaxy and strong upper limits on the latter's luminosity. The QSO is also a powerful infrared emitter, in gravitational interaction with a strongly distorted UltraLuminous InfraRed companion galaxy. We investigate the properties of the companion galaxy, through new near- and mid-infrared observations of the system obtained with NICMOS onboard HST, ISAAC and VISIR on the ESO VLT. The companion galaxy is found to harbour a point source revealed only in the infrared, in what appears as a hole or dark patch in the optical images. Various hypotheses on the nature of this point source are analyzed and it is found that the only plausible one is that it is a strongly reddened AGN hidden behind a thick dust cloud. The hypothesis that the QSO supermassive black hole might have been ejected from the companion galaxy in the course of a galactic collision involving 3-body black holes interaction is also reviewed, on the basis of this new insight on a definitely complex system.
astro-ph.GA:We aim to characterise the properties of a third massive, red supergiant dominated galactic cluster. To accomplish this we utilised a combination of near/mid-IR photometry and spectroscopy to identify and classify the properties of cluster members, and statistical arguments to determine the mass of the cluster. We found a total of 16 strong candidates for cluster membership, for which formal classification of a subset yields spectral types from K3-M4 Ia and luminosities between log(L/L_sun)~4.5-4.8 for an adopted distance of 6+/-1 kpc. For an age in the range of 16-20 Myr, the implied mass is 2-4x10^4 M_sun, making it one of the most massive young clusters in the Galaxy. This discovery supports the hypothesis that a significant burst of star formation occurred at the base of Scutum-Crux arm between 10-20 Myr ago, yielding a stellar complex comprising at least ~10^5M_sun of stars (noting that since the cluster identification criteria rely on the presence of RSGs, we suspect that the true stellar yield will be significantly higher). We highlight the apparent absence of X-ray binaries within the star formation complex and finally, given the physical association of at least two pulsars with this region, discuss the implications of this finding for stellar evolution and the production and properties of neutron stars.
astro-ph.GA:The collapse and fragmentation of initially prolate and oblate, magnetic molecular clouds is calculated in three dimensions with a gravitational, radiative hydrodynamics code. The code includes magnetic field effects in an approximate manner: magnetic pressure, tension, braking, and ambipolar diffusion are all modelled. The parameters varied for both the initially prolate and oblate clouds are the initial degree of central concentration of the radial density profile, the initial angular velocity, and the efficiency of magnetic braking (represented by a factor $f_{mb} = 10^{-4}$ or $10^{-3}$). The oblate cores all collapse to form rings that might be susceptible to fragmentation into multiple systems. The outcome of the collapse of the prolate cores depends strongly on the initial density profile. Prolate cores with central densities 20 times higher than their boundary densities collapse and fragment into binary or quadruple systems, whereas cores with central densities 100 times higher collapse to form single protostars embedded in bars. The inclusion of magnetic braking is able to stifle protostellar fragmentation in the latter set of models, as when identical models were calculated without magnetic braking (Boss 2002), those cores fragmented into binary protostars. These models demonstrate the importance of including magnetic fields in studies of protostellar collapse and fragmentation, and suggest that even when magnetic fields are included, fragmentation into binary and multiple systems remains as a possible outcome of protostellar collapse.
astro-ph.GA:Based on the K\"onigl's inhomogeneous jet model, we estimate the jet parameters, such as bulk Lorentz factor $\Gamma$, viewing angle $\theta$ and electron number density $n_{\rm e}$ from radio VLBI and X-ray data for a sample of active galactic nuclei (AGNs) assuming that the X-rays are from the jet rather than the intracluster gas. The bulk kinetic power of jets is then calculated using the derived jet parameters. We find a strong correlation between the total luminosity of broad emission lines and the bulk kinetic power of the jets. This result supports the scenario that the accretion process are tightly linked with the radio jets, though how the disk and jet are coupled is not revealed by present correlation analysis. Moreover, we find a significant correlation between the bulk kinetic power and radio extended luminosity. This implies that the emission from the radio lobes are closely related with the energy flux transported through jets from the central part of AGNs.
astro-ph.GA:The correlation between black hole masses and stellar velocity dispersions provides an efficient method to determine the masses of black holes in active galaxies. We obtained optical spectra of a Compact-Steep-Spectrum (CSS) galaxy 4C +29.70, using the Canada-France-Hawaii Telescope (CFHT) equipped with OSIS, in August 6, 2003. Several stellar absorption features, such as Mg I (5175\AA), Ca E band (5269\AA) and Na D (5890\AA), were detected in the spectra. The stellar velocity dispersion, $\sigma$, of the host galaxy, measured from absorption features is $\rm \approx 250 km s^{-1}$. If 4C +29.70 follows the $\rm M_{BH}-\sigma$ relation established for nearby galaxies, then its central black hole has a mass of $\rm \approx3.3\times10^{8}M_{\odot}$. In combination with the black hole masses of seven GPS galaxies in Snellen et al. (2003), we find that the average black hole mass of these eight young radio sources is smaller than that of the Bettoni et al. (2003) sample of extended radio galaxies. This may indicate that young radio sources are likely at the early evolutionary stage of radio galaxies, at which the central black holes may still undergo rapid growth. However, this needs further investigations.
astro-ph.GA:Suzaku observed the Galactic center region near the Radio Arc at ~20' southeast of Sagittarius A*.In the 18'x18' field of view, we found four distinct X-ray sources: a bright star and a diffuse source associated with the star clusters in the soft band (0.5-2.0 keV), a small clump in a higher energy band (4-6 keV), and a peculiar clump in the 6.4 keV line band.The latter two clumps are located at the south end of the Radio Arc. This paper reports on the results, and discusses the origin of these X-ray sources, with a particular emphasis on small clumps.
astro-ph.GA:Optical images and high-dispersion spectra have been obtained of the ejected material surrounding the pulsating AGB star Mira A. The two streams of knots on either side of the star, found in far ultra-viollet (FUV) GALEX images, have now been imaged clearly in the light of Halpha. Spatially resolved profiles of the same line reveal that the bulk of these knots form a bi-polar outflow with radial velocity extremes of +- 150 km/s with respect to the central star. The South stream is approaching and the North stream receding from the observer. A displacement away from Mira A between the position of one of the South stream knots in the new Halpha image and its position in the previous Palomar Observatory Sky Survey (POSS I) red plate has been noted. If interpreted as a consequence of expansion proper motions the bipolar outflow is tilted at 69deg +- 2deg to the plane of the sky, has an outflow velocity of 160 +- 10 km/s and is ~1000 y old.
astro-ph.GA:Recent investigations have revealed a surprising lack of close binaries among extreme horizontal branch (EHB) stars in the globular cluster NGC6752, at variance with the analogous sdB field stars. Another puzzling result concerns the derived spectroscopic masses for some EHB stars. The present paper extends our study of NGC6752 to M80 and NGC5986. Twenty-one horizontal branch stars (out of which 5 EHBs) in NGC5986 and 31 in M80 (11 EHBs) were observed during four consecutive nights. We measured radial velocity variations, temperatures, gravities, and helium abundances. By means of a statistical analysis, we detected one EHB close binary candidate per cluster. In M80, the best estimate of the close binary EHB fraction is f=12%, and even the lowest estimate of the binary fraction among field sdB stars can be ruled out within a 90% confidence level. Because of the small observed sample, no strong conclusions can be drawn on the close EHB binary fraction for NGC5986, although our best estimate is rather low (f=25%). For the discrepancy in spectroscopic derived masses with theoretical models observed in NGC6752, our analysis of M80 EHB stars shows a similar trend. For the first time, we report a clear trend in surface helium abundance with temperature. Our results show that the deficiency of close binaries among EHB stars is now confirmed in two, and possibly three, globular clusters. This feature is therefore not a peculiarity of NGC6752. Our analysis also proves that the strangely high spectroscopic masses among EHB stars are now confirmed in at least a second cluster. Our results confirm that f could be a function of the age of the sdB star population, but we find that recent models have some problem reproducing all observations.
astro-ph.GA:The goals of this work are to develop a new method to separate early and late type stellar components of a dense stellar cluster based on narrow band filters, to apply it to the central parsec of the GC, and to conduct a population analysis of this area. We use AO assisted observations obtained at the ESO VLT in the NIR H-band and 7 intermediate bands covering the NIR K-band. A comparison of the resulting SEDs with a blackbody of variable extinction then allows us to determine the presence and strength of a CO absorption feature to distinguish between early and late type stars. The new method is suitable to classify K giants (and later) as well as B2 main sequence (and earlier) stars which are brighter than 15.5 mag in the K band in the central parsec. Compared to previous spectroscopic investigations that are limited to 13-14 mag, this represents a major improvement in the depth of the observations as well as reducing the needed observation time. We classify 312 stars as early type candidates out of a sample of 5914 sources. The distribution of the early type stars can be fitted with a steep power law (beta(R>1'') = -1.49 +/- 0.12, alternatively with a broken power law, beta(R=1-10'') = -1.08 +/- 0.12, beta(R=10-20'') = -3.46 +/- 0.58, since we find a drop of the early type density at ~10''). We also detect early type candidates outside of 0.5 pc in significant numbers for the first time. The late type density function shows an inversion in the inner 6'', with a power law slope of beta(R<6'') = 0.17 +/- 0.09. The late type KLF has a power law slope of 0.30$\pm$0.01, closely resembling the KLF obtained for the bulge of the Milky Way. The early type KLF has a much flatter slope of 0.14 +/- 0.02. Our results agree best with an in-situ star formation scenario.
astro-ph.GA:The massive Arches cluster near the Galactic center should be an ideal laboratory for investigating massive star formation under extreme conditions. But it comes at a high price: the cluster is hidden behind several tens of magnitudes of visual extinction. Severe crowding requires space or AO-assisted instruments to resolve the stellar populations, and even with the best instruments interpreting the data is far from direct. Several investigations using NICMOS and the most advanced AO imagers on the ground revealed an overall top-heavy IMF for the cluster, with a very flat IMF near the center. There are several effects, however, that could potentially bias these results, in particular the strong differential extinction and the problem of transforming the observations into a standard photometric system in the presence of strong reddening. We present new observations obtained with the NAOS-Conica (NACO) AO-imager on the VLT. The problem of photometric transformation is avoided by working in the natural photometric system of NACO, and we use a Bayesian approach to determine masses and reddenings from the broad-band IR colors. A global value of $\Gamma=-1.1 \pm 0.2$ for the high-mass end ($M>10M_{\sun}$) of the IMF is obtained, and we conclude that a power law of Salpeter slope cannot be discarded for the Arches cluster. The flattening of the IMF towards the center is confirmed, but is less severe than previously thought. We find $\Gamma=-0.88\pm0.20$, which is incompatible with previous determinations. Within 0.4 pc we derive a total mass of $\sim2.0(\pm0.6)\times10^{4}M_{\sun}$ for the cluster and a central mass density $\rho = 2(\pm0.4)\times10^{5} M_{\sun}pc^{-3}$ that confirms Arches as the densest known young massive cluster in the Milky Way.
astro-ph.GA:We present near-infrared spectroscopic observations of massive stars in three stellar clusters located in the direction of the inner Galaxy. One of them, the Quartet, is a new discovery while the other two were previously reported as candidate clusters identified on mid-infrared Spitzer images (GLIMPSE20 and GLIMPSE13). Using medium-resolution (R=900-1320) H and K spectroscopy, we firmly establish the nature of the brightest stars in these clusters, yielding new identifications of an early WC and two Ofpe/WN9 stars in the Quartet and an early WC star in GLIMPSE20. We combine this information with the available photometric measurements from 2MASS, to estimate cluster masses, ages, and distances. The presence of several massive stars places the Quartet and GLIMPSE20 among the small sample of known Galactic stellar clusters with masses of a few 10^3 Msun, and ages from 3 to 8 Myr. We estimate a distance of about 3.5 kpc for Glimpse 20, and 6.0 kpc for Quartet. The large number of giant stars identified in GLIMPSE13 indicates that it is another massive (~ 6500 Msun) cluster, but older, with an age between 30 and 100 Myr, at a distance of about 3 kpc.
astro-ph.GA:Supernova explosions inject a considerable amount of energy into the interstellar medium (ISM) in regions with high to moderate star formation rates. In order to assess whether the driving of turbulence by supernovae is also important in the outer Galactic disk, where the star formation rates are lower, we study the spatial distribution of molecular cloud (MC) inclinations with respect to the Galactic plane. The latter contains important information on the nature of the mechanism of energy injection into the ISM. We analyze the spatial correlations between the position angles (PAs) of a selected sample of MCs (the largest clouds in the catalogue of the outer Galaxy published by Heyer et al. 2001). Our results show that when the PAs of the clouds are all mapped to values into the [0,90]degrees interval, there is a significant degree of spatial correlation between the $PA$s on spatial scales in the range of 100-800 pc. These scales are of the order of the sizes of individual SN shells in low density environments such as those prevailing in the outer Galaxy and where the metallicity of the ambient gas is of the order of the solar value or smaller. These findings suggest that individual SN explosions, occurring in the outer regions of the Galaxy and in likewise spiral galaxies, albeit at lower rates, continue to play an important role in shaping the structure and dynamics of the ISM in those regions. The SN explosions we postulate here are likely associated with the existence of young stellar clusters in the far outer regions of the Galaxy and the UV emission and low levels of star formation observed with the GALEX satellite in the outer regions of local galaxies.
astro-ph.GA:We identify, categorize, and quantify alignment effects among host and satellite galaxies using a spectroscopically-confirmed, low-redshift (z<0.23) galaxy sample from the Sloan Digital Sky Survey Data Release 6. Consistent with other recent findings, we find that satellite galaxies (SGs) of red, centrally concentrated (elliptical) host galaxies (HGs) with radial velocity separation |Delta_V|<600 km/s preferentially reside near the projected major axes of their HGs. Among these, this preference is strongest for highly concentrated, red SGs. We find that fractional anisotropy increases with decreasing \Delta_V and Delta_R and is nearly 40% greater among the closest SGs (Delta_R<250 kpc/h) relative to more distant (Delta_R>500 kpc/h) SGs. For highly concentrated SGs at small (<300 kpc/h) projected separation, we observe a strong radial (hostward) alignment signal in isophotal position angles (PAs) due to isophotal twisting and contamination that is not present when using galaxy model PAs. Among objects for which both isophotal and galaxy model PAs agree to <15 degrees, this elongation signal is significantly weaker. We also investigate the "Holmberg Effect," a well-known result wherein nearby (<40 kpc/h) SGs of large, inclined spiral HGs were seen to preferentially reside near the minor axes of their HGs. Survey limitations preclude a strict test of this effect using only SDSS spectroscopic galaxies. By adopting a looser set of cuts than those of Holmberg's study, we recover a comparable preference among faint blue SGs for the HG minor axis at marginal significance (~3 sigma). We conclude that several types of alignment likely exist among different galaxy populations, but that the observed nature and strength of alignment trends depend sensitively on both selection criteria and on the method used to determine galaxy orientation.
astro-ph.GA:A study of the blue compact dwarf (BCD) galaxy Mrk 996 based on high resolution optical VLT VIMOS integral field unit spectroscopy is presented. Mrk 996 displays multi-component line emission, with most line profiles consisting of a narrow, central Gaussian with an underlying broad component. The broad HI Balmer component splits into two separate broad components inside a 1".5 radius from the nucleus; these are attributed to a two-armed mini-spiral. The rotation curve of Mrk 996 derived from the H\alpha narrow component yields a total mass of 5x10^8 Msol within a radius of 3 kpc.   The high excitation energy, high critical density [O III] 4363 and [N II] 5755 lines are only detected from the inner region and exist purely in broad component form, implying unusual excitation conditions. Surface brightness, radial velocity, and FWHM maps for several emission components are presented. A separate physical analysis of the broad and narrow emission line regions is undertaken. We derive an upper limit of 10,000 K for the electron temperature of the narrow line gas, together with an electron density of 170 cm^-3, typical of normal H II regions. For the broad line component, we estimate a temperature of 11,000 K and an electron density of 10^7 cm^-3. The broad line emission regions show a N/H enrichment factor of ~20 relative to the narrow line regions, but no He/H, O/H, S/H, or Ar/H enrichment is inferred. The dominant line excitation mechanism is photoionisation by the ~3000 WR stars and ~150,000 O-type stars estimated to be present in the core. This is indeed a peculiar BCD, with extremely dense zones of gas in the core, through which stellar outflows and possible shock fronts permeate contributing to the excitation of the broad line emission. [Abridged]
astro-ph.GA:The properties of polarization in scattered light by aligned ellipsoidal grains are investigated with the Fredholm integral equation method (FIM) and the T-matrix method (Tmat), and the results are applied to the observed circular polarization in OMC1. We assume that the grains are composed of silicates and ellipsoidal (oblate, prolate, or tri-axial ellipsoid) in shape with a typical axial ratio of 2:1. The angular dependence of circular polarization p_c on directions of incident and scattered light is investigated with spherical harmonics and associated Legendre polynomials. The degree of circular polarization p_c also depends on the Rayleigh reduction factor R which is a measure of imperfect alignment. We find that p_c is approximately proportional to R for grains with |m|x_{eq} < 3 - 5, where x_{eq} is the dimensionless size parameter and m is the refractive index of the grain. Models that include those grains can explain the observed large circular polarization in the near infrared, ~15%, in the south-east region of the BN object (SEBN) in OMC1, if the directions of incidence and scattering of light is optimal, and if grain alignment is strong, i.e. R > 0.5. Such a strong alignment cannot be explained by the Davis-Greenstein mechanism; we prefer instead an alternative mechanism driven by radiative torques. If the grains are mixed with silicates and ice, the degree of circular polarization p_c decreases in the 3 micron ice feature, while that of linear polarization increases. This wavelength dependence is different from that predicted in a process of dichroic extinction.
astro-ph.GA:We use mid-infrared spectroscopy of unobscured active galactic nuclei (AGNs) to reveal their native dusty environments. We concentrate on Seyfert 1 galaxies, observing a sample of 31 with the Infrared Spectrograph aboard the Spitzer Space Telescope, and compare them with 21 higher-luminosity quasar counterparts. Silicate dust reprocessing dominates the mid-infrared spectra, and we generally measure the 10 and 18 micron spectral features weakly in emission in these galaxies. The strengths of the two silicate features together are sensitive to the dust distribution. We present numerical radiative transfer calculations that distinguish between clumpy and smooth geometries, which are applicable to any central heating source, including stars as well as AGNs. In the observations, we detect the obscuring ``torus'' of unified AGN schemes, modeling it as compact and clumpy. We also determine that star formation increases with AGN luminosity, although the proportion of the galaxies' bolometric luminosity attributable to stars decreases with AGN luminosity.
astro-ph.GA:We report the discovery of a previously unknown massive Galactic star cluster at l=29.22, b=-0.20. Identified visually in mid-IR images from the Spitzer GLIMPSE survey, the cluster contains at least 8 late-type supergiants, based on followup near-IR spectroscopy, and an additional 3-6 candidate supergiant embers having IR photometry consistent with a similar distance and reddening. The cluster lies at a local minimum in the 13-CO column density and 8 micron emission. We interpret this feature as a hole carved by the energetic winds of the evolving massive stars. The 13-CO hole seen in molecular maps at V_LSR ~95 km/s corresponds to near/far kinematic distances of 6.1/8.7+/-1 kpc. We calculate a mean spectrophotometric distance of 7.0^+3.7_-2.4 kpc, broadly consistent with the kinematic distances inferred. This location places it near the northern end of the Galactic bar. For the mean extinction of A_V=12.6+/-0.5 mag (A_K=1.5+/-0.1 mag), the color-magnitude diagram of probable cluster members is well fit by isochrones in the age range 18-24 Myr. The estimated cluster mass is ~20,000 Msun. With the most massive original cluster stars likely deceased, no strong radio emission is detected in this vicinity. As such, this RSG cluster is representative of adolescent massive Galactic clusters that lie hidden behind many magnitudes of dust obscuration. This cluster joins two similar red supergiant clusters as residents of the volatile region where the end of our Galaxy's bar joins the base of the Scutum-Crux piral arm, suggesting a recent episode of widespread massive star formation there.
astro-ph.GA:This White Paper, submitted to the National Academy of Sciences' Astro2010 Decadal Review Committee, focuses on 2 central themes in the study of young brown dwarfs -- their formation mechanism and disk characteristics -- which are of direct relevance to fundamental questions of stellar and planetary origins and properties.
astro-ph.GA:We calculate the absorption efficiency of the composite grains, made up of host silicate spheroids and inclusions of ices/graphites/or voids, in the spectral region $7.0-14.0\mu$m The absorption efficiencies of the composite spheroidal grains for three axial ratios are computed using the discrete dipole approximation (DDA) as well as using the effective medium approximation & T-Matrix (EMT-Tmatrix) ap proach. We study the absorption as a function of the volume fraction of the inclusions and porosity. In particular, we study the variation in the $10.0\mu$m feature with the volume fraction of the inclusions and porosity. We then calculate the infrared fluxes for these composite grains and compare the model curves with the average observed IRAS-LRS curve, obtained for several circumstellar dust shells around stars. These results on the composite grains show that the wavelength of the peak absorption shifts and the width of the $10.0\mu$m feature varies with the variation in the volume fraction of the inclusions. The model curves for composite grains with axial ratios not very large (AR$\sim$1.3) and volume fractions of inclusions with f=0.20, and dust temperature of about 250-300$^{\circ}$K, fit the observed emission curves reasonably well.
astro-ph.GA:Simultaneous multifrequency observations of the Crab pulsar giant pulses (GPs) were performed with the 64-m Kalyazin radio telescope at four frequencies 0.6, 1.4, 2.2 and 8.3 GHz using the K5 VLBI recording terminal. The K5 terminal provided continuous recording in 16 4-MHz wide frequency channels distributed over 4 frequency bands. Several thousands of GPs were detected during about 6 hours of observations in two successive days in July 2005. Radio spectra of single GPs were analysed at separate frequencies and over whole frequency range. These spectra manifest notable modulation over frequency ranges, $\Delta\nu$, both on large ($\Delta\nu/\nu\approx 0.5$) and small ($\Delta\nu/\nu\approx 0.01$) frequency scales. Cross-correlation analysis of GPs at 2.2 GHz showed that their pulse shapes can be interpreted as an ensemble of unresolved bursts grouped together at time scales of $\approx 1$ mcs being well-correlated over a 60-MHz band. The corresponding GP cross-correlation functions do not obey the predictions of the amplitude-modulated noise model of Rickett (1975), thus indicating that unresolved components represent a small number of elementary emitters.
astro-ph.GA:Almost all stars in the 1-8 Msun range evolve through the Asymptotic Giant Branch (AGB), preplanetary nebula (PPN) and planetary nebula (PN) evolutionary phases. Most stars that leave the main sequence in a Hubble time will end their lives in this way. The heavy mass loss which occurs during the AGB phase is important across astrophysics, and the particulate matter crucial for the birth of new solar systems is made and ejected by AGB stars. Yet stellar evolution from the beginning of the AGB phase to the PN phase remains poorly understood. We do not understand how the mass-loss (rate, geometry, temporal history) depends on fundamental stellar parameters or the presence of a binary companion. While the study of evolved non-massive stars has maintained a relatively modest profile in recent decades, we are nonetheless in the midst of a quiet but exciting revolution in this area, driven by new observational results, such as the discovery of jets and disks in stellar environments where these were never expected, and by the recognition of new symmetries such as multipolarity and point-symmetry occuring frequently in the nebulae resulting from the outflows. In this paper we summarise the major unsolved problems in this field, and specify the areas where allocation of effort and resources is most likely to help make significant progress.
astro-ph.GA:We have performed observations of water maser emission towards a sample of low-mass protostars, in order to investigate the properties of jets associated with the earliest stages of star formation and their interaction with the surrounding medium. The main aim is to measure the absolute positions and proper motions of the H_2O spots in order to investigate the kinematics of the region from where the jet is launched. We imaged the protostars in the nearby region NGC 1333-IRAS 4 in the water maser line at 22.2 GHz by using the VLBA in phase-reference mode at the milliarcsecond scale over four epochs, spaced by one month to measure proper motions. Two protostars (A2 and B) were detected in a highly variable H_2O maser emission, with an active phase shorter than four weeks. The H_2O maps allow us to trace the fast jet driven by the B protostar: we observed both the red- and blue-shifted lobes very close to the protostar, =< 35 AU, moving away with projected velocities of ~10-50 km/s. The comparison with the molecular outflow observed at larger scale suggests a jet precession with a 18'/yr rate. By measuring the positional spread of the H_2O spots we estimate a jet width of ~2 AU at a distance of ~12 AU from the driving protostar.
astro-ph.GA:In this paper we have analyzed IUE high resolution spectra of the central star (BD+602522) of the Bubble nebula. We discuss velocities of the different regions along the line of sight to the bubble. We find that the Bubble Nebula is younger (by a factor of 100) than the exciting star suggesting that either the bubble is expanding into an inhomogenuous interstellar medium or that the mechanics of the stellar wind are not fully understood.
astro-ph.GA:We use 14 orbits of ACS observations to reach the end of the white-dwarf cooling sequence in the globular cluster M4. Our photometry and completeness tests show that the end is located at magnitude m_F606W = 28.5+/-0.1, which implies an age of 11.6+/-0.6 Gyr (internal errors only). This is consistent with the age from fits to the main sequence turn-off (12.0+/-1.4 Gyr).
astro-ph.GA:A deep wide-field image in the light of the Halpha+[N II] emission lines, of the planetary nebula HFG1 which surrounds the precataclysmic binary system V664 Cas, has revealed a tail of emission at least 20' long, at a position angle of 316deg. Evidence is presented which suggests that this is an ~10^5 y old trail of shocked material, left behind V664 Cas as it ejects matter whilst ploughing through its local interstellar media at anywhere between 29 and 59 km/s depending on its distance from the Sun.
astro-ph.GA:Electromagnetic streaming instabilities of multicomponent collisional magnetized accretion disks are studied. Sufficiently ionized regions of the disk are explored where there is strong collisional coupling of neutral atoms with both ions and dust grains simultaneously. The steady state is investigated in detail and the azimuthal and radial background velocities of species are calculated. The azimuthal velocity of ions, dust grains, and neutrals is found to be less than the Keplerian velocity. The radial velocity of neutrals and dust grains is shown to be directed inward of the disk. The general solution for the perturbed velocities of species taking into account collisions and thermal pressure is obtained. The effect on the collisional frequencies, due to density perturbations of charged species and neutrals, is included. It is shown that dust grains can be involved in the fast electromagnetic perturbations induced by the ions and electrons through the strong collisions of these grains with neutrals that in turn have a strong collisional coupling with the ions. The dispersion relation for the vertical perturbations is derived and its unstable solutions due to different background velocities of ions and electrons are found. The growth rates of the streaming instabilities considered can be much larger than the Keplerian frequency.
astro-ph.GA:We have measured the amount of kinematic substructure in the Galactic halo using the final data set from the Spaghetti project, a pencil-beam high latitude sky survey. Our sample contains 101 photometrically selected and spectroscopically confirmed giants with accurate distance, radial velocity and metallicity information. We have developed a new clustering estimator: the "4distance" measure, which when applied to our data set leads to the identification of 1 group and 7 pairs of clumped stars. The group, with 6 members, can confidently be matched to tidal debris of the Sagittarius dwarf galaxy. Two pairs match the properties of known Virgo structures. Using models of the disruption of Sagittarius in Galactic potentials with different degrees of dark halo flattening, we show that this favors a spherical or prolate halo shape, as demonstrated by Newberg et al. (2007) using SDSS data. One additional pair can be linked to older Sagittarius debris. We find that 20% of the stars in the Spaghetti data set are in substructures. From comparison with random data sets we derive a very conservative lower limit of 10% to the amount of substructure in the halo. However, comparison to numerical simulations shows that our results are also consistent with a halo entirely built up from disrupted satellites, provided the dominating features are relatively broad due to early merging or relatively heavy progenitor satellites.
astro-ph.GA:We describe a technique for probing the statistical properties of cosmic magnetic fields based on radio polarimetry data. Second-order magnetic field statistics like the power spectrum cannot always distinguish between magnetic fields with essentially different spatial structure. Synchrotron polarimetry naturally allows certain 4th-order magnetic field statistics to be inferred from observational data, which lifts this degeneracy and can thereby help us gain a better picture of the structure of the cosmic fields and test theoretical scenarios describing magnetic turbulence. In this work we show that a 4th-order correlator of physical interest, the tension-force spectrum, can be recovered from the polarized synchrotron emission data. We develop an estimator for this quantity based on polarized-emission observations in the Faraday-rotation-free frequency regime. We consider two cases: a statistically isotropic field distribution, and a statistically isotropic field superimposed on a weak mean field. In both cases the tension force power spectrum is measurable; in the latter case, the magnetic power spectrum may also be obtainable. The method is exact in the idealized case of a homogeneous relativistic-electron distribution that has a power-law energy spectrum with a spectral index p=3, and assumes statistical isotropy of the turbulent field. We carry out tests of our method using synthetic data generated from numerically simulated magnetic fields. We show that the method is valid, that it is not prohibitively sensitive to the value of the electron spectral index, and that the observed tension-force spectrum allows one to distinguish between, e.g., a randomly tangled magnetic field (a default assumption in many studies) and a field organized in folded flux sheets or filaments.
astro-ph.GA:We discuss a new type of dust acceleration mechanism that acts in a turbulent magnetized medium. The magnetohydrodynamic (MHD) turbulence can accelerate grains through resonant as well as nonresonant interactions. We show that the magnetic compression provides higher velocities for super-Alfvenic turbulence and can accelerate an extended range of grains in warm media compared to gyroresonance. While fast modes dominate the acceleration for the large grains, slow modes can be important for sub-micron grains. We provide comprehensive discussion of all the possible grain acceleration mechanisms in interstellar medium. We show that supersonic velocities are attainable for Galactic dust grains. We discuss the consequence of the acceleration. The implications for extinction curve, grain alignment, chemical abundance, etc, are provided.
astro-ph.GA:Ammonia is one of the best tracers of cold dense cores. It is also a minor constituent of interstellar ices and, as such, one of the important nitrogen reservoirs in the protosolar nebula, together with the gas phase nitrogen, in the form of N2 and N. An important diagnostic of the various nitrogen sources and reservoirs of nitrogen in the Solar System is the 14N/15N isotopic ratio. While good data exist for the Solar System, corresponding measurements in the interstellar medium are scarce and of low quality. Following the successful detection of the singly, doubly, and triply deuterated isotopologues of ammonia, we have searched for 15NH2D in dense cores, as a new tool for investigating the 14N/15N ratio in dense molecular gas. With the IRAM-30m telescope, we have obtained deep integrations of the ortho 15NH2D (1(1,1)-1(0,1)) line at 86.4 GHz, simultaneously with the corresponding ortho NH2D line at 85.9 GHz. o-15NH2D is detected in Barnard-1b, NGC1333-DCO+, and L1689N, while we obtained upper limits towards LDN1544 and NGC1333-IRAS4A, and a tentative detection towards L134N(S). The 14N/15N abundance ratio in NH2D ranges between 350 and 850, similar to the protosolar value of ~ 424, and likely higher than the terrestrial ratio of 270.
astro-ph.GA:Photon-dominated regions (PDRs) are powerful molecular line emitters in external galaxies. They are expected in galaxies with high rates of massive star formation due to either starburst (SB) events or starburst coupled with active galactic nuclei (AGN) events. We have explored the PDR chemistry for a range of physical conditions representing a variety of galaxy types. Our main result is a demonstration of the sensitivity of the chemistry to changes in the physical conditions. We adopt crude estimates of relevant physical parameters for several galaxy types and use our models to predict suitable molecular tracers of those conditions. The set of recommended molecular tracers differs from that which we recommended for use in galaxies with embedded massive stars. Thus, molecular observations can in principle be used to distinguish between excitation by starburst and by SB+AGN in distant galaxies. Our recommendations are intended to be useful in preparing Herschel and ALMA proposals to identify sources of excitation in galaxies.
astro-ph.GA:We present an analysis of star-forming gas cores in an SPH simulation of a Giant Molecular Cloud. We identify cores using their deep potential wells. This yields a smoother distribution with clearer boundaries than density. Additionally, this gives an indication of future collapse, as bound potential cores (p-cores) represent the earliest stages of fragmentation in molecular clouds. We find that the mass function of the p-cores resembles the stellar IMF and the observed clump mass function, although p-core masses (~0.7 Msol) are smaller than typical density clumps. The bound p-cores are generally subsonic, have internal substructure, and are only quasi-spherical. We see no evidence of massive bound cores supported by turbulence. We trace the evolution of the p-cores forward in time, and investigate the connection between the original p-core mass and the stellar mass that formed from it. We find that there is a poor correlation, with considerable scatter suggesting accretion onto the core is dependent on more factors than just the initial core mass. During the accretion process the p-cores accrete from beyond the region first bound, highlighting the importance of the core environment to its subsequent evolution.
astro-ph.GA:We present high resolution (R = 60,000) measurements of the NaI D1 and D2 (5890 A) and CaII K (3933 A) interstellar absorption line profiles recorded towards several post-AGB stars located within the M13 and M15 globular clusters, supplemented with a lower resolution spectrum of the CaII K-line observed in absorption towards an Ofpe/WN9 star in the central region of the M33 galaxy. The normalized interstellar absorption profiles have been fit with cloud component velocities, doppler widths and column densities in order to investigate the kinematics and physical conditions of the neutral and partially ionized gas observed along each sight-line. Our CaII observations towards M13 have revealed 4 absorption components that can be identified with galactic Intermediate Velocity Clouds (IVCs) spanning the -50 > Vlsr > -80 km/s range. The NaI/CaII ratio for these IVC's is<0.3, which characterizes the gas as being warm (T=1000 K) and partially ionized. Similar observations towards two stars within M15 have revealed absorption due to a galactic IVC at Vlsr=+65 km/s. This IVC is revealed to have considerable velocity structure, requiring at least 3 cloud components to fit the observed NaI and CaII profiles. CaII K-line observations of a sight-line towards the center of the M33 galaxy have revealed at least 10 cloud components. A cloud at Vlsr=-130 km/s is either an IVC associated with the M33 galaxy occurring at +45 km/s with respect to the M33 local standard of rest, or it is a newly discovered HVC associated with our own Galaxy. In addition, 4 clouds have been discovered in the -165 > Vlsr > -205 km/s range. Three of these clouds are identified with the disk gas of M33, whereas a component at - 203 km/s could be IVC gas in the surrounding halo of M33.
astro-ph.GA:We present observations of L1155 and L1148 in the Cepheus molecular cloud, taken using the FIS instrument on the Akari satellite. We compare these data to submillimetre data taken using the SCUBA camera on the JCMT, and far-infrared data taken with the ISOPHOT camera on board the ISO satellite. All of the data show a relation between the position of the peak of emission and the wavelength for the core of L1155. We interpret this as a temperature gradient. We fit modified blackbody curves to the spectral energy distributions at two positions in the core and see that the central core in L1155 (L1155C) is approximately 2 degrees warmer at one edge than it is in the centre. We consider a number of possible heating sources and conclude that the A6V star BD+67 1263 is the most likely candidate. This star is at a distance of 0.7 pc from the front of L1155C in the plane of the sky. We carry out radiative transfer modelling of the L1155C core including the effects from the nearby star. We find that we can generate a good fit to the observed data at all wavelengths, and demonstrate that the different morphologies of the core at different wavelengths can be explained by the observed 2 degree temperature gradient. The L1148 core exhibits a similar morphology to that of L1155C, and the data are also consistent with a temperature gradient across the core. In this case, the most likely heating source is the star BD197053. Our findings illustrate very clearly that the apparent observed morphology of a pre-stellar core can be highly dependent on the wavelength of the observation, and that temperature gradients must be taken into account before converting images into column density distributions. This is important to note when interpreting Akari and Spitzer data and will also be significant for Herschel data.
astro-ph.GA:The cosmological evolution of Active Galactic Nuclei (AGN) is important for understanding the mechanism of accretion onto supermassive black holes, and the related evolution of the host galaxy. In this work, we include objects with very low Eddington ratio (10^{-3} - 10^{-2}) in an evolution scenario, and compare the results with the observed local distribution of black holes. We test several possibilities for the AGN population, considering obscuration and dependence with luminosity, and investigate the role of the Eddington ratio and radiative accretion efficiency on the shape of the evolved mass function. We find that three distinct populations of AGN can evolve with a wider parameter range than is usually considered, and still be consistent with the local mass function. In general, the black holes in our solutions are spinning rapidly. Taking fixed values for accretion efficiency and Eddington ratio neither provides a full knowledge of the evolution mechanism nor is consistent with the existence of low Eddington ratio objects.
astro-ph.GA:We present the first 3D spectroscopic observations of a nearby HI detected poststarburst, or E+A, galaxy, SDSS J230743.41+152558.4, obtained with the VIMOS IFU spectrograph at ESO VLT. Using the NBursts full spectral fitting technique, we derive maps of stellar kinematics, age, and metallicity out to 2-3 half-light radii. Our analysis reveals a large-scale rapidly rotating disc (v_circ = 300km/s) with a positive age gradient (0.6 to 1.5 Gyr), and a very metal-rich central region ([Fe/H]=+0.25 dex). If a merger or interaction is responsible for triggering the starburst, the presence of this undisturbed disc suggests a minor merger with a gas-rich satellite as the most plausible option, rather than a disruptive major merger. We find spectroscopic evidence for the presence of a LINER or AGN. This is an important clue to the feedback mechanism that truncated the starburst. The presently observed quiescent phase may well be a temporary episode in the galaxy's life. SDSS J230743.41+152558.4 is gas-rich and may restart forming stars, again becoming blue before finally settling at the red sequence.
astro-ph.GA:We present a multiwavelength photometric analysis of the globular cluster M2. The data-set has been obtained by combining high-resolution (HST/WFPC2 and ACS) and wide-field (GALEX) space observations and ground based (MEGACAM-CFHT, EMMI-NTT) images. The photometric sample covers the entire cluster extension from the very central regions up to the tidal radius and beyond. It allows an accurate determination of the cluster center of gravity and other structural parameters derived from the star count density profile. Moreover we study the BSS population and its radial distribution. A total of 123 BSS has been selected, and their radial distribution has been found to be bimodal (highly peaked in the center, decreasing at intermediate radii and rising outward), as already found in a number of other clusters. The radial position of the minimum of the BSS distribution is consistent with the radius of avoidance caused by the dynamical friction of massive objects over the cluster age. We also searched for gradients in the red giant branch (RGB) and the asymptotic giant branch (AGB) populations. At the $2\sigma$ level we found an overabundance of AGB stars within the core radius and confirmed the result of Sohn et al.(1996) that the central region of M2 is bluer than the outer part. We show that the latter is due to a deficit of very luminous RGB stars in the central region.
astro-ph.GA:Two WSRT observations were performed and five archival VLA data were reduced in order to redetect the enigmatic radio transient GCRT J1745-3009. The source was not redetected. We were, however, able to extract important new information from the discovery dataset. Our reanalysis excludes models that predict symmetric bursts, but the transient white dwarf pulsar is favoured. Although we now have more contraints on the properties of this source, we are still unsure about its basic model.
astro-ph.GA:We present ATCA interferometric observations of the old (13 Myr), nearby (86pc) classical T Tauri star, PDS 66. Unresolved 3 and 12 mm continuum emission is detected towards PDS 66, and upper limits are derived for the 3 and 6 cm flux densities. The mm-wave data show a spectral slope flatter than that expected for ISM-sized dust particles, which is evidence of grain growth. We also present HST/NICMOS 1.1 micron PSF-subtracted coronagraphic imaging of PDS 66. The HST observations reveal a bilaterally symmetric circumstellar region of dust scattering about 0.32% of the central starlight, declining radially in surface brightness. The light-scattering disk of material is inclined 32 degrees from face-on, and extends to a radius of 170 AU. These data are combined with published optical and longer wavelength observations to make qualitative comparisons between the median Taurus and PDS 66 spectral energy distributions (SEDs). By comparing the near-infrared emission to a simple model, we determine that the location of the inner disk radius is consistent with the dust sublimation radius (1400 K at 0.1 AU). We place constraints on the total disk mass using a flat-disk model and find that it is probably too low to form gas giant planets according to current models. Despite the fact that PDS 66 is much older than a typical classical T Tauri star (< 5 Myr), its physical properties are not much different.
astro-ph.GA:Helium has been proposed as the key element to interpret the observed multiple main sequences (MS), subgiant branches (SGB) and red giant branches (RGB), as well as the complex horizontal branch (HB) morphology in Globular Clusters (GC). However, up to now, He was never directly measured in suitable GC stars (8500<Teff<11500 K) with the purpose of verify this hypothesis. We studied 7 hot blue horizontal branch (BHB) stars (Teff<11500 K) in the GC NGC 6752 with the purpose to measure their Helium content. In addition Fe,Cr,Si,Ti,O,Na, and Ba abundances were measured. We could measure He abundance only for stars warmer than Teff=8500 K. All our targets with measurable He are zero age HB (ZAHB) objects and turned out to have a homogeneous He content with a mean value of Y=0.245+-0.012, compatible with the most recent measurements of the primordial He content of the Universe (Y~0.25). The whole sample of stars have a metallicity of [Fe/H]=-1.56+-0.03 and [alpha/Fe]=+0.21+-0.03. Our HB targets show the same Na-O anticorrelation identified among the TO-SGB-RGB stars. This is the first direct measurement of the He abundance for a significative sample of GC stars in a temperature regime where the He content is not altered by sedimentation processing or extreme mixing as suggested for the hottest, late helium flasher HB stars.
astro-ph.GA:Near-future surveys promise a dramatic improvement in the number and precision of astrometric, photometric and spectroscopic measurements of stars in the Milky Way's disk. We examine the impact of such surveys on our understanding of the Galaxy by "observing" particle realizations of non-axisymmetric disk distributions orbiting in an axisymmetric halo with appropriate errors and then attempting to recover the underlying potential using a Markov Chain Monte Carlo (MCMC) approach. We demonstrate that the azimuthally averaged gravitational force field in the Galactic plane--and hence, to a lesser extent, the Galactic mass distribution--can be tightly constrained over a large range of radii using a variety of types of surveys so long as the error distribution of the measurements of the parallax, proper motion and radial velocity are well-understood and the disk is surveyed globally. One advantage of our method is that the target stars can be selected non-randomly in real or apparent-magnitude space to ensure just such a global sample without biasing the results. Assuming we can always measure the line-of-sight velocity of a star with at least 1 km/s precision, we demonstrate that the force field can be determined to better than ~1% for Galactocentric radii in the range R=4-20 kpc We conclude that near-future surveys, like SIM Lite, Gaia, and VERA, will provide the first precise mapping of the gravitational force field in the region of the Galactic disk.
astro-ph.GA:We present Spitzer IRAC (~2 deg^2) and MIPS (~8 deg^2) observations of the Cepheus Flare which is associated with the Gould Belt, at an approximate distance of ~300 pc. Around 6500 sources are detected in all four IRAC bands, of which ~900 have MIPS 24 micron detections. We identify 133 YSO candidates using color-magnitude diagram techniques, a large number of the YSO candidates are associated with the NGC 7023 reflection nebula. Cross identifications were made with the Guide Star Catalog II and the IRAS Faint Source Catalog, and spectral energy distributions (SED) were constructed. SED modeling was conducted to estimate the degree of infrared excess. It was found that a large majority of disks were optically thick accreting disks, suggesting that there has been little disk evolution in these sources. Nearest-neighbor clustering analysis identified four small protostellar groups (L1228, L1228N, L1251A, and L1251B) with 5-15 members each and the larger NGC 7023 association with 32 YSO members. The star formation efficiency for cores with clusters of protostars and for those without clusters was found to be ~8% and ~1% respectively. The cores L1155, L1241, and L1247 are confirmed to be starless down to our luminosity limit of L_bol=0.06 L_sol.
astro-ph.GA:We investigate the relationship between the star formation rate per unit area and the surface density of the ISM (the local Kennicutt-Schmitt law) using a simplified model of the ISM and a simple estimate of the star formation rate based on the mass of gas in bound clumps, the local dynamical timescales of the clumps, and an efficiency parameter of around 5 per cent. Despite the simplicity of the approach, we are able to reproduce the observed linear relation between star formation rate and surface density of dense (molecular) gas. We use a simple model for the dependence of H_2 fraction on total surface density to argue why neither total surface density nor the HI surface density are good local indicators of star formation rate. We also investigate the dependence of the star formation rate on the depth of the spiral potential. Our model indicates that the mean star formation rate does not depend significantly on the strength of the spiral potential, but that a stronger spiral potential, for a given mean surface density, does result in more of the star formation occurring close to the spiral arms. This agrees with the observation that grand design galaxies do not appear to show a larger degree of star formation compared to their flocculent counterparts.
astro-ph.GA:We have obtained the mass-metallicity (M-Z) relation at different lookback times for the same set of galaxies from the Sloan Digital Sky Survey, using the stellar metallicities estimated with our spectral synthesis code STARLIGHT. We have found that this relation steepens and spans a wider range in both mass and metallicity at higher redshifts. We have modeled the time evolution of stellar metallicity with a closed-box chemical evolution model, for galaxies of different types and masses. Our results suggest that the M-Z relation for galaxies with present-day stellar masses down to 10^10 M_sun is mainly driven by the history of star formation history and not by inflows or outflows.
astro-ph.GA:Classical and Type II Cepheids are used to reinvestigate specific properties of the Galaxy. A new Type II reddening-free Cepheid distance parameterization is formulated from LMC Cepheids (OGLE), with uncertainties typically no larger than 5-15%. A distance to the Galactic centre of R0=7.8+-0.6 kpc is derived from the median distance to Type II Cepheids in the bulge (OGLE), R0=7.7+-0.7 kpc from a distance to the near side of the bulge combined with an estimated bulge radius of 1.3+-0.3 kpc derived from planetary nebulae. The distance of the Sun from the Galactic plane inferred from classical Cepheid variables is Zsun=26+-3 pc, a result dependent on the sample's distance and direction because of the complicating effects of Gould's Belt and warping in the Galactic disk. Classical Cepheids and young open clusters delineate consistent and obvious spiral features, although their characteristics do not match conventional pictures of the Galaxy's spiral pattern. The Sagittarius-Carina arm is confirmed as a major spiral arm that appears to originate from a different Galactic region than suggested previously. Furthermore, a major feature is observed to emanate from Cygnus-Vulpecula and may continue locally near the Sun. Significant concerns related to the effects of metallicity on the VI-based reddening-free Cepheid distance relations used here are allayed by demonstrating that the computed distances to the Galactic centre, and to several globular clusters (M54, NGC 6441, M15, and M5) and galaxies (NGC 5128 and NGC 3198) which likely host Type II Cepheids: agree with literature results to within the uncertainties.
astro-ph.GA:We have analyzed HCN(1-0) and CS(2-1) line profiles obtained with high signal-to-noise ratios toward distinct positions in three selected objects in order to search for small-scale structure in molecular cloud cores associated with regions of high-mass star formation. In some cases, ripples were detected in the line profiles, which could be due to the presence of a large number of unresolved small clumps in the telescope beam. The number of clumps for regions with linear scales of ~0.2-0.5 pc is determined using an analytical model and detailed calculations for a clumpy cloud model; this number varies in the range: ~2 10^4-3 10^5, depending on the source. The clump densities range from ~3 10^5-10^6 cm^{-3}, and the sizes and volume filling factors of the clumps are ~(1-3) 10^{-3} pc and ~0.03-0.12. The clumps are surrounded by inter-clump gas with densities not lower than ~(2-7) 10^4 cm^{-3}. The internal thermal energy of the gas in the model clumps is much higher than their gravitational energy. Their mean lifetimes can depend on the inter-clump collisional rates, and vary in the range ~10^4-10^5 yr. These structures are probably connected with density fluctuations due to turbulence in high-mass star-forming regions.
astro-ph.GA:Observations of distinct positions in Orion and W3 revealed ripples on the HCN(1-0), HCO^+(1-0) and CO(1-0) line profiles which can be result of emission of large number of unresolved thermal clumps in the beam that move with random velocities. The total number of such clumps are ~(0.4-4) 10^5 for the areas with linear sizes ~0.1-0.5 pc.
astro-ph.GA:We present photometry for the globular cluster NGC 6642 using the F606W and F814W filters with the ACS/WFC third generation camera on board of Hubble Space Telescope. The Colour Magnitude Diagram shows sources reaching ~ 6 mags below the turn-off in m_F606W. A theoretical isochrone fitting was performed and evolutionary parameters were obtained, such as the metallicity [Fe/H] = -1.80 +/- 0.2 and age log(Age) = 10.14 +/- 0.05. We confirm that NGC 6642 is located in the Galactic bulge, with a distance to the Sun d_{\odot} = 8.05 +/- 0.66 ~ kpc$ and the reddening E(B-V) = 0.46 +/- 0.02. These values are in general agreement with those of previous authors. About 30 blue stragglers were found within the central 1.6 pc of NGC 6642. They are strongly concentrated to the very central regions. The cluster displays a well-developed horizontal branch, with a much redder morphology than that of typical old halo globular clusters of similar metallicity. Completeness corrected luminosity and mass functions were obtained for different annuli centred on NGC 6642. Their spatial variation indicates the existence of mass segregation and depletion of low mass stars. Most striking is the inverted shape of the mass function itself, with an increase in number as a function of increasing mass. This has been previously observed in other globular clusters and is also the result of N-body simulations of stellar systems which have undergone ~ 90% of their lifetime and which are subjected to strong tidal effects. We also analysed the density profile and concluded that NGC 6642 has a collapsed core, provided completeness effects are correctly accounted for. We thus conclude from independent means that NGC 6642 is a very old, highly-evolved, core-collapsed globular cluster with an atypical HB morphology.
astro-ph.GA:We use the distant outer halo globular cluster Palomar 14 as a test case for classical vs. modified Newtonian dynamics (MOND). Previous theoretical calculations have shown that the line-of-sight velocity dispersion predicted by these theories can differ by up to a factor of three for such sparse, remote clusters like Pal 14. We determine the line-of-sight velocity dispersion of Palomar 14 by measuring radial velocities of 17 red giant cluster members obtained using the Very Large Telescope (VLT) and Keck telescope. The systemic velocity of Palomar 14 is (72.28+-0.12)km/s. The derived velocity dispersion of (0.38+-0.12)km/s of the 16 definite member stars is in agreement with the theoretical prediction for the classical Newtonian case according to Baumgardt et al. (2005). In order to exclude the possibility that a peculiar mass function might have influenced our measurements, we derived the cluster's main sequence mass function down to 0.53Msolar using archival images obtained with the Hubble Space Telescope. We found a mass function slope of 1.27+-0.44, which is, compared to the canonical mass function, a significantly shallower slope. The derived lower limit on the cluster's mass is higher than the theoretically predicted mass in case of MOND. Our data are consistent with a central density of 0.1 Msolar pc^-3. We need no dark matter in Palomar 14. If the cluster is on a circular orbit, our spectroscopic and photometric results argue against MOND, unless this cluster experienced significant mass loss.
astro-ph.GA:We present accurate new ultraviolet and optical BVI photometry for the Galactic globular cluster ngc2808, based on both ground-based and archival HST imagery. From this we have selected a sample of ~2,000 HB stars; given the extensive wavelength range considered and the combination of both high-angular-resolution and wide-field photometric coverage, our sample should be minimally biased. We divide the HB stars into three radial bins and find that the relative fractions of cool, hot and extreme HB stars do not change radically when moving from the center to the outskirts of the cluster: the difference is typically smaller than ~2sigma. These results argue against the presence of strong radial differentiation among any stellar subpopulations having distinctly different helium abundances. The ratio between HB and RG stars brighter than the ZAHB steadly increases when moving from the innermost to the outermost cluster regions. The difference is larger than ~4sigma and indicates a deficiency of bright RGs in the outskirts of the cluster.
astro-ph.GA:The observed dynamical mass-to-light (M/L) ratios of globular clusters (GCs) are systematically lower than those expected from `canonical' simple stellar population models, which do not account for the preferential loss of low-mass stars due to energy equipartition. It was recently shown that low-mass star depletion can qualitatively explain the M/L discrepancy. To verify whether it is indeed the driving mechanism, we derive dissolution timescales and use these to predict the M/L_V ratios of the 24 Galactic GCs for which orbital parameters and dynamical M/L_V are known. We also predict the slopes of their low-mass stellar mass functions (MFs). We use the SPACE cluster models, which include dynamical dissolution, low-mass star depletion, stellar evolution, stellar remnants and various metallicities. The predicted M/L_V are in 1 sigma agreement with the observations for 12 out of 24 GCs. The discrepancy for the other GCs probably arises because our predictions give global M/L ratios, while the observations represent extrapolated central values that are different from global ones in case of mass segregation and a long dissolution timescale. GCs in our sample which likely have dissimilar global and central M/L ratios can be excluded by imposing limits on the dissolution timescale and King parameter. For the remaining GCs, the observed and predicted average M/L_V are 78^+9_-11% and 78+/-2% of the canonically expected values, while for the entire sample the values are 74^+6_-7% and 85+/-1%. The predicted correlation between the slope of the low-mass stellar MF and M/L_V is qualitatively consistent with observed MF slopes. It is concluded that the variation of M/L ratio due to dissolution and low-mass star depletion is a plausible explanation for the discrepancy between the observed and canonically expected M/L ratios of GCs. (Abridged)
astro-ph.GA:It is generally agreed that interstellar dust grains consist of two main components, namely, silicates and graphites. Some models, like MRN model, assume these grains to be homogeneous spheres following a power law size distribution. This paper presents, in the framework of Mie theory, a parametrization of extinction spectrum curves of the silicates and the graphites separately in terms of frequency and the minimum and maximum of sizes in the distribution. Analytic expressions in ultraviolet and far-ultraviolet are presented for both types of grains.The values of maximum and minimum sizes for which these equations are valid have been identified. These equations can be useful in a number of situations involving silicate and graphite grains.
astro-ph.GA:Using the near-infrared spectral stellar library of Cenarro et al. (2001a,b), the behaviours of the Mg I line at 8807 angstrom and nearby TiO bands are analyzed in terms of the effective temperature, surface gravity, and metallicity of the library stars. New spectroscopic indices for both spectral features -namely MgI and sTiO- are defined, and their sensitivities to different signal-to-noise ratios, spectral resolutions, flux calibrations, and sky emission line residuals are characterized. The new two indices exhibit interesting properties. In particular, MgI reveals as a good indicator of the Mg abundance, whereas sTiO is a powerful dwarf-to-giant discriminator for cold spectral types. Empirical fitting polynomials that reproduce the strength of the new indices as a function of the stellar atmospheric parameters are computed, and a FORTRAN routine with the fitting functions predictions is made available. A thorough study of several error sources, non-solar [Mg/Fe] ratios, and their influence on the fitting function residuals is also presented. From this analysis, a [Mg/Fe] underabundance of ~ -0.04 is derived for the Galactic open cluster M67.
astro-ph.GA:This paper presents the analysis of candidate quiescent low mass xray binarie (qLMXBs) observed during a short Chandra/ACIS observation of the globular cluster (GC) NGC 6304. Two out of the three candidate qLMXBs of this cluster, XMMU 171433-292747 and XMMU 171421-292917, lie within the field of view. This permits comparison with the discovery observation of these sources. The one in the GC core -- XMMU 171433-292747 -- is spatially resolved into two separate X-ray sources, one of which is consistent with a pure H-atmosphere qLMXB, and the other is an X-ray power-law spectrum source. These two spectral components separately account for those observed from XMMU 171433-292747 in its discovery observation. We find that the observed flux and spectral parameters of the H-atmosphere spectral components are consistent with the previous observation, as expected from a qLMXB powered by deep crustal heating. XMMU 171421-292917 also has neutron star atmosphere spectral parameters consistent with those in the XMM-Newton observation and the observed flux has decreased by a factor 0.54^{+0.30}_{-0.24}.
astro-ph.GA:We present the largest, most homogeneous catalogue of merging galaxies in the nearby universe obtained through the Galaxy Zoo project - an interface on the world-wide web enabling large-scale morphological classification of galaxies through visual inspection of images from the Sloan Digital Sky Survey (SDSS). The method converts a set of visually-inspected classifications for each galaxy into a single parameter (the `weighted-merger-vote fraction,' $f_m$) which describes our confidence that the system is part of an ongoing merger. We describe how $f_m$ is used to create a catalogue of 3003 visually-selected pairs of merging galaxies from the SDSS in the redshift range $0.005 < z <0.1$. We use our merger sample and values of $f_m$ applied to the SDSS Main Galaxy Spectral sample (MGS) to estimate that the fraction of volume-limited ($M_r < -20.55$) major mergers ($1/3 < {M}^*_1/{M}^*_2 < 3$) in the nearby universe is $1 - 3 \times C%$ where $C \sim 1.5$ is a correction factor for spectroscopic incompleteness. Having visually classified the morphologies of the constituent galaxies in our mergers, we find that the spiral-to-elliptical ratio of galaxies in mergers is higher by a factor $\sim 2$ relative to the global population. In a companion paper, we examine the internal properties of these merging galaxies and conclude that this high spiral-to-elliptical ratio in mergers is due to a longer time-scale over which mergers with spirals are detectable compared to mergers with ellipticals.
astro-ph.GA:We have used archival 74 MHz VLA data spanning the last 15 years in combination with new data from the Long Wavelength Demonstrator Array (LWDA) and data from the literature covering the last 50 years to explore the evolution of Cas A at low radio frequencies. We find that the secular decrease of the flux density of Cas A at ~80 MHz is rather stable over five decades of time, decreasing at a rate of 0.7-0.8% yr^-1. This is entirely consistent with previous estimates at frequencies as low as 38 MHz, indicating that the secular decrease is roughly the same at low frequencies, at least between 38 and 80 MHz. We also find strong evidence for as many as four modes of flux density oscillation about the slower secular decrease with periods of 3.10+/-0.02$ yr, 5.1+/-0.3 yr, 9.0+/-0.2 yr, and 24+/-2 yr. These are also consistent with fluctuations seen previously to occur on scales of a few years. These results provide compelling motivation for a thorough low frequency monitoring campaign of Cas A to constrain the nature and physical origins of these fluctuations, and to be able to better predict the flux density of Cas A at any given epoch so that it may be used as a reliable low frequency calibrator.
astro-ph.GA:Following the study of Darg et al. (2009; hereafter D09a) we explore the environments, optical colours, stellar masses, star formation and AGN activity in a sample of 3003 pairs of merging galaxies drawn from the SDSS using visual classifications from the Galaxy Zoo project. While D09a found that the spiral-to-elliptical ratio in (major) mergers appeared higher than that of the global galaxy population, no significant differences are found between the environmental distributions of mergers and a randomly selected control sample. This makes the high occurrence of spirals in mergers unlikely to be an environmental effect and must, therefore, arise from differing time-scales of detectability for spirals and ellipticals. We find that merging galaxies have a wider spread in colour than the global galaxy population, with a significant blue tail resulting from intense star formation in spiral mergers. Galaxies classed as star-forming using their emission-line properties have average star-formation rates approximately doubled by the merger process though star formation is negligibly enhanced in merging elliptical galaxies. We conclude that the internal properties of galaxies significantly affect the time-scales over which merging systems can be detected (as suggested by recent theoretical studies) which leads to spirals being `over-observed' in mergers. We also suggest that the transition mass $3\times10^{10}{M}_{\astrosun}$, noted by \citet{kauffmann1}, below which ellipticals are rare could be linked to disc survival/destruction in mergers.
astro-ph.GA:We employ an Artificial Neural Network (ANN) based technique to develop a pipeline for automated segregation of stars from the galaxies to be observed by Tel-Aviv University Ultra-Violet Experiment (TAUVEX). We use synthetic spectra of stars from UVBLUE library and selected International Ultraviolet Explorer (IUE) low resolution spectra for galaxies in the ultraviolet (UV) region from 1250 to 3220\AA as the training set and IUE low-resolution spectra for both the stars and the galaxies as the test set. All the data sets have been pre-processed to get band integrated fluxes so as to mimic the observations of the TAUVEX UV imager. We also perform the ANN based segregation scheme using the full length spectral features (which will also be useful for the ASTROSAT mission). Our results suggest that, in the case of the non-availability of full spectral features, the limited band integrated features can be used to segregate the two classes of objects; although the band data classification is less accurate than the full spectral data classification.
astro-ph.GA:Gamma Doradus stars are excellent targets for asteroseismology since the gravity modes present in these stars probe the deep stellar interiors. Mode identification will improve the knowledge of these stars considerably. A selected group of Gamma Doradus stars and some candidates were observed with the Mercator telescope to find and/or confirm the periodicities in the light variations and to derive reliable amplitude ratios in different pass bands. A frequency analysis was performed on all new data obtained in the Geneva photometric system. In order to have more reliable and accurate frequencies, the new data were combined with similar data from the literature and with Hipparcos observations. A set of frequencies that minimized the the residuals in a harmonic fit was searched for while allowing means and amplitudes to vary from one observation set to another. Frequencies and amplitudes in the photometric passbands of the Geneva system are given for 21 Gamma Doradus stars. We report the discovery of HD 74504 as a newly found Gamma Doradus star. Our study provides the first extensive multicolour database for the understanding of gravity modes in F-type stars.
astro-ph.GA:We have detected significant Rotation Measure variations for 9 bright pulsars, as a function of pulse longitude. An additional sample of 10 pulsars showed a rather constant RM with phase, yet a small degree of RM fluctuation is visible in at least 3 of those cases. In all cases, we have found that the rotation of the polarization position angle across our 1.4 GHz observing band is consistent with the wavelength-squared law of interstellar Faraday Rotation. We provide for the first time convincing evidence that RM variations across the pulse are largely due to interstellar scattering, although we cannot exclude that magnetospheric Faraday Rotation may still have a minor contribution; alternative explanations of this phenomenon, like erroneous de-dispersion and the presence of non-orthogonal polarization modes, are excluded. If the observed, phase-resolved RM variations are common amongst pulsars, then many of the previously measured pulsar RMs may be in error by as much as a few tens of rad m-2.
astro-ph.GA:We present GALEX near ultraviolet (NUV:1750 - 2750A) and far ultraviolet (FUV: 1350 - 1750A) imaging observations of two 1.2 degree diameter fields in the Hyades and Pleiades open clusters in order to detect possible UV variability of the member stars. We have performed a detailed software search for short-term UV flux variability during these observations of the approx 400 sources detected in each of the Hyades and Pleiades fields to identify flare-like (dMe) stellar objects. This search resulted in the detection of 16 UV variable sources, of which 13 can be directly associated with probable M-type stars. The other UV sources are G-type stars and one newly discovered RR Lyrae star, USNOB1.0 1069-0046050, of period 0.624 day and distance 4.5-7.0 kpc. Light curves of photon flux versus time are shown for 7 flare events recorded on six probable dMe stars. UV energies for these flares span the range 2E27 to 5E29 erg, with a corresponding NUV variability change of 1.82 mag. Only one of these flare events (on the star Cl* Melotte 25 LH129) can definitely be associated with an origin on a member the Hyades cluster itself. Finally, many of our M-type candidates show long periods of enhanced UV activity but without the associated rapid increase in flux that is normally associated with a flare event. However, the total UV energy output during such periods of increased activity is greater than that of many short-term UV flares. These intervals of enhanced low-level UV activity concur with the idea that, even in quiescence, the UV emission from dMe stars may be related to a superposition of many small flare events possessing a wide range of energies.
astro-ph.GA:Parallax is the most fundamental technique to measure distances to astronomical objects. Although terrestrial parallax was pioneered over 2000 years ago by Hipparchus (ca. 140 BCE) to measure the distance to the Moon, the baseline of the Earth is so small that terrestrial parallax can generally only be applied to objects in the Solar System. However, there exists a class of extreme gravitational microlensing events in which the effects of terrestrial parallax can be readily detected and so permit the measurement of the distance, mass, and transverse velocity of the lens. Here we report observations of the first such extreme microlensing event OGLE-2007-BLG-224, from which we infer that the lens is a brown dwarf of mass M=0.056 +- 0.004 Msun, with a distance of 525 +- 40 pc and a transverse velocity of 113 +- 21 km/s. The velocity places the lens in the thick disk, making this the lowest-mass thick-disk brown dwarf detected so far. Follow-up observations may allow one to observe the light from the brown dwarf itself, thus serving as an important constraint for evolutionary models of these objects and potentially opening a new window on sub-stellar objects. The low a priori probability of detecting a thick-disk brown dwarf in this event, when combined with additional evidence from other observations, suggests that old substellar objects may be more common than previously assumed.
astro-ph.GA:We present a 9 deg^2 map of the North American and Pelican Nebulae regions obtained in all four IRAC channels with the Spitzer Space Telescope. The resulting photometry is merged with that at JHKs from 2MASS and a more spatially limited $BVI$ survey from previous ground-based work. We use a mixture of color- color diagrams to select a minimally contaminated set of more than 1600 objects that we claim are young stellar objects (YSOs) associated with the star forming region. Because our selection technique uses IR excess as a requirement, our sample is strongly biased against inclusion of Class III YSOs. The distribution of IRAC spectral slopes for our YSOs indicates that most of these objects are Class II, with a peak towards steeper spectral slopes but a substantial contribution from a tail of flat spectrum and Class I type objects. By studying the small fraction of the sample that is optically visible, we infer a typical age of a few Myr for the low mass population. The young stars are clustered, with about a third of them located in eight clusters that are located within or near the LDN 935 dark cloud. Half of the YSOs are located in regions with surface densities higher than 1000 YSOs / deg^2. The Class I objects are more clustered than the Class II stars.
astro-ph.GA:We used the Extended Submillimeter Array (eSMA) in its most extended configuration to investigate the innermost (within a radius of 290 R* from the star) circumstellar envelope (CSE) of IRC+10216. We imaged the CSE using HCN and other molecular lines with a beam size of 0."22 x 0."46, deeply into the very inner edge (15 R*) of the envelope where the expansion velocity is only 3 km/s. The excitation mechanism of hot HCN and KCl maser lines is discussed. HCN maser components are spatially resolved for the first time on an astronomical object. We identified two discrete regions in the envelope: a region with a radius of . 15 R*, where molecular species have just formed and the gas has begun to be accelerated (region I) and a shell region (region II) with a radius of 23 R* and a thickness of 15 R*, whose expansion velocity has reached up to 13 km/s, nearly the terminal velocity of 15 km/s. The Si$^{34}$S line detected in region I shows a large expansion velocity of 16 km/s due to strong wing components, indicating that the emission may arise from a shock region in the innermost envelope. In region II, the P.A. of the most copious mass loss direction was found to be 120 +/- 10 degrees, which may correspond to the equatorial direction of the star. Region II contains a torus-like feature. These two regions may have emerged due to significant differences in the size distributions of the dust particles in the two regions.
astro-ph.GA:We have made CO(J=2-1) observations towards the HII region RCW 49 and its ionizing source, the rich stellar cluster Westerlund 2 (hereafter Wd2), with the NANTEN2 sub-mm telescope. These observations have revealed that two molecular clouds in velocity ranges of -11 to +9 km/s and 11 to 21 km/s respectively, show remarkably good spatial correlations with the Spitzer IRAC mid-infrared image of RCW 49, as well a velocity structures indicative of localized expansion around the bright central regions and stellar cluster. This strongly argues that the two clouds are physically associated with RCW 49. We obtain a new kinematic distance estimate to RCW 49 and Wd2 of 5.4^{+ 1.1}_{- 1.4} kpc, based on the mean velocity and velocity spread of the associated gas. We argue that acceleration of the gas by stellar winds from Wd2 is insufficient to explain the entire observed velocity dispersion of the molecular gas, and suggest a scenario in which a collision between the two clouds ~4 Myrs ago may have triggered the formation of the stellar cluster.
astro-ph.GA:We report on phase-referenced 23 GHz Very-Long-Baseline-Interferometry (VLBI) observations of the type IIb supernova SN 2008ax, made with the Very Long Baseline Array (VLBA) on 2 April 2008 (33 days after explosion). These observations resulted in a marginal detection of the supernova. The total flux density recovered from our VLBI image is 0.8$\pm$0.3 mJy (one standard deviation). As it appears, the structure may be interpreted as either a core-jet or a double source. However, the supernova structure could be somewhat confused with a possible close by noise peak. In such a case, the recovered flux density would decrease to 0.48$\pm$0.12 mJy, compatible with the flux densities measured with the VLA at epochs close in time to our VLBI observations. The lowest average expansion velocities derived from our observations are $(1.90 \pm 0.30) \times 10^5$ km s$^{-1}$ (case of a double source) and $(5.2 \pm 1.3) \times 10^4$ km s$^{-1}$ (taking the weaker source component as a spurious, close by, noise peak, which is the more likely interpretation). These velocities are 7.3 and 2 times higher, respectively, than the maximum ejecta velocity inferred from optical-line observations.
astro-ph.GA:Most stars do not form in isolation but as part of a cluster comprising anywhere between a few dozen to several million stars with stellar densities ranging from 0.01 to several 10$^5$ \Msun pc$^{-3}$. The majority of these clusters dissolve within 20 Myr. The general assumption is that clusters are born more or less over this entire density range. A new analysis of cluster observations is presented. It demonstrates that, in fact, clustered star formation works under surprisingly tight constraints with respect to cluster size and density. The observed multitude of cluster densities simply results from snapshots of two sequences evolving in time along pre-defined tracks in the density-radius plane. This implies that the cluster size can actually be used to determine its age.
astro-ph.GA:We present high resolution spectra of the five known hydrogen-deficient carbon (HdC) stars in the vicinity of the 10830 Angstrom line of neutral helium. In R Coronae Borealis (RCB) stars the He I line is known to be strong and broad, often with a P Cygni profile, and must be formed in the powerful winds of those stars. RCB stars have similar chemical abundances as HdC stars and also share greatly enhanced 18O abundances with them, indicating a common origin for these two classes of stars, which has been suggested to be white dwarf mergers. A narrow He I absorption line may be present in the hotter HdC stars, but no line is seen in the cooler stars, and no evidence for a wind is found in any of them. The presence of wind lines in the RCB stars is strongly correlated with dust formation episodes so the absence of wind lines in the HdC stars, which do not make dust, is as expected.
astro-ph.GA:We present the first determination of the radial velocities and metallicities of 78 red giant stars in the isolated dwarf irregular galaxy WLM. Observations of the calcium II triplet in these stars were made with FORS2 at the VLT-UT2 in two separated fields of view in WLM, and the [Fe/H] values were conformed to the Carretta & Gratton (1997) metallicity scale. The mean metallicity is <[Fe/H]> = -1.27 +/- 0.04 dex, with a standard deviation of 0.37. We find that the stars in the inner field are more metal rich by [Fe/H] =0.30 +/- 0.06 dex. These results are in agreement with previous photometric studies that found a radial population gradient, as well as the expectation of higher metallicities in the central star forming regions. Age estimates using Victoria-Regina stellar models show that the youngest stars in the sample (< 6 Gyr) are more metal rich by [Fe/H] = 0.32 +/- 0.08 dex. These stars also show a lower velocity dispersion at all elliptical radii compared to the metal-poor stars. Kinematics for the whole red giant sample suggest a velocity gradient approximately half that of the gas rotation curve, with the stellar component occupying a thicker disk decoupled from the HI rotation plane. Taken together, the kinematics, metallicities, and ages in our sample suggest a young metal-rich, and kinematically cold stellar population in the central gas-rich regions of WLM, surrounded by a separate dynamically hot halo of older, metal poor stars.
astro-ph.GA:To search for Tidal Dwarf Galaxies (TDGs) and to study star formation in tidal features, we are conducting a large UV imaging survey of interacting galaxies selected from the Arp (1996) Atlas using the GALEX telescope. As part of that study, we present a GALEX UV and SDSS and SARA optical study of the gas-rich interacting galaxy pair Arp 305 (NGC 4016/7). The GALEX UV data reveal much extended diffuse UV emission and star formation outside the disks. This includes a luminous star forming region between the two galaxies, and a number of such regions in tidal tails. We have identified 45 young star forming clumps in Arp 305, including several TDG candidates. By comparing the UV and optical colors to population synthesis models, we determined that the clumps are very young, with several having ages of about 6 Myr. We do not find many intermediate age clumps in spite of the fact that the last closest encounter was about 300 Myr ago. We have used a smooth particle hydrodynamics code to model the interaction and determine the fate of the star clusters and candidate TDGs.
astro-ph.GA:We present high angular resolution observations of water masers at 1.3 cm and radio continuum emission at 1.3, 3.6 and 6 cm towards the Bok globule CB 54 using the Very Large Array. At 1.3 cm, with subarsecond angular resolution, we detect a radio continuum compact source located to the south-west of the globule and spatially coincident with a mid-infrared embedded object (MIR-b). The spectral index derived between 6 and 1.3 cm (alpha=0.3+/-0.4) is flat, consistent with optically thin free-free emission from ionized gas. We propose the shock-ionization scenario as a viable mechanism to produce the radio continuum emission observed at cm frequencies. Water masers are detected at two different positions separated by 2.3'', and coincide spatially with two mid-infrared sources: MIR-b and MIR-c. The association of these mid-IR sources with water masers confirms that they are likely protostars undergoing mass-loss, and they are the best candidate as driving sources of the molecular outflows in the region.
astro-ph.GA:We have detected stellar halo streams in the solar neighborhood using data from the 7th public data release of the Sloan Digital Sky Survey (SDSS), which includes the directed stellar program SEGUE: Sloan Extension For Galactic Understanding and Exploration. In order to derive distances to each star, we used the metallicity-dependent photometric parallax relation from Ivezic et al. (2008) for which we examine and quantify the accuracy. Our final sample consists of 22,321 nearby (d < 2 kpc), metal-poor ([Fe/H] < -0.5) main-sequence stars with 6D estimates of position and space velocity. We characterize the orbits of these stars through suitable kinematic proxies for their "effective" integrals of motion, angular momentum, eccentricity, and orbital polar angle and compare the observed distribution to expectations from a smooth distribution in four [Fe/H] bins. On this basis we identify at least five significant "phase-space overdensities" of stars on very similar orbits in the solar neighborhood to which we can assign unambiguously peaked [Fe/H] distributions. Three of them have been identified previously, including the halo stream discovered by Helmi et al. (1999) at a significance level of 12.0. In addition, we find at least two new genuine halo streams, judged by their kinematics and [Fe/H], at significance levels of 2.9 and 4.8, respectively. For one stream the stars even show coherence in configuration space, matching a spatial overdensity of stars found by Juric et al. (2008) at (R,z) \approx (9.5,0.8) kpc. Our results demonstrate the practical power of our search method to detect substructure in the phase-space distribution of nearby stars without making a-priori assumptions about the detailed form of the gravitational potential.
astro-ph.GA:We define new potential-density pairs and examine the impact of the potential flattening on the vertical velocity ellipsoid tilt, $\delta$. By means of numerical integrations and analytical calculations, we estimate $\delta$ in a variety of galactic potentials. We show that at 1 kpc above the Galactic plane at the solar radius, $\delta$ can differ by 5 degrees, depending on whether the dark matter halo is flat or spherical. This result excludes the possibility of an extremely flattened Galactic dark halo.
astro-ph.GA:Molecular outflows provide an alternative method of identifying protostellar cores, complementary to recent mid-infrared studies. Continuing our studies of Perseus, we investigate whether all Spitzer-identified protostars, and particularly those with low luminosities, drive outflows, and if any new protostellar cores (perhaps harbouring low-mass sources) can be identified via their outflows alone. We have used the heterodyne array receiver HARP on JCMT to make deep 12CO 3-2 maps of submm cores in Perseus, extending and deepening our earlier study with RxB and bringing the total number of SCUBA cores studied up to 83. Our survey includes 23/25 of the Dunham et al. (2008) Spitzer low-luminosity objects believed to be embedded protostars, including three VeLLOs. All but one of the cores identified as harbouring embedded YSOs have outflows, confirming outflow detections as a good method for identifying protostars. We detect outflows from 20 Spitzer low-luminosity objects. We do not conclusively detect any outflows from IR-quiet cores, though confusion in clustered regions such as NGC1333 makes it impossible to identify all the individual driving sources. This similarity in detection rates despite the difference in search methods and detection limits suggests either that the sample of protostars in Perseus is now complete, or that the existence of an outflow contributes to the Spitzer detectability, perhaps through the contribution of shocked H2 emission in the IRAC bands. For five of the low-luminosity sources, there is no protostellar envelope detected at 350 microns and the Spitzer emission is entirely due to shocks. Additionally, we detect the outflow from IRAS 03282+3035 at 850 microns with SCUBA due to CO line contamination in the continuum passband.
astro-ph.GA:We investigate the nature of 4 young and low-mass open clusters (OCs) located in the $2^{nd}$ and $3^{rd}$ quadrants with near-IR 2MASS photometry (errors $<0.1$ mag). After field decontamination, the colour-magnitude diagrams (CMDs) display similar morphologies: a poorly-populated main sequence (MS) and a dominant fraction of pre-MS (PMS) stars somewhat affected by differential reddening. Pismis 5, vdB 80 and BDSB 96 have MS ages within $5\pm4$ Myr, while the MS of NGC 1931 is $10\pm3$ Myr old. However, non-instantaneous star formation is implied by the wider ($\sim20$ Myr) PMS age spread. The cluster masses derived from MS + PMS stars are low, within $\sim60-180 \ms$, with mass functions (MFs) significantly flatter than Salpeter's initial mass function (IMF). Distances from the Sun are within $1.0-2.4$ kpc, and the visual absorptions are in the range $\aV=1.0-2.0$. From the stellar radial density profiles (RDPs), we find that they are small ($\rc\la0.48$ pc, $\rl\la5.8$ pc), especially Pismis 5 with $\rc\approx0.2$ pc and $\rl\approx1.8$ pc. Except for the irregular and cuspy inner regions of NGC 1931 and Pismis 5, the stellar RDPs follow a King-like profile. At $\sim10$ Myr, central cusps - which in old clusters appear to be related to advanced dynamical evolution - are probably associated with a star-formation and/or molecular cloud fragmentation effect. Despite the flat MFs, vdB 80 and BDSB 96 appear to be typical young, low-mass OCs. NGC 1931 and especially Pismis 5, with irregular RDPs, low cluster mass and flat MFs, do not appear to be in dynamical equilibrium. Both may be evolving into OB associations and/or doomed to dissolution in a few $10^7$ yr.
astro-ph.GA:We perform a stability test of triaxial models in MOdified Newtonian Dynamics (MOND) using N-body simulations. The triaxial models considered here have densities that vary with $r^{-1}$ in the center and $r^{-4}$ at large radii. The total mass of the model varies from $10^8\Msun$ to $10^{10}\Msun$, representing the mass scale of dwarfs to medium-mass elliptical galaxies, respectively, from deep MOND to quasi-Newtonian gravity. We build triaxial galaxy models using the Schwarzschild technique, and evolve the systems for 200 Keplerian dynamical times (at the typical length scale of 1.0 kpc). We find that the systems are virial overheating, and in quasi-equilibrium with the relaxation taking approximately 5 Keplerian dynamical times (1.0 kpc). For all systems, the change of the inertial (kinetic) energy is less than 10% (20%) after relaxation. However, the central profile of the model is flattened during the relaxation and the (overall) axis ratios change by roughly 10% within 200 Keplerian dynamical times (at 1.0kpc) in our simulations. We further find that the systems are stable once they reach the equilibrium state.
astro-ph.GA:We constructed a sample of 185 Flat Spectrum Radio Quasars (FSRQs) by cross-correlating the Shen et al.'s SDSS DR3 X-ray quasar sample with FIRST and GB6 radio catalogues. From the spectrum energy distribution (SED) constructed using multi-band (radio, UV, optical, Infrared and X-ray) data, we derived the synchrotron peak frequency and peak luminosity. The black hole mass and the broad line region (BLR) luminosity (then the bolometric luminosity) were obtained by measuring the line-width and strength of broad emission lines from SDSS spectra. We define a subsample of 118 FSRQs, of which the nonthermal jet emission is thought to be dominated over the thermal emission from accretion disk and host galaxy. For this subsample, we found 25 FSRQs having synchrotron peak frequency > 10^{15} Hz, which is higher than the typical value for FSRQs. While only a weak anti-correlation is found between the synchrotron peak frequency and peak luminosity, it becomes significant when combining with the Wu et al.'s sample of 170 BL Lac objects. At similar peak frequency, the peak luminosity of FSRQs with $\nupeak > 10^{15}$ Hz is systematically higher than that of BL Lac objects, with some FSRQs out of the range covered by BL Lac objects. Although high $\nupeak$ are found in some FSRQs, they do not reach the extreme value of BL Lacs. For the subsample of 118 FSRQs, we found significant correlations between the peak luminosity and black hole mass, the Eddington ratio, and the BLR luminosity, indicating that the jet physics may be tightly related with the accretion process.
astro-ph.GA:We show that the relation between the mass of supermassive black holes located in the center of the host galaxies and the kinetic energy of random motions of the corresponding bulges is a useful tool to study the evolution of galaxies. In the form log[M_BH] = b + m log[M_G sigma^2/c^2], the best-fitting results for a sample of 64 galaxies of various morphological types are the slope m=0.80 and the normalization b=4.53. We note that, in analogy with the H-R diagram for stars, each morphological type of galaxy generally occupies a different area in the M_BH - (M_G sigma^2)/c^2 plane. In particular, we find elliptical galaxies in the upper part of the line of best fit, the lenticular galaxies in the middle part, and the late-type galaxies in the lower part, the mass of the central black hole giving an estimate of the age, whereas the kinetic energy of the stellar bulges is directly connected with the temperature of each galactic system. Finally, the values of the linear correlation coefficient, the intrinsic scatter, and the chi^2 obtained by using the M_BH - M_G sigma^2 relation are better than the corresponding ones obtained from the M_BH - sigma or M_BH - M_G relation.
astro-ph.GA:We present high resolution (R=80,000) spectroscopy of [NeII] emission from two young stars, GM Aur and AA Tau, which have moderate to high inclinations. The emission from both sources appears centered near the stellar velocity and is broader than the [NeII] emission measured previously for the face-on disk system TW Hya. These properties are consistent with a disk origin for the [NeII] emission we detect, with disk rotation (rather than photoevaporation or turbulence in a hot disk atmosphere) playing the dominant role in the origin of the line width. In the non-face-on systems, the [NeII] emission is narrower than the CO fundamental emission from the same sources. If the widths of both diagnostics are dominated by Keplerian rotation, this suggests that the [NeII] emission arises from larger disk radii on average than does the CO emission. The equivalent width of the [NeII] emission we detect is less than that of the spectrally unresolved [NeII] feature in the Spitzer spectra of the same sources. Variability in the [NeII] emission or the mid-infrared continuum, a spatially extended [NeII] component, or a very (spectrally) broad [NeII] component might account for the difference in the equivalent widths.
astro-ph.GA:Spiral galaxies dominate the local galaxy population. Disks are known to be fragile with respect to collisions. Thus it is worthwhile to probe under which conditions a disk can possibly survive such interactions. We present a detailed morpho-kinematics study of a massive galaxy with two nuclei, J033210.76--274234.6, at z=0.4. The morphological analysis reveals that the object consists of two bulges and a massive disk, as well as a faint blue ring. Combining the kinematics with morphology we propose a near-center collision model to interpret the object. We find that the massive disk is likely to have survived the collision of galaxies with an initial mass ratio of ~4:1. The N-body/SPH simulations show that the collision possibly is a single-shot polar collision with a very small pericentric distance of ~1 kpc and that the remnant of the main galaxy will be dominated by a disk. The results support the disk survival hypothesis. The survival of the disk is related to the polar collision with an extremely small pericentric distance. With the help of N-body/SPH simulations we find the probability of disk survival is quite large regardless whether the two galaxies merge or not.
astro-ph.GA:We exploit the large number of archival HST images of 47 Tuc to examine its subgiant branch (SGB) and main sequence (MS) for signs of multiple populations. In the cluster core, we find that the cluster's SGB exhibits a clear spread in luminosity, with at least two distinct components: a brighter one with a spread that is real but not bimodal, and a second one about 0.05 mag fainter, containing about 10% of the stars. In a less crowded field 6 arcminutes from the center, we find that the MS is broadened much more than can be accounted for by photometric errors, and that this broadening increases at fainter magnitudes.
astro-ph.GA:As an extension of four point mass lenses at the vertices of a rhombus, we present five point mass lenses at the center and vertices of a diamond, which constitute, for a source behind the center, a soluble model giving expressions of all the image positions (with the maximum number of images as twenty for five lenses). For a source near the center, all the image positions are obtained in the linear approximation.
astro-ph.GA:The periodical component predicted by the theory of optic-metrical parametric resonance was recently found in the signal of Sep A radio source. If such observations performed independently give similar results, they would provide another evidence of the gravitational waves (GW) existence and the perspectives of the GW astronomy could be discussed.
astro-ph.GA:We search for very small-diameter galactic planetary nebulae (PNe) representing the earliest phases of PN evolution. A recently published IPHAS catalogue of Ha-emitting stars provides a useful base for this study as all sources present in this catalogue must be of small angular diameter.   The PN candidates are selected based on their location in two colour-colour diagrams: IPHAS (r' - Ha) vs. (r' - i'), and 2MASS (J - H) vs. (H - Ks). Spectroscopic follow-up has been carried out on a sample of candidates in order to confirm their nature.   We present a total of 83 PN candidates. We were able to obtain spectra or find the classification from the literature for 35 candidates. Five of these objects are likely to be new PNe, including one large bipolar PN discovered serendipitously near an emission-line star. PN distances deduced from extinction-distance relations based on IPHAS field-star photometry are presented for the first time. These yield distance estimates for our objects in the range from 2 kpc to 6 kpc. From the data to hand, we conclude that four of the discovered objects are very probably young PNe.
astro-ph.GA:Cosmic rays and magnetic fields can substantially impact the launching of large-scale galactic winds. Many researchers have investigated the role of cosmic rays; our group previously showed that a cosmic-ray and thermally-driven wind could explain soft X-ray emission towards the center of the Galaxy. In this paper, we calculate the synchrotron emission from our original wind model and compare it to observations; the synchrotron data shows that earlier assumptions about the launching conditions of the wind must be changed: we are required to improve that earlier model by restricting the launching region to the domain of the inner "Molecular Ring", and by decreasing the magnetic field strength from the previously assumed maximum strength. With these physically-motived modifications, we find that a wind model can fit both the radio synchrotron and the X-ray emission, although that model is required to have a higher gas pressure and density than the previous model in order to reproduce the observed X-ray emission measure within the smaller `footprint'. The drop in magnetic field also decreases the effect of cosmic-ray heating, requiring a higher temperature at the base of the wind than the previous model.
astro-ph.GA:Interstellar polarization at far-infrared through millimeter wavelengths (0.1 - 1 mm) is primarily due to thermal emission from dust grains aligned with magnetic fields. This mechanism has led to studies of magnetic fields in a variety of celestial sources, as well as the physical characteristics of the dust grains and their interaction with the field. Observations have covered a diverse array of sources, from entire galaxies to molecular clouds and proto-stellar disks. Maps have been generated on a wide range of angular scales, from surveys covering large fractions of the sky, down to those with arcsecond spatial resolution. Additionally, the increasing availability of observations at multiple wavelengths in this band allows empirical tests of models of grain alignment and cloud structure. I review some of the recent work in this field, emphasizing comparisons of observations on multiple spatial scales and at multiple wavelengths.
astro-ph.GA:We propose to the community a comprehensive UV/optical/NIR imaging survey of Galactic star formation regions to probe all aspects of the star formation process. The primary goal of such a study is to understand the evolution of circumstellar protoplanetary disks and other detailed aspects of star formation in a wide variety of different environments. This requires a comprehensive emission-line survey of nearby star-forming regions in the Milky Way, where a high spatial resolution telescope+camera will be capable of resolving circumstellar material and shock structures. In addition to resolving circumstellar disks themselves, such observations will study shocks in the jets and outflows from young stars, which are probes of accretion in the youngest protoplanetary disks still embedded in their surrounding molecular clouds. These data will allow the measurement of proper motions for a large sample of stars and jets/shocks in massive star-forming regions for the first time, opening a new window to study the dynamics of these environments. It will require better than 30 mas resolution and a stable PSF to conduct precision astrometry and photometry of stars and nebulae. Such data will allow production of precise color-color and color magnitude diagrams for millions of young stars to study their evolutionary states. One can also determine stellar rotation, multiplicity, and clustering statistics as functions of environment and location in the Galaxy. For the first time we can systematically map the detailed excitation structure of HII regions, stellar winds, supernova remnants, and supershells/superbubbles. This survey will provide the basic data required to understand star formation as a fundamental astrophysical process that controls the evolution of the baryonic contents of the Universe.
astro-ph.GA:The last two decades have seen remarkable progress in our long-standing goal of determining the abundance and diversity of worlds in the Galaxy. Understanding of this subject involves tracing the path of interstellar material from dense cloud cores, to young stellar objects, protoplanetary disks, and finally extrasolar planets. Here we discuss the critical information provided on these objects by point-source far-ultraviolet spectroscopy with a large aperture, high resolution spectrograph of a large sample of unique protostellar and protoplanetary objects that will leverage our existing knowledge to lay out a path to new and powerful insight into the formation process. We lay out a systematic case of coordinated observations that will yield new knowledge about the process of assembly for both protostellar and protoplanetary systems - that addresses specific uncertainties in our current knowledge and takes advantage of potential new technologies to acquire the data needed.
astro-ph.GA:We present 1" resolution CARMA observations of the 3mm continuum and 95 GHz methanol masers toward 14 candidate high mass protostellar objects (HMPOs). Dust continuum emission is detected toward seven HMPOs, and methanol masers toward 5 sources. The 3mm continuum sources have diameters < 2x10^4 AU, masses between 21 and 1200 M_sun, and volume densities > 10^8 cm^-3. Most of the 3mm continuum sources are spatially coincident with compact HII regions and/or water masers, and are presumed to be formation sites of massive stars. A strong correlation exists between the presence of 3mm continuum emission, 22 GHz water masers, and 95 GHz methanol masers. However, no 3mm continuum emission is detected toward ultracompact HII regions lacking maser emission. These results are consistent with the hypothesis that 22 GHz water masers and methanol masers are signposts of an early phase in the evolution of an HMPO before an expanding HII region destroys the accretion disk.
astro-ph.GA:In this paper we estimated the temperatures and brightnesses of the Monoceros radio loop at 1420, 820 and 408 MHz. Linear spectrum is estimated for mean temperatures versus frequency between 1420, 820 and 408 MHz. The spectral index of Monoceros loop is also obtained. The brightness temperatures and surface brightnesses of the loop are computed using data taken from radio-continuum surveys at the three frequencies. The spectral index of the loop is also obtained from $T-T$ plots between 1420 - 820, 1420 - 408 and 820 - 408 MHz. The obtained results confirm non-thermal origin of the Monoceros radio loop.
astro-ph.GA:An isolated HI cloud with peculiar properties has recently been discovered by Dedes, Dedes, & Kalberla (2008, A&A, 491, L45) with the 300-m Arecibo telescope, and subsequently imaged with the VLA. It has an angular size of ~6', and the HI emission has a narrow line profile of width ~ 3 km/s.   We explore the possibility that this cloud could be associated with a circumstellar envelope ejected by an evolved star.   Observations were made in the rotational lines of CO with the IRAM-30m telescope, on three positions in the cloud, and a total-power mapping in the HI line was obtained with the Nancay Radio Telescope.   CO was not detected and seems too underabundant in this cloud to be a classical late-type star circumstellar envelope. On the other hand, the HI emission is compatible with the detached-shell model that we developed for representing the external environments of AGB stars.   We propose that this cloud could be a fossil circumstellar shell left over from a system that is now in a post-planetary-nebula phase. Nevertheless, we cannot rule out that it is a Galactic cloud or a member of the Local Group, although the narrow line profile would be atypical in both cases.
astro-ph.GA:In extragalactic jets, the apparent position of the bright/narrow end (the core) depends on the observing frequency, owing to synchrotron self-absorption and external absorption. The effect must be taken into account in order to achieve unbiased results from multi-frequency VLBI data on AGN jets. Multi-frequency core shift measurements supplemented by other data enable estimating the absolute geometry and a number of fundamental physical properties of the jets and their environment. We have previously measured the shift between 13 and 3.6 cm in a sample of 29 AGNs to range between 0 and 1.4 mas. In these proceedings, we present and discuss first results of our follow-up study using VLBA between 1.4 and 15.4 GHz.
astro-ph.GA:(Abridged) Gas and star velocity dispersions have been derived for four circumnuclear star-forming regions (CNSFRs) and the nucleus of the spiral galaxy NGC2903 using high resolution spectroscopy in the blue and far red. Stellar velocity dispersions have been obtained from the CaII triplet (CaT) lines at 8494, 8542, 8662A, using cross-correlation techniques while gas velocity dispersions have been measured by Gaussian fits to the Hbeta line.   The CNSFRs, with sizes of about 100 to 150pc in diameter, show a complex structure at the Hubble Space Telescope resolution, with a good number of subclusters with linear diameters between 3 and 8pc. Their stellar velocity dispersions range from 39 to 67 km/s. These values, together with the sizes measured on archival HST images yield upper limits to the dynamical masses for the individual star clusters between 1.8 and 8.7 x 10$^6$ M$_\odot$ and upper limits to the masses for the whole CNSFR between 4.9 x 10$^6$ and 4.3 x 10$^7$ M$_\odot$. ...
astro-ph.GA:We present new results based on high-resolution observations of Sgr A West at the Galactic center with the VLA at 1.3 cm. We measured proper motions for 71 compact HII components. We also investigated radial velocities in the LSR velocity using the H92a line data. Combining proper motion and radial velocity measurements, we have determined the 3D velocity distribution in Sgr A West. We find that the three ionized streams (Northern Arm, Eastern Arm, and Western Arc) can be modeled with three bundles of Keplerian orbits around Sgr A*. We determined the five orbital parameters for each of them using LSQ fitting to the locii of the streams. Our results confirm earlier results on the streams in the Western Arc and the Northern Arm to be in Keplerian orbits, suggesting that the stream in the Eastern Arm is also consistent with an elliptical orbit. Both the Northern and Eastern Arm streams have high eccentricities, while the Western Arc stream is nearly circular. All three streams orbit around Sgr A* in a counterclockwise sense (viewed from the Earth). We also report an ionized nebula associated with IRS 8, including a bow shock in radio continuum emission which shows excellent agreement with near IR observations. From the H92a line data, we find evidence for interaction between the IRS 8 nebula and the Northern Arm stream. Other new morphological features revealed in our high-resolution image include: 1) a helical structure in the Northern Arm, suggesting that MHD plays an important role in the motion of the ionized gas, in addition to the dynamics determined by the central gravitational field and 2) a linear feature in the IRS 16 region, suggesting the compressed edge of the Northern Arm may result from the collective winds and radiation pressure from the high mass stars in the IRS16 cluster.
astro-ph.GA:We report subarcsecond images of the high-mass star forming region Onsala 1 (ON 1) made with the Submillimeter Array (SMA) at 0.85 mm and the Very Large Array at 1.3 cm and 3.6 cm. ON~1 is one of the smallest ultracompact HII regions in the Galaxy and exhibits various star formation signposts. With our VLA and SMA observations, two new cm-wave sources and five sub-mm dust sources, respectively, within a field of ~3" (corresponding to a linear scale of 0.05 pc) are identified, indicating the multiplicity at the center of the ON 1 region. The dust and gas masses of these sub-mm sources are in the range of 0.8 to 6.4 M_sun. Among the five sub-mm dust sources, SMA2, with a dust and gas mass of 2.6 M_sun, demonstrates several star formation signatures, and hence likely represents an intermediate-mass (or even high-mass) star forming core. Due to the low star formation efficiency of ~10%, we suggest that star formation in the ON 1 region will continue. For example, SMA4 and SMA5 are not associated with any star formation signatures and likely mark star formation cores at very early evolutionary stages.
astro-ph.GA:Many physical properties of this SNR such as spectrum and polarization can only be investigated by radio observations. The $\lambda$11 cm and $\lambda$6\ cm continuum and polarization observations of SNR G65.2+5.7 were made with the Effelsberg 100-m and the Urumqi 25-m telescopes, respectively, to investigate the integrated spectrum, the spectral index distribution, and the magnetic field properties. $\lambda$21 cm archival data from the Effelsberg 100-m telescope have been also used. The integrated flux densities of G65.2+5.7 at $\lambda 11$ cm and $\lambda 6$ cm are $21.9\pm3.1$ Jy and 16.8$\pm$1.8 Jy, respectively. The power-law spectrum ($S\sim\nu^{\alpha}$) is well fitted by $\alpha = -0.58\pm0.07$ from 83 MHz to 4.8 GHz. Spatial spectral variations are small. Along the northern shell strong depolarizion is observed at both wavelengths. The southern filamentary shell of SNR G65.2+5.7 is polarized up to 54% at $\lambda 6$ cm. There is significant depolarization at $\lambda 11$ cm and confusion with diffuse polarized Galactic emission. Using equipartition principle, we estimated the magnetic field strength for the southern filamentary shell about 20 $\mu$G (filling factor 1) to 50 $\mu$G (filling factor 0.1). A faint HI shell may be associated with the SNR. Despite its unusual strong X-ray and optical emission and its very low surface brightness, the radio properties of SNR G65.2+5.7 are found to be typical for evolved shell type SNRs. SNR G65.2+5.7 may be expanding in a preblown cavity as indicated by a deficit of HI gas and a possible HI-shell.
astro-ph.GA:Polycyclic Aromatic Hydrocarbons (PAHs) are considered as a major constituent of interstellar dust. They have been proposed as the carriers of the Aromatic Infrared Bands (AIBs) observed in emission in the mid-IR. They likely have a significant contribution to various features of the extinction curve such as the 220 nm bump,the far-UV rise and the diffuse interstellar bands. Emission bands are also expected in the far-IR, which are better fingerprints of molecular identity than the AIBs. They will be searched for with the Herschel Space Observatory. Rotational emission is also expected in the mm range for those molecules which carry significant dipole moments. Despite spectroscopic studies in the laboratory, no individual PAH species could be identified. This emphasises the need for an investigation on where interstellar PAHs come from and how they evolve due to environmental conditions: ionisation and dissociation upon UV irradiation, interactions with electrons, gas and dust. There is also evidence for PAH species to contribute to the depletion of heavy atoms from the gas phase, in particular Si and Fe. This paper illustrates how laboratory work can be inspired from observations. In particular there is a need for understanding the chemical properties of PAHs and PAH-related species, including very small grains, in physical conditions that mimic those found in interstellar space. This motivates a joint effort between astrophysicists, physicists and chemists. Such interdisciplinary studies are currently performed, taking advantage of the PIRENEA set-up, a cold ion trap dedicated to astrochemistry.
astro-ph.GA:- Context: We present the results of a near-infrared photometric and spectroscopic study of the star forming region G61.48+0.09. - Aims: The purpose of this study is to characterize the stellar content of the cluster and to determine its distance, extinction, age and mass. - Methods: The stellar population was studied by using color-magnitude diagrams to select twenty promising cluster members, for which follow up spectroscopy was done. The observed spectra allowed a spectral classification of the stars. - Results: Two stars have emission lines, twelve are G-type stars, and six are late-O or early-B stars. - Conclusions: The cluster's extinction varies from A_{K_S} = 0.9 to A_{K_S} = 2.6, (or A_{V}~8 to A_{V}~23). G61.48+0.09 is a star forming region located at 2.5+/-0.4 Kpc. The cluster is younger than 10 Myr and has a minimum stellar mass of 1500+/-500 Solar masses. However, the actual total mass of the cluster remains undetermined, as we cannot see its whole stellar content.
astro-ph.GA:The observed slope at the high-mass end of the initial mass function (IMF) displays a remarkable universality in a wide variety of physical environments. We predict that competitive accretion, the ongoing accretion of gas from a common reservoir by a collection of protostellar cores, can provide a natural explanation for such a universal slope in star forming regions with metallicities roughly greater than 1e-5 the solar value. In our discussion, we point out that competitive accretion will occur whenever a gaseous region has multiple Jeans masses of material and contains large-scale motions that are controlled by the gravitational potential well. We describe how and when these conditions can be reached during the chemical enrichment of the Universe, showing that they can occur for a wide range of metallicities and environmental conditions. We also discuss the ability of other physical processes to limit the effects of further accretion onto protostellar cores. Current theoretical and numerical studies show that competitive accretion is robust against disrupting effects - such as feedback from young stars, supersonic turbulence and magnetic fields - in all but the most extreme cases.
astro-ph.GA:We present deep HI observations of the moderately inclined spiral galaxy, NGC 2997. The goal of these observations was to search for HI clouds in the vicinity of NGC 2997 analogous to the high velocity clouds of the Milky Way and gain insight into their origins. We find evidence for the presence of a galactic fountain as well as the accretion of intragalactic material, however we do not identify any large clouds of HI far from the disk of the galaxy. NGC 2997 has a thick, lagging HI disk that is modeled with a vertical velocity gradient of 18-31 km/s/kpc. Anomalous velocity HI clouds with masses of order 10^7 Msun, which cannot be explained by galactic fountain models allow us to estimate a lower limit to the accretion of extragalactic gas of 1.2 Msun/yr. The number and mass of these clouds have implications for cosmological simulations of large scale structure and the presence of dark matter halos. We have used values from the the literature to estimate a star formation rate of 5 +/- 1 Msun/yr and to derive a new distance to NGC 2997 of 12.2 +/- 0.9 Mpc using published Tully-Fisher relations.
astro-ph.GA:We investigate the star-formation ocurring in the region towards IRAS07527-3446 in the molecular cloud [MAB97]250.63-3.63, in the far outer Galaxy. We report the discovery of a new young stellar cluster, and describe its properties and those of its parent molecular cloud. Near-infrared JHKS images were obtained with VLT/ISAAC, and millimetre line CO spectra were obtained with the SEST telescope. VLA archive date were also used. The cloud and cluster are located at a distance of 10.3 kpc and a Galactocentric distance of 15.4 kpc, in the far outer Galaxy. Morphologically, IRAS 07527-3446 appears as a young embedded cluster of a few hundred stars seen towards the position of the IRAS source, extending for about 2-4 pc and exhibiting sub-clustering. The cluster contains low and intermediate-mass young reddened stars, a large fraction having cleared the inner regions of their circumstellar discs responsible for (H-Ks) colour excess. The observations are compatible with a < 5 Myr cluster with variable spatial extinction of between Av = 5 and Av = 11. Decomposition of CO emission in clumps, reveals a clump clearly associated with the cluster position, of mass 3.3 x 10^3 M(solar). Estimates of the slopes of the Ks-band luminosity function and of the star-formation efficiency yield values similar to those seen in nearby star-formation sites. These findings reinforce previous results that the distant outer Galaxy continues to be active in the production of new and rich stellar clusters, with the physical conditions required for the formation of rich clusters continuing to be met in the very distant environment of the outer Galactic disc.
astro-ph.GA:A strong signature of a circumstellar disc around a high-mass protostar has been inferred from high resolution methanol maser observations in NGC7538-IRS1 N. This interpretation has however been challenged with a bipolar outflow proposed as an alternative explanation. We compare the two proposed scenarios for best consistency with the observations. Using a newly developed formalism we model the optical depth of the maser emission at each observed point in the map and LOS velocity for the two scenarios. We find that if the emission is symmetric around a central peak in both space and LOS velocity then it has to arise from an edge-on disc in sufficiently fast differential rotation. Disc models successfully fit ~100 independent measurement points in position-velocity space with 4 free parameters to an overall accuracy of 3-4%. Solutions for Keplerian rotation require a central mass of at least 4 solar masses. Close to best-fitting models are obtained if Keplerian motion is assumed around a central mass equaling ~30 solar masses as inferred from other observations. In contrast we find that classical bipolar outflow models cannot fit the data, although could be applicable in other sources. Our results strongly favour the differentially rotating disc hypothesis to describe the main feature of the 12.2 (and 6.7) GHz methanol maser emission in NGC7538 IRS1 N. Furthermore, for Keplerian rotation around a ~30 solar masses protostar we predict the position and velocity at which tangentially amplified masers should be detected in high dynamic range observations. [abridged]
astro-ph.GA:We look for observational signatures that could discriminate between Newtonian and modified Newtonian (MOND) dynamics in the Milky Way, in view of the advent of large astrometric and spectroscopic surveys. Indeed, a typical signature of MOND is an apparent disk of "phantom" dark matter, which is uniquely correlated with the visible disk-density distribution. Due to this phantom dark disk, Newtonian models with a spherical halo have different signatures from MOND models close to the Galactic plane. The models can thus be differentiated by measuring dynamically (within Newtonian dynamics) the disk surface density at the solar radius, the radial mass gradient within the disk, or the velocity ellipsoid tilt angle above the Galactic plane. Using the most realistic possible baryonic mass model for the Milky Way, we predict that, if MOND applies, the local surface density measured by a Newtonist will be approximately 78 Msun/pc2 within 1.1 kpc of the Galactic plane, the dynamically measured disk scale-length will be enhanced by a factor of 1.25 with respect to the visible disk scale-length, and the local vertical tilt of the velocity ellipsoid at 1 kpc above the plane will be approximately 6 degrees. None of these tests can be conclusive for the present-day accuracy of Milky Way data, but they will be of prime interest with the advent of large surveys such as GAIA.
astro-ph.GA:In this paper we use N-body simulations to study the effects of primordial mass segregation on the early and long-term evolution of star clusters. Our simulations show that in segregated clusters early mass loss due to stellar evolution triggers a stronger expansion than for unsegregated clusters. Tidally limited, strongly segregated clusters may dissolve rapidly as a consequence of this early expansion, while segregated clusters initially underfilling their Roche lobe can survive the early expansion and have a lifetime similar to that of unsegregated clusters. Long-lived initially segregated clusters tend to have looser structure and reach core collapse later in their evolution than initially unsegregated clusters. We have also compared the effects of dynamical evolution on the global stellar mass function (MF) of low-mass main sequence stars. In all cases the MF flattens as the cluster loses stars. The amount of MF flattening induced by a given amount of mass loss in a rapidly dissolving initially segregated cluster is less than for an unsegregated cluster. The evolution of the MF of a long-lived segregated cluster, on the other hand, is very similar to that of an initially unsegregated cluster.
astro-ph.GA:Observations indicate that the fraction of potential binary star clusters in the Magellanic Clouds is about 10%. In contrast, it is widely accepted that the binary cluster frequency in the Galaxy disk is much lower. Here we investigate the multiplicity of clusters in the Milky Way disk to either confirm or disprove this dearth of binaries. We quantify the open cluster multiplicity using complete, volume-limited samples from WEBDA and NCOVOCC. At the Solar Circle, at least 12% of all open clusters appear to be experiencing some type of interaction with another cluster; i.e., are possible binaries. As in the Magellanic Clouds, the pair separation histogram hints of a bimodal distribution. Nearly 40% of identified pairs are probably primordial. Most of the remaining pairs could be undergoing some type of close encounter, perhaps as a result of orbital resonances. Confirming early theoretical predictions, the characteristic time scale for destruction of bound pairs in the disk is 200 Myr or one galactic orbit. Our results show that the fraction of possible binary clusters in the Galactic disk is comparable to that in the Magellanic Clouds.
astro-ph.GA:We further develop the model of molecular cloud fragmentation introduced in Field, Blackman and Keto (2007; FBK). We show that external pressure acting on fragments establishes a scale-dependent critical mass. Fragments with masses less than the critical value are confined largely by pressure, while those with masses greater than or equal to the critical value collapse under self gravitation. Both types of fragments are commonly observed. Without specifying the source of the external pressure, and without assuming any other scaling relations, we predict the power - law index in the relation between the rms velocity of supersonic motions and the size of fragments . We then investigate the possibility that the external pressure is due to the kinetic energy of H atoms released by photodissociation of hydrogen molecules in the fragment. This can account approximately for the observed values of external pressure and two additional observations: the value of the scaling coefficient in the power law mentioned above, and the observation of outflowing atomic hydrogen around molecular clouds. A further prediction is HI at fragment edges with column densities of order 1E20 per sq. cm and velocities of a few km/s that should be detectable with high resolution 21 cm observations. Finally, we predict the magnitude of the coefficient of dissipation in the observed supersonic flows.
astro-ph.GA:We report high sensitivity sub-arcsecond angular resolution observations of the massive star forming region DR21(OH) at 3.6, 1.3, and 0.7 cm obtained with the Very Large Array. In addition, we conducted observations of CH3OH 44 GHz masers. We detected more than 30 new maser components in the DR21(OH) region. Most of the masers appear to trace a sequence of bow-shocks in a bipolar outflow. The cm continuum observations reveal a cluster of radio sources; the strongest emission is found toward the molecular core MM1. The radio sources in MM1 are located about 5" north of the symmetry center of the CH3OH outflow, and therefore, they are unlikely to be associated with the outflow. Instead, the driving source of the outflow is likely located in the MM2 core. Although based on circumstantial evidence, the radio continuum from MM1 appears to trace free-free emission from shock-ionized gas in a jet. The orientation of the putative jet in MM1 is approximately parallel to the CH3OH outflow and almost perpendicular to the large scale molecular filament that connects DR21 and DR21(OH). This suggests that the (accretion) disks associated with the outflows/jets in the DR21 - DR21(OH) region have symmetry axes mostly perpendicular to the filament.
astro-ph.GA:We for the first time propose a physical model of the precursor (PR) and interpulse (IP) components of the radio pulsar profiles. It is based on propagation effects in the secondary plasma flow of a pulsar. The components are suggested to result from the induced scattering of the main pulse (MP) into background. The induced scattering appears efficient enough to transfer a significant part of the MP energy to the background radiation. In the regimes of superstrong and moderately strong magnetic field, the scattered components are approximately parallel and antiparallel to the velocity of the scattering particles and can be identified with the PR and IP, respectively. The spectral evolution, polarization properties, and fluctuation behaviour of the scattered components are examined and compared with the observational results. The perspectives of the complex profile studies are outlined as well.
astro-ph.GA:We demonstrate a significant difference in the angular momentum transport properties of galactic disks between regions in which the interstellar medium is single phase or two phase. Our study is motivated by observations of HI in extended galactic disks which indicate velocity dispersions of nonthermal origin, suggesting that turbulence in the gas may be contributing significantly to the observed dispersion. To address this, we have implemented a shearing-box framework within the FLASH code. The new code was used to perform local simulations of galactic disks that incorporate differential rotation, self-gravity, vertical stratification, hydrodynamics and cooling. These simulations explore plausible mechanisms for driving turbulent motions via the thermal and self-gravitational instabilities coupling to differential rotation. Where a two-phase medium develops, gravitational angular momentum transporting stresses are much greater, creating a possible mechanism for transferring energy from galactic rotation to turbulence. In simulations where the disk conditions do not trigger the formation of a two-phase medium, it is found that perturbations to the flow damp without leading to a sustained mechanism for driving turbulence. The differing angular momentum transport properties of the single- and two-phase regimes of the disk suggest that a significant, dynamically motivated division can be drawn between the two, even when this division occurs far outside the star formation cutoff in a galactic disk.
astro-ph.GA:We report on the presence of 6.7-GHz methanol masers, known tracers of high-mass star formation, in the 3-kpc arms of the inner Galaxy. We present 49 detections from the Methanol Multibeam Survey, the largest Galactic plane survey for 6.7-GHz methanol masers, which coincide in longitude, latitude and velocity with the recently discovered far-side 3-kpc arm and the well known near-side 3-kpc arm. The presence of these masers is significant evidence for high-mass star formation actively occurring in both 3-kpc arms.
astro-ph.GA:Recent VLBI (Very Long Baseline Interferometer) observations determined the distances and proper motions of star-forming regions in spiral arms directly. They showed that star-forming regions and young stars have large peculiar motions, as large as 30 km/s with complex structures. Such a large peculiar motion is incompatible with the prediction of the standard theory of quasi-stationary spiral arms. We use a high-resolution, self-consistent N-body+hydrodynamical simulation to explore how the spiral arms are formed and maintained, and how star-forming regions move. We found that arms are not quasi-stationary but transient and recurrent, as suggested in alternative theories of spiral structures. Because of this transient nature of the spiral arms, star-forming regions exhibit a trend of large and complex non-circular motions, which is qualitatively consistent with the VLBI observations. Owing to this large non-circular motion, a kinematically estimated gas map of our Galaxy has a large systematic errors of ~2-3 kpc in the distance from the Sun.
astro-ph.GA:The correlation between stellar metallicity and the presence of giant planets is well established. It has been tentatively explained by the possible increase of planet formation probability in stellar disks with enhanced amount of metals. However, there are two caveats to this explanation. First, giant stars with planets do not show a metallicity distribution skewed towards metal-rich objects, as found for dwarfs. Second, the correlation with metallicity is not valid at intermediate metallicities, for which it can be shown that giant planets are preferentially found orbiting thick disk stars.   None of these two peculiarities is explained by the proposed scenarios of giant planet formation. We contend that they are galactic in nature, and probably not linked to the formation process of giant planets. It is suggested that the same dynamical effect, namely the migration of stars in the galactic disk, is at the origin of both features, with the important consequence that most metal-rich stars hosting giant planets originate from the inner disk, a property that has been largely neglected until now. We illustrate that a planet-metallicity correlation similar to the observed one is easily obtained if stars from the inner disk have a higher percentage of giant planets than stars born at the solar radius, with no specific dependence on metallicity. We propose that the density of molecular hydrogen in the inner galactic disk (the molecular ring) could play a role in setting the high percentage of giant planets that originate from this region.
astro-ph.GA:We explore the gravitational influence of pressure supported stellar systems on the internal density distribution of a gaseous environment. We conclude that compact massive star clusters with masses >= 10^6 M_sun act as cloud condensation nuclei and are able to accrete gas recurrently from a warm interstellar medium which may cause further star formation events and account for multiple stellar populations in the most massive globular and nuclear star clusters. The same analytical arguments can be used to decide whether an arbitrary spherical stellar system is able to keep warm or hot interstellar material or not. These mass thresholds coincide with transition masses between pressure supported galaxies of different morphological types.
